//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-25769353
// Cuda compilation tools, release 10.1, V10.1.105
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_60
.address_size 64

	// .globl	_Z13adjust_levelsv
.visible .global .align 1 .b8 readback_buffer[1];
.visible .global .align 1 .b8 output_buffer[1];
.visible .global .align 8 .b8 launch_index[8];
.visible .global .align 8 .b8 launch_dim[8];
.visible .global .align 4 .b8 levels_low_range[12] = {111, 18, 131, 58, 111, 18, 131, 58, 111, 18, 131, 58};
.visible .global .align 4 .b8 levels_high_range[12] = {119, 190, 127, 63, 119, 190, 127, 63, 119, 190, 127, 63};
.visible .global .align 4 .f32 tonemap_exposure = 0f3F800000;
.visible .global .align 4 .f32 tonemap_igamma = 0f3F800000;
.visible .global .texref tone_curve_gray;
.visible .global .texref tone_curve_r;
.visible .global .texref tone_curve_g;
.visible .global .texref tone_curve_b;
.visible .global .texref frame_mask;
.visible .global .align 4 .b8 _ZN21rti_internal_typeinfo12launch_indexE[8] = {82, 97, 121, 0, 8, 0, 0, 0};
.visible .global .align 4 .b8 _ZN21rti_internal_typeinfo10launch_dimE[8] = {82, 97, 121, 0, 8, 0, 0, 0};
.visible .global .align 4 .b8 _ZN21rti_internal_typeinfo16levels_low_rangeE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.visible .global .align 4 .b8 _ZN21rti_internal_typeinfo17levels_high_rangeE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.visible .global .align 4 .b8 _ZN21rti_internal_typeinfo16tonemap_exposureE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.visible .global .align 4 .b8 _ZN21rti_internal_typeinfo14tonemap_igammaE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.visible .global .align 8 .u64 _ZN21rti_internal_register20reg_bitness_detectorE;
.visible .global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail0E;
.visible .global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail1E;
.visible .global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail2E;
.visible .global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail3E;
.visible .global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail4E;
.visible .global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail5E;
.visible .global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail6E;
.visible .global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail7E;
.visible .global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail8E;
.visible .global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail9E;
.visible .global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail0E;
.visible .global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail1E;
.visible .global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail2E;
.visible .global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail3E;
.visible .global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail4E;
.visible .global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail5E;
.visible .global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail6E;
.visible .global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail7E;
.visible .global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail8E;
.visible .global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail9E;
.visible .global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_xE;
.visible .global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_yE;
.visible .global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_zE;
.visible .global .align 1 .b8 _ZN21rti_internal_typename12launch_indexE[6] = {117, 105, 110, 116, 50, 0};
.visible .global .align 1 .b8 _ZN21rti_internal_typename10launch_dimE[6] = {117, 105, 110, 116, 50, 0};
.visible .global .align 1 .b8 _ZN21rti_internal_typename16levels_low_rangeE[7] = {102, 108, 111, 97, 116, 51, 0};
.visible .global .align 1 .b8 _ZN21rti_internal_typename17levels_high_rangeE[7] = {102, 108, 111, 97, 116, 51, 0};
.visible .global .align 1 .b8 _ZN21rti_internal_typename16tonemap_exposureE[6] = {102, 108, 111, 97, 116, 0};
.visible .global .align 1 .b8 _ZN21rti_internal_typename14tonemap_igammaE[6] = {102, 108, 111, 97, 116, 0};
.visible .global .align 4 .u32 _ZN21rti_internal_typeenum12launch_indexE = 4919;
.visible .global .align 4 .u32 _ZN21rti_internal_typeenum10launch_dimE = 4919;
.visible .global .align 4 .u32 _ZN21rti_internal_typeenum16levels_low_rangeE = 4919;
.visible .global .align 4 .u32 _ZN21rti_internal_typeenum17levels_high_rangeE = 4919;
.visible .global .align 4 .u32 _ZN21rti_internal_typeenum16tonemap_exposureE = 4919;
.visible .global .align 4 .u32 _ZN21rti_internal_typeenum14tonemap_igammaE = 4919;
.visible .global .align 1 .b8 _ZN21rti_internal_semantic12launch_indexE[14] = {114, 116, 76, 97, 117, 110, 99, 104, 73, 110, 100, 101, 120, 0};
.visible .global .align 1 .b8 _ZN21rti_internal_semantic10launch_dimE[12] = {114, 116, 76, 97, 117, 110, 99, 104, 68, 105, 109, 0};
.visible .global .align 1 .b8 _ZN21rti_internal_semantic16levels_low_rangeE[1];
.visible .global .align 1 .b8 _ZN21rti_internal_semantic17levels_high_rangeE[1];
.visible .global .align 1 .b8 _ZN21rti_internal_semantic16tonemap_exposureE[1];
.visible .global .align 1 .b8 _ZN21rti_internal_semantic14tonemap_igammaE[1];
.visible .global .align 1 .b8 _ZN23rti_internal_annotation12launch_indexE[1];
.visible .global .align 1 .b8 _ZN23rti_internal_annotation10launch_dimE[1];
.visible .global .align 1 .b8 _ZN23rti_internal_annotation16levels_low_rangeE[1];
.visible .global .align 1 .b8 _ZN23rti_internal_annotation17levels_high_rangeE[1];
.visible .global .align 1 .b8 _ZN23rti_internal_annotation16tonemap_exposureE[1];
.visible .global .align 1 .b8 _ZN23rti_internal_annotation14tonemap_igammaE[1];

.visible .entry _Z13adjust_levelsv(

)
{
	.reg .f32 	%f<24>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<14>;


	ld.global.v2.u32 	{%r5, %r6}, [launch_index];
	cvt.u64.u32	%rd3, %r5;
	cvt.u64.u32	%rd4, %r6;
	mov.u64 	%rd13, output_buffer;
	cvta.global.u64 	%rd2, %rd13;
	mov.u32 	%r3, 2;
	mov.u32 	%r4, 16;
	mov.u64 	%rd12, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r3, %r4, %rd3, %rd4, %rd12, %rd12);
	// inline asm
	ld.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd1];
	ld.global.f32 	%f8, [levels_low_range];
	sub.ftz.f32 	%f9, %f1, %f8;
	ld.global.f32 	%f10, [levels_low_range+4];
	sub.ftz.f32 	%f11, %f2, %f10;
	ld.global.f32 	%f12, [levels_low_range+8];
	sub.ftz.f32 	%f13, %f3, %f12;
	ld.global.f32 	%f14, [levels_high_range];
	sub.ftz.f32 	%f15, %f14, %f8;
	ld.global.f32 	%f16, [levels_high_range+4];
	sub.ftz.f32 	%f17, %f16, %f10;
	ld.global.f32 	%f18, [levels_high_range+8];
	sub.ftz.f32 	%f19, %f18, %f12;
	ld.global.v2.u32 	{%r9, %r10}, [launch_index];
	cvt.u64.u32	%rd9, %r9;
	cvt.u64.u32	%rd10, %r10;
	// inline asm
	call (%rd7), _rt_buffer_get_64, (%rd2, %r3, %r4, %rd9, %rd10, %rd12, %rd12);
	// inline asm
	div.approx.ftz.f32 	%f20, %f13, %f19;
	div.approx.ftz.f32 	%f21, %f11, %f17;
	div.approx.ftz.f32 	%f22, %f9, %f15;
	st.v4.f32 	[%rd7], {%f22, %f21, %f20, %f4};
	ret;
}

	// .globl	_Z12tone_mappingv
.visible .entry _Z12tone_mappingv(

)
{
	.reg .f32 	%f<23>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<14>;


	ld.global.v2.u32 	{%r5, %r6}, [launch_index];
	cvt.u64.u32	%rd3, %r5;
	cvt.u64.u32	%rd4, %r6;
	mov.u64 	%rd13, output_buffer;
	cvta.global.u64 	%rd2, %rd13;
	mov.u32 	%r3, 2;
	mov.u32 	%r4, 16;
	mov.u64 	%rd12, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r3, %r4, %rd3, %rd4, %rd12, %rd12);
	// inline asm
	ld.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd1];
	ld.global.f32 	%f8, [tonemap_exposure];
	mul.ftz.f32 	%f9, %f8, %f1;
	mul.ftz.f32 	%f10, %f8, %f2;
	mul.ftz.f32 	%f11, %f8, %f3;
	ld.global.f32 	%f12, [tonemap_igamma];
	lg2.approx.ftz.f32 	%f13, %f9;
	mul.ftz.f32 	%f14, %f12, %f13;
	lg2.approx.ftz.f32 	%f15, %f10;
	mul.ftz.f32 	%f16, %f12, %f15;
	lg2.approx.ftz.f32 	%f17, %f11;
	mul.ftz.f32 	%f18, %f12, %f17;
	ld.global.v2.u32 	{%r9, %r10}, [launch_index];
	cvt.u64.u32	%rd9, %r9;
	cvt.u64.u32	%rd10, %r10;
	// inline asm
	call (%rd7), _rt_buffer_get_64, (%rd2, %r3, %r4, %rd9, %rd10, %rd12, %rd12);
	// inline asm
	ex2.approx.ftz.f32 	%f20, %f18;
	ex2.approx.ftz.f32 	%f21, %f16;
	ex2.approx.ftz.f32 	%f22, %f14;
	st.v4.f32 	[%rd7], {%f22, %f21, %f20, %f4};
	ret;
}

	// .globl	_Z23tone_curve_gray_mappingv
.visible .entry _Z23tone_curve_gray_mappingv(

)
{
	.reg .f32 	%f<25>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<15>;


	ld.global.v2.u32 	{%r5, %r6}, [launch_index];
	cvt.u64.u32	%rd3, %r5;
	cvt.u64.u32	%rd4, %r6;
	mov.u64 	%rd13, output_buffer;
	cvta.global.u64 	%rd2, %rd13;
	mov.u32 	%r3, 2;
	mov.u32 	%r4, 16;
	mov.u64 	%rd12, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r3, %r4, %rd3, %rd4, %rd12, %rd12);
	// inline asm
	ld.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd1];
	ld.global.f32 	%f8, [tonemap_exposure];
	mul.ftz.f32 	%f9, %f8, %f1;
	mul.ftz.f32 	%f10, %f8, %f2;
	mul.ftz.f32 	%f11, %f8, %f3;
	tex.1d.v4.f32.f32	{%f12, %f13, %f14, %f15}, [tone_curve_gray, {%f9}];
	tex.1d.v4.f32.f32	{%f16, %f17, %f18, %f19}, [tone_curve_gray, {%f10}];
	tex.1d.v4.f32.f32	{%f20, %f21, %f22, %f23}, [tone_curve_gray, {%f11}];
	ld.global.v2.u32 	{%r9, %r10}, [launch_index];
	cvt.u64.u32	%rd9, %r9;
	cvt.u64.u32	%rd10, %r10;
	// inline asm
	call (%rd7), _rt_buffer_get_64, (%rd2, %r3, %r4, %rd9, %rd10, %rd12, %rd12);
	// inline asm
	st.v4.f32 	[%rd7], {%f12, %f16, %f20, %f4};
	ret;
}

	// .globl	_Z22tone_curve_rgb_mappingv
.visible .entry _Z22tone_curve_rgb_mappingv(

)
{
	.reg .f32 	%f<25>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<17>;


	ld.global.v2.u32 	{%r5, %r6}, [launch_index];
	cvt.u64.u32	%rd3, %r5;
	cvt.u64.u32	%rd4, %r6;
	mov.u64 	%rd13, output_buffer;
	cvta.global.u64 	%rd2, %rd13;
	mov.u32 	%r3, 2;
	mov.u32 	%r4, 16;
	mov.u64 	%rd12, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r3, %r4, %rd3, %rd4, %rd12, %rd12);
	// inline asm
	ld.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd1];
	ld.global.f32 	%f8, [tonemap_exposure];
	mul.ftz.f32 	%f9, %f8, %f1;
	mul.ftz.f32 	%f10, %f8, %f2;
	mul.ftz.f32 	%f11, %f8, %f3;
	tex.1d.v4.f32.f32	{%f12, %f13, %f14, %f15}, [tone_curve_r, {%f9}];
	tex.1d.v4.f32.f32	{%f16, %f17, %f18, %f19}, [tone_curve_g, {%f10}];
	tex.1d.v4.f32.f32	{%f20, %f21, %f22, %f23}, [tone_curve_b, {%f11}];
	ld.global.v2.u32 	{%r9, %r10}, [launch_index];
	cvt.u64.u32	%rd9, %r9;
	cvt.u64.u32	%rd10, %r10;
	// inline asm
	call (%rd7), _rt_buffer_get_64, (%rd2, %r3, %r4, %rd9, %rd10, %rd12, %rd12);
	// inline asm
	st.v4.f32 	[%rd7], {%f12, %f16, %f20, %f4};
	ret;
}

	// .globl	_Z16apply_frame_maskv
.visible .entry _Z16apply_frame_maskv(

)
{
	.reg .f32 	%f<22>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<15>;


	ld.global.v2.u32 	{%r5, %r6}, [launch_index];
	cvt.rn.f32.u32	%f1, %r5;
	cvt.rn.f32.u32	%f2, %r6;
	ld.global.v2.u32 	{%r9, %r10}, [launch_dim];
	cvt.rn.f32.u32	%f3, %r9;
	cvt.rn.f32.u32	%f4, %r10;
	div.approx.ftz.f32 	%f5, %f1, %f3;
	div.approx.ftz.f32 	%f6, %f2, %f4;
	cvt.u64.u32	%rd3, %r5;
	cvt.u64.u32	%rd4, %r6;
	mov.u64 	%rd13, output_buffer;
	cvta.global.u64 	%rd2, %rd13;
	mov.u32 	%r3, 2;
	mov.u32 	%r4, 16;
	mov.u64 	%rd12, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r3, %r4, %rd3, %rd4, %rd12, %rd12);
	// inline asm
	tex.2d.v4.f32.f32	{%f7, %f8, %f9, %f10}, [frame_mask, {%f5, %f6}];
	ld.v4.f32 	{%f11, %f12, %f13, %f14}, [%rd1];
	ld.global.v2.u32 	{%r13, %r14}, [launch_index];
	cvt.u64.u32	%rd9, %r13;
	cvt.u64.u32	%rd10, %r14;
	// inline asm
	call (%rd7), _rt_buffer_get_64, (%rd2, %r3, %r4, %rd9, %rd10, %rd12, %rd12);
	// inline asm
	mul.ftz.f32 	%f18, %f7, %f13;
	mul.ftz.f32 	%f19, %f7, %f12;
	mul.ftz.f32 	%f20, %f7, %f11;
	st.v4.f32 	[%rd7], {%f20, %f19, %f18, %f14};
	ret;
}

	// .globl	_Z19write_readback_bgrav
.visible .entry _Z19write_readback_bgrav(

)
{
	.reg .b16 	%rs<5>;
	.reg .f32 	%f<14>;
	.reg .b32 	%r<19>;
	.reg .b64 	%rd<15>;


	ld.global.v2.u32 	{%r5, %r6}, [launch_index];
	cvt.u64.u32	%rd3, %r5;
	cvt.u64.u32	%rd4, %r6;
	mov.u64 	%rd13, output_buffer;
	cvta.global.u64 	%rd2, %rd13;
	mov.u32 	%r3, 2;
	mov.u32 	%r2, 16;
	mov.u64 	%rd12, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r3, %r2, %rd3, %rd4, %rd12, %rd12);
	// inline asm
	ld.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd1];
	ld.global.v2.u32 	{%r9, %r10}, [launch_index];
	ld.global.u32 	%r13, [launch_dim+4];
	add.s32 	%r14, %r13, -1;
	sub.s32 	%r15, %r14, %r10;
	cvt.u64.u32	%rd9, %r9;
	cvt.u64.u32	%rd10, %r15;
	mov.u64 	%rd14, readback_buffer;
	cvta.global.u64 	%rd8, %rd14;
	mov.u32 	%r4, 4;
	// inline asm
	call (%rd7), _rt_buffer_get_64, (%rd8, %r3, %r4, %rd9, %rd10, %rd12, %rd12);
	// inline asm
	cvt.ftz.sat.f32.f32	%f8, %f3;
	mul.ftz.f32 	%f9, %f8, 0f437FFD71;
	cvt.rzi.ftz.u32.f32	%r16, %f9;
	cvt.ftz.sat.f32.f32	%f10, %f2;
	mul.ftz.f32 	%f11, %f10, 0f437FFD71;
	cvt.rzi.ftz.u32.f32	%r17, %f11;
	cvt.ftz.sat.f32.f32	%f12, %f1;
	mul.ftz.f32 	%f13, %f12, 0f437FFD71;
	cvt.rzi.ftz.u32.f32	%r18, %f13;
	cvt.u16.u32	%rs1, %r18;
	cvt.u16.u32	%rs2, %r17;
	cvt.u16.u32	%rs3, %r16;
	mov.u16 	%rs4, 255;
	st.v4.u8 	[%rd7], {%rs3, %rs2, %rs1, %rs4};
	ret;
}

	// .globl	_Z19write_readback_rgbav
.visible .entry _Z19write_readback_rgbav(

)
{
	.reg .b16 	%rs<5>;
	.reg .f32 	%f<14>;
	.reg .b32 	%r<19>;
	.reg .b64 	%rd<15>;


	ld.global.v2.u32 	{%r5, %r6}, [launch_index];
	cvt.u64.u32	%rd3, %r5;
	cvt.u64.u32	%rd4, %r6;
	mov.u64 	%rd13, output_buffer;
	cvta.global.u64 	%rd2, %rd13;
	mov.u32 	%r3, 2;
	mov.u32 	%r2, 16;
	mov.u64 	%rd12, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r3, %r2, %rd3, %rd4, %rd12, %rd12);
	// inline asm
	ld.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd1];
	ld.global.v2.u32 	{%r9, %r10}, [launch_index];
	ld.global.u32 	%r13, [launch_dim+4];
	add.s32 	%r14, %r13, -1;
	sub.s32 	%r15, %r14, %r10;
	cvt.u64.u32	%rd9, %r9;
	cvt.u64.u32	%rd10, %r15;
	mov.u64 	%rd14, readback_buffer;
	cvta.global.u64 	%rd8, %rd14;
	mov.u32 	%r4, 4;
	// inline asm
	call (%rd7), _rt_buffer_get_64, (%rd8, %r3, %r4, %rd9, %rd10, %rd12, %rd12);
	// inline asm
	cvt.ftz.sat.f32.f32	%f8, %f1;
	mul.ftz.f32 	%f9, %f8, 0f437FFD71;
	cvt.rzi.ftz.u32.f32	%r16, %f9;
	cvt.ftz.sat.f32.f32	%f10, %f2;
	mul.ftz.f32 	%f11, %f10, 0f437FFD71;
	cvt.rzi.ftz.u32.f32	%r17, %f11;
	cvt.ftz.sat.f32.f32	%f12, %f3;
	mul.ftz.f32 	%f13, %f12, 0f437FFD71;
	cvt.rzi.ftz.u32.f32	%r18, %f13;
	cvt.u16.u32	%rs1, %r18;
	cvt.u16.u32	%rs2, %r17;
	cvt.u16.u32	%rs3, %r16;
	mov.u16 	%rs4, 255;
	st.v4.u8 	[%rd7], {%rs3, %rs2, %rs1, %rs4};
	ret;
}


 