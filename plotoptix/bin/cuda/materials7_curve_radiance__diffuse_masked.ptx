//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30033411
// Cuda compilation tools, release 11.4, V11.4.48
// Based on NVVM 7.0.1
//

.version 7.4
.target sm_50
.address_size 64

	// .globl	__closesthit__curve_radiance__diffuse_masked
.const .align 8 .b8 params[288];

.visible .entry __closesthit__curve_radiance__diffuse_masked()
{
	.reg .pred 	%p<111>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<3674>;
	.reg .b32 	%r<1168>;
	.reg .b64 	%rd<794>;


	// begin inline asm
	call (%rd50), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	// begin inline asm
	call (%r73), _optix_read_primitive_idx, ();
	// end inline asm
	mov.u32 	%r74, 3;
	// begin inline asm
	call _optix_set_payload, (%r74, %r73);
	// end inline asm
	// begin inline asm
	call (%f1242), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f1243), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f1244), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%f1245), _optix_get_ray_tmax, ();
	// end inline asm
	// begin inline asm
	call (%f1246), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f1247), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f1248), _optix_get_world_ray_direction_z, ();
	// end inline asm
	fma.rn.ftz.f32 	%f1, %f1245, %f1246, %f1242;
	fma.rn.ftz.f32 	%f2, %f1245, %f1247, %f1243;
	fma.rn.ftz.f32 	%f3, %f1245, %f1248, %f1244;
	// begin inline asm
	call (%r76), _optix_get_hit_kind, ();
	// end inline asm
	// begin inline asm
	call (%r77), _optix_get_primitive_type_from_hit_kind, (%r76);
	// end inline asm
	setp.eq.s32 	%p1, %r77, 9473;
	@%p1 bra 	$L__BB0_97;

	setp.eq.s32 	%p2, %r77, 9474;
	@%p2 bra 	$L__BB0_50;

	setp.ne.s32 	%p3, %r77, 9475;
	@%p3 bra 	$L__BB0_144;

	// begin inline asm
	call (%rd51), _optix_get_gas_traversable_handle, ();
	// end inline asm
	// begin inline asm
	call (%r80), _optix_read_sbt_gas_idx, ();
	// end inline asm
	mov.f32 	%f1258, 0f00000000;
	// begin inline asm
	call (%f1250, %f1251, %f1252, %f1253,  %f1254, %f1255, %f1256, %f1257), _optix_get_linear_curve_vertex_data, (%rd51, %r73, %r80, %f1258);
	// end inline asm
	sub.ftz.f32 	%f13, %f1254, %f1250;
	sub.ftz.f32 	%f15, %f1255, %f1251;
	sub.ftz.f32 	%f17, %f1256, %f1252;
	// begin inline asm
	call (%r83), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p4, %r83, 0;
	@%p4 bra 	$L__BB0_23;

	// begin inline asm
	call (%r84), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1259), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p5, %r84, 0;
	@%p5 bra 	$L__BB0_22;

	mov.u32 	%r1157, 0;

$L__BB0_6:
	.pragma "nounroll";
	// begin inline asm
	call (%rd53), _optix_get_transform_list_handle, (%r1157);
	// end inline asm
	// begin inline asm
	call (%r87), _optix_get_transform_type_from_handle, (%rd53);
	// end inline asm
	or.b32  	%r88, %r87, 1;
	setp.eq.s32 	%p6, %r88, 3;
	@%p6 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_7;

$L__BB0_12:
	setp.eq.s32 	%p9, %r87, 2;
	@%p9 bra 	$L__BB0_16;
	bra.uni 	$L__BB0_13;

$L__BB0_16:
	// begin inline asm
	call (%rd125), _optix_get_matrix_motion_transform_from_handle, (%rd53);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd127, %rd125;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r176,%r177,%r178,%r179}, [%rd127];
	// end inline asm
	add.s64 	%rd131, %rd125, 16;
	// begin inline asm
	cvta.to.global.u64 %rd130, %rd131;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r180,%r181,%r182,%r183}, [%rd130];
	// end inline asm
	add.s64 	%rd134, %rd125, 32;
	// begin inline asm
	cvta.to.global.u64 %rd133, %rd134;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r184,%r185,%r186,%r187}, [%rd133];
	// end inline asm
	add.s64 	%rd137, %rd125, 48;
	// begin inline asm
	cvta.to.global.u64 %rd136, %rd137;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r188,%r189,%r190,%r191}, [%rd136];
	// end inline asm
	add.s64 	%rd140, %rd125, 64;
	// begin inline asm
	cvta.to.global.u64 %rd139, %rd140;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r192,%r193,%r194,%r195}, [%rd139];
	// end inline asm
	add.s64 	%rd143, %rd125, 80;
	// begin inline asm
	cvta.to.global.u64 %rd142, %rd143;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r196,%r197,%r198,%r199}, [%rd142];
	// end inline asm
	add.s64 	%rd146, %rd125, 96;
	// begin inline asm
	cvta.to.global.u64 %rd145, %rd146;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r200,%r201,%r202,%r203}, [%rd145];
	// end inline asm
	add.s64 	%rd149, %rd125, 112;
	// begin inline asm
	cvta.to.global.u64 %rd148, %rd149;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r204,%r205,%r206,%r207}, [%rd148];
	// end inline asm
	mov.b32 	%f1386, %r179;
	mov.b32 	%f1387, %r180;
	and.b32  	%r220, %r178, 65535;
	add.s32 	%r221, %r220, -1;
	cvt.rn.f32.s32 	%f1388, %r221;
	sub.ftz.f32 	%f1389, %f1259, %f1386;
	mul.ftz.f32 	%f1390, %f1389, %f1388;
	sub.ftz.f32 	%f1391, %f1387, %f1386;
	div.approx.ftz.f32 	%f1392, %f1390, %f1391;
	min.ftz.f32 	%f1393, %f1388, %f1392;
	mov.f32 	%f1394, 0f00000000;
	max.ftz.f32 	%f1395, %f1394, %f1393;
	cvt.rmi.ftz.f32.f32 	%f1396, %f1395;
	sub.ftz.f32 	%f104, %f1395, %f1396;
	cvt.rzi.ftz.s32.f32 	%r222, %f1396;
	cvt.s64.s32 	%rd8, %r222;
	mul.wide.s32 	%rd160, %r222, 48;
	add.s64 	%rd152, %rd134, %rd160;
	// begin inline asm
	cvta.to.global.u64 %rd151, %rd152;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r208,%r209,%r210,%r211}, [%rd151];
	// end inline asm
	mov.b32 	%f3265, %r208;
	mov.b32 	%f3264, %r209;
	mov.b32 	%f3263, %r210;
	mov.b32 	%f3262, %r211;
	add.s64 	%rd155, %rd152, 16;
	// begin inline asm
	cvta.to.global.u64 %rd154, %rd155;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r212,%r213,%r214,%r215}, [%rd154];
	// end inline asm
	mov.b32 	%f3269, %r212;
	mov.b32 	%f3268, %r213;
	mov.b32 	%f3267, %r214;
	mov.b32 	%f3266, %r215;
	add.s64 	%rd158, %rd152, 32;
	// begin inline asm
	cvta.to.global.u64 %rd157, %rd158;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r216,%r217,%r218,%r219}, [%rd157];
	// end inline asm
	mov.b32 	%f3273, %r216;
	mov.b32 	%f3272, %r217;
	mov.b32 	%f3271, %r218;
	mov.b32 	%f3270, %r219;
	setp.leu.ftz.f32 	%p11, %f104, 0f00000000;
	@%p11 bra 	$L__BB0_18;

	mov.f32 	%f1397, 0f3F800000;
	sub.ftz.f32 	%f1398, %f1397, %f104;
	mul.lo.s64 	%rd170, %rd8, 48;
	add.s64 	%rd171, %rd125, %rd170;
	add.s64 	%rd162, %rd171, 80;
	// begin inline asm
	cvta.to.global.u64 %rd161, %rd162;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r223,%r224,%r225,%r226}, [%rd161];
	// end inline asm
	mov.b32 	%f1399, %r223;
	mov.b32 	%f1400, %r224;
	mov.b32 	%f1401, %r225;
	mov.b32 	%f1402, %r226;
	mul.ftz.f32 	%f1403, %f104, %f1399;
	mul.ftz.f32 	%f1404, %f104, %f1400;
	mul.ftz.f32 	%f1405, %f104, %f1401;
	mul.ftz.f32 	%f1406, %f104, %f1402;
	fma.rn.ftz.f32 	%f3265, %f1398, %f3265, %f1403;
	fma.rn.ftz.f32 	%f3264, %f1398, %f3264, %f1404;
	fma.rn.ftz.f32 	%f3263, %f1398, %f3263, %f1405;
	fma.rn.ftz.f32 	%f3262, %f1398, %f3262, %f1406;
	add.s64 	%rd165, %rd171, 96;
	// begin inline asm
	cvta.to.global.u64 %rd164, %rd165;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r227,%r228,%r229,%r230}, [%rd164];
	// end inline asm
	mov.b32 	%f1407, %r227;
	mov.b32 	%f1408, %r228;
	mov.b32 	%f1409, %r229;
	mov.b32 	%f1410, %r230;
	mul.ftz.f32 	%f1411, %f104, %f1407;
	mul.ftz.f32 	%f1412, %f104, %f1408;
	mul.ftz.f32 	%f1413, %f104, %f1409;
	mul.ftz.f32 	%f1414, %f104, %f1410;
	fma.rn.ftz.f32 	%f3269, %f1398, %f3269, %f1411;
	fma.rn.ftz.f32 	%f3268, %f1398, %f3268, %f1412;
	fma.rn.ftz.f32 	%f3267, %f1398, %f3267, %f1413;
	fma.rn.ftz.f32 	%f3266, %f1398, %f3266, %f1414;
	add.s64 	%rd168, %rd171, 112;
	// begin inline asm
	cvta.to.global.u64 %rd167, %rd168;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r231,%r232,%r233,%r234}, [%rd167];
	// end inline asm
	mov.b32 	%f1415, %r231;
	mov.b32 	%f1416, %r232;
	mov.b32 	%f1417, %r233;
	mov.b32 	%f1418, %r234;
	mul.ftz.f32 	%f1419, %f104, %f1415;
	mul.ftz.f32 	%f1420, %f104, %f1416;
	mul.ftz.f32 	%f1421, %f104, %f1417;
	mul.ftz.f32 	%f1422, %f104, %f1418;
	fma.rn.ftz.f32 	%f3273, %f1398, %f3273, %f1419;
	fma.rn.ftz.f32 	%f3272, %f1398, %f3272, %f1420;
	fma.rn.ftz.f32 	%f3271, %f1398, %f3271, %f1421;
	fma.rn.ftz.f32 	%f3270, %f1398, %f3270, %f1422;
	bra.uni 	$L__BB0_18;

$L__BB0_7:
	mov.f32 	%f3277, 0f3F800000;
	setp.eq.s32 	%p7, %r87, 4;
	@%p7 bra 	$L__BB0_10;

	setp.ne.s32 	%p8, %r87, 1;
	mov.f32 	%f3274, %f1258;
	mov.f32 	%f3275, %f1258;
	mov.f32 	%f3276, %f1258;
	mov.f32 	%f3278, %f1258;
	mov.f32 	%f3279, %f1258;
	mov.f32 	%f3280, %f3277;
	mov.f32 	%f3281, %f1258;
	mov.f32 	%f3282, %f1258;
	mov.f32 	%f3283, %f3277;
	mov.f32 	%f3284, %f1258;
	mov.f32 	%f3285, %f1258;
	@%p8 bra 	$L__BB0_19;

	// begin inline asm
	call (%rd55), _optix_get_static_transform_from_handle, (%rd53);
	// end inline asm
	add.s64 	%rd787, %rd55, 64;
	bra.uni 	$L__BB0_11;

$L__BB0_13:
	// begin inline asm
	call (%rd68), _optix_get_srt_motion_transform_from_handle, (%rd53);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd70, %rd68;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r101,%r102,%r103,%r104}, [%rd70];
	// end inline asm
	add.s64 	%rd74, %rd68, 16;
	// begin inline asm
	cvta.to.global.u64 %rd73, %rd74;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r105,%r106,%r107,%r108}, [%rd73];
	// end inline asm
	add.s64 	%rd77, %rd68, 32;
	// begin inline asm
	cvta.to.global.u64 %rd76, %rd77;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r109,%r110,%r111,%r112}, [%rd76];
	// end inline asm
	add.s64 	%rd80, %rd68, 48;
	// begin inline asm
	cvta.to.global.u64 %rd79, %rd80;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r113,%r114,%r115,%r116}, [%rd79];
	// end inline asm
	add.s64 	%rd83, %rd68, 64;
	// begin inline asm
	cvta.to.global.u64 %rd82, %rd83;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r117,%r118,%r119,%r120}, [%rd82];
	// end inline asm
	add.s64 	%rd86, %rd68, 80;
	// begin inline asm
	cvta.to.global.u64 %rd85, %rd86;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r121,%r122,%r123,%r124}, [%rd85];
	// end inline asm
	add.s64 	%rd89, %rd68, 96;
	// begin inline asm
	cvta.to.global.u64 %rd88, %rd89;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r125,%r126,%r127,%r128}, [%rd88];
	// end inline asm
	add.s64 	%rd92, %rd68, 112;
	// begin inline asm
	cvta.to.global.u64 %rd91, %rd92;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r129,%r130,%r131,%r132}, [%rd91];
	// end inline asm
	add.s64 	%rd95, %rd68, 128;
	// begin inline asm
	cvta.to.global.u64 %rd94, %rd95;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r133,%r134,%r135,%r136}, [%rd94];
	// end inline asm
	add.s64 	%rd98, %rd68, 144;
	// begin inline asm
	cvta.to.global.u64 %rd97, %rd98;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r137,%r138,%r139,%r140}, [%rd97];
	// end inline asm
	mov.b32 	%f1274, %r104;
	mov.b32 	%f1275, %r105;
	and.b32  	%r157, %r103, 65535;
	add.s32 	%r158, %r157, -1;
	cvt.rn.f32.s32 	%f1276, %r158;
	sub.ftz.f32 	%f1277, %f1259, %f1274;
	mul.ftz.f32 	%f1278, %f1277, %f1276;
	sub.ftz.f32 	%f1279, %f1275, %f1274;
	div.approx.ftz.f32 	%f1280, %f1278, %f1279;
	min.ftz.f32 	%f1281, %f1276, %f1280;
	mov.f32 	%f1282, 0f00000000;
	max.ftz.f32 	%f1283, %f1282, %f1281;
	cvt.rmi.ftz.f32.f32 	%f1284, %f1283;
	sub.ftz.f32 	%f43, %f1283, %f1284;
	cvt.rzi.ftz.s32.f32 	%r159, %f1284;
	mul.wide.s32 	%rd112, %r159, 64;
	add.s64 	%rd101, %rd77, %rd112;
	// begin inline asm
	cvta.to.global.u64 %rd100, %rd101;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r141,%r142,%r143,%r144}, [%rd100];
	// end inline asm
	mov.b32 	%f3258, %r141;
	mov.b32 	%f3257, %r142;
	mov.b32 	%f3256, %r143;
	mov.b32 	%f3255, %r144;
	add.s64 	%rd104, %rd101, 16;
	// begin inline asm
	cvta.to.global.u64 %rd103, %rd104;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r145,%r146,%r147,%r148}, [%rd103];
	// end inline asm
	mov.b32 	%f3254, %r145;
	mov.b32 	%f3253, %r146;
	mov.b32 	%f3252, %r147;
	mov.b32 	%f3251, %r148;
	add.s64 	%rd107, %rd101, 32;
	// begin inline asm
	cvta.to.global.u64 %rd106, %rd107;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r149,%r150,%r151,%r152}, [%rd106];
	// end inline asm
	mov.b32 	%f3250, %r149;
	mov.b32 	%f3249, %r150;
	mov.b32 	%f3248, %r151;
	mov.b32 	%f3247, %r152;
	add.s64 	%rd110, %rd101, 48;
	// begin inline asm
	cvta.to.global.u64 %rd109, %rd110;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r153,%r154,%r155,%r156}, [%rd109];
	// end inline asm
	mov.b32 	%f3246, %r153;
	mov.b32 	%f3259, %r154;
	mov.b32 	%f3260, %r155;
	mov.b32 	%f3261, %r156;
	setp.leu.ftz.f32 	%p10, %f43, 0f00000000;
	@%p10 bra 	$L__BB0_15;

	mov.f32 	%f1285, 0f3F800000;
	sub.ftz.f32 	%f1286, %f1285, %f43;
	add.s64 	%rd114, %rd101, 64;
	// begin inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r160,%r161,%r162,%r163}, [%rd113];
	// end inline asm
	mov.b32 	%f1287, %r160;
	mov.b32 	%f1288, %r161;
	mov.b32 	%f1289, %r162;
	mov.b32 	%f1290, %r163;
	mul.ftz.f32 	%f1291, %f43, %f1287;
	mul.ftz.f32 	%f1292, %f43, %f1288;
	mul.ftz.f32 	%f1293, %f43, %f1289;
	mul.ftz.f32 	%f1294, %f43, %f1290;
	fma.rn.ftz.f32 	%f3258, %f1286, %f3258, %f1291;
	fma.rn.ftz.f32 	%f3257, %f1286, %f3257, %f1292;
	fma.rn.ftz.f32 	%f3256, %f1286, %f3256, %f1293;
	fma.rn.ftz.f32 	%f3255, %f1286, %f3255, %f1294;
	add.s64 	%rd117, %rd101, 80;
	// begin inline asm
	cvta.to.global.u64 %rd116, %rd117;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r164,%r165,%r166,%r167}, [%rd116];
	// end inline asm
	mov.b32 	%f1295, %r164;
	mov.b32 	%f1296, %r165;
	mov.b32 	%f1297, %r166;
	mov.b32 	%f1298, %r167;
	mul.ftz.f32 	%f1299, %f43, %f1295;
	mul.ftz.f32 	%f1300, %f43, %f1296;
	mul.ftz.f32 	%f1301, %f43, %f1297;
	mul.ftz.f32 	%f1302, %f43, %f1298;
	fma.rn.ftz.f32 	%f3254, %f1286, %f3254, %f1299;
	fma.rn.ftz.f32 	%f3253, %f1286, %f3253, %f1300;
	fma.rn.ftz.f32 	%f3252, %f1286, %f3252, %f1301;
	fma.rn.ftz.f32 	%f3251, %f1286, %f3251, %f1302;
	add.s64 	%rd120, %rd101, 96;
	// begin inline asm
	cvta.to.global.u64 %rd119, %rd120;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r168,%r169,%r170,%r171}, [%rd119];
	// end inline asm
	mov.b32 	%f1303, %r168;
	mov.b32 	%f1304, %r169;
	mov.b32 	%f1305, %r170;
	mov.b32 	%f1306, %r171;
	mul.ftz.f32 	%f1307, %f43, %f1303;
	mul.ftz.f32 	%f1308, %f43, %f1304;
	mul.ftz.f32 	%f1309, %f43, %f1305;
	mul.ftz.f32 	%f1310, %f43, %f1306;
	fma.rn.ftz.f32 	%f3250, %f1286, %f3250, %f1307;
	fma.rn.ftz.f32 	%f1311, %f1286, %f3249, %f1308;
	fma.rn.ftz.f32 	%f1312, %f1286, %f3248, %f1309;
	fma.rn.ftz.f32 	%f1313, %f1286, %f3247, %f1310;
	add.s64 	%rd123, %rd101, 112;
	// begin inline asm
	cvta.to.global.u64 %rd122, %rd123;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r172,%r173,%r174,%r175}, [%rd122];
	// end inline asm
	mov.b32 	%f1314, %r172;
	mov.b32 	%f1315, %r173;
	mov.b32 	%f1316, %r174;
	mov.b32 	%f1317, %r175;
	mul.ftz.f32 	%f1318, %f43, %f1314;
	mul.ftz.f32 	%f1319, %f43, %f1315;
	mul.ftz.f32 	%f1320, %f43, %f1316;
	mul.ftz.f32 	%f1321, %f43, %f1317;
	fma.rn.ftz.f32 	%f1322, %f1286, %f3246, %f1318;
	fma.rn.ftz.f32 	%f3259, %f1286, %f3259, %f1319;
	fma.rn.ftz.f32 	%f3260, %f1286, %f3260, %f1320;
	fma.rn.ftz.f32 	%f3261, %f1286, %f3261, %f1321;
	mul.ftz.f32 	%f1323, %f1312, %f1312;
	fma.rn.ftz.f32 	%f1324, %f1311, %f1311, %f1323;
	fma.rn.ftz.f32 	%f1325, %f1313, %f1313, %f1324;
	fma.rn.ftz.f32 	%f1326, %f1322, %f1322, %f1325;
	rsqrt.approx.ftz.f32 	%f1327, %f1326;
	mul.ftz.f32 	%f3249, %f1311, %f1327;
	mul.ftz.f32 	%f3248, %f1312, %f1327;
	mul.ftz.f32 	%f3247, %f1313, %f1327;
	mul.ftz.f32 	%f3246, %f1327, %f1322;

$L__BB0_15:
	mul.ftz.f32 	%f1328, %f3249, %f3249;
	fma.rn.ftz.f32 	%f1329, %f3248, %f3248, %f1328;
	fma.rn.ftz.f32 	%f1330, %f3247, %f3247, %f1329;
	fma.rn.ftz.f32 	%f1331, %f3246, %f3246, %f1330;
	rcp.approx.ftz.f32 	%f1332, %f1331;
	mul.ftz.f32 	%f1333, %f3249, %f1332;
	mul.ftz.f32 	%f1334, %f3248, %f1332;
	mul.ftz.f32 	%f1335, %f3247, %f1332;
	mul.ftz.f32 	%f1336, %f3246, %f1332;
	mul.ftz.f32 	%f1337, %f3249, %f1333;
	mul.ftz.f32 	%f1338, %f3248, %f1334;
	mul.ftz.f32 	%f1339, %f3247, %f1335;
	mul.ftz.f32 	%f1340, %f3249, %f1334;
	mul.ftz.f32 	%f1341, %f3247, %f1336;
	mul.ftz.f32 	%f1342, %f3249, %f1335;
	mul.ftz.f32 	%f1343, %f3248, %f1336;
	mul.ftz.f32 	%f1344, %f3248, %f1335;
	mul.ftz.f32 	%f1345, %f3249, %f1336;
	sub.ftz.f32 	%f1346, %f1337, %f1338;
	sub.ftz.f32 	%f1347, %f1346, %f1339;
	fma.rn.ftz.f32 	%f1348, %f3246, %f1336, %f1347;
	sub.ftz.f32 	%f1349, %f1340, %f1341;
	add.ftz.f32 	%f1350, %f1349, %f1349;
	add.ftz.f32 	%f1351, %f1342, %f1343;
	add.ftz.f32 	%f1352, %f1351, %f1351;
	add.ftz.f32 	%f1353, %f1340, %f1341;
	add.ftz.f32 	%f1354, %f1353, %f1353;
	sub.ftz.f32 	%f1355, %f1338, %f1337;
	sub.ftz.f32 	%f1356, %f1355, %f1339;
	fma.rn.ftz.f32 	%f1357, %f3246, %f1336, %f1356;
	sub.ftz.f32 	%f1358, %f1344, %f1345;
	add.ftz.f32 	%f1359, %f1358, %f1358;
	sub.ftz.f32 	%f1360, %f1342, %f1343;
	add.ftz.f32 	%f1361, %f1360, %f1360;
	add.ftz.f32 	%f1362, %f1344, %f1345;
	add.ftz.f32 	%f1363, %f1362, %f1362;
	neg.ftz.f32 	%f1364, %f1337;
	sub.ftz.f32 	%f1365, %f1364, %f1338;
	add.ftz.f32 	%f1366, %f1339, %f1365;
	fma.rn.ftz.f32 	%f1367, %f3246, %f1336, %f1366;
	mul.ftz.f32 	%f1368, %f3255, %f1348;
	fma.rn.ftz.f32 	%f1369, %f3252, %f1350, %f1368;
	fma.rn.ftz.f32 	%f1370, %f3250, %f1352, %f1369;
	add.ftz.f32 	%f3262, %f3259, %f1370;
	mul.ftz.f32 	%f1371, %f3252, %f1357;
	fma.rn.ftz.f32 	%f1372, %f3255, %f1354, %f1371;
	fma.rn.ftz.f32 	%f1373, %f3250, %f1359, %f1372;
	add.ftz.f32 	%f3266, %f3260, %f1373;
	mul.ftz.f32 	%f1374, %f3252, %f1363;
	fma.rn.ftz.f32 	%f1375, %f3255, %f1361, %f1374;
	fma.rn.ftz.f32 	%f1376, %f3250, %f1367, %f1375;
	add.ftz.f32 	%f3270, %f1376, %f3261;
	mul.ftz.f32 	%f1377, %f3256, %f1348;
	fma.rn.ftz.f32 	%f1378, %f3253, %f1350, %f1377;
	fma.rn.ftz.f32 	%f3263, %f3251, %f1352, %f1378;
	mul.ftz.f32 	%f1379, %f3253, %f1357;
	fma.rn.ftz.f32 	%f1380, %f3256, %f1354, %f1379;
	fma.rn.ftz.f32 	%f3267, %f3251, %f1359, %f1380;
	mul.ftz.f32 	%f1381, %f3253, %f1363;
	fma.rn.ftz.f32 	%f1382, %f3256, %f1361, %f1381;
	fma.rn.ftz.f32 	%f3271, %f3251, %f1367, %f1382;
	mul.ftz.f32 	%f1383, %f3257, %f1348;
	fma.rn.ftz.f32 	%f3264, %f3254, %f1350, %f1383;
	mul.ftz.f32 	%f1384, %f3254, %f1357;
	fma.rn.ftz.f32 	%f3268, %f3257, %f1354, %f1384;
	mul.ftz.f32 	%f1385, %f3254, %f1363;
	fma.rn.ftz.f32 	%f3272, %f3257, %f1361, %f1385;
	mul.ftz.f32 	%f3265, %f3258, %f1348;
	mul.ftz.f32 	%f3269, %f1354, %f3258;
	mul.ftz.f32 	%f3273, %f1361, %f3258;

$L__BB0_18:
	mul.ftz.f32 	%f1423, %f3267, %f3272;
	mul.ftz.f32 	%f1424, %f3268, %f3271;
	sub.ftz.f32 	%f1425, %f1424, %f1423;
	mul.ftz.f32 	%f1426, %f3265, %f1425;
	mul.ftz.f32 	%f1427, %f3267, %f3273;
	mul.ftz.f32 	%f1428, %f3269, %f3271;
	sub.ftz.f32 	%f1429, %f1428, %f1427;
	mul.ftz.f32 	%f1430, %f3264, %f1429;
	sub.ftz.f32 	%f1431, %f1426, %f1430;
	mul.ftz.f32 	%f1432, %f3268, %f3273;
	mul.ftz.f32 	%f1433, %f3269, %f3272;
	sub.ftz.f32 	%f1434, %f1433, %f1432;
	fma.rn.ftz.f32 	%f1435, %f3263, %f1434, %f1431;
	rcp.approx.ftz.f32 	%f1436, %f1435;
	mul.ftz.f32 	%f3277, %f1425, %f1436;
	mul.ftz.f32 	%f1437, %f3264, %f3271;
	mul.ftz.f32 	%f1438, %f3263, %f3272;
	sub.ftz.f32 	%f1439, %f1438, %f1437;
	mul.ftz.f32 	%f3276, %f1439, %f1436;
	mul.ftz.f32 	%f1440, %f3263, %f3268;
	mul.ftz.f32 	%f1441, %f3264, %f3267;
	sub.ftz.f32 	%f1442, %f1441, %f1440;
	mul.ftz.f32 	%f3275, %f1442, %f1436;
	sub.ftz.f32 	%f1443, %f1427, %f1428;
	mul.ftz.f32 	%f3281, %f1443, %f1436;
	mul.ftz.f32 	%f1444, %f3263, %f3273;
	mul.ftz.f32 	%f1445, %f3265, %f3271;
	sub.ftz.f32 	%f1446, %f1445, %f1444;
	mul.ftz.f32 	%f3280, %f1446, %f1436;
	mul.ftz.f32 	%f1447, %f3265, %f3267;
	mul.ftz.f32 	%f1448, %f3263, %f3269;
	sub.ftz.f32 	%f1449, %f1448, %f1447;
	mul.ftz.f32 	%f3279, %f1449, %f1436;
	mul.ftz.f32 	%f3285, %f1434, %f1436;
	mul.ftz.f32 	%f1450, %f3265, %f3272;
	mul.ftz.f32 	%f1451, %f3264, %f3273;
	sub.ftz.f32 	%f1452, %f1451, %f1450;
	mul.ftz.f32 	%f3284, %f1452, %f1436;
	mul.ftz.f32 	%f1453, %f3264, %f3269;
	mul.ftz.f32 	%f1454, %f3265, %f3268;
	sub.ftz.f32 	%f1455, %f1454, %f1453;
	mul.ftz.f32 	%f3283, %f1455, %f1436;
	mul.ftz.f32 	%f1456, %f3262, %f3277;
	neg.ftz.f32 	%f1457, %f1456;
	mul.ftz.f32 	%f1458, %f3266, %f3276;
	sub.ftz.f32 	%f1459, %f1457, %f1458;
	mul.ftz.f32 	%f1460, %f3270, %f3275;
	sub.ftz.f32 	%f3274, %f1459, %f1460;
	mul.ftz.f32 	%f1461, %f3262, %f3281;
	neg.ftz.f32 	%f1462, %f1461;
	mul.ftz.f32 	%f1463, %f3266, %f3280;
	sub.ftz.f32 	%f1464, %f1462, %f1463;
	mul.ftz.f32 	%f1465, %f3270, %f3279;
	sub.ftz.f32 	%f3278, %f1464, %f1465;
	mul.ftz.f32 	%f1466, %f3262, %f3285;
	neg.ftz.f32 	%f1467, %f1466;
	mul.ftz.f32 	%f1468, %f3266, %f3284;
	sub.ftz.f32 	%f1469, %f1467, %f1468;
	mul.ftz.f32 	%f1470, %f3270, %f3283;
	sub.ftz.f32 	%f3282, %f1469, %f1470;
	bra.uni 	$L__BB0_19;

$L__BB0_10:
	// begin inline asm
	call (%rd787), _optix_get_instance_inverse_transform_from_handle, (%rd53);
	// end inline asm

$L__BB0_11:
	// begin inline asm
	cvta.to.global.u64 %rd59, %rd787;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r89,%r90,%r91,%r92}, [%rd59];
	// end inline asm
	mov.b32 	%f3277, %r89;
	mov.b32 	%f3276, %r90;
	mov.b32 	%f3275, %r91;
	mov.b32 	%f3274, %r92;
	add.s64 	%rd63, %rd787, 16;
	// begin inline asm
	cvta.to.global.u64 %rd62, %rd63;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r93,%r94,%r95,%r96}, [%rd62];
	// end inline asm
	mov.b32 	%f3281, %r93;
	mov.b32 	%f3280, %r94;
	mov.b32 	%f3279, %r95;
	mov.b32 	%f3278, %r96;
	add.s64 	%rd66, %rd787, 32;
	// begin inline asm
	cvta.to.global.u64 %rd65, %rd66;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r97,%r98,%r99,%r100}, [%rd65];
	// end inline asm
	mov.b32 	%f3285, %r97;
	mov.b32 	%f3284, %r98;
	mov.b32 	%f3283, %r99;
	mov.b32 	%f3282, %r100;

$L__BB0_19:
	setp.eq.s32 	%p12, %r1157, 0;
	@%p12 bra 	$L__BB0_21;

	mul.ftz.f32 	%f1471, %f3242, %f3277;
	fma.rn.ftz.f32 	%f1472, %f3238, %f3276, %f1471;
	fma.rn.ftz.f32 	%f165, %f3234, %f3275, %f1472;
	mul.ftz.f32 	%f1473, %f3243, %f3277;
	fma.rn.ftz.f32 	%f1474, %f3239, %f3276, %f1473;
	fma.rn.ftz.f32 	%f166, %f3235, %f3275, %f1474;
	mul.ftz.f32 	%f1475, %f3244, %f3277;
	fma.rn.ftz.f32 	%f1476, %f3240, %f3276, %f1475;
	fma.rn.ftz.f32 	%f167, %f3236, %f3275, %f1476;
	mul.ftz.f32 	%f1477, %f3245, %f3277;
	fma.rn.ftz.f32 	%f1478, %f3241, %f3276, %f1477;
	fma.rn.ftz.f32 	%f1479, %f3237, %f3275, %f1478;
	add.ftz.f32 	%f3274, %f3274, %f1479;
	mul.ftz.f32 	%f1480, %f3242, %f3281;
	fma.rn.ftz.f32 	%f1481, %f3238, %f3280, %f1480;
	fma.rn.ftz.f32 	%f169, %f3234, %f3279, %f1481;
	mul.ftz.f32 	%f1482, %f3243, %f3281;
	fma.rn.ftz.f32 	%f1483, %f3239, %f3280, %f1482;
	fma.rn.ftz.f32 	%f170, %f3235, %f3279, %f1483;
	mul.ftz.f32 	%f1484, %f3244, %f3281;
	fma.rn.ftz.f32 	%f1485, %f3240, %f3280, %f1484;
	fma.rn.ftz.f32 	%f171, %f3236, %f3279, %f1485;
	mul.ftz.f32 	%f1486, %f3245, %f3281;
	fma.rn.ftz.f32 	%f1487, %f3241, %f3280, %f1486;
	fma.rn.ftz.f32 	%f1488, %f3237, %f3279, %f1487;
	add.ftz.f32 	%f3278, %f3278, %f1488;
	mul.ftz.f32 	%f1489, %f3242, %f3285;
	fma.rn.ftz.f32 	%f1490, %f3238, %f3284, %f1489;
	fma.rn.ftz.f32 	%f173, %f3234, %f3283, %f1490;
	mul.ftz.f32 	%f1491, %f3243, %f3285;
	fma.rn.ftz.f32 	%f1492, %f3239, %f3284, %f1491;
	fma.rn.ftz.f32 	%f174, %f3235, %f3283, %f1492;
	mul.ftz.f32 	%f1493, %f3244, %f3285;
	fma.rn.ftz.f32 	%f1494, %f3240, %f3284, %f1493;
	fma.rn.ftz.f32 	%f175, %f3236, %f3283, %f1494;
	mul.ftz.f32 	%f1495, %f3245, %f3285;
	fma.rn.ftz.f32 	%f1496, %f3241, %f3284, %f1495;
	fma.rn.ftz.f32 	%f1497, %f3237, %f3283, %f1496;
	add.ftz.f32 	%f3282, %f3282, %f1497;
	mov.f32 	%f3275, %f167;
	mov.f32 	%f3276, %f166;
	mov.f32 	%f3277, %f165;
	mov.f32 	%f3279, %f171;
	mov.f32 	%f3280, %f170;
	mov.f32 	%f3281, %f169;
	mov.f32 	%f3283, %f175;
	mov.f32 	%f3284, %f174;
	mov.f32 	%f3285, %f173;

$L__BB0_21:
	add.s32 	%r1157, %r1157, 1;
	setp.lt.u32 	%p13, %r1157, %r84;
	mov.f32 	%f3234, %f3285;
	mov.f32 	%f3235, %f3284;
	mov.f32 	%f3236, %f3283;
	mov.f32 	%f3237, %f3282;
	mov.f32 	%f3238, %f3281;
	mov.f32 	%f3239, %f3280;
	mov.f32 	%f3240, %f3279;
	mov.f32 	%f3241, %f3278;
	mov.f32 	%f3242, %f3277;
	mov.f32 	%f3243, %f3276;
	mov.f32 	%f3244, %f3275;
	mov.f32 	%f3245, %f3274;
	@%p13 bra 	$L__BB0_6;

$L__BB0_22:
	mul.ftz.f32 	%f1498, %f1, %f3277;
	fma.rn.ftz.f32 	%f1499, %f2, %f3276, %f1498;
	fma.rn.ftz.f32 	%f1500, %f3, %f3275, %f1499;
	mul.ftz.f32 	%f1501, %f1, %f3281;
	fma.rn.ftz.f32 	%f1502, %f2, %f3280, %f1501;
	fma.rn.ftz.f32 	%f1503, %f3, %f3279, %f1502;
	mul.ftz.f32 	%f1504, %f1, %f3285;
	fma.rn.ftz.f32 	%f1505, %f2, %f3284, %f1504;
	fma.rn.ftz.f32 	%f1506, %f3, %f3283, %f1505;
	add.ftz.f32 	%f209, %f3282, %f1506;
	add.ftz.f32 	%f208, %f3278, %f1503;
	add.ftz.f32 	%f207, %f3274, %f1500;
	bra.uni 	$L__BB0_24;

$L__BB0_97:
	// begin inline asm
	call (%rd531), _optix_get_gas_traversable_handle, ();
	// end inline asm
	// begin inline asm
	call (%r696), _optix_read_sbt_gas_idx, ();
	// end inline asm
	mov.f32 	%f2340, 0f00000000;
	// begin inline asm
	call (%f2328, %f2329, %f2330, %f2331,  %f2332, %f2333, %f2334, %f2335,  %f2336, %f2337, %f2338, %f2339), _optix_get_quadratic_bspline_vertex_data, (%rd531, %r73, %r696, %f2340);
	// end inline asm
	mul.ftz.f32 	%f2341, %f2328, 0f3F000000;
	mul.ftz.f32 	%f2342, %f2329, 0f3F000000;
	mul.ftz.f32 	%f2343, %f2330, 0f3F000000;
	mul.ftz.f32 	%f2344, %f2331, 0f3F000000;
	fma.rn.ftz.f32 	%f744, %f2332, 0f3F000000, %f2341;
	fma.rn.ftz.f32 	%f745, %f2333, 0f3F000000, %f2342;
	fma.rn.ftz.f32 	%f746, %f2334, 0f3F000000, %f2343;
	fma.rn.ftz.f32 	%f747, %f2335, 0f3F000000, %f2344;
	sub.ftz.f32 	%f748, %f2332, %f2328;
	sub.ftz.f32 	%f749, %f2333, %f2329;
	sub.ftz.f32 	%f750, %f2334, %f2330;
	sub.ftz.f32 	%f751, %f2335, %f2331;
	sub.ftz.f32 	%f2345, %f2341, %f2332;
	sub.ftz.f32 	%f2346, %f2342, %f2333;
	sub.ftz.f32 	%f2347, %f2343, %f2334;
	sub.ftz.f32 	%f2348, %f2344, %f2335;
	fma.rn.ftz.f32 	%f752, %f2336, 0f3F000000, %f2345;
	fma.rn.ftz.f32 	%f753, %f2337, 0f3F000000, %f2346;
	fma.rn.ftz.f32 	%f754, %f2338, 0f3F000000, %f2347;
	fma.rn.ftz.f32 	%f755, %f2339, 0f3F000000, %f2348;
	// begin inline asm
	call (%r699), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p48, %r699, 0;
	@%p48 bra 	$L__BB0_117;

	// begin inline asm
	call (%r700), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f2349), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p49, %r700, 0;
	@%p49 bra 	$L__BB0_116;

	mov.u32 	%r1161, 0;

$L__BB0_100:
	.pragma "nounroll";
	// begin inline asm
	call (%rd533), _optix_get_transform_list_handle, (%r1161);
	// end inline asm
	// begin inline asm
	call (%r703), _optix_get_transform_type_from_handle, (%rd533);
	// end inline asm
	or.b32  	%r704, %r703, 1;
	setp.eq.s32 	%p50, %r704, 3;
	@%p50 bra 	$L__BB0_106;
	bra.uni 	$L__BB0_101;

$L__BB0_106:
	setp.eq.s32 	%p53, %r703, 2;
	@%p53 bra 	$L__BB0_110;
	bra.uni 	$L__BB0_107;

$L__BB0_110:
	// begin inline asm
	call (%rd605), _optix_get_matrix_motion_transform_from_handle, (%rd533);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd607, %rd605;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r792,%r793,%r794,%r795}, [%rd607];
	// end inline asm
	add.s64 	%rd611, %rd605, 16;
	// begin inline asm
	cvta.to.global.u64 %rd610, %rd611;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r796,%r797,%r798,%r799}, [%rd610];
	// end inline asm
	add.s64 	%rd614, %rd605, 32;
	// begin inline asm
	cvta.to.global.u64 %rd613, %rd614;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r800,%r801,%r802,%r803}, [%rd613];
	// end inline asm
	add.s64 	%rd617, %rd605, 48;
	// begin inline asm
	cvta.to.global.u64 %rd616, %rd617;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r804,%r805,%r806,%r807}, [%rd616];
	// end inline asm
	add.s64 	%rd620, %rd605, 64;
	// begin inline asm
	cvta.to.global.u64 %rd619, %rd620;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r808,%r809,%r810,%r811}, [%rd619];
	// end inline asm
	add.s64 	%rd623, %rd605, 80;
	// begin inline asm
	cvta.to.global.u64 %rd622, %rd623;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r812,%r813,%r814,%r815}, [%rd622];
	// end inline asm
	add.s64 	%rd626, %rd605, 96;
	// begin inline asm
	cvta.to.global.u64 %rd625, %rd626;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r816,%r817,%r818,%r819}, [%rd625];
	// end inline asm
	add.s64 	%rd629, %rd605, 112;
	// begin inline asm
	cvta.to.global.u64 %rd628, %rd629;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r820,%r821,%r822,%r823}, [%rd628];
	// end inline asm
	mov.b32 	%f2476, %r795;
	mov.b32 	%f2477, %r796;
	and.b32  	%r836, %r794, 65535;
	add.s32 	%r837, %r836, -1;
	cvt.rn.f32.s32 	%f2478, %r837;
	sub.ftz.f32 	%f2479, %f2349, %f2476;
	mul.ftz.f32 	%f2480, %f2479, %f2478;
	sub.ftz.f32 	%f2481, %f2477, %f2476;
	div.approx.ftz.f32 	%f2482, %f2480, %f2481;
	min.ftz.f32 	%f2483, %f2478, %f2482;
	mov.f32 	%f2484, 0f00000000;
	max.ftz.f32 	%f2485, %f2484, %f2483;
	cvt.rmi.ftz.f32.f32 	%f2486, %f2485;
	sub.ftz.f32 	%f842, %f2485, %f2486;
	cvt.rzi.ftz.s32.f32 	%r838, %f2486;
	cvt.s64.s32 	%rd36, %r838;
	mul.wide.s32 	%rd640, %r838, 48;
	add.s64 	%rd632, %rd614, %rd640;
	// begin inline asm
	cvta.to.global.u64 %rd631, %rd632;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r824,%r825,%r826,%r827}, [%rd631];
	// end inline asm
	mov.b32 	%f3544, %r824;
	mov.b32 	%f3545, %r825;
	mov.b32 	%f3546, %r826;
	mov.b32 	%f3547, %r827;
	add.s64 	%rd635, %rd632, 16;
	// begin inline asm
	cvta.to.global.u64 %rd634, %rd635;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r828,%r829,%r830,%r831}, [%rd634];
	// end inline asm
	mov.b32 	%f3540, %r828;
	mov.b32 	%f3541, %r829;
	mov.b32 	%f3542, %r830;
	mov.b32 	%f3543, %r831;
	add.s64 	%rd638, %rd632, 32;
	// begin inline asm
	cvta.to.global.u64 %rd637, %rd638;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r832,%r833,%r834,%r835}, [%rd637];
	// end inline asm
	mov.b32 	%f3536, %r832;
	mov.b32 	%f3537, %r833;
	mov.b32 	%f3538, %r834;
	mov.b32 	%f3539, %r835;
	setp.leu.ftz.f32 	%p55, %f842, 0f00000000;
	@%p55 bra 	$L__BB0_112;

	mov.f32 	%f2487, 0f3F800000;
	sub.ftz.f32 	%f2488, %f2487, %f842;
	mul.lo.s64 	%rd650, %rd36, 48;
	add.s64 	%rd651, %rd605, %rd650;
	add.s64 	%rd642, %rd651, 80;
	// begin inline asm
	cvta.to.global.u64 %rd641, %rd642;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r839,%r840,%r841,%r842}, [%rd641];
	// end inline asm
	mov.b32 	%f2489, %r839;
	mov.b32 	%f2490, %r840;
	mov.b32 	%f2491, %r841;
	mov.b32 	%f2492, %r842;
	mul.ftz.f32 	%f2493, %f842, %f2489;
	mul.ftz.f32 	%f2494, %f842, %f2490;
	mul.ftz.f32 	%f2495, %f842, %f2491;
	mul.ftz.f32 	%f2496, %f842, %f2492;
	fma.rn.ftz.f32 	%f3544, %f2488, %f3544, %f2493;
	fma.rn.ftz.f32 	%f3545, %f2488, %f3545, %f2494;
	fma.rn.ftz.f32 	%f3546, %f2488, %f3546, %f2495;
	fma.rn.ftz.f32 	%f3547, %f2488, %f3547, %f2496;
	add.s64 	%rd645, %rd651, 96;
	// begin inline asm
	cvta.to.global.u64 %rd644, %rd645;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r843,%r844,%r845,%r846}, [%rd644];
	// end inline asm
	mov.b32 	%f2497, %r843;
	mov.b32 	%f2498, %r844;
	mov.b32 	%f2499, %r845;
	mov.b32 	%f2500, %r846;
	mul.ftz.f32 	%f2501, %f842, %f2497;
	mul.ftz.f32 	%f2502, %f842, %f2498;
	mul.ftz.f32 	%f2503, %f842, %f2499;
	mul.ftz.f32 	%f2504, %f842, %f2500;
	fma.rn.ftz.f32 	%f3540, %f2488, %f3540, %f2501;
	fma.rn.ftz.f32 	%f3541, %f2488, %f3541, %f2502;
	fma.rn.ftz.f32 	%f3542, %f2488, %f3542, %f2503;
	fma.rn.ftz.f32 	%f3543, %f2488, %f3543, %f2504;
	add.s64 	%rd648, %rd651, 112;
	// begin inline asm
	cvta.to.global.u64 %rd647, %rd648;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r847,%r848,%r849,%r850}, [%rd647];
	// end inline asm
	mov.b32 	%f2505, %r847;
	mov.b32 	%f2506, %r848;
	mov.b32 	%f2507, %r849;
	mov.b32 	%f2508, %r850;
	mul.ftz.f32 	%f2509, %f842, %f2505;
	mul.ftz.f32 	%f2510, %f842, %f2506;
	mul.ftz.f32 	%f2511, %f842, %f2507;
	mul.ftz.f32 	%f2512, %f842, %f2508;
	fma.rn.ftz.f32 	%f3536, %f2488, %f3536, %f2509;
	fma.rn.ftz.f32 	%f3537, %f2488, %f3537, %f2510;
	fma.rn.ftz.f32 	%f3538, %f2488, %f3538, %f2511;
	fma.rn.ftz.f32 	%f3539, %f2488, %f3539, %f2512;
	bra.uni 	$L__BB0_112;

$L__BB0_101:
	mov.f32 	%f3550, 0f3F800000;
	setp.eq.s32 	%p51, %r703, 4;
	@%p51 bra 	$L__BB0_104;

	setp.ne.s32 	%p52, %r703, 1;
	mov.f32 	%f3548, %f2340;
	mov.f32 	%f3549, %f2340;
	mov.f32 	%f3551, %f2340;
	mov.f32 	%f3552, %f2340;
	mov.f32 	%f3553, %f3550;
	mov.f32 	%f3554, %f2340;
	mov.f32 	%f3555, %f2340;
	mov.f32 	%f3556, %f3550;
	mov.f32 	%f3557, %f2340;
	mov.f32 	%f3558, %f2340;
	mov.f32 	%f3559, %f2340;
	@%p52 bra 	$L__BB0_113;

	// begin inline asm
	call (%rd535), _optix_get_static_transform_from_handle, (%rd533);
	// end inline asm
	add.s64 	%rd791, %rd535, 64;
	bra.uni 	$L__BB0_105;

$L__BB0_107:
	// begin inline asm
	call (%rd548), _optix_get_srt_motion_transform_from_handle, (%rd533);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd550, %rd548;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r717,%r718,%r719,%r720}, [%rd550];
	// end inline asm
	add.s64 	%rd554, %rd548, 16;
	// begin inline asm
	cvta.to.global.u64 %rd553, %rd554;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r721,%r722,%r723,%r724}, [%rd553];
	// end inline asm
	add.s64 	%rd557, %rd548, 32;
	// begin inline asm
	cvta.to.global.u64 %rd556, %rd557;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r725,%r726,%r727,%r728}, [%rd556];
	// end inline asm
	add.s64 	%rd560, %rd548, 48;
	// begin inline asm
	cvta.to.global.u64 %rd559, %rd560;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r729,%r730,%r731,%r732}, [%rd559];
	// end inline asm
	add.s64 	%rd563, %rd548, 64;
	// begin inline asm
	cvta.to.global.u64 %rd562, %rd563;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r733,%r734,%r735,%r736}, [%rd562];
	// end inline asm
	add.s64 	%rd566, %rd548, 80;
	// begin inline asm
	cvta.to.global.u64 %rd565, %rd566;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r737,%r738,%r739,%r740}, [%rd565];
	// end inline asm
	add.s64 	%rd569, %rd548, 96;
	// begin inline asm
	cvta.to.global.u64 %rd568, %rd569;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r741,%r742,%r743,%r744}, [%rd568];
	// end inline asm
	add.s64 	%rd572, %rd548, 112;
	// begin inline asm
	cvta.to.global.u64 %rd571, %rd572;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r745,%r746,%r747,%r748}, [%rd571];
	// end inline asm
	add.s64 	%rd575, %rd548, 128;
	// begin inline asm
	cvta.to.global.u64 %rd574, %rd575;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r749,%r750,%r751,%r752}, [%rd574];
	// end inline asm
	add.s64 	%rd578, %rd548, 144;
	// begin inline asm
	cvta.to.global.u64 %rd577, %rd578;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r753,%r754,%r755,%r756}, [%rd577];
	// end inline asm
	mov.b32 	%f2364, %r720;
	mov.b32 	%f2365, %r721;
	and.b32  	%r773, %r719, 65535;
	add.s32 	%r774, %r773, -1;
	cvt.rn.f32.s32 	%f2366, %r774;
	sub.ftz.f32 	%f2367, %f2349, %f2364;
	mul.ftz.f32 	%f2368, %f2367, %f2366;
	sub.ftz.f32 	%f2369, %f2365, %f2364;
	div.approx.ftz.f32 	%f2370, %f2368, %f2369;
	min.ftz.f32 	%f2371, %f2366, %f2370;
	mov.f32 	%f2372, 0f00000000;
	max.ftz.f32 	%f2373, %f2372, %f2371;
	cvt.rmi.ftz.f32.f32 	%f2374, %f2373;
	sub.ftz.f32 	%f781, %f2373, %f2374;
	cvt.rzi.ftz.s32.f32 	%r775, %f2374;
	mul.wide.s32 	%rd592, %r775, 64;
	add.s64 	%rd581, %rd557, %rd592;
	// begin inline asm
	cvta.to.global.u64 %rd580, %rd581;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r757,%r758,%r759,%r760}, [%rd580];
	// end inline asm
	mov.b32 	%f3532, %r757;
	mov.b32 	%f3531, %r758;
	mov.b32 	%f3530, %r759;
	mov.b32 	%f3529, %r760;
	add.s64 	%rd584, %rd581, 16;
	// begin inline asm
	cvta.to.global.u64 %rd583, %rd584;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r761,%r762,%r763,%r764}, [%rd583];
	// end inline asm
	mov.b32 	%f3528, %r761;
	mov.b32 	%f3527, %r762;
	mov.b32 	%f3526, %r763;
	mov.b32 	%f3525, %r764;
	add.s64 	%rd587, %rd581, 32;
	// begin inline asm
	cvta.to.global.u64 %rd586, %rd587;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r765,%r766,%r767,%r768}, [%rd586];
	// end inline asm
	mov.b32 	%f3524, %r765;
	mov.b32 	%f3523, %r766;
	mov.b32 	%f3522, %r767;
	mov.b32 	%f3521, %r768;
	add.s64 	%rd590, %rd581, 48;
	// begin inline asm
	cvta.to.global.u64 %rd589, %rd590;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r769,%r770,%r771,%r772}, [%rd589];
	// end inline asm
	mov.b32 	%f3520, %r769;
	mov.b32 	%f3533, %r770;
	mov.b32 	%f3534, %r771;
	mov.b32 	%f3535, %r772;
	setp.leu.ftz.f32 	%p54, %f781, 0f00000000;
	@%p54 bra 	$L__BB0_109;

	mov.f32 	%f2375, 0f3F800000;
	sub.ftz.f32 	%f2376, %f2375, %f781;
	add.s64 	%rd594, %rd581, 64;
	// begin inline asm
	cvta.to.global.u64 %rd593, %rd594;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r776,%r777,%r778,%r779}, [%rd593];
	// end inline asm
	mov.b32 	%f2377, %r776;
	mov.b32 	%f2378, %r777;
	mov.b32 	%f2379, %r778;
	mov.b32 	%f2380, %r779;
	mul.ftz.f32 	%f2381, %f781, %f2377;
	mul.ftz.f32 	%f2382, %f781, %f2378;
	mul.ftz.f32 	%f2383, %f781, %f2379;
	mul.ftz.f32 	%f2384, %f781, %f2380;
	fma.rn.ftz.f32 	%f3532, %f2376, %f3532, %f2381;
	fma.rn.ftz.f32 	%f3531, %f2376, %f3531, %f2382;
	fma.rn.ftz.f32 	%f3530, %f2376, %f3530, %f2383;
	fma.rn.ftz.f32 	%f3529, %f2376, %f3529, %f2384;
	add.s64 	%rd597, %rd581, 80;
	// begin inline asm
	cvta.to.global.u64 %rd596, %rd597;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r780,%r781,%r782,%r783}, [%rd596];
	// end inline asm
	mov.b32 	%f2385, %r780;
	mov.b32 	%f2386, %r781;
	mov.b32 	%f2387, %r782;
	mov.b32 	%f2388, %r783;
	mul.ftz.f32 	%f2389, %f781, %f2385;
	mul.ftz.f32 	%f2390, %f781, %f2386;
	mul.ftz.f32 	%f2391, %f781, %f2387;
	mul.ftz.f32 	%f2392, %f781, %f2388;
	fma.rn.ftz.f32 	%f3528, %f2376, %f3528, %f2389;
	fma.rn.ftz.f32 	%f3527, %f2376, %f3527, %f2390;
	fma.rn.ftz.f32 	%f3526, %f2376, %f3526, %f2391;
	fma.rn.ftz.f32 	%f3525, %f2376, %f3525, %f2392;
	add.s64 	%rd600, %rd581, 96;
	// begin inline asm
	cvta.to.global.u64 %rd599, %rd600;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r784,%r785,%r786,%r787}, [%rd599];
	// end inline asm
	mov.b32 	%f2393, %r784;
	mov.b32 	%f2394, %r785;
	mov.b32 	%f2395, %r786;
	mov.b32 	%f2396, %r787;
	mul.ftz.f32 	%f2397, %f781, %f2393;
	mul.ftz.f32 	%f2398, %f781, %f2394;
	mul.ftz.f32 	%f2399, %f781, %f2395;
	mul.ftz.f32 	%f2400, %f781, %f2396;
	fma.rn.ftz.f32 	%f3524, %f2376, %f3524, %f2397;
	fma.rn.ftz.f32 	%f2401, %f2376, %f3523, %f2398;
	fma.rn.ftz.f32 	%f2402, %f2376, %f3522, %f2399;
	fma.rn.ftz.f32 	%f2403, %f2376, %f3521, %f2400;
	add.s64 	%rd603, %rd581, 112;
	// begin inline asm
	cvta.to.global.u64 %rd602, %rd603;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r788,%r789,%r790,%r791}, [%rd602];
	// end inline asm
	mov.b32 	%f2404, %r788;
	mov.b32 	%f2405, %r789;
	mov.b32 	%f2406, %r790;
	mov.b32 	%f2407, %r791;
	mul.ftz.f32 	%f2408, %f781, %f2404;
	mul.ftz.f32 	%f2409, %f781, %f2405;
	mul.ftz.f32 	%f2410, %f781, %f2406;
	mul.ftz.f32 	%f2411, %f781, %f2407;
	fma.rn.ftz.f32 	%f2412, %f2376, %f3520, %f2408;
	fma.rn.ftz.f32 	%f3533, %f2376, %f3533, %f2409;
	fma.rn.ftz.f32 	%f3534, %f2376, %f3534, %f2410;
	fma.rn.ftz.f32 	%f3535, %f2376, %f3535, %f2411;
	mul.ftz.f32 	%f2413, %f2402, %f2402;
	fma.rn.ftz.f32 	%f2414, %f2401, %f2401, %f2413;
	fma.rn.ftz.f32 	%f2415, %f2403, %f2403, %f2414;
	fma.rn.ftz.f32 	%f2416, %f2412, %f2412, %f2415;
	rsqrt.approx.ftz.f32 	%f2417, %f2416;
	mul.ftz.f32 	%f3523, %f2401, %f2417;
	mul.ftz.f32 	%f3522, %f2402, %f2417;
	mul.ftz.f32 	%f3521, %f2403, %f2417;
	mul.ftz.f32 	%f3520, %f2417, %f2412;

$L__BB0_109:
	mul.ftz.f32 	%f2418, %f3523, %f3523;
	fma.rn.ftz.f32 	%f2419, %f3522, %f3522, %f2418;
	fma.rn.ftz.f32 	%f2420, %f3521, %f3521, %f2419;
	fma.rn.ftz.f32 	%f2421, %f3520, %f3520, %f2420;
	rcp.approx.ftz.f32 	%f2422, %f2421;
	mul.ftz.f32 	%f2423, %f3523, %f2422;
	mul.ftz.f32 	%f2424, %f3522, %f2422;
	mul.ftz.f32 	%f2425, %f3521, %f2422;
	mul.ftz.f32 	%f2426, %f3520, %f2422;
	mul.ftz.f32 	%f2427, %f3523, %f2423;
	mul.ftz.f32 	%f2428, %f3522, %f2424;
	mul.ftz.f32 	%f2429, %f3521, %f2425;
	mul.ftz.f32 	%f2430, %f3523, %f2424;
	mul.ftz.f32 	%f2431, %f3521, %f2426;
	mul.ftz.f32 	%f2432, %f3523, %f2425;
	mul.ftz.f32 	%f2433, %f3522, %f2426;
	mul.ftz.f32 	%f2434, %f3522, %f2425;
	mul.ftz.f32 	%f2435, %f3523, %f2426;
	sub.ftz.f32 	%f2436, %f2427, %f2428;
	sub.ftz.f32 	%f2437, %f2436, %f2429;
	fma.rn.ftz.f32 	%f2438, %f3520, %f2426, %f2437;
	sub.ftz.f32 	%f2439, %f2430, %f2431;
	add.ftz.f32 	%f2440, %f2439, %f2439;
	add.ftz.f32 	%f2441, %f2432, %f2433;
	add.ftz.f32 	%f2442, %f2441, %f2441;
	add.ftz.f32 	%f2443, %f2430, %f2431;
	add.ftz.f32 	%f2444, %f2443, %f2443;
	sub.ftz.f32 	%f2445, %f2428, %f2427;
	sub.ftz.f32 	%f2446, %f2445, %f2429;
	fma.rn.ftz.f32 	%f2447, %f3520, %f2426, %f2446;
	sub.ftz.f32 	%f2448, %f2434, %f2435;
	add.ftz.f32 	%f2449, %f2448, %f2448;
	sub.ftz.f32 	%f2450, %f2432, %f2433;
	add.ftz.f32 	%f2451, %f2450, %f2450;
	add.ftz.f32 	%f2452, %f2434, %f2435;
	add.ftz.f32 	%f2453, %f2452, %f2452;
	neg.ftz.f32 	%f2454, %f2427;
	sub.ftz.f32 	%f2455, %f2454, %f2428;
	add.ftz.f32 	%f2456, %f2429, %f2455;
	fma.rn.ftz.f32 	%f2457, %f3520, %f2426, %f2456;
	mul.ftz.f32 	%f2458, %f3529, %f2438;
	fma.rn.ftz.f32 	%f2459, %f3526, %f2440, %f2458;
	fma.rn.ftz.f32 	%f2460, %f3524, %f2442, %f2459;
	add.ftz.f32 	%f3547, %f3533, %f2460;
	mul.ftz.f32 	%f2461, %f3526, %f2447;
	fma.rn.ftz.f32 	%f2462, %f3529, %f2444, %f2461;
	fma.rn.ftz.f32 	%f2463, %f3524, %f2449, %f2462;
	add.ftz.f32 	%f3543, %f3534, %f2463;
	mul.ftz.f32 	%f2464, %f3526, %f2453;
	fma.rn.ftz.f32 	%f2465, %f3529, %f2451, %f2464;
	fma.rn.ftz.f32 	%f2466, %f3524, %f2457, %f2465;
	add.ftz.f32 	%f3539, %f2466, %f3535;
	mul.ftz.f32 	%f2467, %f3530, %f2438;
	fma.rn.ftz.f32 	%f2468, %f3527, %f2440, %f2467;
	fma.rn.ftz.f32 	%f3546, %f3525, %f2442, %f2468;
	mul.ftz.f32 	%f2469, %f3527, %f2447;
	fma.rn.ftz.f32 	%f2470, %f3530, %f2444, %f2469;
	fma.rn.ftz.f32 	%f3542, %f3525, %f2449, %f2470;
	mul.ftz.f32 	%f2471, %f3527, %f2453;
	fma.rn.ftz.f32 	%f2472, %f3530, %f2451, %f2471;
	fma.rn.ftz.f32 	%f3538, %f3525, %f2457, %f2472;
	mul.ftz.f32 	%f2473, %f3531, %f2438;
	fma.rn.ftz.f32 	%f3545, %f3528, %f2440, %f2473;
	mul.ftz.f32 	%f2474, %f3528, %f2447;
	fma.rn.ftz.f32 	%f3541, %f3531, %f2444, %f2474;
	mul.ftz.f32 	%f2475, %f3528, %f2453;
	fma.rn.ftz.f32 	%f3537, %f3531, %f2451, %f2475;
	mul.ftz.f32 	%f3544, %f3532, %f2438;
	mul.ftz.f32 	%f3540, %f2444, %f3532;
	mul.ftz.f32 	%f3536, %f2451, %f3532;

$L__BB0_112:
	mul.ftz.f32 	%f2513, %f3537, %f3542;
	mul.ftz.f32 	%f2514, %f3538, %f3541;
	sub.ftz.f32 	%f2515, %f2514, %f2513;
	mul.ftz.f32 	%f2516, %f3544, %f2515;
	mul.ftz.f32 	%f2517, %f3536, %f3542;
	mul.ftz.f32 	%f2518, %f3538, %f3540;
	sub.ftz.f32 	%f2519, %f2518, %f2517;
	mul.ftz.f32 	%f2520, %f2519, %f3545;
	sub.ftz.f32 	%f2521, %f2516, %f2520;
	mul.ftz.f32 	%f2522, %f3536, %f3541;
	mul.ftz.f32 	%f2523, %f3537, %f3540;
	sub.ftz.f32 	%f2524, %f2523, %f2522;
	fma.rn.ftz.f32 	%f2525, %f2524, %f3546, %f2521;
	rcp.approx.ftz.f32 	%f2526, %f2525;
	mul.ftz.f32 	%f3556, %f2515, %f2526;
	mul.ftz.f32 	%f2527, %f3538, %f3545;
	mul.ftz.f32 	%f2528, %f3537, %f3546;
	sub.ftz.f32 	%f2529, %f2528, %f2527;
	mul.ftz.f32 	%f3557, %f2529, %f2526;
	mul.ftz.f32 	%f2530, %f3541, %f3546;
	mul.ftz.f32 	%f2531, %f3542, %f3545;
	sub.ftz.f32 	%f2532, %f2531, %f2530;
	mul.ftz.f32 	%f3558, %f2532, %f2526;
	sub.ftz.f32 	%f2533, %f2517, %f2518;
	mul.ftz.f32 	%f3552, %f2533, %f2526;
	mul.ftz.f32 	%f2534, %f3536, %f3546;
	mul.ftz.f32 	%f2535, %f3538, %f3544;
	sub.ftz.f32 	%f2536, %f2535, %f2534;
	mul.ftz.f32 	%f3553, %f2536, %f2526;
	mul.ftz.f32 	%f2537, %f3542, %f3544;
	mul.ftz.f32 	%f2538, %f3540, %f3546;
	sub.ftz.f32 	%f2539, %f2538, %f2537;
	mul.ftz.f32 	%f3554, %f2539, %f2526;
	mul.ftz.f32 	%f3548, %f2524, %f2526;
	mul.ftz.f32 	%f2540, %f3537, %f3544;
	mul.ftz.f32 	%f2541, %f3536, %f3545;
	sub.ftz.f32 	%f2542, %f2541, %f2540;
	mul.ftz.f32 	%f3549, %f2542, %f2526;
	mul.ftz.f32 	%f2543, %f3540, %f3545;
	mul.ftz.f32 	%f2544, %f3541, %f3544;
	sub.ftz.f32 	%f2545, %f2544, %f2543;
	mul.ftz.f32 	%f3550, %f2545, %f2526;
	mul.ftz.f32 	%f2546, %f3547, %f3556;
	neg.ftz.f32 	%f2547, %f2546;
	mul.ftz.f32 	%f2548, %f3543, %f3557;
	sub.ftz.f32 	%f2549, %f2547, %f2548;
	mul.ftz.f32 	%f2550, %f3539, %f3558;
	sub.ftz.f32 	%f3559, %f2549, %f2550;
	mul.ftz.f32 	%f2551, %f3547, %f3552;
	neg.ftz.f32 	%f2552, %f2551;
	mul.ftz.f32 	%f2553, %f3543, %f3553;
	sub.ftz.f32 	%f2554, %f2552, %f2553;
	mul.ftz.f32 	%f2555, %f3539, %f3554;
	sub.ftz.f32 	%f3555, %f2554, %f2555;
	mul.ftz.f32 	%f2556, %f3547, %f3548;
	neg.ftz.f32 	%f2557, %f2556;
	mul.ftz.f32 	%f2558, %f3543, %f3549;
	sub.ftz.f32 	%f2559, %f2557, %f2558;
	mul.ftz.f32 	%f2560, %f3539, %f3550;
	sub.ftz.f32 	%f3551, %f2559, %f2560;
	bra.uni 	$L__BB0_113;

$L__BB0_104:
	// begin inline asm
	call (%rd791), _optix_get_instance_inverse_transform_from_handle, (%rd533);
	// end inline asm

$L__BB0_105:
	// begin inline asm
	cvta.to.global.u64 %rd539, %rd791;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r705,%r706,%r707,%r708}, [%rd539];
	// end inline asm
	mov.b32 	%f3556, %r705;
	mov.b32 	%f3557, %r706;
	mov.b32 	%f3558, %r707;
	mov.b32 	%f3559, %r708;
	add.s64 	%rd543, %rd791, 16;
	// begin inline asm
	cvta.to.global.u64 %rd542, %rd543;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r709,%r710,%r711,%r712}, [%rd542];
	// end inline asm
	mov.b32 	%f3552, %r709;
	mov.b32 	%f3553, %r710;
	mov.b32 	%f3554, %r711;
	mov.b32 	%f3555, %r712;
	add.s64 	%rd546, %rd791, 32;
	// begin inline asm
	cvta.to.global.u64 %rd545, %rd546;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r713,%r714,%r715,%r716}, [%rd545];
	// end inline asm
	mov.b32 	%f3548, %r713;
	mov.b32 	%f3549, %r714;
	mov.b32 	%f3550, %r715;
	mov.b32 	%f3551, %r716;

$L__BB0_113:
	setp.eq.s32 	%p56, %r1161, 0;
	@%p56 bra 	$L__BB0_115;

	mul.ftz.f32 	%f2561, %f3515, %f3557;
	fma.rn.ftz.f32 	%f2562, %f3511, %f3556, %f2561;
	fma.rn.ftz.f32 	%f903, %f3519, %f3558, %f2562;
	mul.ftz.f32 	%f2563, %f3514, %f3557;
	fma.rn.ftz.f32 	%f2564, %f3510, %f3556, %f2563;
	fma.rn.ftz.f32 	%f904, %f3518, %f3558, %f2564;
	mul.ftz.f32 	%f2565, %f3513, %f3557;
	fma.rn.ftz.f32 	%f2566, %f3509, %f3556, %f2565;
	fma.rn.ftz.f32 	%f905, %f3517, %f3558, %f2566;
	mul.ftz.f32 	%f2567, %f3512, %f3557;
	fma.rn.ftz.f32 	%f2568, %f3508, %f3556, %f2567;
	fma.rn.ftz.f32 	%f2569, %f3516, %f3558, %f2568;
	add.ftz.f32 	%f3559, %f3559, %f2569;
	mul.ftz.f32 	%f2570, %f3515, %f3553;
	fma.rn.ftz.f32 	%f2571, %f3511, %f3552, %f2570;
	fma.rn.ftz.f32 	%f907, %f3519, %f3554, %f2571;
	mul.ftz.f32 	%f2572, %f3514, %f3553;
	fma.rn.ftz.f32 	%f2573, %f3510, %f3552, %f2572;
	fma.rn.ftz.f32 	%f908, %f3518, %f3554, %f2573;
	mul.ftz.f32 	%f2574, %f3513, %f3553;
	fma.rn.ftz.f32 	%f2575, %f3509, %f3552, %f2574;
	fma.rn.ftz.f32 	%f909, %f3517, %f3554, %f2575;
	mul.ftz.f32 	%f2576, %f3512, %f3553;
	fma.rn.ftz.f32 	%f2577, %f3508, %f3552, %f2576;
	fma.rn.ftz.f32 	%f2578, %f3516, %f3554, %f2577;
	add.ftz.f32 	%f3555, %f3555, %f2578;
	mul.ftz.f32 	%f2579, %f3515, %f3549;
	fma.rn.ftz.f32 	%f2580, %f3511, %f3548, %f2579;
	fma.rn.ftz.f32 	%f911, %f3519, %f3550, %f2580;
	mul.ftz.f32 	%f2581, %f3514, %f3549;
	fma.rn.ftz.f32 	%f2582, %f3510, %f3548, %f2581;
	fma.rn.ftz.f32 	%f912, %f3518, %f3550, %f2582;
	mul.ftz.f32 	%f2583, %f3513, %f3549;
	fma.rn.ftz.f32 	%f2584, %f3509, %f3548, %f2583;
	fma.rn.ftz.f32 	%f913, %f3517, %f3550, %f2584;
	mul.ftz.f32 	%f2585, %f3512, %f3549;
	fma.rn.ftz.f32 	%f2586, %f3508, %f3548, %f2585;
	fma.rn.ftz.f32 	%f2587, %f3516, %f3550, %f2586;
	add.ftz.f32 	%f3551, %f3551, %f2587;
	mov.f32 	%f3548, %f911;
	mov.f32 	%f3549, %f912;
	mov.f32 	%f3550, %f913;
	mov.f32 	%f3552, %f907;
	mov.f32 	%f3553, %f908;
	mov.f32 	%f3554, %f909;
	mov.f32 	%f3556, %f903;
	mov.f32 	%f3557, %f904;
	mov.f32 	%f3558, %f905;

$L__BB0_115:
	add.s32 	%r1161, %r1161, 1;
	setp.lt.u32 	%p57, %r1161, %r700;
	mov.f32 	%f3508, %f3559;
	mov.f32 	%f3509, %f3558;
	mov.f32 	%f3510, %f3557;
	mov.f32 	%f3511, %f3556;
	mov.f32 	%f3512, %f3555;
	mov.f32 	%f3513, %f3554;
	mov.f32 	%f3514, %f3553;
	mov.f32 	%f3515, %f3552;
	mov.f32 	%f3516, %f3551;
	mov.f32 	%f3517, %f3550;
	mov.f32 	%f3518, %f3549;
	mov.f32 	%f3519, %f3548;
	@%p57 bra 	$L__BB0_100;

$L__BB0_116:
	mul.ftz.f32 	%f2588, %f2, %f3557;
	fma.rn.ftz.f32 	%f2589, %f1, %f3556, %f2588;
	fma.rn.ftz.f32 	%f2590, %f3, %f3558, %f2589;
	mul.ftz.f32 	%f2591, %f2, %f3553;
	fma.rn.ftz.f32 	%f2592, %f1, %f3552, %f2591;
	fma.rn.ftz.f32 	%f2593, %f3, %f3554, %f2592;
	mul.ftz.f32 	%f2594, %f2, %f3549;
	fma.rn.ftz.f32 	%f2595, %f1, %f3548, %f2594;
	fma.rn.ftz.f32 	%f2596, %f3, %f3550, %f2595;
	add.ftz.f32 	%f3586, %f3551, %f2596;
	add.ftz.f32 	%f3585, %f3555, %f2593;
	add.ftz.f32 	%f3584, %f3559, %f2590;
	bra.uni 	$L__BB0_118;

$L__BB0_50:
	// begin inline asm
	call (%rd291), _optix_get_gas_traversable_handle, ();
	// end inline asm
	// begin inline asm
	call (%r388), _optix_read_sbt_gas_idx, ();
	// end inline asm
	mov.f32 	%f1757, 0f00000000;
	// begin inline asm
	call (%f1741, %f1742, %f1743, %f1744,  %f1745, %f1746, %f1747, %f1748,  %f1749, %f1750, %f1751, %f1752,  %f1753, %f1754, %f1755, %f1756), _optix_get_cubic_bspline_vertex_data, (%rd291, %r73, %r388, %f1757);
	// end inline asm
	add.ftz.f32 	%f1758, %f1749, %f1741;
	add.ftz.f32 	%f1759, %f1750, %f1742;
	add.ftz.f32 	%f1760, %f1751, %f1743;
	add.ftz.f32 	%f1761, %f1752, %f1744;
	mul.ftz.f32 	%f1762, %f1758, 0f3E2AAAAB;
	mul.ftz.f32 	%f1763, %f1759, 0f3E2AAAAB;
	mul.ftz.f32 	%f1764, %f1760, 0f3E2AAAAB;
	mul.ftz.f32 	%f1765, %f1761, 0f3E2AAAAB;
	fma.rn.ftz.f32 	%f373, %f1745, 0f3F2AAAAB, %f1762;
	fma.rn.ftz.f32 	%f374, %f1746, 0f3F2AAAAB, %f1763;
	fma.rn.ftz.f32 	%f375, %f1747, 0f3F2AAAAB, %f1764;
	fma.rn.ftz.f32 	%f376, %f1748, 0f3F2AAAAB, %f1765;
	sub.ftz.f32 	%f377, %f1749, %f1741;
	sub.ftz.f32 	%f378, %f1750, %f1742;
	sub.ftz.f32 	%f379, %f1751, %f1743;
	sub.ftz.f32 	%f380, %f1752, %f1744;
	sub.ftz.f32 	%f381, %f1749, %f1745;
	sub.ftz.f32 	%f382, %f1750, %f1746;
	sub.ftz.f32 	%f383, %f1751, %f1747;
	sub.ftz.f32 	%f384, %f1752, %f1748;
	sub.ftz.f32 	%f385, %f1753, %f1745;
	sub.ftz.f32 	%f386, %f1754, %f1746;
	sub.ftz.f32 	%f387, %f1755, %f1747;
	sub.ftz.f32 	%f388, %f1756, %f1748;
	// begin inline asm
	call (%r391), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p26, %r391, 0;
	@%p26 bra 	$L__BB0_70;

	// begin inline asm
	call (%r392), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1766), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p27, %r392, 0;
	@%p27 bra 	$L__BB0_69;

	mov.u32 	%r1159, 0;

$L__BB0_53:
	.pragma "nounroll";
	// begin inline asm
	call (%rd293), _optix_get_transform_list_handle, (%r1159);
	// end inline asm
	// begin inline asm
	call (%r395), _optix_get_transform_type_from_handle, (%rd293);
	// end inline asm
	or.b32  	%r396, %r395, 1;
	setp.eq.s32 	%p28, %r396, 3;
	@%p28 bra 	$L__BB0_59;
	bra.uni 	$L__BB0_54;

$L__BB0_59:
	setp.eq.s32 	%p31, %r395, 2;
	@%p31 bra 	$L__BB0_63;
	bra.uni 	$L__BB0_60;

$L__BB0_63:
	// begin inline asm
	call (%rd365), _optix_get_matrix_motion_transform_from_handle, (%rd293);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd367, %rd365;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r484,%r485,%r486,%r487}, [%rd367];
	// end inline asm
	add.s64 	%rd371, %rd365, 16;
	// begin inline asm
	cvta.to.global.u64 %rd370, %rd371;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r488,%r489,%r490,%r491}, [%rd370];
	// end inline asm
	add.s64 	%rd374, %rd365, 32;
	// begin inline asm
	cvta.to.global.u64 %rd373, %rd374;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r492,%r493,%r494,%r495}, [%rd373];
	// end inline asm
	add.s64 	%rd377, %rd365, 48;
	// begin inline asm
	cvta.to.global.u64 %rd376, %rd377;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r496,%r497,%r498,%r499}, [%rd376];
	// end inline asm
	add.s64 	%rd380, %rd365, 64;
	// begin inline asm
	cvta.to.global.u64 %rd379, %rd380;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r500,%r501,%r502,%r503}, [%rd379];
	// end inline asm
	add.s64 	%rd383, %rd365, 80;
	// begin inline asm
	cvta.to.global.u64 %rd382, %rd383;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r504,%r505,%r506,%r507}, [%rd382];
	// end inline asm
	add.s64 	%rd386, %rd365, 96;
	// begin inline asm
	cvta.to.global.u64 %rd385, %rd386;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r508,%r509,%r510,%r511}, [%rd385];
	// end inline asm
	add.s64 	%rd389, %rd365, 112;
	// begin inline asm
	cvta.to.global.u64 %rd388, %rd389;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r512,%r513,%r514,%r515}, [%rd388];
	// end inline asm
	mov.b32 	%f1893, %r487;
	mov.b32 	%f1894, %r488;
	and.b32  	%r528, %r486, 65535;
	add.s32 	%r529, %r528, -1;
	cvt.rn.f32.s32 	%f1895, %r529;
	sub.ftz.f32 	%f1896, %f1766, %f1893;
	mul.ftz.f32 	%f1897, %f1896, %f1895;
	sub.ftz.f32 	%f1898, %f1894, %f1893;
	div.approx.ftz.f32 	%f1899, %f1897, %f1898;
	min.ftz.f32 	%f1900, %f1895, %f1899;
	mov.f32 	%f1901, 0f00000000;
	max.ftz.f32 	%f1902, %f1901, %f1900;
	cvt.rmi.ftz.f32.f32 	%f1903, %f1902;
	sub.ftz.f32 	%f475, %f1902, %f1903;
	cvt.rzi.ftz.s32.f32 	%r530, %f1903;
	cvt.s64.s32 	%rd22, %r530;
	mul.wide.s32 	%rd400, %r530, 48;
	add.s64 	%rd392, %rd374, %rd400;
	// begin inline asm
	cvta.to.global.u64 %rd391, %rd392;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r516,%r517,%r518,%r519}, [%rd391];
	// end inline asm
	mov.b32 	%f3407, %r516;
	mov.b32 	%f3408, %r517;
	mov.b32 	%f3409, %r518;
	mov.b32 	%f3410, %r519;
	add.s64 	%rd395, %rd392, 16;
	// begin inline asm
	cvta.to.global.u64 %rd394, %rd395;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r520,%r521,%r522,%r523}, [%rd394];
	// end inline asm
	mov.b32 	%f3403, %r520;
	mov.b32 	%f3404, %r521;
	mov.b32 	%f3405, %r522;
	mov.b32 	%f3406, %r523;
	add.s64 	%rd398, %rd392, 32;
	// begin inline asm
	cvta.to.global.u64 %rd397, %rd398;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r524,%r525,%r526,%r527}, [%rd397];
	// end inline asm
	mov.b32 	%f3399, %r524;
	mov.b32 	%f3400, %r525;
	mov.b32 	%f3401, %r526;
	mov.b32 	%f3402, %r527;
	setp.leu.ftz.f32 	%p33, %f475, 0f00000000;
	@%p33 bra 	$L__BB0_65;

	mov.f32 	%f1904, 0f3F800000;
	sub.ftz.f32 	%f1905, %f1904, %f475;
	mul.lo.s64 	%rd410, %rd22, 48;
	add.s64 	%rd411, %rd365, %rd410;
	add.s64 	%rd402, %rd411, 80;
	// begin inline asm
	cvta.to.global.u64 %rd401, %rd402;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r531,%r532,%r533,%r534}, [%rd401];
	// end inline asm
	mov.b32 	%f1906, %r531;
	mov.b32 	%f1907, %r532;
	mov.b32 	%f1908, %r533;
	mov.b32 	%f1909, %r534;
	mul.ftz.f32 	%f1910, %f475, %f1906;
	mul.ftz.f32 	%f1911, %f475, %f1907;
	mul.ftz.f32 	%f1912, %f475, %f1908;
	mul.ftz.f32 	%f1913, %f475, %f1909;
	fma.rn.ftz.f32 	%f3407, %f1905, %f3407, %f1910;
	fma.rn.ftz.f32 	%f3408, %f1905, %f3408, %f1911;
	fma.rn.ftz.f32 	%f3409, %f1905, %f3409, %f1912;
	fma.rn.ftz.f32 	%f3410, %f1905, %f3410, %f1913;
	add.s64 	%rd405, %rd411, 96;
	// begin inline asm
	cvta.to.global.u64 %rd404, %rd405;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r535,%r536,%r537,%r538}, [%rd404];
	// end inline asm
	mov.b32 	%f1914, %r535;
	mov.b32 	%f1915, %r536;
	mov.b32 	%f1916, %r537;
	mov.b32 	%f1917, %r538;
	mul.ftz.f32 	%f1918, %f475, %f1914;
	mul.ftz.f32 	%f1919, %f475, %f1915;
	mul.ftz.f32 	%f1920, %f475, %f1916;
	mul.ftz.f32 	%f1921, %f475, %f1917;
	fma.rn.ftz.f32 	%f3403, %f1905, %f3403, %f1918;
	fma.rn.ftz.f32 	%f3404, %f1905, %f3404, %f1919;
	fma.rn.ftz.f32 	%f3405, %f1905, %f3405, %f1920;
	fma.rn.ftz.f32 	%f3406, %f1905, %f3406, %f1921;
	add.s64 	%rd408, %rd411, 112;
	// begin inline asm
	cvta.to.global.u64 %rd407, %rd408;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r539,%r540,%r541,%r542}, [%rd407];
	// end inline asm
	mov.b32 	%f1922, %r539;
	mov.b32 	%f1923, %r540;
	mov.b32 	%f1924, %r541;
	mov.b32 	%f1925, %r542;
	mul.ftz.f32 	%f1926, %f475, %f1922;
	mul.ftz.f32 	%f1927, %f475, %f1923;
	mul.ftz.f32 	%f1928, %f475, %f1924;
	mul.ftz.f32 	%f1929, %f475, %f1925;
	fma.rn.ftz.f32 	%f3399, %f1905, %f3399, %f1926;
	fma.rn.ftz.f32 	%f3400, %f1905, %f3400, %f1927;
	fma.rn.ftz.f32 	%f3401, %f1905, %f3401, %f1928;
	fma.rn.ftz.f32 	%f3402, %f1905, %f3402, %f1929;
	bra.uni 	$L__BB0_65;

$L__BB0_54:
	mov.f32 	%f3413, 0f3F800000;
	setp.eq.s32 	%p29, %r395, 4;
	@%p29 bra 	$L__BB0_57;

	setp.ne.s32 	%p30, %r395, 1;
	mov.f32 	%f3411, %f1757;
	mov.f32 	%f3412, %f1757;
	mov.f32 	%f3414, %f1757;
	mov.f32 	%f3415, %f1757;
	mov.f32 	%f3416, %f3413;
	mov.f32 	%f3417, %f1757;
	mov.f32 	%f3418, %f1757;
	mov.f32 	%f3419, %f3413;
	mov.f32 	%f3420, %f1757;
	mov.f32 	%f3421, %f1757;
	mov.f32 	%f3422, %f1757;
	@%p30 bra 	$L__BB0_66;

	// begin inline asm
	call (%rd295), _optix_get_static_transform_from_handle, (%rd293);
	// end inline asm
	add.s64 	%rd789, %rd295, 64;
	bra.uni 	$L__BB0_58;

$L__BB0_60:
	// begin inline asm
	call (%rd308), _optix_get_srt_motion_transform_from_handle, (%rd293);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd310, %rd308;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r409,%r410,%r411,%r412}, [%rd310];
	// end inline asm
	add.s64 	%rd314, %rd308, 16;
	// begin inline asm
	cvta.to.global.u64 %rd313, %rd314;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r413,%r414,%r415,%r416}, [%rd313];
	// end inline asm
	add.s64 	%rd317, %rd308, 32;
	// begin inline asm
	cvta.to.global.u64 %rd316, %rd317;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r417,%r418,%r419,%r420}, [%rd316];
	// end inline asm
	add.s64 	%rd320, %rd308, 48;
	// begin inline asm
	cvta.to.global.u64 %rd319, %rd320;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r421,%r422,%r423,%r424}, [%rd319];
	// end inline asm
	add.s64 	%rd323, %rd308, 64;
	// begin inline asm
	cvta.to.global.u64 %rd322, %rd323;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r425,%r426,%r427,%r428}, [%rd322];
	// end inline asm
	add.s64 	%rd326, %rd308, 80;
	// begin inline asm
	cvta.to.global.u64 %rd325, %rd326;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r429,%r430,%r431,%r432}, [%rd325];
	// end inline asm
	add.s64 	%rd329, %rd308, 96;
	// begin inline asm
	cvta.to.global.u64 %rd328, %rd329;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r433,%r434,%r435,%r436}, [%rd328];
	// end inline asm
	add.s64 	%rd332, %rd308, 112;
	// begin inline asm
	cvta.to.global.u64 %rd331, %rd332;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r437,%r438,%r439,%r440}, [%rd331];
	// end inline asm
	add.s64 	%rd335, %rd308, 128;
	// begin inline asm
	cvta.to.global.u64 %rd334, %rd335;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r441,%r442,%r443,%r444}, [%rd334];
	// end inline asm
	add.s64 	%rd338, %rd308, 144;
	// begin inline asm
	cvta.to.global.u64 %rd337, %rd338;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r445,%r446,%r447,%r448}, [%rd337];
	// end inline asm
	mov.b32 	%f1781, %r412;
	mov.b32 	%f1782, %r413;
	and.b32  	%r465, %r411, 65535;
	add.s32 	%r466, %r465, -1;
	cvt.rn.f32.s32 	%f1783, %r466;
	sub.ftz.f32 	%f1784, %f1766, %f1781;
	mul.ftz.f32 	%f1785, %f1784, %f1783;
	sub.ftz.f32 	%f1786, %f1782, %f1781;
	div.approx.ftz.f32 	%f1787, %f1785, %f1786;
	min.ftz.f32 	%f1788, %f1783, %f1787;
	mov.f32 	%f1789, 0f00000000;
	max.ftz.f32 	%f1790, %f1789, %f1788;
	cvt.rmi.ftz.f32.f32 	%f1791, %f1790;
	sub.ftz.f32 	%f414, %f1790, %f1791;
	cvt.rzi.ftz.s32.f32 	%r467, %f1791;
	mul.wide.s32 	%rd352, %r467, 64;
	add.s64 	%rd341, %rd317, %rd352;
	// begin inline asm
	cvta.to.global.u64 %rd340, %rd341;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r449,%r450,%r451,%r452}, [%rd340];
	// end inline asm
	mov.b32 	%f3395, %r449;
	mov.b32 	%f3394, %r450;
	mov.b32 	%f3393, %r451;
	mov.b32 	%f3392, %r452;
	add.s64 	%rd344, %rd341, 16;
	// begin inline asm
	cvta.to.global.u64 %rd343, %rd344;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r453,%r454,%r455,%r456}, [%rd343];
	// end inline asm
	mov.b32 	%f3391, %r453;
	mov.b32 	%f3390, %r454;
	mov.b32 	%f3389, %r455;
	mov.b32 	%f3388, %r456;
	add.s64 	%rd347, %rd341, 32;
	// begin inline asm
	cvta.to.global.u64 %rd346, %rd347;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r457,%r458,%r459,%r460}, [%rd346];
	// end inline asm
	mov.b32 	%f3387, %r457;
	mov.b32 	%f3386, %r458;
	mov.b32 	%f3385, %r459;
	mov.b32 	%f3384, %r460;
	add.s64 	%rd350, %rd341, 48;
	// begin inline asm
	cvta.to.global.u64 %rd349, %rd350;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r461,%r462,%r463,%r464}, [%rd349];
	// end inline asm
	mov.b32 	%f3383, %r461;
	mov.b32 	%f3396, %r462;
	mov.b32 	%f3397, %r463;
	mov.b32 	%f3398, %r464;
	setp.leu.ftz.f32 	%p32, %f414, 0f00000000;
	@%p32 bra 	$L__BB0_62;

	mov.f32 	%f1792, 0f3F800000;
	sub.ftz.f32 	%f1793, %f1792, %f414;
	add.s64 	%rd354, %rd341, 64;
	// begin inline asm
	cvta.to.global.u64 %rd353, %rd354;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r468,%r469,%r470,%r471}, [%rd353];
	// end inline asm
	mov.b32 	%f1794, %r468;
	mov.b32 	%f1795, %r469;
	mov.b32 	%f1796, %r470;
	mov.b32 	%f1797, %r471;
	mul.ftz.f32 	%f1798, %f414, %f1794;
	mul.ftz.f32 	%f1799, %f414, %f1795;
	mul.ftz.f32 	%f1800, %f414, %f1796;
	mul.ftz.f32 	%f1801, %f414, %f1797;
	fma.rn.ftz.f32 	%f3395, %f1793, %f3395, %f1798;
	fma.rn.ftz.f32 	%f3394, %f1793, %f3394, %f1799;
	fma.rn.ftz.f32 	%f3393, %f1793, %f3393, %f1800;
	fma.rn.ftz.f32 	%f3392, %f1793, %f3392, %f1801;
	add.s64 	%rd357, %rd341, 80;
	// begin inline asm
	cvta.to.global.u64 %rd356, %rd357;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r472,%r473,%r474,%r475}, [%rd356];
	// end inline asm
	mov.b32 	%f1802, %r472;
	mov.b32 	%f1803, %r473;
	mov.b32 	%f1804, %r474;
	mov.b32 	%f1805, %r475;
	mul.ftz.f32 	%f1806, %f414, %f1802;
	mul.ftz.f32 	%f1807, %f414, %f1803;
	mul.ftz.f32 	%f1808, %f414, %f1804;
	mul.ftz.f32 	%f1809, %f414, %f1805;
	fma.rn.ftz.f32 	%f3391, %f1793, %f3391, %f1806;
	fma.rn.ftz.f32 	%f3390, %f1793, %f3390, %f1807;
	fma.rn.ftz.f32 	%f3389, %f1793, %f3389, %f1808;
	fma.rn.ftz.f32 	%f3388, %f1793, %f3388, %f1809;
	add.s64 	%rd360, %rd341, 96;
	// begin inline asm
	cvta.to.global.u64 %rd359, %rd360;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r476,%r477,%r478,%r479}, [%rd359];
	// end inline asm
	mov.b32 	%f1810, %r476;
	mov.b32 	%f1811, %r477;
	mov.b32 	%f1812, %r478;
	mov.b32 	%f1813, %r479;
	mul.ftz.f32 	%f1814, %f414, %f1810;
	mul.ftz.f32 	%f1815, %f414, %f1811;
	mul.ftz.f32 	%f1816, %f414, %f1812;
	mul.ftz.f32 	%f1817, %f414, %f1813;
	fma.rn.ftz.f32 	%f3387, %f1793, %f3387, %f1814;
	fma.rn.ftz.f32 	%f1818, %f1793, %f3386, %f1815;
	fma.rn.ftz.f32 	%f1819, %f1793, %f3385, %f1816;
	fma.rn.ftz.f32 	%f1820, %f1793, %f3384, %f1817;
	add.s64 	%rd363, %rd341, 112;
	// begin inline asm
	cvta.to.global.u64 %rd362, %rd363;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r480,%r481,%r482,%r483}, [%rd362];
	// end inline asm
	mov.b32 	%f1821, %r480;
	mov.b32 	%f1822, %r481;
	mov.b32 	%f1823, %r482;
	mov.b32 	%f1824, %r483;
	mul.ftz.f32 	%f1825, %f414, %f1821;
	mul.ftz.f32 	%f1826, %f414, %f1822;
	mul.ftz.f32 	%f1827, %f414, %f1823;
	mul.ftz.f32 	%f1828, %f414, %f1824;
	fma.rn.ftz.f32 	%f1829, %f1793, %f3383, %f1825;
	fma.rn.ftz.f32 	%f3396, %f1793, %f3396, %f1826;
	fma.rn.ftz.f32 	%f3397, %f1793, %f3397, %f1827;
	fma.rn.ftz.f32 	%f3398, %f1793, %f3398, %f1828;
	mul.ftz.f32 	%f1830, %f1819, %f1819;
	fma.rn.ftz.f32 	%f1831, %f1818, %f1818, %f1830;
	fma.rn.ftz.f32 	%f1832, %f1820, %f1820, %f1831;
	fma.rn.ftz.f32 	%f1833, %f1829, %f1829, %f1832;
	rsqrt.approx.ftz.f32 	%f1834, %f1833;
	mul.ftz.f32 	%f3386, %f1818, %f1834;
	mul.ftz.f32 	%f3385, %f1819, %f1834;
	mul.ftz.f32 	%f3384, %f1820, %f1834;
	mul.ftz.f32 	%f3383, %f1834, %f1829;

$L__BB0_62:
	mul.ftz.f32 	%f1835, %f3386, %f3386;
	fma.rn.ftz.f32 	%f1836, %f3385, %f3385, %f1835;
	fma.rn.ftz.f32 	%f1837, %f3384, %f3384, %f1836;
	fma.rn.ftz.f32 	%f1838, %f3383, %f3383, %f1837;
	rcp.approx.ftz.f32 	%f1839, %f1838;
	mul.ftz.f32 	%f1840, %f3386, %f1839;
	mul.ftz.f32 	%f1841, %f3385, %f1839;
	mul.ftz.f32 	%f1842, %f3384, %f1839;
	mul.ftz.f32 	%f1843, %f3383, %f1839;
	mul.ftz.f32 	%f1844, %f3386, %f1840;
	mul.ftz.f32 	%f1845, %f3385, %f1841;
	mul.ftz.f32 	%f1846, %f3384, %f1842;
	mul.ftz.f32 	%f1847, %f3386, %f1841;
	mul.ftz.f32 	%f1848, %f3384, %f1843;
	mul.ftz.f32 	%f1849, %f3386, %f1842;
	mul.ftz.f32 	%f1850, %f3385, %f1843;
	mul.ftz.f32 	%f1851, %f3385, %f1842;
	mul.ftz.f32 	%f1852, %f3386, %f1843;
	sub.ftz.f32 	%f1853, %f1844, %f1845;
	sub.ftz.f32 	%f1854, %f1853, %f1846;
	fma.rn.ftz.f32 	%f1855, %f3383, %f1843, %f1854;
	sub.ftz.f32 	%f1856, %f1847, %f1848;
	add.ftz.f32 	%f1857, %f1856, %f1856;
	add.ftz.f32 	%f1858, %f1849, %f1850;
	add.ftz.f32 	%f1859, %f1858, %f1858;
	add.ftz.f32 	%f1860, %f1847, %f1848;
	add.ftz.f32 	%f1861, %f1860, %f1860;
	sub.ftz.f32 	%f1862, %f1845, %f1844;
	sub.ftz.f32 	%f1863, %f1862, %f1846;
	fma.rn.ftz.f32 	%f1864, %f3383, %f1843, %f1863;
	sub.ftz.f32 	%f1865, %f1851, %f1852;
	add.ftz.f32 	%f1866, %f1865, %f1865;
	sub.ftz.f32 	%f1867, %f1849, %f1850;
	add.ftz.f32 	%f1868, %f1867, %f1867;
	add.ftz.f32 	%f1869, %f1851, %f1852;
	add.ftz.f32 	%f1870, %f1869, %f1869;
	neg.ftz.f32 	%f1871, %f1844;
	sub.ftz.f32 	%f1872, %f1871, %f1845;
	add.ftz.f32 	%f1873, %f1846, %f1872;
	fma.rn.ftz.f32 	%f1874, %f3383, %f1843, %f1873;
	mul.ftz.f32 	%f1875, %f3392, %f1855;
	fma.rn.ftz.f32 	%f1876, %f3389, %f1857, %f1875;
	fma.rn.ftz.f32 	%f1877, %f3387, %f1859, %f1876;
	add.ftz.f32 	%f3410, %f3396, %f1877;
	mul.ftz.f32 	%f1878, %f3389, %f1864;
	fma.rn.ftz.f32 	%f1879, %f3392, %f1861, %f1878;
	fma.rn.ftz.f32 	%f1880, %f3387, %f1866, %f1879;
	add.ftz.f32 	%f3406, %f3397, %f1880;
	mul.ftz.f32 	%f1881, %f3389, %f1870;
	fma.rn.ftz.f32 	%f1882, %f3392, %f1868, %f1881;
	fma.rn.ftz.f32 	%f1883, %f3387, %f1874, %f1882;
	add.ftz.f32 	%f3402, %f1883, %f3398;
	mul.ftz.f32 	%f1884, %f3393, %f1855;
	fma.rn.ftz.f32 	%f1885, %f3390, %f1857, %f1884;
	fma.rn.ftz.f32 	%f3409, %f3388, %f1859, %f1885;
	mul.ftz.f32 	%f1886, %f3390, %f1864;
	fma.rn.ftz.f32 	%f1887, %f3393, %f1861, %f1886;
	fma.rn.ftz.f32 	%f3405, %f3388, %f1866, %f1887;
	mul.ftz.f32 	%f1888, %f3390, %f1870;
	fma.rn.ftz.f32 	%f1889, %f3393, %f1868, %f1888;
	fma.rn.ftz.f32 	%f3401, %f3388, %f1874, %f1889;
	mul.ftz.f32 	%f1890, %f3394, %f1855;
	fma.rn.ftz.f32 	%f3408, %f3391, %f1857, %f1890;
	mul.ftz.f32 	%f1891, %f3391, %f1864;
	fma.rn.ftz.f32 	%f3404, %f3394, %f1861, %f1891;
	mul.ftz.f32 	%f1892, %f3391, %f1870;
	fma.rn.ftz.f32 	%f3400, %f3394, %f1868, %f1892;
	mul.ftz.f32 	%f3407, %f3395, %f1855;
	mul.ftz.f32 	%f3403, %f1861, %f3395;
	mul.ftz.f32 	%f3399, %f1868, %f3395;

$L__BB0_65:
	mul.ftz.f32 	%f1930, %f3400, %f3405;
	mul.ftz.f32 	%f1931, %f3401, %f3404;
	sub.ftz.f32 	%f1932, %f1931, %f1930;
	mul.ftz.f32 	%f1933, %f3407, %f1932;
	mul.ftz.f32 	%f1934, %f3399, %f3405;
	mul.ftz.f32 	%f1935, %f3401, %f3403;
	sub.ftz.f32 	%f1936, %f1935, %f1934;
	mul.ftz.f32 	%f1937, %f1936, %f3408;
	sub.ftz.f32 	%f1938, %f1933, %f1937;
	mul.ftz.f32 	%f1939, %f3399, %f3404;
	mul.ftz.f32 	%f1940, %f3400, %f3403;
	sub.ftz.f32 	%f1941, %f1940, %f1939;
	fma.rn.ftz.f32 	%f1942, %f1941, %f3409, %f1938;
	rcp.approx.ftz.f32 	%f1943, %f1942;
	mul.ftz.f32 	%f3419, %f1932, %f1943;
	mul.ftz.f32 	%f1944, %f3401, %f3408;
	mul.ftz.f32 	%f1945, %f3400, %f3409;
	sub.ftz.f32 	%f1946, %f1945, %f1944;
	mul.ftz.f32 	%f3420, %f1946, %f1943;
	mul.ftz.f32 	%f1947, %f3404, %f3409;
	mul.ftz.f32 	%f1948, %f3405, %f3408;
	sub.ftz.f32 	%f1949, %f1948, %f1947;
	mul.ftz.f32 	%f3421, %f1949, %f1943;
	sub.ftz.f32 	%f1950, %f1934, %f1935;
	mul.ftz.f32 	%f3415, %f1950, %f1943;
	mul.ftz.f32 	%f1951, %f3399, %f3409;
	mul.ftz.f32 	%f1952, %f3401, %f3407;
	sub.ftz.f32 	%f1953, %f1952, %f1951;
	mul.ftz.f32 	%f3416, %f1953, %f1943;
	mul.ftz.f32 	%f1954, %f3405, %f3407;
	mul.ftz.f32 	%f1955, %f3403, %f3409;
	sub.ftz.f32 	%f1956, %f1955, %f1954;
	mul.ftz.f32 	%f3417, %f1956, %f1943;
	mul.ftz.f32 	%f3411, %f1941, %f1943;
	mul.ftz.f32 	%f1957, %f3400, %f3407;
	mul.ftz.f32 	%f1958, %f3399, %f3408;
	sub.ftz.f32 	%f1959, %f1958, %f1957;
	mul.ftz.f32 	%f3412, %f1959, %f1943;
	mul.ftz.f32 	%f1960, %f3403, %f3408;
	mul.ftz.f32 	%f1961, %f3404, %f3407;
	sub.ftz.f32 	%f1962, %f1961, %f1960;
	mul.ftz.f32 	%f3413, %f1962, %f1943;
	mul.ftz.f32 	%f1963, %f3410, %f3419;
	neg.ftz.f32 	%f1964, %f1963;
	mul.ftz.f32 	%f1965, %f3406, %f3420;
	sub.ftz.f32 	%f1966, %f1964, %f1965;
	mul.ftz.f32 	%f1967, %f3402, %f3421;
	sub.ftz.f32 	%f3422, %f1966, %f1967;
	mul.ftz.f32 	%f1968, %f3410, %f3415;
	neg.ftz.f32 	%f1969, %f1968;
	mul.ftz.f32 	%f1970, %f3406, %f3416;
	sub.ftz.f32 	%f1971, %f1969, %f1970;
	mul.ftz.f32 	%f1972, %f3402, %f3417;
	sub.ftz.f32 	%f3418, %f1971, %f1972;
	mul.ftz.f32 	%f1973, %f3410, %f3411;
	neg.ftz.f32 	%f1974, %f1973;
	mul.ftz.f32 	%f1975, %f3406, %f3412;
	sub.ftz.f32 	%f1976, %f1974, %f1975;
	mul.ftz.f32 	%f1977, %f3402, %f3413;
	sub.ftz.f32 	%f3414, %f1976, %f1977;
	bra.uni 	$L__BB0_66;

$L__BB0_57:
	// begin inline asm
	call (%rd789), _optix_get_instance_inverse_transform_from_handle, (%rd293);
	// end inline asm

$L__BB0_58:
	// begin inline asm
	cvta.to.global.u64 %rd299, %rd789;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r397,%r398,%r399,%r400}, [%rd299];
	// end inline asm
	mov.b32 	%f3419, %r397;
	mov.b32 	%f3420, %r398;
	mov.b32 	%f3421, %r399;
	mov.b32 	%f3422, %r400;
	add.s64 	%rd303, %rd789, 16;
	// begin inline asm
	cvta.to.global.u64 %rd302, %rd303;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r401,%r402,%r403,%r404}, [%rd302];
	// end inline asm
	mov.b32 	%f3415, %r401;
	mov.b32 	%f3416, %r402;
	mov.b32 	%f3417, %r403;
	mov.b32 	%f3418, %r404;
	add.s64 	%rd306, %rd789, 32;
	// begin inline asm
	cvta.to.global.u64 %rd305, %rd306;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r405,%r406,%r407,%r408}, [%rd305];
	// end inline asm
	mov.b32 	%f3411, %r405;
	mov.b32 	%f3412, %r406;
	mov.b32 	%f3413, %r407;
	mov.b32 	%f3414, %r408;

$L__BB0_66:
	setp.eq.s32 	%p34, %r1159, 0;
	@%p34 bra 	$L__BB0_68;

	mul.ftz.f32 	%f1978, %f3378, %f3420;
	fma.rn.ftz.f32 	%f1979, %f3374, %f3419, %f1978;
	fma.rn.ftz.f32 	%f536, %f3382, %f3421, %f1979;
	mul.ftz.f32 	%f1980, %f3377, %f3420;
	fma.rn.ftz.f32 	%f1981, %f3373, %f3419, %f1980;
	fma.rn.ftz.f32 	%f537, %f3381, %f3421, %f1981;
	mul.ftz.f32 	%f1982, %f3376, %f3420;
	fma.rn.ftz.f32 	%f1983, %f3372, %f3419, %f1982;
	fma.rn.ftz.f32 	%f538, %f3380, %f3421, %f1983;
	mul.ftz.f32 	%f1984, %f3375, %f3420;
	fma.rn.ftz.f32 	%f1985, %f3371, %f3419, %f1984;
	fma.rn.ftz.f32 	%f1986, %f3379, %f3421, %f1985;
	add.ftz.f32 	%f3422, %f3422, %f1986;
	mul.ftz.f32 	%f1987, %f3378, %f3416;
	fma.rn.ftz.f32 	%f1988, %f3374, %f3415, %f1987;
	fma.rn.ftz.f32 	%f540, %f3382, %f3417, %f1988;
	mul.ftz.f32 	%f1989, %f3377, %f3416;
	fma.rn.ftz.f32 	%f1990, %f3373, %f3415, %f1989;
	fma.rn.ftz.f32 	%f541, %f3381, %f3417, %f1990;
	mul.ftz.f32 	%f1991, %f3376, %f3416;
	fma.rn.ftz.f32 	%f1992, %f3372, %f3415, %f1991;
	fma.rn.ftz.f32 	%f542, %f3380, %f3417, %f1992;
	mul.ftz.f32 	%f1993, %f3375, %f3416;
	fma.rn.ftz.f32 	%f1994, %f3371, %f3415, %f1993;
	fma.rn.ftz.f32 	%f1995, %f3379, %f3417, %f1994;
	add.ftz.f32 	%f3418, %f3418, %f1995;
	mul.ftz.f32 	%f1996, %f3378, %f3412;
	fma.rn.ftz.f32 	%f1997, %f3374, %f3411, %f1996;
	fma.rn.ftz.f32 	%f544, %f3382, %f3413, %f1997;
	mul.ftz.f32 	%f1998, %f3377, %f3412;
	fma.rn.ftz.f32 	%f1999, %f3373, %f3411, %f1998;
	fma.rn.ftz.f32 	%f545, %f3381, %f3413, %f1999;
	mul.ftz.f32 	%f2000, %f3376, %f3412;
	fma.rn.ftz.f32 	%f2001, %f3372, %f3411, %f2000;
	fma.rn.ftz.f32 	%f546, %f3380, %f3413, %f2001;
	mul.ftz.f32 	%f2002, %f3375, %f3412;
	fma.rn.ftz.f32 	%f2003, %f3371, %f3411, %f2002;
	fma.rn.ftz.f32 	%f2004, %f3379, %f3413, %f2003;
	add.ftz.f32 	%f3414, %f3414, %f2004;
	mov.f32 	%f3411, %f544;
	mov.f32 	%f3412, %f545;
	mov.f32 	%f3413, %f546;
	mov.f32 	%f3415, %f540;
	mov.f32 	%f3416, %f541;
	mov.f32 	%f3417, %f542;
	mov.f32 	%f3419, %f536;
	mov.f32 	%f3420, %f537;
	mov.f32 	%f3421, %f538;

$L__BB0_68:
	add.s32 	%r1159, %r1159, 1;
	setp.lt.u32 	%p35, %r1159, %r392;
	mov.f32 	%f3371, %f3422;
	mov.f32 	%f3372, %f3421;
	mov.f32 	%f3373, %f3420;
	mov.f32 	%f3374, %f3419;
	mov.f32 	%f3375, %f3418;
	mov.f32 	%f3376, %f3417;
	mov.f32 	%f3377, %f3416;
	mov.f32 	%f3378, %f3415;
	mov.f32 	%f3379, %f3414;
	mov.f32 	%f3380, %f3413;
	mov.f32 	%f3381, %f3412;
	mov.f32 	%f3382, %f3411;
	@%p35 bra 	$L__BB0_53;

$L__BB0_69:
	mul.ftz.f32 	%f2005, %f2, %f3420;
	fma.rn.ftz.f32 	%f2006, %f1, %f3419, %f2005;
	fma.rn.ftz.f32 	%f2007, %f3, %f3421, %f2006;
	mul.ftz.f32 	%f2008, %f2, %f3416;
	fma.rn.ftz.f32 	%f2009, %f1, %f3415, %f2008;
	fma.rn.ftz.f32 	%f2010, %f3, %f3417, %f2009;
	mul.ftz.f32 	%f2011, %f2, %f3412;
	fma.rn.ftz.f32 	%f2012, %f1, %f3411, %f2011;
	fma.rn.ftz.f32 	%f2013, %f3, %f3413, %f2012;
	add.ftz.f32 	%f3449, %f3414, %f2013;
	add.ftz.f32 	%f3448, %f3418, %f2010;
	add.ftz.f32 	%f3447, %f3422, %f2007;
	bra.uni 	$L__BB0_71;

$L__BB0_23:
	mov.f32 	%f207, %f1;
	mov.f32 	%f208, %f2;
	mov.f32 	%f209, %f3;

$L__BB0_24:
	// begin inline asm
	call (%r235), _optix_get_attribute_0, ();
	// end inline asm
	mov.b32 	%f213, %r235;
	setp.eq.ftz.f32 	%p14, %f213, 0f00000000;
	@%p14 bra 	$L__BB0_28;
	bra.uni 	$L__BB0_25;

$L__BB0_28:
	sub.ftz.f32 	%f3313, %f207, %f1250;
	sub.ftz.f32 	%f3314, %f208, %f1251;
	sub.ftz.f32 	%f3315, %f209, %f1252;
	bra.uni 	$L__BB0_29;

$L__BB0_117:
	mov.f32 	%f3584, %f1;
	mov.f32 	%f3585, %f2;
	mov.f32 	%f3586, %f3;

$L__BB0_118:
	// begin inline asm
	call (%r851), _optix_get_attribute_0, ();
	// end inline asm
	mov.b32 	%f951, %r851;
	setp.eq.ftz.f32 	%p58, %f951, 0f00000000;
	@%p58 bra 	$L__BB0_122;
	bra.uni 	$L__BB0_119;

$L__BB0_122:
	fma.rn.ftz.f32 	%f2646, %f752, 0f00000000, %f748;
	fma.rn.ftz.f32 	%f2647, %f753, 0f00000000, %f749;
	fma.rn.ftz.f32 	%f2648, %f754, 0f00000000, %f750;
	neg.ftz.f32 	%f3587, %f2646;
	neg.ftz.f32 	%f3588, %f2647;
	neg.ftz.f32 	%f3589, %f2648;
	bra.uni 	$L__BB0_123;

$L__BB0_70:
	mov.f32 	%f3447, %f1;
	mov.f32 	%f3448, %f2;
	mov.f32 	%f3449, %f3;

$L__BB0_71:
	// begin inline asm
	call (%r543), _optix_get_attribute_0, ();
	// end inline asm
	mov.b32 	%f584, %r543;
	setp.eq.ftz.f32 	%p36, %f584, 0f00000000;
	@%p36 bra 	$L__BB0_75;
	bra.uni 	$L__BB0_72;

$L__BB0_75:
	mov.f32 	%f2118, 0f3F800000;
	sub.ftz.f32 	%f2119, %f2118, 0f358637BD;
	mul.ftz.f32 	%f2120, %f2119, 0f3F000000;
	mul.ftz.f32 	%f2121, %f2120, %f2119;
	add.ftz.f32 	%f2122, %f2119, %f2119;
	mul.ftz.f32 	%f2123, %f2122, 0f358637BD;
	mul.ftz.f32 	%f2124, %f381, %f2123;
	fma.rn.ftz.f32 	%f2125, %f377, %f2121, %f2124;
	mul.ftz.f32 	%f2126, %f382, %f2123;
	fma.rn.ftz.f32 	%f2127, %f378, %f2121, %f2126;
	mul.ftz.f32 	%f2128, %f383, %f2123;
	fma.rn.ftz.f32 	%f2129, %f379, %f2121, %f2128;
	fma.rn.ftz.f32 	%f2130, %f385, 0f2B0CBCCC, %f2125;
	fma.rn.ftz.f32 	%f2131, %f386, 0f2B0CBCCC, %f2127;
	fma.rn.ftz.f32 	%f2132, %f387, 0f2B0CBCCC, %f2129;
	neg.ftz.f32 	%f3450, %f2130;
	neg.ftz.f32 	%f3451, %f2131;
	neg.ftz.f32 	%f3452, %f2132;
	bra.uni 	$L__BB0_76;

$L__BB0_25:
	setp.ltu.ftz.f32 	%p15, %f213, 0f3F800000;
	@%p15 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_26;

$L__BB0_27:
	sub.ftz.f32 	%f1510, %f1257, %f1253;
	fma.rn.ftz.f32 	%f1511, %f13, %f213, %f1250;
	fma.rn.ftz.f32 	%f1512, %f15, %f213, %f1251;
	fma.rn.ftz.f32 	%f1513, %f17, %f213, %f1252;
	fma.rn.ftz.f32 	%f1514, %f1510, %f213, %f1253;
	mul.ftz.f32 	%f1515, %f15, %f15;
	fma.rn.ftz.f32 	%f1516, %f13, %f13, %f1515;
	fma.rn.ftz.f32 	%f1517, %f17, %f17, %f1516;
	sub.ftz.f32 	%f1518, %f207, %f1511;
	sub.ftz.f32 	%f1519, %f208, %f1512;
	sub.ftz.f32 	%f1520, %f209, %f1513;
	mul.ftz.f32 	%f1521, %f15, %f1519;
	fma.rn.ftz.f32 	%f1522, %f13, %f1518, %f1521;
	fma.rn.ftz.f32 	%f1523, %f17, %f1520, %f1522;
	div.approx.ftz.f32 	%f1524, %f1523, %f1517;
	mul.ftz.f32 	%f1525, %f13, %f1524;
	mul.ftz.f32 	%f1526, %f15, %f1524;
	mul.ftz.f32 	%f1527, %f17, %f1524;
	sub.ftz.f32 	%f1528, %f1518, %f1525;
	sub.ftz.f32 	%f1529, %f1519, %f1526;
	sub.ftz.f32 	%f1530, %f1520, %f1527;
	mul.ftz.f32 	%f1531, %f1529, %f1529;
	fma.rn.ftz.f32 	%f1532, %f1528, %f1528, %f1531;
	fma.rn.ftz.f32 	%f1533, %f1530, %f1530, %f1532;
	sqrt.approx.ftz.f32 	%f1534, %f1533;
	div.approx.ftz.f32 	%f1535, %f1514, %f1534;
	mul.ftz.f32 	%f1536, %f1528, %f1535;
	mul.ftz.f32 	%f1537, %f1529, %f1535;
	mul.ftz.f32 	%f1538, %f1530, %f1535;
	mul.ftz.f32 	%f1539, %f1517, %f1536;
	mul.ftz.f32 	%f1540, %f1517, %f1537;
	mul.ftz.f32 	%f1541, %f1517, %f1538;
	mul.ftz.f32 	%f1542, %f1510, %f1514;
	mul.ftz.f32 	%f1543, %f13, %f1542;
	mul.ftz.f32 	%f1544, %f15, %f1542;
	mul.ftz.f32 	%f1545, %f17, %f1542;
	sub.ftz.f32 	%f3313, %f1539, %f1543;
	sub.ftz.f32 	%f3314, %f1540, %f1544;
	sub.ftz.f32 	%f3315, %f1541, %f1545;
	bra.uni 	$L__BB0_29;

$L__BB0_119:
	setp.eq.ftz.f32 	%p59, %f951, 0f3F800000;
	add.ftz.f32 	%f952, %f752, %f752;
	add.ftz.f32 	%f953, %f753, %f753;
	add.ftz.f32 	%f954, %f754, %f754;
	@%p59 bra 	$L__BB0_121;
	bra.uni 	$L__BB0_120;

$L__BB0_121:
	add.ftz.f32 	%f3587, %f748, %f952;
	add.ftz.f32 	%f3588, %f749, %f953;
	add.ftz.f32 	%f3589, %f750, %f954;
	bra.uni 	$L__BB0_123;

$L__BB0_72:
	setp.eq.ftz.f32 	%p37, %f584, 0f3F800000;
	@%p37 bra 	$L__BB0_74;
	bra.uni 	$L__BB0_73;

$L__BB0_74:
	mov.f32 	%f2106, 0f3F800000;
	sub.ftz.f32 	%f2107, %f2106, 0f3F7FFFEF;
	mul.ftz.f32 	%f2108, %f2107, 0f3F000000;
	mul.ftz.f32 	%f2109, %f2108, %f2107;
	add.ftz.f32 	%f2110, %f2107, %f2107;
	mul.ftz.f32 	%f2111, %f2110, 0f3F7FFFEF;
	mul.ftz.f32 	%f2112, %f381, %f2111;
	fma.rn.ftz.f32 	%f2113, %f377, %f2109, %f2112;
	mul.ftz.f32 	%f2114, %f382, %f2111;
	fma.rn.ftz.f32 	%f2115, %f378, %f2109, %f2114;
	mul.ftz.f32 	%f2116, %f383, %f2111;
	fma.rn.ftz.f32 	%f2117, %f379, %f2109, %f2116;
	fma.rn.ftz.f32 	%f3450, %f385, 0f3EFFFFDE, %f2113;
	fma.rn.ftz.f32 	%f3451, %f386, 0f3EFFFFDE, %f2115;
	fma.rn.ftz.f32 	%f3452, %f387, 0f3EFFFFDE, %f2117;
	bra.uni 	$L__BB0_76;

$L__BB0_26:
	add.ftz.f32 	%f1507, %f1250, %f13;
	sub.ftz.f32 	%f3313, %f207, %f1507;
	add.ftz.f32 	%f1508, %f1251, %f15;
	sub.ftz.f32 	%f3314, %f208, %f1508;
	add.ftz.f32 	%f1509, %f1252, %f17;
	sub.ftz.f32 	%f3315, %f209, %f1509;

$L__BB0_29:
	mul.ftz.f32 	%f1546, %f3314, %f3314;
	fma.rn.ftz.f32 	%f1547, %f3313, %f3313, %f1546;
	fma.rn.ftz.f32 	%f1548, %f3315, %f3315, %f1547;
	rsqrt.approx.ftz.f32 	%f1549, %f1548;
	mul.ftz.f32 	%f3650, %f3313, %f1549;
	mul.ftz.f32 	%f3649, %f3314, %f1549;
	mul.ftz.f32 	%f228, %f3315, %f1549;
	// begin inline asm
	call (%r236), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p16, %r236, 0;
	@%p16 bra 	$L__BB0_49;

	// begin inline asm
	call (%r237), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1550), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p17, %r237, 0;
	@%p17 bra 	$L__BB0_48;

	mov.u32 	%r1158, 0;

$L__BB0_32:
	.pragma "nounroll";
	// begin inline asm
	call (%rd172), _optix_get_transform_list_handle, (%r1158);
	// end inline asm
	// begin inline asm
	call (%r240), _optix_get_transform_type_from_handle, (%rd172);
	// end inline asm
	or.b32  	%r241, %r240, 1;
	setp.eq.s32 	%p18, %r241, 3;
	@%p18 bra 	$L__BB0_38;
	bra.uni 	$L__BB0_33;

$L__BB0_38:
	setp.eq.s32 	%p21, %r240, 2;
	@%p21 bra 	$L__BB0_42;
	bra.uni 	$L__BB0_39;

$L__BB0_42:
	// begin inline asm
	call (%rd244), _optix_get_matrix_motion_transform_from_handle, (%rd172);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd246, %rd244;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r329,%r330,%r331,%r332}, [%rd246];
	// end inline asm
	add.s64 	%rd250, %rd244, 16;
	// begin inline asm
	cvta.to.global.u64 %rd249, %rd250;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r333,%r334,%r335,%r336}, [%rd249];
	// end inline asm
	add.s64 	%rd253, %rd244, 32;
	// begin inline asm
	cvta.to.global.u64 %rd252, %rd253;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r337,%r338,%r339,%r340}, [%rd252];
	// end inline asm
	add.s64 	%rd256, %rd244, 48;
	// begin inline asm
	cvta.to.global.u64 %rd255, %rd256;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r341,%r342,%r343,%r344}, [%rd255];
	// end inline asm
	add.s64 	%rd259, %rd244, 64;
	// begin inline asm
	cvta.to.global.u64 %rd258, %rd259;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r345,%r346,%r347,%r348}, [%rd258];
	// end inline asm
	add.s64 	%rd262, %rd244, 80;
	// begin inline asm
	cvta.to.global.u64 %rd261, %rd262;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r349,%r350,%r351,%r352}, [%rd261];
	// end inline asm
	add.s64 	%rd265, %rd244, 96;
	// begin inline asm
	cvta.to.global.u64 %rd264, %rd265;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r353,%r354,%r355,%r356}, [%rd264];
	// end inline asm
	add.s64 	%rd268, %rd244, 112;
	// begin inline asm
	cvta.to.global.u64 %rd267, %rd268;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r357,%r358,%r359,%r360}, [%rd267];
	// end inline asm
	mov.b32 	%f1653, %r332;
	mov.b32 	%f1654, %r333;
	and.b32  	%r373, %r331, 65535;
	add.s32 	%r374, %r373, -1;
	cvt.rn.f32.s32 	%f1655, %r374;
	sub.ftz.f32 	%f1656, %f1550, %f1653;
	mul.ftz.f32 	%f1657, %f1656, %f1655;
	sub.ftz.f32 	%f1658, %f1654, %f1653;
	div.approx.ftz.f32 	%f1659, %f1657, %f1658;
	min.ftz.f32 	%f1660, %f1655, %f1659;
	mov.f32 	%f1661, 0f00000000;
	max.ftz.f32 	%f1662, %f1661, %f1660;
	cvt.rmi.ftz.f32.f32 	%f1663, %f1662;
	sub.ftz.f32 	%f288, %f1662, %f1663;
	cvt.rzi.ftz.s32.f32 	%r375, %f1663;
	cvt.s64.s32 	%rd15, %r375;
	mul.wide.s32 	%rd279, %r375, 48;
	add.s64 	%rd271, %rd253, %rd279;
	// begin inline asm
	cvta.to.global.u64 %rd270, %rd271;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r361,%r362,%r363,%r364}, [%rd270];
	// end inline asm
	mov.b32 	%f3341, %r361;
	mov.b32 	%f3342, %r362;
	mov.b32 	%f3343, %r363;
	add.s64 	%rd274, %rd271, 16;
	// begin inline asm
	cvta.to.global.u64 %rd273, %rd274;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r365,%r366,%r367,%r368}, [%rd273];
	// end inline asm
	mov.b32 	%f3338, %r365;
	mov.b32 	%f3339, %r366;
	mov.b32 	%f3340, %r367;
	add.s64 	%rd277, %rd271, 32;
	// begin inline asm
	cvta.to.global.u64 %rd276, %rd277;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r369,%r370,%r371,%r372}, [%rd276];
	// end inline asm
	mov.b32 	%f3335, %r369;
	mov.b32 	%f3336, %r370;
	mov.b32 	%f3337, %r371;
	setp.leu.ftz.f32 	%p23, %f288, 0f00000000;
	@%p23 bra 	$L__BB0_44;

	mov.f32 	%f1664, 0f3F800000;
	sub.ftz.f32 	%f1665, %f1664, %f288;
	mul.lo.s64 	%rd289, %rd15, 48;
	add.s64 	%rd290, %rd244, %rd289;
	add.s64 	%rd281, %rd290, 80;
	// begin inline asm
	cvta.to.global.u64 %rd280, %rd281;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r376,%r377,%r378,%r379}, [%rd280];
	// end inline asm
	mov.b32 	%f1666, %r376;
	mov.b32 	%f1667, %r377;
	mov.b32 	%f1668, %r378;
	mul.ftz.f32 	%f1669, %f288, %f1666;
	mul.ftz.f32 	%f1670, %f288, %f1667;
	mul.ftz.f32 	%f1671, %f288, %f1668;
	fma.rn.ftz.f32 	%f3341, %f1665, %f3341, %f1669;
	fma.rn.ftz.f32 	%f3342, %f1665, %f3342, %f1670;
	fma.rn.ftz.f32 	%f3343, %f1665, %f3343, %f1671;
	add.s64 	%rd284, %rd290, 96;
	// begin inline asm
	cvta.to.global.u64 %rd283, %rd284;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r380,%r381,%r382,%r383}, [%rd283];
	// end inline asm
	mov.b32 	%f1672, %r380;
	mov.b32 	%f1673, %r381;
	mov.b32 	%f1674, %r382;
	mul.ftz.f32 	%f1675, %f288, %f1672;
	mul.ftz.f32 	%f1676, %f288, %f1673;
	mul.ftz.f32 	%f1677, %f288, %f1674;
	fma.rn.ftz.f32 	%f3338, %f1665, %f3338, %f1675;
	fma.rn.ftz.f32 	%f3339, %f1665, %f3339, %f1676;
	fma.rn.ftz.f32 	%f3340, %f1665, %f3340, %f1677;
	add.s64 	%rd287, %rd290, 112;
	// begin inline asm
	cvta.to.global.u64 %rd286, %rd287;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r384,%r385,%r386,%r387}, [%rd286];
	// end inline asm
	mov.b32 	%f1678, %r384;
	mov.b32 	%f1679, %r385;
	mov.b32 	%f1680, %r386;
	mul.ftz.f32 	%f1681, %f288, %f1678;
	mul.ftz.f32 	%f1682, %f288, %f1679;
	mul.ftz.f32 	%f1683, %f288, %f1680;
	fma.rn.ftz.f32 	%f3335, %f1665, %f3335, %f1681;
	fma.rn.ftz.f32 	%f3336, %f1665, %f3336, %f1682;
	fma.rn.ftz.f32 	%f3337, %f1665, %f3337, %f1683;
	bra.uni 	$L__BB0_44;

$L__BB0_33:
	mov.f32 	%f3344, 0f00000000;
	mov.f32 	%f3346, 0f3F800000;
	setp.eq.s32 	%p19, %r240, 4;
	@%p19 bra 	$L__BB0_36;

	setp.ne.s32 	%p20, %r240, 1;
	mov.f32 	%f3345, %f3344;
	mov.f32 	%f3347, %f3344;
	mov.f32 	%f3348, %f3346;
	mov.f32 	%f3349, %f3344;
	mov.f32 	%f3350, %f3346;
	mov.f32 	%f3351, %f3344;
	mov.f32 	%f3352, %f3344;
	@%p20 bra 	$L__BB0_45;

	// begin inline asm
	call (%rd174), _optix_get_static_transform_from_handle, (%rd172);
	// end inline asm
	add.s64 	%rd788, %rd174, 64;
	bra.uni 	$L__BB0_37;

$L__BB0_39:
	// begin inline asm
	call (%rd187), _optix_get_srt_motion_transform_from_handle, (%rd172);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd189, %rd187;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd189];
	// end inline asm
	add.s64 	%rd193, %rd187, 16;
	// begin inline asm
	cvta.to.global.u64 %rd192, %rd193;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r258,%r259,%r260,%r261}, [%rd192];
	// end inline asm
	add.s64 	%rd196, %rd187, 32;
	// begin inline asm
	cvta.to.global.u64 %rd195, %rd196;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r262,%r263,%r264,%r265}, [%rd195];
	// end inline asm
	add.s64 	%rd199, %rd187, 48;
	// begin inline asm
	cvta.to.global.u64 %rd198, %rd199;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r266,%r267,%r268,%r269}, [%rd198];
	// end inline asm
	add.s64 	%rd202, %rd187, 64;
	// begin inline asm
	cvta.to.global.u64 %rd201, %rd202;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r270,%r271,%r272,%r273}, [%rd201];
	// end inline asm
	add.s64 	%rd205, %rd187, 80;
	// begin inline asm
	cvta.to.global.u64 %rd204, %rd205;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r274,%r275,%r276,%r277}, [%rd204];
	// end inline asm
	add.s64 	%rd208, %rd187, 96;
	// begin inline asm
	cvta.to.global.u64 %rd207, %rd208;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r278,%r279,%r280,%r281}, [%rd207];
	// end inline asm
	add.s64 	%rd211, %rd187, 112;
	// begin inline asm
	cvta.to.global.u64 %rd210, %rd211;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r282,%r283,%r284,%r285}, [%rd210];
	// end inline asm
	add.s64 	%rd214, %rd187, 128;
	// begin inline asm
	cvta.to.global.u64 %rd213, %rd214;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r286,%r287,%r288,%r289}, [%rd213];
	// end inline asm
	add.s64 	%rd217, %rd187, 144;
	// begin inline asm
	cvta.to.global.u64 %rd216, %rd217;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r290,%r291,%r292,%r293}, [%rd216];
	// end inline asm
	mov.b32 	%f1562, %r257;
	mov.b32 	%f1563, %r258;
	and.b32  	%r310, %r256, 65535;
	add.s32 	%r311, %r310, -1;
	cvt.rn.f32.s32 	%f1564, %r311;
	sub.ftz.f32 	%f1565, %f1550, %f1562;
	mul.ftz.f32 	%f1566, %f1565, %f1564;
	sub.ftz.f32 	%f1567, %f1563, %f1562;
	div.approx.ftz.f32 	%f1568, %f1566, %f1567;
	min.ftz.f32 	%f1569, %f1564, %f1568;
	mov.f32 	%f1570, 0f00000000;
	max.ftz.f32 	%f1571, %f1570, %f1569;
	cvt.rmi.ftz.f32.f32 	%f1572, %f1571;
	sub.ftz.f32 	%f248, %f1571, %f1572;
	cvt.rzi.ftz.s32.f32 	%r312, %f1572;
	mul.wide.s32 	%rd231, %r312, 64;
	add.s64 	%rd220, %rd196, %rd231;
	// begin inline asm
	cvta.to.global.u64 %rd219, %rd220;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r294,%r295,%r296,%r297}, [%rd219];
	// end inline asm
	mov.b32 	%f3334, %r294;
	mov.b32 	%f3333, %r295;
	mov.b32 	%f3332, %r296;
	add.s64 	%rd223, %rd220, 16;
	// begin inline asm
	cvta.to.global.u64 %rd222, %rd223;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r298,%r299,%r300,%r301}, [%rd222];
	// end inline asm
	mov.b32 	%f3331, %r298;
	mov.b32 	%f3330, %r299;
	mov.b32 	%f3329, %r301;
	add.s64 	%rd226, %rd220, 32;
	// begin inline asm
	cvta.to.global.u64 %rd225, %rd226;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r302,%r303,%r304,%r305}, [%rd225];
	// end inline asm
	mov.b32 	%f3328, %r303;
	mov.b32 	%f3327, %r304;
	mov.b32 	%f3326, %r305;
	add.s64 	%rd229, %rd220, 48;
	// begin inline asm
	cvta.to.global.u64 %rd228, %rd229;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r306,%r307,%r308,%r309}, [%rd228];
	// end inline asm
	mov.b32 	%f3325, %r306;
	setp.leu.ftz.f32 	%p22, %f248, 0f00000000;
	@%p22 bra 	$L__BB0_41;

	mov.f32 	%f1573, 0f3F800000;
	sub.ftz.f32 	%f1574, %f1573, %f248;
	add.s64 	%rd233, %rd220, 64;
	// begin inline asm
	cvta.to.global.u64 %rd232, %rd233;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r313,%r314,%r315,%r316}, [%rd232];
	// end inline asm
	mov.b32 	%f1575, %r313;
	mov.b32 	%f1576, %r314;
	mov.b32 	%f1577, %r315;
	mul.ftz.f32 	%f1578, %f248, %f1575;
	mul.ftz.f32 	%f1579, %f248, %f1576;
	mul.ftz.f32 	%f1580, %f248, %f1577;
	fma.rn.ftz.f32 	%f3334, %f1574, %f3334, %f1578;
	fma.rn.ftz.f32 	%f3333, %f1574, %f3333, %f1579;
	fma.rn.ftz.f32 	%f3332, %f1574, %f3332, %f1580;
	add.s64 	%rd236, %rd220, 80;
	// begin inline asm
	cvta.to.global.u64 %rd235, %rd236;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r317,%r318,%r319,%r320}, [%rd235];
	// end inline asm
	mov.b32 	%f1581, %r317;
	mov.b32 	%f1582, %r318;
	mov.b32 	%f1583, %r320;
	mul.ftz.f32 	%f1584, %f248, %f1581;
	mul.ftz.f32 	%f1585, %f248, %f1582;
	mul.ftz.f32 	%f1586, %f248, %f1583;
	fma.rn.ftz.f32 	%f3331, %f1574, %f3331, %f1584;
	fma.rn.ftz.f32 	%f3330, %f1574, %f3330, %f1585;
	fma.rn.ftz.f32 	%f3329, %f1574, %f3329, %f1586;
	add.s64 	%rd239, %rd220, 96;
	// begin inline asm
	cvta.to.global.u64 %rd238, %rd239;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r321,%r322,%r323,%r324}, [%rd238];
	// end inline asm
	mov.b32 	%f1587, %r322;
	mov.b32 	%f1588, %r323;
	mov.b32 	%f1589, %r324;
	mul.ftz.f32 	%f1590, %f248, %f1587;
	mul.ftz.f32 	%f1591, %f248, %f1588;
	mul.ftz.f32 	%f1592, %f248, %f1589;
	fma.rn.ftz.f32 	%f1593, %f1574, %f3328, %f1590;
	fma.rn.ftz.f32 	%f1594, %f1574, %f3327, %f1591;
	fma.rn.ftz.f32 	%f1595, %f1574, %f3326, %f1592;
	add.s64 	%rd242, %rd220, 112;
	// begin inline asm
	cvta.to.global.u64 %rd241, %rd242;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r325,%r326,%r327,%r328}, [%rd241];
	// end inline asm
	mov.b32 	%f1596, %r325;
	mul.ftz.f32 	%f1597, %f248, %f1596;
	fma.rn.ftz.f32 	%f1598, %f1574, %f3325, %f1597;
	mul.ftz.f32 	%f1599, %f1594, %f1594;
	fma.rn.ftz.f32 	%f1600, %f1593, %f1593, %f1599;
	fma.rn.ftz.f32 	%f1601, %f1595, %f1595, %f1600;
	fma.rn.ftz.f32 	%f1602, %f1598, %f1598, %f1601;
	rsqrt.approx.ftz.f32 	%f1603, %f1602;
	mul.ftz.f32 	%f3328, %f1593, %f1603;
	mul.ftz.f32 	%f3327, %f1594, %f1603;
	mul.ftz.f32 	%f3326, %f1595, %f1603;
	mul.ftz.f32 	%f3325, %f1603, %f1598;

$L__BB0_41:
	mul.ftz.f32 	%f1604, %f3328, %f3328;
	fma.rn.ftz.f32 	%f1605, %f3327, %f3327, %f1604;
	fma.rn.ftz.f32 	%f1606, %f3326, %f3326, %f1605;
	fma.rn.ftz.f32 	%f1607, %f3325, %f3325, %f1606;
	rcp.approx.ftz.f32 	%f1608, %f1607;
	mul.ftz.f32 	%f1609, %f3328, %f1608;
	mul.ftz.f32 	%f1610, %f3327, %f1608;
	mul.ftz.f32 	%f1611, %f3326, %f1608;
	mul.ftz.f32 	%f1612, %f3325, %f1608;
	mul.ftz.f32 	%f1613, %f3328, %f1609;
	mul.ftz.f32 	%f1614, %f3327, %f1610;
	mul.ftz.f32 	%f1615, %f3326, %f1611;
	mul.ftz.f32 	%f1616, %f3328, %f1610;
	mul.ftz.f32 	%f1617, %f3326, %f1612;
	mul.ftz.f32 	%f1618, %f3328, %f1611;
	mul.ftz.f32 	%f1619, %f3327, %f1612;
	mul.ftz.f32 	%f1620, %f3327, %f1611;
	mul.ftz.f32 	%f1621, %f3328, %f1612;
	sub.ftz.f32 	%f1622, %f1613, %f1614;
	sub.ftz.f32 	%f1623, %f1622, %f1615;
	fma.rn.ftz.f32 	%f1624, %f3325, %f1612, %f1623;
	sub.ftz.f32 	%f1625, %f1616, %f1617;
	add.ftz.f32 	%f1626, %f1625, %f1625;
	add.ftz.f32 	%f1627, %f1618, %f1619;
	add.ftz.f32 	%f1628, %f1627, %f1627;
	add.ftz.f32 	%f1629, %f1616, %f1617;
	add.ftz.f32 	%f1630, %f1629, %f1629;
	sub.ftz.f32 	%f1631, %f1614, %f1613;
	sub.ftz.f32 	%f1632, %f1631, %f1615;
	fma.rn.ftz.f32 	%f1633, %f3325, %f1612, %f1632;
	sub.ftz.f32 	%f1634, %f1620, %f1621;
	add.ftz.f32 	%f1635, %f1634, %f1634;
	sub.ftz.f32 	%f1636, %f1618, %f1619;
	add.ftz.f32 	%f1637, %f1636, %f1636;
	add.ftz.f32 	%f1638, %f1620, %f1621;
	add.ftz.f32 	%f1639, %f1638, %f1638;
	neg.ftz.f32 	%f1640, %f1613;
	sub.ftz.f32 	%f1641, %f1640, %f1614;
	add.ftz.f32 	%f1642, %f1615, %f1641;
	fma.rn.ftz.f32 	%f1643, %f3325, %f1612, %f1642;
	mul.ftz.f32 	%f1644, %f3332, %f1624;
	fma.rn.ftz.f32 	%f1645, %f3330, %f1626, %f1644;
	fma.rn.ftz.f32 	%f3343, %f3329, %f1628, %f1645;
	mul.ftz.f32 	%f1646, %f3330, %f1633;
	fma.rn.ftz.f32 	%f1647, %f3332, %f1630, %f1646;
	fma.rn.ftz.f32 	%f3340, %f3329, %f1635, %f1647;
	mul.ftz.f32 	%f1648, %f3330, %f1639;
	fma.rn.ftz.f32 	%f1649, %f3332, %f1637, %f1648;
	fma.rn.ftz.f32 	%f3337, %f3329, %f1643, %f1649;
	mul.ftz.f32 	%f1650, %f3333, %f1624;
	fma.rn.ftz.f32 	%f3342, %f3331, %f1626, %f1650;
	mul.ftz.f32 	%f1651, %f3331, %f1633;
	fma.rn.ftz.f32 	%f3339, %f3333, %f1630, %f1651;
	mul.ftz.f32 	%f1652, %f3331, %f1639;
	fma.rn.ftz.f32 	%f3336, %f3333, %f1637, %f1652;
	mul.ftz.f32 	%f3341, %f3334, %f1624;
	mul.ftz.f32 	%f3338, %f1630, %f3334;
	mul.ftz.f32 	%f3335, %f1637, %f3334;

$L__BB0_44:
	mul.ftz.f32 	%f1684, %f3336, %f3340;
	mul.ftz.f32 	%f1685, %f3337, %f3339;
	sub.ftz.f32 	%f1686, %f1685, %f1684;
	mul.ftz.f32 	%f1687, %f3341, %f1686;
	mul.ftz.f32 	%f1688, %f3335, %f3340;
	mul.ftz.f32 	%f1689, %f3337, %f3338;
	sub.ftz.f32 	%f1690, %f1689, %f1688;
	mul.ftz.f32 	%f1691, %f1690, %f3342;
	sub.ftz.f32 	%f1692, %f1687, %f1691;
	mul.ftz.f32 	%f1693, %f3335, %f3339;
	mul.ftz.f32 	%f1694, %f3336, %f3338;
	sub.ftz.f32 	%f1695, %f1694, %f1693;
	fma.rn.ftz.f32 	%f1696, %f1695, %f3343, %f1692;
	rcp.approx.ftz.f32 	%f1697, %f1696;
	mul.ftz.f32 	%f3350, %f1686, %f1697;
	mul.ftz.f32 	%f1698, %f3337, %f3342;
	mul.ftz.f32 	%f1699, %f3336, %f3343;
	sub.ftz.f32 	%f1700, %f1699, %f1698;
	mul.ftz.f32 	%f3351, %f1700, %f1697;
	mul.ftz.f32 	%f1701, %f3339, %f3343;
	mul.ftz.f32 	%f1702, %f3340, %f3342;
	sub.ftz.f32 	%f1703, %f1702, %f1701;
	mul.ftz.f32 	%f3352, %f1703, %f1697;
	sub.ftz.f32 	%f1704, %f1688, %f1689;
	mul.ftz.f32 	%f3347, %f1704, %f1697;
	mul.ftz.f32 	%f1705, %f3335, %f3343;
	mul.ftz.f32 	%f1706, %f3337, %f3341;
	sub.ftz.f32 	%f1707, %f1706, %f1705;
	mul.ftz.f32 	%f3348, %f1707, %f1697;
	mul.ftz.f32 	%f1708, %f3340, %f3341;
	mul.ftz.f32 	%f1709, %f3338, %f3343;
	sub.ftz.f32 	%f1710, %f1709, %f1708;
	mul.ftz.f32 	%f3349, %f1710, %f1697;
	mul.ftz.f32 	%f3344, %f1695, %f1697;
	mul.ftz.f32 	%f1711, %f3336, %f3341;
	mul.ftz.f32 	%f1712, %f3335, %f3342;
	sub.ftz.f32 	%f1713, %f1712, %f1711;
	mul.ftz.f32 	%f3345, %f1713, %f1697;
	mul.ftz.f32 	%f1714, %f3338, %f3342;
	mul.ftz.f32 	%f1715, %f3339, %f3341;
	sub.ftz.f32 	%f1716, %f1715, %f1714;
	mul.ftz.f32 	%f3346, %f1716, %f1697;
	bra.uni 	$L__BB0_45;

$L__BB0_36:
	// begin inline asm
	call (%rd788), _optix_get_instance_inverse_transform_from_handle, (%rd172);
	// end inline asm

$L__BB0_37:
	// begin inline asm
	cvta.to.global.u64 %rd178, %rd788;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd178];
	// end inline asm
	mov.b32 	%f3350, %r242;
	mov.b32 	%f3351, %r243;
	mov.b32 	%f3352, %r244;
	add.s64 	%rd182, %rd788, 16;
	// begin inline asm
	cvta.to.global.u64 %rd181, %rd182;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd181];
	// end inline asm
	mov.b32 	%f3347, %r246;
	mov.b32 	%f3348, %r247;
	mov.b32 	%f3349, %r248;
	add.s64 	%rd185, %rd788, 32;
	// begin inline asm
	cvta.to.global.u64 %rd184, %rd185;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd184];
	// end inline asm
	mov.b32 	%f3344, %r250;
	mov.b32 	%f3345, %r251;
	mov.b32 	%f3346, %r252;

$L__BB0_45:
	setp.eq.s32 	%p24, %r1158, 0;
	@%p24 bra 	$L__BB0_47;

	mul.ftz.f32 	%f1717, %f3321, %f3351;
	fma.rn.ftz.f32 	%f1718, %f3318, %f3350, %f1717;
	fma.rn.ftz.f32 	%f334, %f3324, %f3352, %f1718;
	mul.ftz.f32 	%f1719, %f3320, %f3351;
	fma.rn.ftz.f32 	%f1720, %f3317, %f3350, %f1719;
	fma.rn.ftz.f32 	%f335, %f3323, %f3352, %f1720;
	mul.ftz.f32 	%f1721, %f3319, %f3351;
	fma.rn.ftz.f32 	%f1722, %f3316, %f3350, %f1721;
	fma.rn.ftz.f32 	%f3352, %f3322, %f3352, %f1722;
	mul.ftz.f32 	%f1723, %f3321, %f3348;
	fma.rn.ftz.f32 	%f1724, %f3318, %f3347, %f1723;
	fma.rn.ftz.f32 	%f337, %f3324, %f3349, %f1724;
	mul.ftz.f32 	%f1725, %f3320, %f3348;
	fma.rn.ftz.f32 	%f1726, %f3317, %f3347, %f1725;
	fma.rn.ftz.f32 	%f338, %f3323, %f3349, %f1726;
	mul.ftz.f32 	%f1727, %f3319, %f3348;
	fma.rn.ftz.f32 	%f1728, %f3316, %f3347, %f1727;
	fma.rn.ftz.f32 	%f3349, %f3322, %f3349, %f1728;
	mul.ftz.f32 	%f1729, %f3321, %f3345;
	fma.rn.ftz.f32 	%f1730, %f3318, %f3344, %f1729;
	fma.rn.ftz.f32 	%f340, %f3324, %f3346, %f1730;
	mul.ftz.f32 	%f1731, %f3320, %f3345;
	fma.rn.ftz.f32 	%f1732, %f3317, %f3344, %f1731;
	fma.rn.ftz.f32 	%f341, %f3323, %f3346, %f1732;
	mul.ftz.f32 	%f1733, %f3319, %f3345;
	fma.rn.ftz.f32 	%f1734, %f3316, %f3344, %f1733;
	fma.rn.ftz.f32 	%f3346, %f3322, %f3346, %f1734;
	mov.f32 	%f3344, %f340;
	mov.f32 	%f3345, %f341;
	mov.f32 	%f3347, %f337;
	mov.f32 	%f3348, %f338;
	mov.f32 	%f3350, %f334;
	mov.f32 	%f3351, %f335;

$L__BB0_47:
	add.s32 	%r1158, %r1158, 1;
	setp.lt.u32 	%p25, %r1158, %r237;
	mov.f32 	%f3316, %f3352;
	mov.f32 	%f3317, %f3351;
	mov.f32 	%f3318, %f3350;
	mov.f32 	%f3319, %f3349;
	mov.f32 	%f3320, %f3348;
	mov.f32 	%f3321, %f3347;
	mov.f32 	%f3322, %f3346;
	mov.f32 	%f3323, %f3345;
	mov.f32 	%f3324, %f3344;
	@%p25 bra 	$L__BB0_32;

$L__BB0_48:
	mul.ftz.f32 	%f1735, %f3650, %f3350;
	fma.rn.ftz.f32 	%f1736, %f3649, %f3347, %f1735;
	mul.ftz.f32 	%f1737, %f3650, %f3351;
	fma.rn.ftz.f32 	%f1738, %f3649, %f3348, %f1737;
	mul.ftz.f32 	%f1739, %f3650, %f3352;
	fma.rn.ftz.f32 	%f1740, %f3649, %f3349, %f1739;
	fma.rn.ftz.f32 	%f3648, %f228, %f3346, %f1740;
	fma.rn.ftz.f32 	%f3649, %f228, %f3345, %f1738;
	fma.rn.ftz.f32 	%f3650, %f228, %f3344, %f1736;
	bra.uni 	$L__BB0_144;

$L__BB0_49:
	mov.f32 	%f3648, %f228;
	bra.uni 	$L__BB0_144;

$L__BB0_120:
	fma.rn.ftz.f32 	%f2597, %f748, %f951, %f744;
	fma.rn.ftz.f32 	%f2598, %f749, %f951, %f745;
	fma.rn.ftz.f32 	%f2599, %f750, %f951, %f746;
	fma.rn.ftz.f32 	%f2600, %f751, %f951, %f747;
	mul.ftz.f32 	%f2601, %f951, %f951;
	fma.rn.ftz.f32 	%f2602, %f752, %f2601, %f2597;
	fma.rn.ftz.f32 	%f2603, %f753, %f2601, %f2598;
	fma.rn.ftz.f32 	%f2604, %f754, %f2601, %f2599;
	fma.rn.ftz.f32 	%f2605, %f755, %f2601, %f2600;
	add.ftz.f32 	%f2606, %f951, %f951;
	fma.rn.ftz.f32 	%f2607, %f752, %f2606, %f748;
	fma.rn.ftz.f32 	%f2608, %f753, %f2606, %f749;
	fma.rn.ftz.f32 	%f2609, %f754, %f2606, %f750;
	fma.rn.ftz.f32 	%f2610, %f755, %f2606, %f751;
	mul.ftz.f32 	%f2611, %f2608, %f2608;
	fma.rn.ftz.f32 	%f2612, %f2607, %f2607, %f2611;
	fma.rn.ftz.f32 	%f2613, %f2609, %f2609, %f2612;
	sub.ftz.f32 	%f2614, %f3584, %f2602;
	sub.ftz.f32 	%f2615, %f3585, %f2603;
	sub.ftz.f32 	%f2616, %f3586, %f2604;
	mul.ftz.f32 	%f2617, %f2608, %f2615;
	fma.rn.ftz.f32 	%f2618, %f2607, %f2614, %f2617;
	fma.rn.ftz.f32 	%f2619, %f2609, %f2616, %f2618;
	div.approx.ftz.f32 	%f2620, %f2619, %f2613;
	mul.ftz.f32 	%f2621, %f2607, %f2620;
	mul.ftz.f32 	%f2622, %f2608, %f2620;
	mul.ftz.f32 	%f2623, %f2609, %f2620;
	sub.ftz.f32 	%f2624, %f2614, %f2621;
	sub.ftz.f32 	%f2625, %f2615, %f2622;
	sub.ftz.f32 	%f2626, %f2616, %f2623;
	mul.ftz.f32 	%f2627, %f2625, %f2625;
	fma.rn.ftz.f32 	%f2628, %f2624, %f2624, %f2627;
	fma.rn.ftz.f32 	%f2629, %f2626, %f2626, %f2628;
	sqrt.approx.ftz.f32 	%f2630, %f2629;
	div.approx.ftz.f32 	%f2631, %f2605, %f2630;
	mul.ftz.f32 	%f2632, %f2624, %f2631;
	mul.ftz.f32 	%f2633, %f2625, %f2631;
	mul.ftz.f32 	%f2634, %f2626, %f2631;
	mul.ftz.f32 	%f2635, %f953, %f2633;
	fma.rn.ftz.f32 	%f2636, %f952, %f2632, %f2635;
	fma.rn.ftz.f32 	%f2637, %f954, %f2634, %f2636;
	sub.ftz.f32 	%f2638, %f2613, %f2637;
	mul.ftz.f32 	%f2639, %f2632, %f2638;
	mul.ftz.f32 	%f2640, %f2633, %f2638;
	mul.ftz.f32 	%f2641, %f2634, %f2638;
	mul.ftz.f32 	%f2642, %f2610, %f2605;
	mul.ftz.f32 	%f2643, %f2607, %f2642;
	mul.ftz.f32 	%f2644, %f2608, %f2642;
	mul.ftz.f32 	%f2645, %f2609, %f2642;
	sub.ftz.f32 	%f3587, %f2639, %f2643;
	sub.ftz.f32 	%f3588, %f2640, %f2644;
	sub.ftz.f32 	%f3589, %f2641, %f2645;

$L__BB0_123:
	mul.ftz.f32 	%f2649, %f3588, %f3588;
	fma.rn.ftz.f32 	%f2650, %f3587, %f3587, %f2649;
	fma.rn.ftz.f32 	%f2651, %f3589, %f3589, %f2650;
	rsqrt.approx.ftz.f32 	%f2652, %f2651;
	mul.ftz.f32 	%f3650, %f3587, %f2652;
	mul.ftz.f32 	%f3649, %f3588, %f2652;
	mul.ftz.f32 	%f969, %f3589, %f2652;
	// begin inline asm
	call (%r852), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p60, %r852, 0;
	@%p60 bra 	$L__BB0_143;

	// begin inline asm
	call (%r853), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f2653), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p61, %r853, 0;
	@%p61 bra 	$L__BB0_142;

	mov.u32 	%r1162, 0;

$L__BB0_126:
	.pragma "nounroll";
	// begin inline asm
	call (%rd652), _optix_get_transform_list_handle, (%r1162);
	// end inline asm
	// begin inline asm
	call (%r856), _optix_get_transform_type_from_handle, (%rd652);
	// end inline asm
	or.b32  	%r857, %r856, 1;
	setp.eq.s32 	%p62, %r857, 3;
	@%p62 bra 	$L__BB0_132;
	bra.uni 	$L__BB0_127;

$L__BB0_132:
	setp.eq.s32 	%p65, %r856, 2;
	@%p65 bra 	$L__BB0_136;
	bra.uni 	$L__BB0_133;

$L__BB0_136:
	// begin inline asm
	call (%rd724), _optix_get_matrix_motion_transform_from_handle, (%rd652);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd726, %rd724;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r945,%r946,%r947,%r948}, [%rd726];
	// end inline asm
	add.s64 	%rd730, %rd724, 16;
	// begin inline asm
	cvta.to.global.u64 %rd729, %rd730;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r949,%r950,%r951,%r952}, [%rd729];
	// end inline asm
	add.s64 	%rd733, %rd724, 32;
	// begin inline asm
	cvta.to.global.u64 %rd732, %rd733;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r953,%r954,%r955,%r956}, [%rd732];
	// end inline asm
	add.s64 	%rd736, %rd724, 48;
	// begin inline asm
	cvta.to.global.u64 %rd735, %rd736;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r957,%r958,%r959,%r960}, [%rd735];
	// end inline asm
	add.s64 	%rd739, %rd724, 64;
	// begin inline asm
	cvta.to.global.u64 %rd738, %rd739;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r961,%r962,%r963,%r964}, [%rd738];
	// end inline asm
	add.s64 	%rd742, %rd724, 80;
	// begin inline asm
	cvta.to.global.u64 %rd741, %rd742;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r965,%r966,%r967,%r968}, [%rd741];
	// end inline asm
	add.s64 	%rd745, %rd724, 96;
	// begin inline asm
	cvta.to.global.u64 %rd744, %rd745;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r969,%r970,%r971,%r972}, [%rd744];
	// end inline asm
	add.s64 	%rd748, %rd724, 112;
	// begin inline asm
	cvta.to.global.u64 %rd747, %rd748;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r973,%r974,%r975,%r976}, [%rd747];
	// end inline asm
	mov.b32 	%f2756, %r948;
	mov.b32 	%f2757, %r949;
	and.b32  	%r989, %r947, 65535;
	add.s32 	%r990, %r989, -1;
	cvt.rn.f32.s32 	%f2758, %r990;
	sub.ftz.f32 	%f2759, %f2653, %f2756;
	mul.ftz.f32 	%f2760, %f2759, %f2758;
	sub.ftz.f32 	%f2761, %f2757, %f2756;
	div.approx.ftz.f32 	%f2762, %f2760, %f2761;
	min.ftz.f32 	%f2763, %f2758, %f2762;
	mov.f32 	%f2764, 0f00000000;
	max.ftz.f32 	%f2765, %f2764, %f2763;
	cvt.rmi.ftz.f32.f32 	%f2766, %f2765;
	sub.ftz.f32 	%f1029, %f2765, %f2766;
	cvt.rzi.ftz.s32.f32 	%r991, %f2766;
	cvt.s64.s32 	%rd43, %r991;
	mul.wide.s32 	%rd759, %r991, 48;
	add.s64 	%rd751, %rd733, %rd759;
	// begin inline asm
	cvta.to.global.u64 %rd750, %rd751;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r977,%r978,%r979,%r980}, [%rd750];
	// end inline asm
	mov.b32 	%f3615, %r977;
	mov.b32 	%f3616, %r978;
	mov.b32 	%f3617, %r979;
	add.s64 	%rd754, %rd751, 16;
	// begin inline asm
	cvta.to.global.u64 %rd753, %rd754;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r981,%r982,%r983,%r984}, [%rd753];
	// end inline asm
	mov.b32 	%f3612, %r981;
	mov.b32 	%f3613, %r982;
	mov.b32 	%f3614, %r983;
	add.s64 	%rd757, %rd751, 32;
	// begin inline asm
	cvta.to.global.u64 %rd756, %rd757;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r985,%r986,%r987,%r988}, [%rd756];
	// end inline asm
	mov.b32 	%f3609, %r985;
	mov.b32 	%f3610, %r986;
	mov.b32 	%f3611, %r987;
	setp.leu.ftz.f32 	%p67, %f1029, 0f00000000;
	@%p67 bra 	$L__BB0_138;

	mov.f32 	%f2767, 0f3F800000;
	sub.ftz.f32 	%f2768, %f2767, %f1029;
	mul.lo.s64 	%rd769, %rd43, 48;
	add.s64 	%rd770, %rd724, %rd769;
	add.s64 	%rd761, %rd770, 80;
	// begin inline asm
	cvta.to.global.u64 %rd760, %rd761;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r992,%r993,%r994,%r995}, [%rd760];
	// end inline asm
	mov.b32 	%f2769, %r992;
	mov.b32 	%f2770, %r993;
	mov.b32 	%f2771, %r994;
	mul.ftz.f32 	%f2772, %f1029, %f2769;
	mul.ftz.f32 	%f2773, %f1029, %f2770;
	mul.ftz.f32 	%f2774, %f1029, %f2771;
	fma.rn.ftz.f32 	%f3615, %f2768, %f3615, %f2772;
	fma.rn.ftz.f32 	%f3616, %f2768, %f3616, %f2773;
	fma.rn.ftz.f32 	%f3617, %f2768, %f3617, %f2774;
	add.s64 	%rd764, %rd770, 96;
	// begin inline asm
	cvta.to.global.u64 %rd763, %rd764;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r996,%r997,%r998,%r999}, [%rd763];
	// end inline asm
	mov.b32 	%f2775, %r996;
	mov.b32 	%f2776, %r997;
	mov.b32 	%f2777, %r998;
	mul.ftz.f32 	%f2778, %f1029, %f2775;
	mul.ftz.f32 	%f2779, %f1029, %f2776;
	mul.ftz.f32 	%f2780, %f1029, %f2777;
	fma.rn.ftz.f32 	%f3612, %f2768, %f3612, %f2778;
	fma.rn.ftz.f32 	%f3613, %f2768, %f3613, %f2779;
	fma.rn.ftz.f32 	%f3614, %f2768, %f3614, %f2780;
	add.s64 	%rd767, %rd770, 112;
	// begin inline asm
	cvta.to.global.u64 %rd766, %rd767;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1000,%r1001,%r1002,%r1003}, [%rd766];
	// end inline asm
	mov.b32 	%f2781, %r1000;
	mov.b32 	%f2782, %r1001;
	mov.b32 	%f2783, %r1002;
	mul.ftz.f32 	%f2784, %f1029, %f2781;
	mul.ftz.f32 	%f2785, %f1029, %f2782;
	mul.ftz.f32 	%f2786, %f1029, %f2783;
	fma.rn.ftz.f32 	%f3609, %f2768, %f3609, %f2784;
	fma.rn.ftz.f32 	%f3610, %f2768, %f3610, %f2785;
	fma.rn.ftz.f32 	%f3611, %f2768, %f3611, %f2786;
	bra.uni 	$L__BB0_138;

$L__BB0_127:
	mov.f32 	%f3618, 0f00000000;
	mov.f32 	%f3620, 0f3F800000;
	setp.eq.s32 	%p63, %r856, 4;
	@%p63 bra 	$L__BB0_130;

	setp.ne.s32 	%p64, %r856, 1;
	mov.f32 	%f3619, %f3618;
	mov.f32 	%f3621, %f3618;
	mov.f32 	%f3622, %f3620;
	mov.f32 	%f3623, %f3618;
	mov.f32 	%f3624, %f3620;
	mov.f32 	%f3625, %f3618;
	mov.f32 	%f3626, %f3618;
	@%p64 bra 	$L__BB0_139;

	// begin inline asm
	call (%rd654), _optix_get_static_transform_from_handle, (%rd652);
	// end inline asm
	add.s64 	%rd792, %rd654, 64;
	bra.uni 	$L__BB0_131;

$L__BB0_133:
	// begin inline asm
	call (%rd667), _optix_get_srt_motion_transform_from_handle, (%rd652);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd669, %rd667;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r870,%r871,%r872,%r873}, [%rd669];
	// end inline asm
	add.s64 	%rd673, %rd667, 16;
	// begin inline asm
	cvta.to.global.u64 %rd672, %rd673;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r874,%r875,%r876,%r877}, [%rd672];
	// end inline asm
	add.s64 	%rd676, %rd667, 32;
	// begin inline asm
	cvta.to.global.u64 %rd675, %rd676;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r878,%r879,%r880,%r881}, [%rd675];
	// end inline asm
	add.s64 	%rd679, %rd667, 48;
	// begin inline asm
	cvta.to.global.u64 %rd678, %rd679;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r882,%r883,%r884,%r885}, [%rd678];
	// end inline asm
	add.s64 	%rd682, %rd667, 64;
	// begin inline asm
	cvta.to.global.u64 %rd681, %rd682;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r886,%r887,%r888,%r889}, [%rd681];
	// end inline asm
	add.s64 	%rd685, %rd667, 80;
	// begin inline asm
	cvta.to.global.u64 %rd684, %rd685;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r890,%r891,%r892,%r893}, [%rd684];
	// end inline asm
	add.s64 	%rd688, %rd667, 96;
	// begin inline asm
	cvta.to.global.u64 %rd687, %rd688;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r894,%r895,%r896,%r897}, [%rd687];
	// end inline asm
	add.s64 	%rd691, %rd667, 112;
	// begin inline asm
	cvta.to.global.u64 %rd690, %rd691;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r898,%r899,%r900,%r901}, [%rd690];
	// end inline asm
	add.s64 	%rd694, %rd667, 128;
	// begin inline asm
	cvta.to.global.u64 %rd693, %rd694;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r902,%r903,%r904,%r905}, [%rd693];
	// end inline asm
	add.s64 	%rd697, %rd667, 144;
	// begin inline asm
	cvta.to.global.u64 %rd696, %rd697;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r906,%r907,%r908,%r909}, [%rd696];
	// end inline asm
	mov.b32 	%f2665, %r873;
	mov.b32 	%f2666, %r874;
	and.b32  	%r926, %r872, 65535;
	add.s32 	%r927, %r926, -1;
	cvt.rn.f32.s32 	%f2667, %r927;
	sub.ftz.f32 	%f2668, %f2653, %f2665;
	mul.ftz.f32 	%f2669, %f2668, %f2667;
	sub.ftz.f32 	%f2670, %f2666, %f2665;
	div.approx.ftz.f32 	%f2671, %f2669, %f2670;
	min.ftz.f32 	%f2672, %f2667, %f2671;
	mov.f32 	%f2673, 0f00000000;
	max.ftz.f32 	%f2674, %f2673, %f2672;
	cvt.rmi.ftz.f32.f32 	%f2675, %f2674;
	sub.ftz.f32 	%f989, %f2674, %f2675;
	cvt.rzi.ftz.s32.f32 	%r928, %f2675;
	mul.wide.s32 	%rd711, %r928, 64;
	add.s64 	%rd700, %rd676, %rd711;
	// begin inline asm
	cvta.to.global.u64 %rd699, %rd700;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r910,%r911,%r912,%r913}, [%rd699];
	// end inline asm
	mov.b32 	%f3608, %r910;
	mov.b32 	%f3607, %r911;
	mov.b32 	%f3606, %r912;
	add.s64 	%rd703, %rd700, 16;
	// begin inline asm
	cvta.to.global.u64 %rd702, %rd703;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r914,%r915,%r916,%r917}, [%rd702];
	// end inline asm
	mov.b32 	%f3605, %r914;
	mov.b32 	%f3604, %r915;
	mov.b32 	%f3603, %r917;
	add.s64 	%rd706, %rd700, 32;
	// begin inline asm
	cvta.to.global.u64 %rd705, %rd706;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r918,%r919,%r920,%r921}, [%rd705];
	// end inline asm
	mov.b32 	%f3602, %r919;
	mov.b32 	%f3601, %r920;
	mov.b32 	%f3600, %r921;
	add.s64 	%rd709, %rd700, 48;
	// begin inline asm
	cvta.to.global.u64 %rd708, %rd709;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r922,%r923,%r924,%r925}, [%rd708];
	// end inline asm
	mov.b32 	%f3599, %r922;
	setp.leu.ftz.f32 	%p66, %f989, 0f00000000;
	@%p66 bra 	$L__BB0_135;

	mov.f32 	%f2676, 0f3F800000;
	sub.ftz.f32 	%f2677, %f2676, %f989;
	add.s64 	%rd713, %rd700, 64;
	// begin inline asm
	cvta.to.global.u64 %rd712, %rd713;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r929,%r930,%r931,%r932}, [%rd712];
	// end inline asm
	mov.b32 	%f2678, %r929;
	mov.b32 	%f2679, %r930;
	mov.b32 	%f2680, %r931;
	mul.ftz.f32 	%f2681, %f989, %f2678;
	mul.ftz.f32 	%f2682, %f989, %f2679;
	mul.ftz.f32 	%f2683, %f989, %f2680;
	fma.rn.ftz.f32 	%f3608, %f2677, %f3608, %f2681;
	fma.rn.ftz.f32 	%f3607, %f2677, %f3607, %f2682;
	fma.rn.ftz.f32 	%f3606, %f2677, %f3606, %f2683;
	add.s64 	%rd716, %rd700, 80;
	// begin inline asm
	cvta.to.global.u64 %rd715, %rd716;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r933,%r934,%r935,%r936}, [%rd715];
	// end inline asm
	mov.b32 	%f2684, %r933;
	mov.b32 	%f2685, %r934;
	mov.b32 	%f2686, %r936;
	mul.ftz.f32 	%f2687, %f989, %f2684;
	mul.ftz.f32 	%f2688, %f989, %f2685;
	mul.ftz.f32 	%f2689, %f989, %f2686;
	fma.rn.ftz.f32 	%f3605, %f2677, %f3605, %f2687;
	fma.rn.ftz.f32 	%f3604, %f2677, %f3604, %f2688;
	fma.rn.ftz.f32 	%f3603, %f2677, %f3603, %f2689;
	add.s64 	%rd719, %rd700, 96;
	// begin inline asm
	cvta.to.global.u64 %rd718, %rd719;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r937,%r938,%r939,%r940}, [%rd718];
	// end inline asm
	mov.b32 	%f2690, %r938;
	mov.b32 	%f2691, %r939;
	mov.b32 	%f2692, %r940;
	mul.ftz.f32 	%f2693, %f989, %f2690;
	mul.ftz.f32 	%f2694, %f989, %f2691;
	mul.ftz.f32 	%f2695, %f989, %f2692;
	fma.rn.ftz.f32 	%f2696, %f2677, %f3602, %f2693;
	fma.rn.ftz.f32 	%f2697, %f2677, %f3601, %f2694;
	fma.rn.ftz.f32 	%f2698, %f2677, %f3600, %f2695;
	add.s64 	%rd722, %rd700, 112;
	// begin inline asm
	cvta.to.global.u64 %rd721, %rd722;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r941,%r942,%r943,%r944}, [%rd721];
	// end inline asm
	mov.b32 	%f2699, %r941;
	mul.ftz.f32 	%f2700, %f989, %f2699;
	fma.rn.ftz.f32 	%f2701, %f2677, %f3599, %f2700;
	mul.ftz.f32 	%f2702, %f2697, %f2697;
	fma.rn.ftz.f32 	%f2703, %f2696, %f2696, %f2702;
	fma.rn.ftz.f32 	%f2704, %f2698, %f2698, %f2703;
	fma.rn.ftz.f32 	%f2705, %f2701, %f2701, %f2704;
	rsqrt.approx.ftz.f32 	%f2706, %f2705;
	mul.ftz.f32 	%f3602, %f2696, %f2706;
	mul.ftz.f32 	%f3601, %f2697, %f2706;
	mul.ftz.f32 	%f3600, %f2698, %f2706;
	mul.ftz.f32 	%f3599, %f2706, %f2701;

$L__BB0_135:
	mul.ftz.f32 	%f2707, %f3602, %f3602;
	fma.rn.ftz.f32 	%f2708, %f3601, %f3601, %f2707;
	fma.rn.ftz.f32 	%f2709, %f3600, %f3600, %f2708;
	fma.rn.ftz.f32 	%f2710, %f3599, %f3599, %f2709;
	rcp.approx.ftz.f32 	%f2711, %f2710;
	mul.ftz.f32 	%f2712, %f3602, %f2711;
	mul.ftz.f32 	%f2713, %f3601, %f2711;
	mul.ftz.f32 	%f2714, %f3600, %f2711;
	mul.ftz.f32 	%f2715, %f3599, %f2711;
	mul.ftz.f32 	%f2716, %f3602, %f2712;
	mul.ftz.f32 	%f2717, %f3601, %f2713;
	mul.ftz.f32 	%f2718, %f3600, %f2714;
	mul.ftz.f32 	%f2719, %f3602, %f2713;
	mul.ftz.f32 	%f2720, %f3600, %f2715;
	mul.ftz.f32 	%f2721, %f3602, %f2714;
	mul.ftz.f32 	%f2722, %f3601, %f2715;
	mul.ftz.f32 	%f2723, %f3601, %f2714;
	mul.ftz.f32 	%f2724, %f3602, %f2715;
	sub.ftz.f32 	%f2725, %f2716, %f2717;
	sub.ftz.f32 	%f2726, %f2725, %f2718;
	fma.rn.ftz.f32 	%f2727, %f3599, %f2715, %f2726;
	sub.ftz.f32 	%f2728, %f2719, %f2720;
	add.ftz.f32 	%f2729, %f2728, %f2728;
	add.ftz.f32 	%f2730, %f2721, %f2722;
	add.ftz.f32 	%f2731, %f2730, %f2730;
	add.ftz.f32 	%f2732, %f2719, %f2720;
	add.ftz.f32 	%f2733, %f2732, %f2732;
	sub.ftz.f32 	%f2734, %f2717, %f2716;
	sub.ftz.f32 	%f2735, %f2734, %f2718;
	fma.rn.ftz.f32 	%f2736, %f3599, %f2715, %f2735;
	sub.ftz.f32 	%f2737, %f2723, %f2724;
	add.ftz.f32 	%f2738, %f2737, %f2737;
	sub.ftz.f32 	%f2739, %f2721, %f2722;
	add.ftz.f32 	%f2740, %f2739, %f2739;
	add.ftz.f32 	%f2741, %f2723, %f2724;
	add.ftz.f32 	%f2742, %f2741, %f2741;
	neg.ftz.f32 	%f2743, %f2716;
	sub.ftz.f32 	%f2744, %f2743, %f2717;
	add.ftz.f32 	%f2745, %f2718, %f2744;
	fma.rn.ftz.f32 	%f2746, %f3599, %f2715, %f2745;
	mul.ftz.f32 	%f2747, %f3606, %f2727;
	fma.rn.ftz.f32 	%f2748, %f3604, %f2729, %f2747;
	fma.rn.ftz.f32 	%f3617, %f3603, %f2731, %f2748;
	mul.ftz.f32 	%f2749, %f3604, %f2736;
	fma.rn.ftz.f32 	%f2750, %f3606, %f2733, %f2749;
	fma.rn.ftz.f32 	%f3614, %f3603, %f2738, %f2750;
	mul.ftz.f32 	%f2751, %f3604, %f2742;
	fma.rn.ftz.f32 	%f2752, %f3606, %f2740, %f2751;
	fma.rn.ftz.f32 	%f3611, %f3603, %f2746, %f2752;
	mul.ftz.f32 	%f2753, %f3607, %f2727;
	fma.rn.ftz.f32 	%f3616, %f3605, %f2729, %f2753;
	mul.ftz.f32 	%f2754, %f3605, %f2736;
	fma.rn.ftz.f32 	%f3613, %f3607, %f2733, %f2754;
	mul.ftz.f32 	%f2755, %f3605, %f2742;
	fma.rn.ftz.f32 	%f3610, %f3607, %f2740, %f2755;
	mul.ftz.f32 	%f3615, %f3608, %f2727;
	mul.ftz.f32 	%f3612, %f2733, %f3608;
	mul.ftz.f32 	%f3609, %f2740, %f3608;

$L__BB0_138:
	mul.ftz.f32 	%f2787, %f3610, %f3614;
	mul.ftz.f32 	%f2788, %f3611, %f3613;
	sub.ftz.f32 	%f2789, %f2788, %f2787;
	mul.ftz.f32 	%f2790, %f3615, %f2789;
	mul.ftz.f32 	%f2791, %f3609, %f3614;
	mul.ftz.f32 	%f2792, %f3611, %f3612;
	sub.ftz.f32 	%f2793, %f2792, %f2791;
	mul.ftz.f32 	%f2794, %f2793, %f3616;
	sub.ftz.f32 	%f2795, %f2790, %f2794;
	mul.ftz.f32 	%f2796, %f3609, %f3613;
	mul.ftz.f32 	%f2797, %f3610, %f3612;
	sub.ftz.f32 	%f2798, %f2797, %f2796;
	fma.rn.ftz.f32 	%f2799, %f2798, %f3617, %f2795;
	rcp.approx.ftz.f32 	%f2800, %f2799;
	mul.ftz.f32 	%f3624, %f2789, %f2800;
	mul.ftz.f32 	%f2801, %f3611, %f3616;
	mul.ftz.f32 	%f2802, %f3610, %f3617;
	sub.ftz.f32 	%f2803, %f2802, %f2801;
	mul.ftz.f32 	%f3625, %f2803, %f2800;
	mul.ftz.f32 	%f2804, %f3613, %f3617;
	mul.ftz.f32 	%f2805, %f3614, %f3616;
	sub.ftz.f32 	%f2806, %f2805, %f2804;
	mul.ftz.f32 	%f3626, %f2806, %f2800;
	sub.ftz.f32 	%f2807, %f2791, %f2792;
	mul.ftz.f32 	%f3621, %f2807, %f2800;
	mul.ftz.f32 	%f2808, %f3609, %f3617;
	mul.ftz.f32 	%f2809, %f3611, %f3615;
	sub.ftz.f32 	%f2810, %f2809, %f2808;
	mul.ftz.f32 	%f3622, %f2810, %f2800;
	mul.ftz.f32 	%f2811, %f3614, %f3615;
	mul.ftz.f32 	%f2812, %f3612, %f3617;
	sub.ftz.f32 	%f2813, %f2812, %f2811;
	mul.ftz.f32 	%f3623, %f2813, %f2800;
	mul.ftz.f32 	%f3618, %f2798, %f2800;
	mul.ftz.f32 	%f2814, %f3610, %f3615;
	mul.ftz.f32 	%f2815, %f3609, %f3616;
	sub.ftz.f32 	%f2816, %f2815, %f2814;
	mul.ftz.f32 	%f3619, %f2816, %f2800;
	mul.ftz.f32 	%f2817, %f3612, %f3616;
	mul.ftz.f32 	%f2818, %f3613, %f3615;
	sub.ftz.f32 	%f2819, %f2818, %f2817;
	mul.ftz.f32 	%f3620, %f2819, %f2800;
	bra.uni 	$L__BB0_139;

$L__BB0_130:
	// begin inline asm
	call (%rd792), _optix_get_instance_inverse_transform_from_handle, (%rd652);
	// end inline asm

$L__BB0_131:
	// begin inline asm
	cvta.to.global.u64 %rd658, %rd792;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r858,%r859,%r860,%r861}, [%rd658];
	// end inline asm
	mov.b32 	%f3624, %r858;
	mov.b32 	%f3625, %r859;
	mov.b32 	%f3626, %r860;
	add.s64 	%rd662, %rd792, 16;
	// begin inline asm
	cvta.to.global.u64 %rd661, %rd662;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r862,%r863,%r864,%r865}, [%rd661];
	// end inline asm
	mov.b32 	%f3621, %r862;
	mov.b32 	%f3622, %r863;
	mov.b32 	%f3623, %r864;
	add.s64 	%rd665, %rd792, 32;
	// begin inline asm
	cvta.to.global.u64 %rd664, %rd665;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r866,%r867,%r868,%r869}, [%rd664];
	// end inline asm
	mov.b32 	%f3618, %r866;
	mov.b32 	%f3619, %r867;
	mov.b32 	%f3620, %r868;

$L__BB0_139:
	setp.eq.s32 	%p68, %r1162, 0;
	@%p68 bra 	$L__BB0_141;

	mul.ftz.f32 	%f2820, %f3595, %f3625;
	fma.rn.ftz.f32 	%f2821, %f3592, %f3624, %f2820;
	fma.rn.ftz.f32 	%f1075, %f3598, %f3626, %f2821;
	mul.ftz.f32 	%f2822, %f3594, %f3625;
	fma.rn.ftz.f32 	%f2823, %f3591, %f3624, %f2822;
	fma.rn.ftz.f32 	%f1076, %f3597, %f3626, %f2823;
	mul.ftz.f32 	%f2824, %f3593, %f3625;
	fma.rn.ftz.f32 	%f2825, %f3590, %f3624, %f2824;
	fma.rn.ftz.f32 	%f3626, %f3596, %f3626, %f2825;
	mul.ftz.f32 	%f2826, %f3595, %f3622;
	fma.rn.ftz.f32 	%f2827, %f3592, %f3621, %f2826;
	fma.rn.ftz.f32 	%f1078, %f3598, %f3623, %f2827;
	mul.ftz.f32 	%f2828, %f3594, %f3622;
	fma.rn.ftz.f32 	%f2829, %f3591, %f3621, %f2828;
	fma.rn.ftz.f32 	%f1079, %f3597, %f3623, %f2829;
	mul.ftz.f32 	%f2830, %f3593, %f3622;
	fma.rn.ftz.f32 	%f2831, %f3590, %f3621, %f2830;
	fma.rn.ftz.f32 	%f3623, %f3596, %f3623, %f2831;
	mul.ftz.f32 	%f2832, %f3595, %f3619;
	fma.rn.ftz.f32 	%f2833, %f3592, %f3618, %f2832;
	fma.rn.ftz.f32 	%f1081, %f3598, %f3620, %f2833;
	mul.ftz.f32 	%f2834, %f3594, %f3619;
	fma.rn.ftz.f32 	%f2835, %f3591, %f3618, %f2834;
	fma.rn.ftz.f32 	%f1082, %f3597, %f3620, %f2835;
	mul.ftz.f32 	%f2836, %f3593, %f3619;
	fma.rn.ftz.f32 	%f2837, %f3590, %f3618, %f2836;
	fma.rn.ftz.f32 	%f3620, %f3596, %f3620, %f2837;
	mov.f32 	%f3618, %f1081;
	mov.f32 	%f3619, %f1082;
	mov.f32 	%f3621, %f1078;
	mov.f32 	%f3622, %f1079;
	mov.f32 	%f3624, %f1075;
	mov.f32 	%f3625, %f1076;

$L__BB0_141:
	add.s32 	%r1162, %r1162, 1;
	setp.lt.u32 	%p69, %r1162, %r853;
	mov.f32 	%f3590, %f3626;
	mov.f32 	%f3591, %f3625;
	mov.f32 	%f3592, %f3624;
	mov.f32 	%f3593, %f3623;
	mov.f32 	%f3594, %f3622;
	mov.f32 	%f3595, %f3621;
	mov.f32 	%f3596, %f3620;
	mov.f32 	%f3597, %f3619;
	mov.f32 	%f3598, %f3618;
	@%p69 bra 	$L__BB0_126;

$L__BB0_142:
	mul.ftz.f32 	%f2838, %f3650, %f3624;
	fma.rn.ftz.f32 	%f2839, %f3649, %f3621, %f2838;
	mul.ftz.f32 	%f2840, %f3650, %f3625;
	fma.rn.ftz.f32 	%f2841, %f3649, %f3622, %f2840;
	mul.ftz.f32 	%f2842, %f3650, %f3626;
	fma.rn.ftz.f32 	%f2843, %f3649, %f3623, %f2842;
	fma.rn.ftz.f32 	%f3648, %f969, %f3620, %f2843;
	fma.rn.ftz.f32 	%f3649, %f969, %f3619, %f2841;
	fma.rn.ftz.f32 	%f3650, %f969, %f3618, %f2839;
	bra.uni 	$L__BB0_144;

$L__BB0_143:
	mov.f32 	%f3648, %f969;
	bra.uni 	$L__BB0_144;

$L__BB0_73:
	mul.ftz.f32 	%f2014, %f584, %f584;
	mul.ftz.f32 	%f2015, %f2014, 0f3E2AAAAB;
	mul.ftz.f32 	%f2016, %f2015, %f584;
	sub.ftz.f32 	%f2017, %f584, %f2014;
	fma.rn.ftz.f32 	%f2018, %f2017, 0f3F000000, %f2016;
	mul.ftz.f32 	%f2019, %f2016, 0f40800000;
	sub.ftz.f32 	%f2020, %f2014, %f2019;
	fma.rn.ftz.f32 	%f2021, %f377, %f2018, %f373;
	fma.rn.ftz.f32 	%f2022, %f378, %f2018, %f374;
	fma.rn.ftz.f32 	%f2023, %f379, %f2018, %f375;
	fma.rn.ftz.f32 	%f2024, %f380, %f2018, %f376;
	fma.rn.ftz.f32 	%f2025, %f381, %f2020, %f2021;
	fma.rn.ftz.f32 	%f2026, %f382, %f2020, %f2022;
	fma.rn.ftz.f32 	%f2027, %f383, %f2020, %f2023;
	fma.rn.ftz.f32 	%f2028, %f384, %f2020, %f2024;
	fma.rn.ftz.f32 	%f2029, %f385, %f2016, %f2025;
	fma.rn.ftz.f32 	%f2030, %f386, %f2016, %f2026;
	fma.rn.ftz.f32 	%f2031, %f387, %f2016, %f2027;
	fma.rn.ftz.f32 	%f2032, %f388, %f2016, %f2028;
	mov.f32 	%f2033, 0f3F800000;
	sub.ftz.f32 	%f2034, %f2033, %f584;
	mul.ftz.f32 	%f2035, %f2034, 0f3F000000;
	mul.ftz.f32 	%f2036, %f2034, %f2035;
	add.ftz.f32 	%f2037, %f2034, %f2034;
	mul.ftz.f32 	%f2038, %f2037, %f584;
	mul.ftz.f32 	%f2039, %f381, %f2038;
	mul.ftz.f32 	%f2040, %f382, %f2038;
	mul.ftz.f32 	%f2041, %f383, %f2038;
	mul.ftz.f32 	%f2042, %f384, %f2038;
	fma.rn.ftz.f32 	%f2043, %f377, %f2036, %f2039;
	fma.rn.ftz.f32 	%f2044, %f378, %f2036, %f2040;
	fma.rn.ftz.f32 	%f2045, %f379, %f2036, %f2041;
	fma.rn.ftz.f32 	%f2046, %f380, %f2036, %f2042;
	mul.ftz.f32 	%f2047, %f584, 0f3F000000;
	mul.ftz.f32 	%f2048, %f2047, %f584;
	fma.rn.ftz.f32 	%f2049, %f385, %f2048, %f2043;
	fma.rn.ftz.f32 	%f2050, %f386, %f2048, %f2044;
	fma.rn.ftz.f32 	%f2051, %f387, %f2048, %f2045;
	fma.rn.ftz.f32 	%f2052, %f388, %f2048, %f2046;
	mul.ftz.f32 	%f2053, %f2050, %f2050;
	fma.rn.ftz.f32 	%f2054, %f2049, %f2049, %f2053;
	fma.rn.ftz.f32 	%f2055, %f2051, %f2051, %f2054;
	sub.ftz.f32 	%f2056, %f3447, %f2029;
	sub.ftz.f32 	%f2057, %f3448, %f2030;
	sub.ftz.f32 	%f2058, %f3449, %f2031;
	mul.ftz.f32 	%f2059, %f2050, %f2057;
	fma.rn.ftz.f32 	%f2060, %f2049, %f2056, %f2059;
	fma.rn.ftz.f32 	%f2061, %f2051, %f2058, %f2060;
	div.approx.ftz.f32 	%f2062, %f2061, %f2055;
	mul.ftz.f32 	%f2063, %f2049, %f2062;
	mul.ftz.f32 	%f2064, %f2050, %f2062;
	mul.ftz.f32 	%f2065, %f2051, %f2062;
	sub.ftz.f32 	%f2066, %f2056, %f2063;
	sub.ftz.f32 	%f2067, %f2057, %f2064;
	sub.ftz.f32 	%f2068, %f2058, %f2065;
	mul.ftz.f32 	%f2069, %f2067, %f2067;
	fma.rn.ftz.f32 	%f2070, %f2066, %f2066, %f2069;
	fma.rn.ftz.f32 	%f2071, %f2068, %f2068, %f2070;
	sqrt.approx.ftz.f32 	%f2072, %f2071;
	div.approx.ftz.f32 	%f2073, %f2032, %f2072;
	mul.ftz.f32 	%f2074, %f2066, %f2073;
	mul.ftz.f32 	%f2075, %f2067, %f2073;
	mul.ftz.f32 	%f2076, %f2068, %f2073;
	add.ftz.f32 	%f2077, %f381, %f381;
	sub.ftz.f32 	%f2078, %f2077, %f377;
	add.ftz.f32 	%f2079, %f382, %f382;
	sub.ftz.f32 	%f2080, %f2079, %f378;
	add.ftz.f32 	%f2081, %f383, %f383;
	sub.ftz.f32 	%f2082, %f2081, %f379;
	mul.ftz.f32 	%f2083, %f381, 0f40800000;
	sub.ftz.f32 	%f2084, %f377, %f2083;
	mul.ftz.f32 	%f2085, %f382, 0f40800000;
	sub.ftz.f32 	%f2086, %f378, %f2085;
	mul.ftz.f32 	%f2087, %f383, 0f40800000;
	sub.ftz.f32 	%f2088, %f379, %f2087;
	add.ftz.f32 	%f2089, %f385, %f2084;
	add.ftz.f32 	%f2090, %f386, %f2086;
	add.ftz.f32 	%f2091, %f387, %f2088;
	fma.rn.ftz.f32 	%f2092, %f2089, %f584, %f2078;
	fma.rn.ftz.f32 	%f2093, %f2090, %f584, %f2080;
	fma.rn.ftz.f32 	%f2094, %f2091, %f584, %f2082;
	mul.ftz.f32 	%f2095, %f2093, %f2075;
	fma.rn.ftz.f32 	%f2096, %f2092, %f2074, %f2095;
	fma.rn.ftz.f32 	%f2097, %f2094, %f2076, %f2096;
	sub.ftz.f32 	%f2098, %f2055, %f2097;
	mul.ftz.f32 	%f2099, %f2074, %f2098;
	mul.ftz.f32 	%f2100, %f2075, %f2098;
	mul.ftz.f32 	%f2101, %f2076, %f2098;
	mul.ftz.f32 	%f2102, %f2052, %f2032;
	mul.ftz.f32 	%f2103, %f2049, %f2102;
	mul.ftz.f32 	%f2104, %f2050, %f2102;
	mul.ftz.f32 	%f2105, %f2051, %f2102;
	sub.ftz.f32 	%f3450, %f2099, %f2103;
	sub.ftz.f32 	%f3451, %f2100, %f2104;
	sub.ftz.f32 	%f3452, %f2101, %f2105;

$L__BB0_76:
	mul.ftz.f32 	%f2133, %f3451, %f3451;
	fma.rn.ftz.f32 	%f2134, %f3450, %f3450, %f2133;
	fma.rn.ftz.f32 	%f2135, %f3452, %f3452, %f2134;
	rsqrt.approx.ftz.f32 	%f2136, %f2135;
	mul.ftz.f32 	%f3650, %f3450, %f2136;
	mul.ftz.f32 	%f3649, %f3451, %f2136;
	mul.ftz.f32 	%f599, %f3452, %f2136;
	// begin inline asm
	call (%r544), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p38, %r544, 0;
	@%p38 bra 	$L__BB0_96;

	// begin inline asm
	call (%r545), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f2137), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p39, %r545, 0;
	@%p39 bra 	$L__BB0_95;

	mov.u32 	%r1160, 0;

$L__BB0_79:
	.pragma "nounroll";
	// begin inline asm
	call (%rd412), _optix_get_transform_list_handle, (%r1160);
	// end inline asm
	// begin inline asm
	call (%r548), _optix_get_transform_type_from_handle, (%rd412);
	// end inline asm
	or.b32  	%r549, %r548, 1;
	setp.eq.s32 	%p40, %r549, 3;
	@%p40 bra 	$L__BB0_85;
	bra.uni 	$L__BB0_80;

$L__BB0_85:
	setp.eq.s32 	%p43, %r548, 2;
	@%p43 bra 	$L__BB0_89;
	bra.uni 	$L__BB0_86;

$L__BB0_89:
	// begin inline asm
	call (%rd484), _optix_get_matrix_motion_transform_from_handle, (%rd412);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd486, %rd484;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r637,%r638,%r639,%r640}, [%rd486];
	// end inline asm
	add.s64 	%rd490, %rd484, 16;
	// begin inline asm
	cvta.to.global.u64 %rd489, %rd490;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r641,%r642,%r643,%r644}, [%rd489];
	// end inline asm
	add.s64 	%rd493, %rd484, 32;
	// begin inline asm
	cvta.to.global.u64 %rd492, %rd493;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r645,%r646,%r647,%r648}, [%rd492];
	// end inline asm
	add.s64 	%rd496, %rd484, 48;
	// begin inline asm
	cvta.to.global.u64 %rd495, %rd496;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r649,%r650,%r651,%r652}, [%rd495];
	// end inline asm
	add.s64 	%rd499, %rd484, 64;
	// begin inline asm
	cvta.to.global.u64 %rd498, %rd499;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r653,%r654,%r655,%r656}, [%rd498];
	// end inline asm
	add.s64 	%rd502, %rd484, 80;
	// begin inline asm
	cvta.to.global.u64 %rd501, %rd502;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r657,%r658,%r659,%r660}, [%rd501];
	// end inline asm
	add.s64 	%rd505, %rd484, 96;
	// begin inline asm
	cvta.to.global.u64 %rd504, %rd505;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r661,%r662,%r663,%r664}, [%rd504];
	// end inline asm
	add.s64 	%rd508, %rd484, 112;
	// begin inline asm
	cvta.to.global.u64 %rd507, %rd508;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r665,%r666,%r667,%r668}, [%rd507];
	// end inline asm
	mov.b32 	%f2240, %r640;
	mov.b32 	%f2241, %r641;
	and.b32  	%r681, %r639, 65535;
	add.s32 	%r682, %r681, -1;
	cvt.rn.f32.s32 	%f2242, %r682;
	sub.ftz.f32 	%f2243, %f2137, %f2240;
	mul.ftz.f32 	%f2244, %f2243, %f2242;
	sub.ftz.f32 	%f2245, %f2241, %f2240;
	div.approx.ftz.f32 	%f2246, %f2244, %f2245;
	min.ftz.f32 	%f2247, %f2242, %f2246;
	mov.f32 	%f2248, 0f00000000;
	max.ftz.f32 	%f2249, %f2248, %f2247;
	cvt.rmi.ftz.f32.f32 	%f2250, %f2249;
	sub.ftz.f32 	%f659, %f2249, %f2250;
	cvt.rzi.ftz.s32.f32 	%r683, %f2250;
	cvt.s64.s32 	%rd29, %r683;
	mul.wide.s32 	%rd519, %r683, 48;
	add.s64 	%rd511, %rd493, %rd519;
	// begin inline asm
	cvta.to.global.u64 %rd510, %rd511;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r669,%r670,%r671,%r672}, [%rd510];
	// end inline asm
	mov.b32 	%f3478, %r669;
	mov.b32 	%f3479, %r670;
	mov.b32 	%f3480, %r671;
	add.s64 	%rd514, %rd511, 16;
	// begin inline asm
	cvta.to.global.u64 %rd513, %rd514;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r673,%r674,%r675,%r676}, [%rd513];
	// end inline asm
	mov.b32 	%f3475, %r673;
	mov.b32 	%f3476, %r674;
	mov.b32 	%f3477, %r675;
	add.s64 	%rd517, %rd511, 32;
	// begin inline asm
	cvta.to.global.u64 %rd516, %rd517;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r677,%r678,%r679,%r680}, [%rd516];
	// end inline asm
	mov.b32 	%f3472, %r677;
	mov.b32 	%f3473, %r678;
	mov.b32 	%f3474, %r679;
	setp.leu.ftz.f32 	%p45, %f659, 0f00000000;
	@%p45 bra 	$L__BB0_91;

	mov.f32 	%f2251, 0f3F800000;
	sub.ftz.f32 	%f2252, %f2251, %f659;
	mul.lo.s64 	%rd529, %rd29, 48;
	add.s64 	%rd530, %rd484, %rd529;
	add.s64 	%rd521, %rd530, 80;
	// begin inline asm
	cvta.to.global.u64 %rd520, %rd521;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r684,%r685,%r686,%r687}, [%rd520];
	// end inline asm
	mov.b32 	%f2253, %r684;
	mov.b32 	%f2254, %r685;
	mov.b32 	%f2255, %r686;
	mul.ftz.f32 	%f2256, %f659, %f2253;
	mul.ftz.f32 	%f2257, %f659, %f2254;
	mul.ftz.f32 	%f2258, %f659, %f2255;
	fma.rn.ftz.f32 	%f3478, %f2252, %f3478, %f2256;
	fma.rn.ftz.f32 	%f3479, %f2252, %f3479, %f2257;
	fma.rn.ftz.f32 	%f3480, %f2252, %f3480, %f2258;
	add.s64 	%rd524, %rd530, 96;
	// begin inline asm
	cvta.to.global.u64 %rd523, %rd524;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r688,%r689,%r690,%r691}, [%rd523];
	// end inline asm
	mov.b32 	%f2259, %r688;
	mov.b32 	%f2260, %r689;
	mov.b32 	%f2261, %r690;
	mul.ftz.f32 	%f2262, %f659, %f2259;
	mul.ftz.f32 	%f2263, %f659, %f2260;
	mul.ftz.f32 	%f2264, %f659, %f2261;
	fma.rn.ftz.f32 	%f3475, %f2252, %f3475, %f2262;
	fma.rn.ftz.f32 	%f3476, %f2252, %f3476, %f2263;
	fma.rn.ftz.f32 	%f3477, %f2252, %f3477, %f2264;
	add.s64 	%rd527, %rd530, 112;
	// begin inline asm
	cvta.to.global.u64 %rd526, %rd527;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r692,%r693,%r694,%r695}, [%rd526];
	// end inline asm
	mov.b32 	%f2265, %r692;
	mov.b32 	%f2266, %r693;
	mov.b32 	%f2267, %r694;
	mul.ftz.f32 	%f2268, %f659, %f2265;
	mul.ftz.f32 	%f2269, %f659, %f2266;
	mul.ftz.f32 	%f2270, %f659, %f2267;
	fma.rn.ftz.f32 	%f3472, %f2252, %f3472, %f2268;
	fma.rn.ftz.f32 	%f3473, %f2252, %f3473, %f2269;
	fma.rn.ftz.f32 	%f3474, %f2252, %f3474, %f2270;
	bra.uni 	$L__BB0_91;

$L__BB0_80:
	mov.f32 	%f3481, 0f00000000;
	mov.f32 	%f3483, 0f3F800000;
	setp.eq.s32 	%p41, %r548, 4;
	@%p41 bra 	$L__BB0_83;

	setp.ne.s32 	%p42, %r548, 1;
	mov.f32 	%f3482, %f3481;
	mov.f32 	%f3484, %f3481;
	mov.f32 	%f3485, %f3483;
	mov.f32 	%f3486, %f3481;
	mov.f32 	%f3487, %f3483;
	mov.f32 	%f3488, %f3481;
	mov.f32 	%f3489, %f3481;
	@%p42 bra 	$L__BB0_92;

	// begin inline asm
	call (%rd414), _optix_get_static_transform_from_handle, (%rd412);
	// end inline asm
	add.s64 	%rd790, %rd414, 64;
	bra.uni 	$L__BB0_84;

$L__BB0_86:
	// begin inline asm
	call (%rd427), _optix_get_srt_motion_transform_from_handle, (%rd412);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd429, %rd427;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r562,%r563,%r564,%r565}, [%rd429];
	// end inline asm
	add.s64 	%rd433, %rd427, 16;
	// begin inline asm
	cvta.to.global.u64 %rd432, %rd433;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r566,%r567,%r568,%r569}, [%rd432];
	// end inline asm
	add.s64 	%rd436, %rd427, 32;
	// begin inline asm
	cvta.to.global.u64 %rd435, %rd436;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r570,%r571,%r572,%r573}, [%rd435];
	// end inline asm
	add.s64 	%rd439, %rd427, 48;
	// begin inline asm
	cvta.to.global.u64 %rd438, %rd439;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r574,%r575,%r576,%r577}, [%rd438];
	// end inline asm
	add.s64 	%rd442, %rd427, 64;
	// begin inline asm
	cvta.to.global.u64 %rd441, %rd442;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r578,%r579,%r580,%r581}, [%rd441];
	// end inline asm
	add.s64 	%rd445, %rd427, 80;
	// begin inline asm
	cvta.to.global.u64 %rd444, %rd445;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r582,%r583,%r584,%r585}, [%rd444];
	// end inline asm
	add.s64 	%rd448, %rd427, 96;
	// begin inline asm
	cvta.to.global.u64 %rd447, %rd448;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r586,%r587,%r588,%r589}, [%rd447];
	// end inline asm
	add.s64 	%rd451, %rd427, 112;
	// begin inline asm
	cvta.to.global.u64 %rd450, %rd451;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r590,%r591,%r592,%r593}, [%rd450];
	// end inline asm
	add.s64 	%rd454, %rd427, 128;
	// begin inline asm
	cvta.to.global.u64 %rd453, %rd454;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r594,%r595,%r596,%r597}, [%rd453];
	// end inline asm
	add.s64 	%rd457, %rd427, 144;
	// begin inline asm
	cvta.to.global.u64 %rd456, %rd457;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r598,%r599,%r600,%r601}, [%rd456];
	// end inline asm
	mov.b32 	%f2149, %r565;
	mov.b32 	%f2150, %r566;
	and.b32  	%r618, %r564, 65535;
	add.s32 	%r619, %r618, -1;
	cvt.rn.f32.s32 	%f2151, %r619;
	sub.ftz.f32 	%f2152, %f2137, %f2149;
	mul.ftz.f32 	%f2153, %f2152, %f2151;
	sub.ftz.f32 	%f2154, %f2150, %f2149;
	div.approx.ftz.f32 	%f2155, %f2153, %f2154;
	min.ftz.f32 	%f2156, %f2151, %f2155;
	mov.f32 	%f2157, 0f00000000;
	max.ftz.f32 	%f2158, %f2157, %f2156;
	cvt.rmi.ftz.f32.f32 	%f2159, %f2158;
	sub.ftz.f32 	%f619, %f2158, %f2159;
	cvt.rzi.ftz.s32.f32 	%r620, %f2159;
	mul.wide.s32 	%rd471, %r620, 64;
	add.s64 	%rd460, %rd436, %rd471;
	// begin inline asm
	cvta.to.global.u64 %rd459, %rd460;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r602,%r603,%r604,%r605}, [%rd459];
	// end inline asm
	mov.b32 	%f3471, %r602;
	mov.b32 	%f3470, %r603;
	mov.b32 	%f3469, %r604;
	add.s64 	%rd463, %rd460, 16;
	// begin inline asm
	cvta.to.global.u64 %rd462, %rd463;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r606,%r607,%r608,%r609}, [%rd462];
	// end inline asm
	mov.b32 	%f3468, %r606;
	mov.b32 	%f3467, %r607;
	mov.b32 	%f3466, %r609;
	add.s64 	%rd466, %rd460, 32;
	// begin inline asm
	cvta.to.global.u64 %rd465, %rd466;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r610,%r611,%r612,%r613}, [%rd465];
	// end inline asm
	mov.b32 	%f3465, %r611;
	mov.b32 	%f3464, %r612;
	mov.b32 	%f3463, %r613;
	add.s64 	%rd469, %rd460, 48;
	// begin inline asm
	cvta.to.global.u64 %rd468, %rd469;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r614,%r615,%r616,%r617}, [%rd468];
	// end inline asm
	mov.b32 	%f3462, %r614;
	setp.leu.ftz.f32 	%p44, %f619, 0f00000000;
	@%p44 bra 	$L__BB0_88;

	mov.f32 	%f2160, 0f3F800000;
	sub.ftz.f32 	%f2161, %f2160, %f619;
	add.s64 	%rd473, %rd460, 64;
	// begin inline asm
	cvta.to.global.u64 %rd472, %rd473;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r621,%r622,%r623,%r624}, [%rd472];
	// end inline asm
	mov.b32 	%f2162, %r621;
	mov.b32 	%f2163, %r622;
	mov.b32 	%f2164, %r623;
	mul.ftz.f32 	%f2165, %f619, %f2162;
	mul.ftz.f32 	%f2166, %f619, %f2163;
	mul.ftz.f32 	%f2167, %f619, %f2164;
	fma.rn.ftz.f32 	%f3471, %f2161, %f3471, %f2165;
	fma.rn.ftz.f32 	%f3470, %f2161, %f3470, %f2166;
	fma.rn.ftz.f32 	%f3469, %f2161, %f3469, %f2167;
	add.s64 	%rd476, %rd460, 80;
	// begin inline asm
	cvta.to.global.u64 %rd475, %rd476;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r625,%r626,%r627,%r628}, [%rd475];
	// end inline asm
	mov.b32 	%f2168, %r625;
	mov.b32 	%f2169, %r626;
	mov.b32 	%f2170, %r628;
	mul.ftz.f32 	%f2171, %f619, %f2168;
	mul.ftz.f32 	%f2172, %f619, %f2169;
	mul.ftz.f32 	%f2173, %f619, %f2170;
	fma.rn.ftz.f32 	%f3468, %f2161, %f3468, %f2171;
	fma.rn.ftz.f32 	%f3467, %f2161, %f3467, %f2172;
	fma.rn.ftz.f32 	%f3466, %f2161, %f3466, %f2173;
	add.s64 	%rd479, %rd460, 96;
	// begin inline asm
	cvta.to.global.u64 %rd478, %rd479;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r629,%r630,%r631,%r632}, [%rd478];
	// end inline asm
	mov.b32 	%f2174, %r630;
	mov.b32 	%f2175, %r631;
	mov.b32 	%f2176, %r632;
	mul.ftz.f32 	%f2177, %f619, %f2174;
	mul.ftz.f32 	%f2178, %f619, %f2175;
	mul.ftz.f32 	%f2179, %f619, %f2176;
	fma.rn.ftz.f32 	%f2180, %f2161, %f3465, %f2177;
	fma.rn.ftz.f32 	%f2181, %f2161, %f3464, %f2178;
	fma.rn.ftz.f32 	%f2182, %f2161, %f3463, %f2179;
	add.s64 	%rd482, %rd460, 112;
	// begin inline asm
	cvta.to.global.u64 %rd481, %rd482;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r633,%r634,%r635,%r636}, [%rd481];
	// end inline asm
	mov.b32 	%f2183, %r633;
	mul.ftz.f32 	%f2184, %f619, %f2183;
	fma.rn.ftz.f32 	%f2185, %f2161, %f3462, %f2184;
	mul.ftz.f32 	%f2186, %f2181, %f2181;
	fma.rn.ftz.f32 	%f2187, %f2180, %f2180, %f2186;
	fma.rn.ftz.f32 	%f2188, %f2182, %f2182, %f2187;
	fma.rn.ftz.f32 	%f2189, %f2185, %f2185, %f2188;
	rsqrt.approx.ftz.f32 	%f2190, %f2189;
	mul.ftz.f32 	%f3465, %f2180, %f2190;
	mul.ftz.f32 	%f3464, %f2181, %f2190;
	mul.ftz.f32 	%f3463, %f2182, %f2190;
	mul.ftz.f32 	%f3462, %f2190, %f2185;

$L__BB0_88:
	mul.ftz.f32 	%f2191, %f3465, %f3465;
	fma.rn.ftz.f32 	%f2192, %f3464, %f3464, %f2191;
	fma.rn.ftz.f32 	%f2193, %f3463, %f3463, %f2192;
	fma.rn.ftz.f32 	%f2194, %f3462, %f3462, %f2193;
	rcp.approx.ftz.f32 	%f2195, %f2194;
	mul.ftz.f32 	%f2196, %f3465, %f2195;
	mul.ftz.f32 	%f2197, %f3464, %f2195;
	mul.ftz.f32 	%f2198, %f3463, %f2195;
	mul.ftz.f32 	%f2199, %f3462, %f2195;
	mul.ftz.f32 	%f2200, %f3465, %f2196;
	mul.ftz.f32 	%f2201, %f3464, %f2197;
	mul.ftz.f32 	%f2202, %f3463, %f2198;
	mul.ftz.f32 	%f2203, %f3465, %f2197;
	mul.ftz.f32 	%f2204, %f3463, %f2199;
	mul.ftz.f32 	%f2205, %f3465, %f2198;
	mul.ftz.f32 	%f2206, %f3464, %f2199;
	mul.ftz.f32 	%f2207, %f3464, %f2198;
	mul.ftz.f32 	%f2208, %f3465, %f2199;
	sub.ftz.f32 	%f2209, %f2200, %f2201;
	sub.ftz.f32 	%f2210, %f2209, %f2202;
	fma.rn.ftz.f32 	%f2211, %f3462, %f2199, %f2210;
	sub.ftz.f32 	%f2212, %f2203, %f2204;
	add.ftz.f32 	%f2213, %f2212, %f2212;
	add.ftz.f32 	%f2214, %f2205, %f2206;
	add.ftz.f32 	%f2215, %f2214, %f2214;
	add.ftz.f32 	%f2216, %f2203, %f2204;
	add.ftz.f32 	%f2217, %f2216, %f2216;
	sub.ftz.f32 	%f2218, %f2201, %f2200;
	sub.ftz.f32 	%f2219, %f2218, %f2202;
	fma.rn.ftz.f32 	%f2220, %f3462, %f2199, %f2219;
	sub.ftz.f32 	%f2221, %f2207, %f2208;
	add.ftz.f32 	%f2222, %f2221, %f2221;
	sub.ftz.f32 	%f2223, %f2205, %f2206;
	add.ftz.f32 	%f2224, %f2223, %f2223;
	add.ftz.f32 	%f2225, %f2207, %f2208;
	add.ftz.f32 	%f2226, %f2225, %f2225;
	neg.ftz.f32 	%f2227, %f2200;
	sub.ftz.f32 	%f2228, %f2227, %f2201;
	add.ftz.f32 	%f2229, %f2202, %f2228;
	fma.rn.ftz.f32 	%f2230, %f3462, %f2199, %f2229;
	mul.ftz.f32 	%f2231, %f3469, %f2211;
	fma.rn.ftz.f32 	%f2232, %f3467, %f2213, %f2231;
	fma.rn.ftz.f32 	%f3480, %f3466, %f2215, %f2232;
	mul.ftz.f32 	%f2233, %f3467, %f2220;
	fma.rn.ftz.f32 	%f2234, %f3469, %f2217, %f2233;
	fma.rn.ftz.f32 	%f3477, %f3466, %f2222, %f2234;
	mul.ftz.f32 	%f2235, %f3467, %f2226;
	fma.rn.ftz.f32 	%f2236, %f3469, %f2224, %f2235;
	fma.rn.ftz.f32 	%f3474, %f3466, %f2230, %f2236;
	mul.ftz.f32 	%f2237, %f3470, %f2211;
	fma.rn.ftz.f32 	%f3479, %f3468, %f2213, %f2237;
	mul.ftz.f32 	%f2238, %f3468, %f2220;
	fma.rn.ftz.f32 	%f3476, %f3470, %f2217, %f2238;
	mul.ftz.f32 	%f2239, %f3468, %f2226;
	fma.rn.ftz.f32 	%f3473, %f3470, %f2224, %f2239;
	mul.ftz.f32 	%f3478, %f3471, %f2211;
	mul.ftz.f32 	%f3475, %f2217, %f3471;
	mul.ftz.f32 	%f3472, %f2224, %f3471;

$L__BB0_91:
	mul.ftz.f32 	%f2271, %f3473, %f3477;
	mul.ftz.f32 	%f2272, %f3474, %f3476;
	sub.ftz.f32 	%f2273, %f2272, %f2271;
	mul.ftz.f32 	%f2274, %f3478, %f2273;
	mul.ftz.f32 	%f2275, %f3472, %f3477;
	mul.ftz.f32 	%f2276, %f3474, %f3475;
	sub.ftz.f32 	%f2277, %f2276, %f2275;
	mul.ftz.f32 	%f2278, %f2277, %f3479;
	sub.ftz.f32 	%f2279, %f2274, %f2278;
	mul.ftz.f32 	%f2280, %f3472, %f3476;
	mul.ftz.f32 	%f2281, %f3473, %f3475;
	sub.ftz.f32 	%f2282, %f2281, %f2280;
	fma.rn.ftz.f32 	%f2283, %f2282, %f3480, %f2279;
	rcp.approx.ftz.f32 	%f2284, %f2283;
	mul.ftz.f32 	%f3487, %f2273, %f2284;
	mul.ftz.f32 	%f2285, %f3474, %f3479;
	mul.ftz.f32 	%f2286, %f3473, %f3480;
	sub.ftz.f32 	%f2287, %f2286, %f2285;
	mul.ftz.f32 	%f3488, %f2287, %f2284;
	mul.ftz.f32 	%f2288, %f3476, %f3480;
	mul.ftz.f32 	%f2289, %f3477, %f3479;
	sub.ftz.f32 	%f2290, %f2289, %f2288;
	mul.ftz.f32 	%f3489, %f2290, %f2284;
	sub.ftz.f32 	%f2291, %f2275, %f2276;
	mul.ftz.f32 	%f3484, %f2291, %f2284;
	mul.ftz.f32 	%f2292, %f3472, %f3480;
	mul.ftz.f32 	%f2293, %f3474, %f3478;
	sub.ftz.f32 	%f2294, %f2293, %f2292;
	mul.ftz.f32 	%f3485, %f2294, %f2284;
	mul.ftz.f32 	%f2295, %f3477, %f3478;
	mul.ftz.f32 	%f2296, %f3475, %f3480;
	sub.ftz.f32 	%f2297, %f2296, %f2295;
	mul.ftz.f32 	%f3486, %f2297, %f2284;
	mul.ftz.f32 	%f3481, %f2282, %f2284;
	mul.ftz.f32 	%f2298, %f3473, %f3478;
	mul.ftz.f32 	%f2299, %f3472, %f3479;
	sub.ftz.f32 	%f2300, %f2299, %f2298;
	mul.ftz.f32 	%f3482, %f2300, %f2284;
	mul.ftz.f32 	%f2301, %f3475, %f3479;
	mul.ftz.f32 	%f2302, %f3476, %f3478;
	sub.ftz.f32 	%f2303, %f2302, %f2301;
	mul.ftz.f32 	%f3483, %f2303, %f2284;
	bra.uni 	$L__BB0_92;

$L__BB0_83:
	// begin inline asm
	call (%rd790), _optix_get_instance_inverse_transform_from_handle, (%rd412);
	// end inline asm

$L__BB0_84:
	// begin inline asm
	cvta.to.global.u64 %rd418, %rd790;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r550,%r551,%r552,%r553}, [%rd418];
	// end inline asm
	mov.b32 	%f3487, %r550;
	mov.b32 	%f3488, %r551;
	mov.b32 	%f3489, %r552;
	add.s64 	%rd422, %rd790, 16;
	// begin inline asm
	cvta.to.global.u64 %rd421, %rd422;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r554,%r555,%r556,%r557}, [%rd421];
	// end inline asm
	mov.b32 	%f3484, %r554;
	mov.b32 	%f3485, %r555;
	mov.b32 	%f3486, %r556;
	add.s64 	%rd425, %rd790, 32;
	// begin inline asm
	cvta.to.global.u64 %rd424, %rd425;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r558,%r559,%r560,%r561}, [%rd424];
	// end inline asm
	mov.b32 	%f3481, %r558;
	mov.b32 	%f3482, %r559;
	mov.b32 	%f3483, %r560;

$L__BB0_92:
	setp.eq.s32 	%p46, %r1160, 0;
	@%p46 bra 	$L__BB0_94;

	mul.ftz.f32 	%f2304, %f3458, %f3488;
	fma.rn.ftz.f32 	%f2305, %f3455, %f3487, %f2304;
	fma.rn.ftz.f32 	%f705, %f3461, %f3489, %f2305;
	mul.ftz.f32 	%f2306, %f3457, %f3488;
	fma.rn.ftz.f32 	%f2307, %f3454, %f3487, %f2306;
	fma.rn.ftz.f32 	%f706, %f3460, %f3489, %f2307;
	mul.ftz.f32 	%f2308, %f3456, %f3488;
	fma.rn.ftz.f32 	%f2309, %f3453, %f3487, %f2308;
	fma.rn.ftz.f32 	%f3489, %f3459, %f3489, %f2309;
	mul.ftz.f32 	%f2310, %f3458, %f3485;
	fma.rn.ftz.f32 	%f2311, %f3455, %f3484, %f2310;
	fma.rn.ftz.f32 	%f708, %f3461, %f3486, %f2311;
	mul.ftz.f32 	%f2312, %f3457, %f3485;
	fma.rn.ftz.f32 	%f2313, %f3454, %f3484, %f2312;
	fma.rn.ftz.f32 	%f709, %f3460, %f3486, %f2313;
	mul.ftz.f32 	%f2314, %f3456, %f3485;
	fma.rn.ftz.f32 	%f2315, %f3453, %f3484, %f2314;
	fma.rn.ftz.f32 	%f3486, %f3459, %f3486, %f2315;
	mul.ftz.f32 	%f2316, %f3458, %f3482;
	fma.rn.ftz.f32 	%f2317, %f3455, %f3481, %f2316;
	fma.rn.ftz.f32 	%f711, %f3461, %f3483, %f2317;
	mul.ftz.f32 	%f2318, %f3457, %f3482;
	fma.rn.ftz.f32 	%f2319, %f3454, %f3481, %f2318;
	fma.rn.ftz.f32 	%f712, %f3460, %f3483, %f2319;
	mul.ftz.f32 	%f2320, %f3456, %f3482;
	fma.rn.ftz.f32 	%f2321, %f3453, %f3481, %f2320;
	fma.rn.ftz.f32 	%f3483, %f3459, %f3483, %f2321;
	mov.f32 	%f3481, %f711;
	mov.f32 	%f3482, %f712;
	mov.f32 	%f3484, %f708;
	mov.f32 	%f3485, %f709;
	mov.f32 	%f3487, %f705;
	mov.f32 	%f3488, %f706;

$L__BB0_94:
	add.s32 	%r1160, %r1160, 1;
	setp.lt.u32 	%p47, %r1160, %r545;
	mov.f32 	%f3453, %f3489;
	mov.f32 	%f3454, %f3488;
	mov.f32 	%f3455, %f3487;
	mov.f32 	%f3456, %f3486;
	mov.f32 	%f3457, %f3485;
	mov.f32 	%f3458, %f3484;
	mov.f32 	%f3459, %f3483;
	mov.f32 	%f3460, %f3482;
	mov.f32 	%f3461, %f3481;
	@%p47 bra 	$L__BB0_79;

$L__BB0_95:
	mul.ftz.f32 	%f2322, %f3650, %f3487;
	fma.rn.ftz.f32 	%f2323, %f3649, %f3484, %f2322;
	mul.ftz.f32 	%f2324, %f3650, %f3488;
	fma.rn.ftz.f32 	%f2325, %f3649, %f3485, %f2324;
	mul.ftz.f32 	%f2326, %f3650, %f3489;
	fma.rn.ftz.f32 	%f2327, %f3649, %f3486, %f2326;
	fma.rn.ftz.f32 	%f3648, %f599, %f3483, %f2327;
	fma.rn.ftz.f32 	%f3649, %f599, %f3482, %f2325;
	fma.rn.ftz.f32 	%f3650, %f599, %f3481, %f2323;
	bra.uni 	$L__BB0_144;

$L__BB0_96:
	mov.f32 	%f3648, %f599;

$L__BB0_144:
	ld.u32 	%r1004, [%rd50+100];
	setp.eq.s32 	%p70, %r1004, 14;
	@%p70 bra 	$L__BB0_146;
	bra.uni 	$L__BB0_145;

$L__BB0_146:
	ld.u64 	%rd771, [%rd50+24];
	mul.wide.u32 	%rd772, %r73, 8;
	add.s64 	%rd773, %rd771, %rd772;
	ld.v2.u32 	{%r30, %r29}, [%rd773];
	bra.uni 	$L__BB0_147;

$L__BB0_145:
	add.s32 	%r29, %r73, 1;
	mov.u32 	%r30, %r73;

$L__BB0_147:
	// begin inline asm
	call (%r1007), _optix_get_attribute_0, ();
	// end inline asm
	mov.b32 	%f1117, %r1007;
	ld.u32 	%r1010, [%rd50+96];
	and.b32  	%r1011, %r1010, 1073741823;
	setp.gt.ftz.f32 	%p71, %f1117, 0f3F000000;
	or.b32  	%r1012, %r1011, 1073741824;
	selp.b32 	%r1009, %r1012, %r1011, %p71;
	mov.u32 	%r1008, 2;
	// begin inline asm
	call _optix_set_payload, (%r1008, %r1009);
	// end inline asm
	ld.f32 	%f1118, [%rd50+156];
	ld.v4.f32 	{%f2844, %f2845, %f2846, %f2847}, [%rd50+112];
	ld.f32 	%f3653, [%rd50+80];
	setp.lt.ftz.f32 	%p72, %f3653, 0f00000000;
	@%p72 bra 	$L__BB0_149;
	bra.uni 	$L__BB0_148;

$L__BB0_149:
	ld.u64 	%rd44, [%rd50+8];
	ld.u8 	%rs1, [%rd50+188];
	and.b16  	%rs2, %rs1, 64;
	setp.eq.s16 	%p73, %rs2, 0;
	@%p73 bra 	$L__BB0_151;
	bra.uni 	$L__BB0_150;

$L__BB0_151:
	mul.wide.s32 	%rd776, %r29, 12;
	add.s64 	%rd777, %rd44, %rd776;
	mul.wide.s32 	%rd778, %r30, 12;
	add.s64 	%rd779, %rd44, %rd778;
	ld.f32 	%f2848, [%rd779];
	ld.f32 	%f2849, [%rd777];
	sub.ftz.f32 	%f2850, %f2849, %f2848;
	ld.f32 	%f2851, [%rd779+4];
	ld.f32 	%f2852, [%rd777+4];
	sub.ftz.f32 	%f2853, %f2852, %f2851;
	ld.f32 	%f2854, [%rd779+8];
	ld.f32 	%f2855, [%rd777+8];
	sub.ftz.f32 	%f2856, %f2855, %f2854;
	fma.rn.ftz.f32 	%f3653, %f2850, %f1117, %f2848;
	fma.rn.ftz.f32 	%f3652, %f2853, %f1117, %f2851;
	fma.rn.ftz.f32 	%f3651, %f2856, %f1117, %f2854;
	bra.uni 	$L__BB0_152;

$L__BB0_148:
	ld.f32 	%f3652, [%rd50+84];
	ld.f32 	%f3651, [%rd50+88];
	bra.uni 	$L__BB0_152;

$L__BB0_150:
	mul.wide.u32 	%rd774, %r73, 12;
	add.s64 	%rd775, %rd44, %rd774;
	ld.f32 	%f3653, [%rd775];
	ld.f32 	%f3652, [%rd775+4];
	ld.f32 	%f3651, [%rd775+8];

$L__BB0_152:
	mov.u32 	%r1014, 0;
	mul.ftz.f32 	%f1136, %f2844, %f3653;
	mov.u32 	%r1016, 1;
	mul.ftz.f32 	%f1137, %f2845, %f3652;
	mul.ftz.f32 	%f1138, %f2846, %f3651;
	// begin inline asm
	call (%r1013), _optix_get_payload, (%r1014);
	// end inline asm
	// begin inline asm
	call (%r1015), _optix_get_payload, (%r1016);
	// end inline asm
	cvt.u64.u32 	%rd780, %r1013;
	cvt.u64.u32 	%rd781, %r1015;
	bfi.b64 	%rd45, %rd780, %rd781, 32, 32;
	// begin inline asm
	call (%f2857), _optix_get_ray_tmax, ();
	// end inline asm
	st.f32 	[%rd45+108], %f2857;
	setp.geu.ftz.f32 	%p74, %f2847, 0f3F800000;
	@%p74 bra 	$L__BB0_155;

	ld.u32 	%r1017, [%rd45+28];
	mad.lo.s32 	%r1018, %r1017, 1664525, 1013904223;
	st.u32 	[%rd45+28], %r1018;
	and.b32  	%r1019, %r1018, 16777215;
	cvt.rn.f32.u32 	%f2858, %r1019;
	mov.f32 	%f2859, 0f4B800000;
	div.approx.ftz.f32 	%f2860, %f2858, %f2859;
	setp.ltu.ftz.f32 	%p75, %f2860, %f2847;
	@%p75 bra 	$L__BB0_155;
	bra.uni 	$L__BB0_154;

$L__BB0_155:
	mul.ftz.f32 	%f2863, %f3650, %f3650;
	fma.rn.ftz.f32 	%f2864, %f3649, %f3649, %f2863;
	fma.rn.ftz.f32 	%f2865, %f3648, %f3648, %f2864;
	rsqrt.approx.ftz.f32 	%f2866, %f2865;
	mul.ftz.f32 	%f2867, %f3650, %f2866;
	mul.ftz.f32 	%f2868, %f3649, %f2866;
	mul.ftz.f32 	%f2869, %f3648, %f2866;
	ld.f32 	%f1139, [%rd45+112];
	ld.f32 	%f1140, [%rd45+116];
	mul.ftz.f32 	%f2870, %f1140, %f2868;
	fma.rn.ftz.f32 	%f2871, %f1139, %f2867, %f2870;
	ld.f32 	%f1141, [%rd45+120];
	fma.rn.ftz.f32 	%f2872, %f2869, %f1141, %f2871;
	setp.ge.ftz.f32 	%p76, %f2872, 0f00000000;
	ld.u32 	%r1023, [%rd50+188];
	or.b32  	%r1024, %r1023, 16;
	selp.b32 	%r1025, %r1024, %r1023, %p76;
	ld.u32 	%r1026, [%rd45+12];
	or.b32  	%r31, %r1025, %r1026;
	st.u32 	[%rd45+12], %r31;
	and.b32  	%r1027, %r31, 16;
	setp.eq.s32 	%p77, %r1027, 0;
	neg.ftz.f32 	%f2873, %f2867;
	neg.ftz.f32 	%f2874, %f2868;
	neg.ftz.f32 	%f2875, %f2869;
	selp.f32 	%f1142, %f2875, %f2869, %p77;
	selp.f32 	%f1143, %f2874, %f2868, %p77;
	selp.f32 	%f1144, %f2873, %f2867, %p77;
	ld.const.f32 	%f1145, [params+76];
	fma.rn.ftz.f32 	%f2876, %f1145, %f1142, %f3;
	fma.rn.ftz.f32 	%f2877, %f1145, %f1143, %f2;
	fma.rn.ftz.f32 	%f2878, %f1145, %f1144, %f1;
	st.v2.f32 	[%rd45+96], {%f2878, %f2877};
	st.f32 	[%rd45+104], %f2876;
	mov.f32 	%f2879, 0f00000000;
	st.v4.f32 	[%rd45+48], {%f2879, %f2879, %f2879, %f2879};
	and.b32  	%r1028, %r31, 16777216;
	setp.eq.s32 	%p78, %r1028, 0;
	@%p78 bra 	$L__BB0_157;

	ld.f32 	%f2880, [%rd45+16];
	mul.ftz.f32 	%f2881, %f1136, %f2880;
	st.f32 	[%rd45+16], %f2881;
	ld.f32 	%f2882, [%rd45+20];
	mul.ftz.f32 	%f2883, %f1137, %f2882;
	st.f32 	[%rd45+20], %f2883;
	ld.f32 	%f2884, [%rd45+24];
	mul.ftz.f32 	%f2885, %f1138, %f2884;
	st.f32 	[%rd45+24], %f2885;
	and.b32  	%r1029, %r31, -16777217;
	st.u32 	[%rd45+12], %r1029;

$L__BB0_157:
	ld.u32 	%r1030, [%rd45+44];
	setp.ne.s32 	%p79, %r1030, 0;
	@%p79 bra 	$L__BB0_159;

	ld.const.v2.f32 	{%f2886, %f2887}, [params+144];
	mul.ftz.f32 	%f2890, %f1143, %f2887;
	fma.rn.ftz.f32 	%f2891, %f1144, %f2886, %f2890;
	ld.const.f32 	%f2892, [params+152];
	ld.const.v2.f32 	{%f2893, %f2894}, [params+160];
	mul.ftz.f32 	%f2897, %f1143, %f2894;
	fma.rn.ftz.f32 	%f2898, %f1144, %f2893, %f2897;
	ld.const.f32 	%f2899, [params+168];
	ld.const.v2.f32 	{%f2900, %f2901}, [params+176];
	mul.ftz.f32 	%f2904, %f1143, %f2901;
	fma.rn.ftz.f32 	%f2905, %f1144, %f2900, %f2904;
	ld.const.f32 	%f2906, [params+184];
	fma.rn.ftz.f32 	%f2907, %f1142, %f2906, %f2905;
	fma.rn.ftz.f32 	%f2908, %f1142, %f2899, %f2898;
	fma.rn.ftz.f32 	%f2909, %f1142, %f2892, %f2891;
	st.v2.f32 	[%rd45+32], {%f2909, %f2908};
	st.f32 	[%rd45+40], %f2907;

$L__BB0_159:
	mul.ftz.f32 	%f2910, %f1143, %f1140;
	fma.rn.ftz.f32 	%f2911, %f1144, %f1139, %f2910;
	fma.rn.ftz.f32 	%f2912, %f1142, %f1141, %f2911;
	ld.f32 	%f2913, [%rd50+140];
	mul.ftz.f32 	%f2914, %f2913, %f2912;
	mul.ftz.f32 	%f2915, %f1138, %f2914;
	mul.ftz.f32 	%f2916, %f1137, %f2914;
	mul.ftz.f32 	%f2917, %f1136, %f2914;
	st.v2.f32 	[%rd45], {%f2917, %f2916};
	st.f32 	[%rd45+8], %f2915;
	ld.u32 	%r1031, [%rd45+28];
	mad.lo.s32 	%r1032, %r1031, 1664525, 1013904223;
	and.b32  	%r1033, %r1032, 16777215;
	cvt.rn.f32.u32 	%f2918, %r1033;
	mov.f32 	%f2919, 0f4B800000;
	div.approx.ftz.f32 	%f2920, %f2918, %f2919;
	mad.lo.s32 	%r32, %r1032, 1664525, 1013904223;
	st.u32 	[%rd45+28], %r32;
	and.b32  	%r1034, %r32, 16777215;
	cvt.rn.f32.u32 	%f2921, %r1034;
	div.approx.ftz.f32 	%f2922, %f2921, %f2919;
	mul.ftz.f32 	%f2923, %f2920, 0f40C90FDB;
	sqrt.approx.ftz.f32 	%f2924, %f2922;
	cos.approx.ftz.f32 	%f2925, %f2923;
	mul.ftz.f32 	%f1146, %f2924, %f2925;
	sin.approx.ftz.f32 	%f2926, %f2923;
	mul.ftz.f32 	%f1147, %f2924, %f2926;
	mul.ftz.f32 	%f2927, %f1146, %f1146;
	mov.f32 	%f2928, 0f3F800000;
	sub.ftz.f32 	%f2929, %f2928, %f2927;
	mul.ftz.f32 	%f2930, %f1147, %f1147;
	sub.ftz.f32 	%f1148, %f2929, %f2930;
	st.f32 	[%rd45+128], %f1146;
	st.f32 	[%rd45+132], %f1147;
	st.f32 	[%rd45+136], %f1148;
	setp.eq.ftz.f32 	%p80, %f1118, 0f00000000;
	@%p80 bra 	$L__BB0_163;
	bra.uni 	$L__BB0_160;

$L__BB0_163:
	setp.leu.ftz.f32 	%p82, %f1148, 0f00000000;
	mov.f32 	%f3655, 0f00000000;
	@%p82 bra 	$L__BB0_165;

	sqrt.approx.ftz.f32 	%f3655, %f1148;

$L__BB0_165:
	mov.b32 	%r1038, %f1142;
	and.b32  	%r1039, %r1038, -2147483648;
	or.b32  	%r1040, %r1039, 1065353216;
	mov.b32 	%f3020, %r1040;
	mul.ftz.f32 	%f3021, %f3655, %f3020;
	add.ftz.f32 	%f3022, %f1142, %f3020;
	mul.ftz.f32 	%f3023, %f1143, %f1147;
	fma.rn.ftz.f32 	%f3024, %f1144, %f1146, %f3023;
	fma.rn.ftz.f32 	%f3025, %f3022, %f3021, %f3024;
	abs.ftz.f32 	%f3026, %f1142;
	add.ftz.f32 	%f3027, %f3026, 0f3F800000;
	div.approx.ftz.f32 	%f3028, %f3025, %f3027;
	mul.ftz.f32 	%f3029, %f1144, %f3028;
	mul.ftz.f32 	%f3030, %f1143, %f3028;
	mul.ftz.f32 	%f3031, %f3022, %f3028;
	sub.ftz.f32 	%f3658, %f3029, %f1146;
	sub.ftz.f32 	%f3657, %f3030, %f1147;
	sub.ftz.f32 	%f3656, %f3031, %f3021;
	st.f32 	[%rd45+128], %f3658;
	st.f32 	[%rd45+132], %f3657;
	st.f32 	[%rd45+136], %f3656;
	mul.ftz.f32 	%f3659, %f3655, 0f3EA2F983;
	st.v4.f32 	[%rd45+48], {%f1136, %f1137, %f1138, %f3659};
	bra.uni 	$L__BB0_166;

$L__BB0_160:
	setp.leu.ftz.f32 	%p81, %f1148, 0f00000000;
	mov.f32 	%f3654, %f2879;
	@%p81 bra 	$L__BB0_162;

	sqrt.approx.ftz.f32 	%f3654, %f1148;

$L__BB0_162:
	mov.b32 	%r1035, %f1142;
	and.b32  	%r1036, %r1035, -2147483648;
	or.b32  	%r1037, %r1036, 1065353216;
	mov.b32 	%f2932, %r1037;
	mul.ftz.f32 	%f2933, %f3654, %f2932;
	add.ftz.f32 	%f2934, %f1142, %f2932;
	mul.ftz.f32 	%f2935, %f1143, %f1147;
	fma.rn.ftz.f32 	%f2936, %f1144, %f1146, %f2935;
	fma.rn.ftz.f32 	%f2937, %f2934, %f2933, %f2936;
	abs.ftz.f32 	%f2938, %f1142;
	add.ftz.f32 	%f2939, %f2938, 0f3F800000;
	div.approx.ftz.f32 	%f2941, %f2937, %f2939;
	mul.ftz.f32 	%f2942, %f1144, %f2941;
	mul.ftz.f32 	%f2943, %f1143, %f2941;
	mul.ftz.f32 	%f2944, %f2934, %f2941;
	sub.ftz.f32 	%f3658, %f2942, %f1146;
	sub.ftz.f32 	%f3657, %f2943, %f1147;
	sub.ftz.f32 	%f3656, %f2944, %f2933;
	st.f32 	[%rd45+128], %f3658;
	st.f32 	[%rd45+132], %f3657;
	st.f32 	[%rd45+136], %f3656;
	mul.ftz.f32 	%f2945, %f1118, %f1118;
	add.ftz.f32 	%f2946, %f2945, 0f3EA8F5C3;
	add.ftz.f32 	%f2947, %f2945, 0f3DB851EC;
	div.approx.ftz.f32 	%f2948, %f2945, %f2946;
	div.approx.ftz.f32 	%f2949, %f2945, %f2947;
	fma.rn.ftz.f32 	%f2950, %f2948, 0fBF000000, 0f3F800000;
	fma.rn.ftz.f32 	%f2951, %f2949, 0f3EE66666, 0f00000000;
	mul.ftz.f32 	%f2953, %f1143, %f3657;
	fma.rn.ftz.f32 	%f2954, %f1144, %f3658, %f2953;
	fma.rn.ftz.f32 	%f2955, %f1142, %f3656, %f2954;
	ld.f32 	%f2956, [%rd45+112];
	ld.f32 	%f2957, [%rd45+116];
	mul.ftz.f32 	%f2958, %f1143, %f2957;
	fma.rn.ftz.f32 	%f2959, %f1144, %f2956, %f2958;
	ld.f32 	%f2960, [%rd45+120];
	fma.rn.ftz.f32 	%f2961, %f1142, %f2960, %f2959;
	min.ftz.f32 	%f2962, %f2955, %f2928;
	max.ftz.f32 	%f2963, %f2879, %f2962;
	min.ftz.f32 	%f2964, %f2961, %f2928;
	max.ftz.f32 	%f2965, %f2879, %f2964;
	mul.ftz.f32 	%f2966, %f2963, %f2963;
	mul.ftz.f32 	%f2967, %f2965, %f2965;
	sub.ftz.f32 	%f2968, %f2928, %f2966;
	sub.ftz.f32 	%f2969, %f2928, %f2967;
	mul.ftz.f32 	%f2970, %f2968, %f2969;
	sqrt.approx.ftz.f32 	%f2971, %f2970;
	mul.ftz.f32 	%f2972, %f1144, %f2963;
	mul.ftz.f32 	%f2973, %f1143, %f2963;
	mul.ftz.f32 	%f2974, %f1142, %f2963;
	sub.ftz.f32 	%f2975, %f3658, %f2972;
	sub.ftz.f32 	%f2976, %f3657, %f2973;
	sub.ftz.f32 	%f2977, %f3656, %f2974;
	mul.ftz.f32 	%f2978, %f2976, %f2976;
	fma.rn.ftz.f32 	%f2979, %f2975, %f2975, %f2978;
	fma.rn.ftz.f32 	%f2980, %f2977, %f2977, %f2979;
	rsqrt.approx.ftz.f32 	%f2981, %f2980;
	mul.ftz.f32 	%f2982, %f2975, %f2981;
	mul.ftz.f32 	%f2983, %f2976, %f2981;
	mul.ftz.f32 	%f2984, %f2977, %f2981;
	mul.ftz.f32 	%f2985, %f1144, %f2965;
	mul.ftz.f32 	%f2986, %f1143, %f2965;
	mul.ftz.f32 	%f2987, %f1142, %f2965;
	sub.ftz.f32 	%f2988, %f2956, %f2985;
	sub.ftz.f32 	%f2989, %f2957, %f2986;
	sub.ftz.f32 	%f2990, %f2960, %f2987;
	mul.ftz.f32 	%f2991, %f2989, %f2989;
	fma.rn.ftz.f32 	%f2992, %f2988, %f2988, %f2991;
	fma.rn.ftz.f32 	%f2993, %f2990, %f2990, %f2992;
	rsqrt.approx.ftz.f32 	%f2994, %f2993;
	mul.ftz.f32 	%f2995, %f2988, %f2994;
	mul.ftz.f32 	%f2996, %f2989, %f2994;
	mul.ftz.f32 	%f2997, %f2990, %f2994;
	mul.ftz.f32 	%f2998, %f2983, %f2996;
	fma.rn.ftz.f32 	%f2999, %f2982, %f2995, %f2998;
	fma.rn.ftz.f32 	%f3000, %f2984, %f2997, %f2999;
	min.ftz.f32 	%f3001, %f3000, %f2928;
	max.ftz.f32 	%f3002, %f2879, %f3001;
	mul.ftz.f32 	%f3003, %f2971, %f3002;
	max.ftz.f32 	%f3004, %f2963, %f2965;
	div.approx.ftz.f32 	%f3005, %f3003, %f3004;
	fma.rn.ftz.f32 	%f3006, %f2951, %f3005, %f2950;
	mul.ftz.f32 	%f3007, %f2963, %f3006;
	mul.ftz.f32 	%f3659, %f3007, 0f3EA2F983;
	abs.ftz.f32 	%f3008, %f2955;
	mul.ftz.f32 	%f3009, %f1136, 0f3EA2F983;
	mul.ftz.f32 	%f3010, %f3009, %f3008;
	mul.ftz.f32 	%f3011, %f1137, 0f3EA2F983;
	mul.ftz.f32 	%f3012, %f3011, %f3008;
	mul.ftz.f32 	%f3013, %f1138, 0f3EA2F983;
	mul.ftz.f32 	%f3014, %f3013, %f3008;
	rcp.approx.ftz.f32 	%f3015, %f3659;
	mul.ftz.f32 	%f3016, %f3014, %f3015;
	mul.ftz.f32 	%f3017, %f3012, %f3015;
	mul.ftz.f32 	%f3018, %f3010, %f3015;
	st.v4.f32 	[%rd45+48], {%f3018, %f3017, %f3016, %f3659};

$L__BB0_166:
	setp.le.ftz.f32 	%p83, %f3659, 0f00000000;
	@%p83 bra 	$L__BB0_168;

	mul.ftz.f32 	%f3032, %f1143, %f3657;
	fma.rn.ftz.f32 	%f3033, %f1144, %f3658, %f3032;
	fma.rn.ftz.f32 	%f3034, %f1142, %f3656, %f3033;
	setp.gtu.ftz.f32 	%p84, %f3034, 0f3A83126F;
	@%p84 bra 	$L__BB0_169;

$L__BB0_168:
	ld.u32 	%r1041, [%rd45+12];
	or.b32  	%r1042, %r1041, -2147483648;
	st.u32 	[%rd45+12], %r1042;

$L__BB0_169:
	ld.const.u32 	%r33, [params+192];
	setp.eq.s32 	%p85, %r33, 0;
	@%p85 bra 	$L__BB0_192;

	mad.lo.s32 	%r1043, %r32, 1664525, 1013904223;
	and.b32  	%r1044, %r1043, 16777215;
	cvt.rn.f32.u32 	%f3035, %r1044;
	div.approx.ftz.f32 	%f1165, %f3035, %f2919;
	mad.lo.s32 	%r34, %r1043, 1664525, 1013904223;
	mov.u64 	%rd793, 0;
	st.u32 	[%rd45+28], %r34;
	and.b32  	%r1045, %r34, 16777215;
	cvt.rn.f32.u32 	%f3037, %r1045;
	div.approx.ftz.f32 	%f1166, %f3037, %f2919;
	setp.eq.s32 	%p86, %r33, 1;
	@%p86 bra 	$L__BB0_172;

	mad.lo.s32 	%r1046, %r34, 1664525, 1013904223;
	st.u32 	[%rd45+28], %r1046;
	and.b32  	%r1047, %r1046, 16777215;
	cvt.rn.f32.u32 	%f3038, %r1047;
	div.approx.ftz.f32 	%f3040, %f3038, %f2919;
	cvt.rn.f32.u32 	%f3041, %r33;
	mul.ftz.f32 	%f3042, %f3040, %f3041;
	cvt.rmi.ftz.f32.f32 	%f3043, %f3042;
	cvt.rzi.ftz.u32.f32 	%r1048, %f3043;
	add.s32 	%r1049, %r33, -1;
	min.u32 	%r1050, %r1048, %r1049;
	cvt.s64.s32 	%rd793, %r1050;

$L__BB0_172:
	ld.const.u64 	%rd783, [params+200];
	cvta.to.global.u64 	%rd784, %rd783;
	mul.lo.s64 	%rd785, %rd793, 80;
	add.s64 	%rd48, %rd784, %rd785;
	ld.global.f32 	%f1167, [%rd48];
	ld.global.f32 	%f1168, [%rd48+4];
	ld.global.f32 	%f1169, [%rd48+8];
	ld.global.f32 	%f1170, [%rd48+16];
	ld.global.f32 	%f1171, [%rd48+20];
	ld.global.f32 	%f1172, [%rd48+24];
	ld.global.f32 	%f1173, [%rd48+28];
	ld.global.u32 	%r1051, [%rd48+12];
	setp.eq.s32 	%p87, %r1051, 0;
	@%p87 bra 	$L__BB0_177;

	ld.global.f32 	%f1174, [%rd48+44];
	ld.f32 	%f1175, [%rd45+96];
	sub.ftz.f32 	%f3045, %f1175, %f1167;
	ld.f32 	%f1176, [%rd45+100];
	sub.ftz.f32 	%f3046, %f1176, %f1168;
	ld.f32 	%f1177, [%rd45+104];
	sub.ftz.f32 	%f3047, %f1177, %f1169;
	mul.ftz.f32 	%f3048, %f3046, %f3046;
	fma.rn.ftz.f32 	%f3049, %f3045, %f3045, %f3048;
	fma.rn.ftz.f32 	%f3050, %f3047, %f3047, %f3049;
	rsqrt.approx.ftz.f32 	%f3051, %f3050;
	mul.ftz.f32 	%f1178, %f3045, %f3051;
	mul.ftz.f32 	%f1179, %f3046, %f3051;
	mul.ftz.f32 	%f1180, %f3047, %f3051;
	mul.ftz.f32 	%f3053, %f1165, 0f40C90FDB;
	cos.approx.ftz.f32 	%f3054, %f3053;
	sqrt.approx.ftz.f32 	%f3055, %f1166;
	mul.ftz.f32 	%f1181, %f3055, %f3054;
	sin.approx.ftz.f32 	%f3056, %f3053;
	mul.ftz.f32 	%f1182, %f3055, %f3056;
	mul.ftz.f32 	%f3057, %f1181, %f1181;
	sub.ftz.f32 	%f3058, %f2928, %f3057;
	mul.ftz.f32 	%f3059, %f1182, %f1182;
	sub.ftz.f32 	%f1183, %f3058, %f3059;
	setp.leu.ftz.f32 	%p88, %f1183, 0f00000000;
	mov.f32 	%f3668, 0f00000000;
	mov.f32 	%f3660, %f3668;
	@%p88 bra 	$L__BB0_175;

	sqrt.approx.ftz.f32 	%f3660, %f1183;

$L__BB0_175:
	mov.b32 	%r1052, %f1180;
	and.b32  	%r1053, %r1052, -2147483648;
	or.b32  	%r1054, %r1053, 1065353216;
	mov.b32 	%f3062, %r1054;
	mul.ftz.f32 	%f3063, %f3660, %f3062;
	add.ftz.f32 	%f3064, %f1180, %f3062;
	mul.ftz.f32 	%f3065, %f1179, %f1182;
	fma.rn.ftz.f32 	%f3066, %f1178, %f1181, %f3065;
	fma.rn.ftz.f32 	%f3067, %f3064, %f3063, %f3066;
	abs.ftz.f32 	%f3068, %f1180;
	add.ftz.f32 	%f3069, %f3068, 0f3F800000;
	div.approx.ftz.f32 	%f3070, %f3067, %f3069;
	mul.ftz.f32 	%f3071, %f1178, %f3070;
	mul.ftz.f32 	%f3072, %f1179, %f3070;
	mul.ftz.f32 	%f3073, %f3064, %f3070;
	sub.ftz.f32 	%f3074, %f3071, %f1181;
	sub.ftz.f32 	%f3075, %f3072, %f1182;
	sub.ftz.f32 	%f3076, %f3073, %f3063;
	fma.rn.ftz.f32 	%f3077, %f1174, %f3074, %f1167;
	fma.rn.ftz.f32 	%f3078, %f1174, %f3075, %f1168;
	fma.rn.ftz.f32 	%f3079, %f1174, %f3076, %f1169;
	sub.ftz.f32 	%f3661, %f3077, %f1175;
	sub.ftz.f32 	%f3662, %f3078, %f1176;
	sub.ftz.f32 	%f3663, %f3079, %f1177;
	mul.ftz.f32 	%f3080, %f3662, %f3662;
	fma.rn.ftz.f32 	%f3081, %f3661, %f3661, %f3080;
	fma.rn.ftz.f32 	%f3082, %f3663, %f3663, %f3081;
	sqrt.approx.ftz.f32 	%f3664, %f3082;
	setp.leu.ftz.f32 	%p89, %f3664, 0f358637BD;
	@%p89 bra 	$L__BB0_180;

	rcp.approx.ftz.f32 	%f3083, %f3664;
	mul.ftz.f32 	%f3661, %f3661, %f3083;
	mul.ftz.f32 	%f3662, %f3662, %f3083;
	mul.ftz.f32 	%f3663, %f3663, %f3083;
	cvt.rn.f32.u32 	%f3084, %r33;
	mul.ftz.f32 	%f3665, %f1170, %f3084;
	mul.ftz.f32 	%f3666, %f1171, %f3084;
	mul.ftz.f32 	%f3667, %f1172, %f3084;
	mul.ftz.f32 	%f3085, %f3664, %f3664;
	div.approx.ftz.f32 	%f3668, %f3085, %f1173;
	bra.uni 	$L__BB0_180;

$L__BB0_154:
	st.v2.f32 	[%rd45+96], {%f1, %f2};
	st.f32 	[%rd45+104], %f3;
	mov.f32 	%f2861, 0f00000000;
	st.v2.f32 	[%rd45], {%f2861, %f2861};
	st.u32 	[%rd45+8], %r1014;
	mov.f32 	%f2862, 0f3F800000;
	st.v4.f32 	[%rd45+48], {%f2862, %f2862, %f2862, %f2862};
	ld.u32 	%r1021, [%rd45+44];
	add.s32 	%r1022, %r1021, -1;
	st.u32 	[%rd45+44], %r1022;
	bra.uni 	$L__BB0_192;

$L__BB0_177:
	ld.global.f32 	%f3088, [%rd48+32];
	ld.global.f32 	%f3089, [%rd48+36];
	ld.global.f32 	%f3090, [%rd48+40];
	fma.rn.ftz.f32 	%f3091, %f1165, %f3088, %f1167;
	fma.rn.ftz.f32 	%f3092, %f1165, %f3089, %f1168;
	fma.rn.ftz.f32 	%f3093, %f1165, %f3090, %f1169;
	ld.global.f32 	%f3094, [%rd48+48];
	ld.global.f32 	%f3095, [%rd48+52];
	ld.global.f32 	%f3096, [%rd48+56];
	fma.rn.ftz.f32 	%f3097, %f1166, %f3094, %f3091;
	fma.rn.ftz.f32 	%f3098, %f1166, %f3095, %f3092;
	fma.rn.ftz.f32 	%f3099, %f1166, %f3096, %f3093;
	ld.f32 	%f3100, [%rd45+96];
	sub.ftz.f32 	%f3661, %f3097, %f3100;
	ld.f32 	%f3101, [%rd45+100];
	sub.ftz.f32 	%f3662, %f3098, %f3101;
	ld.f32 	%f3102, [%rd45+104];
	sub.ftz.f32 	%f3663, %f3099, %f3102;
	mul.ftz.f32 	%f3103, %f3661, %f3661;
	fma.rn.ftz.f32 	%f3104, %f3662, %f3662, %f3103;
	fma.rn.ftz.f32 	%f3105, %f3663, %f3663, %f3104;
	sqrt.approx.ftz.f32 	%f3664, %f3105;
	setp.leu.ftz.f32 	%p90, %f3664, 0f358637BD;
	mov.f32 	%f3668, 0f00000000;
	@%p90 bra 	$L__BB0_180;

	ld.global.f32 	%f3108, [%rd48+64];
	ld.global.f32 	%f3109, [%rd48+68];
	ld.global.f32 	%f3110, [%rd48+72];
	rcp.approx.ftz.f32 	%f3111, %f3664;
	mul.ftz.f32 	%f3661, %f3661, %f3111;
	mul.ftz.f32 	%f3662, %f3662, %f3111;
	mul.ftz.f32 	%f3663, %f3663, %f3111;
	mul.ftz.f32 	%f3112, %f3108, %f3661;
	mul.ftz.f32 	%f3113, %f3109, %f3662;
	neg.ftz.f32 	%f3114, %f3113;
	sub.ftz.f32 	%f3115, %f3114, %f3112;
	mul.ftz.f32 	%f3116, %f3110, %f3663;
	sub.ftz.f32 	%f1204, %f3115, %f3116;
	setp.leu.ftz.f32 	%p91, %f1204, 0f358637BD;
	@%p91 bra 	$L__BB0_180;

	cvt.rn.f32.u32 	%f3117, %r33;
	mul.ftz.f32 	%f3665, %f1170, %f3117;
	mul.ftz.f32 	%f3666, %f1171, %f3117;
	mul.ftz.f32 	%f3667, %f1172, %f3117;
	mul.ftz.f32 	%f3118, %f1173, %f1204;
	mul.ftz.f32 	%f3119, %f3664, %f3664;
	div.approx.ftz.f32 	%f3668, %f3119, %f3118;

$L__BB0_180:
	setp.leu.ftz.f32 	%p92, %f3668, 0f00000000;
	@%p92 bra 	$L__BB0_192;

	mul.ftz.f32 	%f3120, %f1136, %f3665;
	mul.ftz.f32 	%f1217, %f3120, 0f3EA2F983;
	mul.ftz.f32 	%f3121, %f1137, %f3666;
	mul.ftz.f32 	%f1218, %f3121, 0f3EA2F983;
	mul.ftz.f32 	%f3122, %f1138, %f3667;
	mul.ftz.f32 	%f1219, %f3122, 0f3EA2F983;
	mul.ftz.f32 	%f3123, %f1143, %f3662;
	fma.rn.ftz.f32 	%f3124, %f1144, %f3661, %f3123;
	fma.rn.ftz.f32 	%f1220, %f1142, %f3663, %f3124;
	@%p80 bra 	$L__BB0_183;
	bra.uni 	$L__BB0_182;

$L__BB0_183:
	mul.ftz.f32 	%f3186, %f1220, 0f3EA2F983;
	mov.f32 	%f3187, 0f00000000;
	max.ftz.f32 	%f3669, %f3187, %f3186;
	bra.uni 	$L__BB0_184;

$L__BB0_182:
	mul.ftz.f32 	%f3125, %f1118, %f1118;
	add.ftz.f32 	%f3126, %f3125, 0f3EA8F5C3;
	add.ftz.f32 	%f3127, %f3125, 0f3DB851EC;
	div.approx.ftz.f32 	%f3128, %f3125, %f3126;
	div.approx.ftz.f32 	%f3129, %f3125, %f3127;
	fma.rn.ftz.f32 	%f3130, %f3128, 0fBF000000, 0f3F800000;
	fma.rn.ftz.f32 	%f3132, %f3129, 0f3EE66666, 0f00000000;
	mov.f32 	%f3133, 0f00000000;
	ld.f32 	%f3134, [%rd45+112];
	ld.f32 	%f3135, [%rd45+116];
	mul.ftz.f32 	%f3136, %f1143, %f3135;
	fma.rn.ftz.f32 	%f3137, %f1144, %f3134, %f3136;
	ld.f32 	%f3138, [%rd45+120];
	fma.rn.ftz.f32 	%f3139, %f1142, %f3138, %f3137;
	min.ftz.f32 	%f3140, %f1220, %f2928;
	max.ftz.f32 	%f3141, %f3133, %f3140;
	min.ftz.f32 	%f3142, %f3139, %f2928;
	max.ftz.f32 	%f3143, %f3133, %f3142;
	mul.ftz.f32 	%f3144, %f3141, %f3141;
	mul.ftz.f32 	%f3145, %f3143, %f3143;
	sub.ftz.f32 	%f3146, %f2928, %f3144;
	sub.ftz.f32 	%f3147, %f2928, %f3145;
	mul.ftz.f32 	%f3148, %f3146, %f3147;
	sqrt.approx.ftz.f32 	%f3149, %f3148;
	mul.ftz.f32 	%f3150, %f1144, %f3141;
	mul.ftz.f32 	%f3151, %f1143, %f3141;
	mul.ftz.f32 	%f3152, %f1142, %f3141;
	sub.ftz.f32 	%f3153, %f3661, %f3150;
	sub.ftz.f32 	%f3154, %f3662, %f3151;
	sub.ftz.f32 	%f3155, %f3663, %f3152;
	mul.ftz.f32 	%f3156, %f3154, %f3154;
	fma.rn.ftz.f32 	%f3157, %f3153, %f3153, %f3156;
	fma.rn.ftz.f32 	%f3158, %f3155, %f3155, %f3157;
	rsqrt.approx.ftz.f32 	%f3159, %f3158;
	mul.ftz.f32 	%f3160, %f3153, %f3159;
	mul.ftz.f32 	%f3161, %f3154, %f3159;
	mul.ftz.f32 	%f3162, %f3155, %f3159;
	mul.ftz.f32 	%f3163, %f1144, %f3143;
	mul.ftz.f32 	%f3164, %f1143, %f3143;
	mul.ftz.f32 	%f3165, %f1142, %f3143;
	sub.ftz.f32 	%f3166, %f3134, %f3163;
	sub.ftz.f32 	%f3167, %f3135, %f3164;
	sub.ftz.f32 	%f3168, %f3138, %f3165;
	mul.ftz.f32 	%f3169, %f3167, %f3167;
	fma.rn.ftz.f32 	%f3170, %f3166, %f3166, %f3169;
	fma.rn.ftz.f32 	%f3171, %f3168, %f3168, %f3170;
	rsqrt.approx.ftz.f32 	%f3172, %f3171;
	mul.ftz.f32 	%f3173, %f3166, %f3172;
	mul.ftz.f32 	%f3174, %f3167, %f3172;
	mul.ftz.f32 	%f3175, %f3168, %f3172;
	mul.ftz.f32 	%f3176, %f3161, %f3174;
	fma.rn.ftz.f32 	%f3177, %f3160, %f3173, %f3176;
	fma.rn.ftz.f32 	%f3178, %f3162, %f3175, %f3177;
	min.ftz.f32 	%f3179, %f3178, %f2928;
	max.ftz.f32 	%f3180, %f3133, %f3179;
	mul.ftz.f32 	%f3181, %f3149, %f3180;
	max.ftz.f32 	%f3182, %f3141, %f3143;
	div.approx.ftz.f32 	%f3183, %f3181, %f3182;
	fma.rn.ftz.f32 	%f3184, %f3132, %f3183, %f3130;
	mul.ftz.f32 	%f3185, %f3141, %f3184;
	mul.ftz.f32 	%f3669, %f3185, 0f3EA2F983;

$L__BB0_184:
	setp.leu.ftz.f32 	%p94, %f1220, 0f00000000;
	setp.leu.ftz.f32 	%p95, %f3669, 0f00000000;
	or.pred  	%p96, %p94, %p95;
	@%p96 bra 	$L__BB0_192;

	setp.eq.ftz.f32 	%p97, %f1217, 0f00000000;
	setp.eq.ftz.f32 	%p98, %f1218, 0f00000000;
	and.pred  	%p99, %p97, %p98;
	setp.eq.ftz.f32 	%p100, %f1219, 0f00000000;
	and.pred  	%p101, %p99, %p100;
	@%p101 bra 	$L__BB0_192;

	ld.const.u64 	%rd49, [params+280];
	ld.v4.f32 	{%f3188, %f3189, %f3190, %f3191}, [%rd45+96];
	sub.ftz.f32 	%f1227, %f3664, %f1145;
	mov.u32 	%r1165, 1065353216;
	mov.u32 	%r1096, 4;
	mov.f32 	%f3670, %f1145;
	mov.u32 	%r1166, %r1165;
	mov.u32 	%r1167, %r1165;

$L__BB0_187:
	mov.f32 	%f3671, 0f00000000;
	// begin inline asm
	call(%r1165,%r1166,%r1167,%r1061,%r1062,%r1063,%r1064,%r1065,%r1066,%r1067,%r1068,%r1069,%r1070,%r1071,%r1072,%r1073,%r1074,%r1075,%r1076,%r1077,%r1078,%r1079,%r1080,%r1081,%r1082,%r1083,%r1084,%r1085,%r1086,%r1087,%r1088,%r1089),_optix_trace_typed_32,(%r1014,%rd49,%f3188,%f3189,%f3190,%f3661,%f3662,%f3663,%f3670,%f1227,%f3671,%r1016,%r1014,%r1016,%r1008,%r1016,%r1096,%r1165,%r1166,%r1167,%r1014,%r1129,%r1130,%r1131,%r1132,%r1133,%r1134,%r1135,%r1136,%r1137,%r1138,%r1139,%r1140,%r1141,%r1142,%r1143,%r1144,%r1145,%r1146,%r1147,%r1148,%r1149,%r1150,%r1151,%r1152,%r1153,%r1154,%r1155,%r1156);
	// end inline asm
	mov.b32 	%f1229, %r1165;
	mov.b32 	%f1230, %r1166;
	mov.b32 	%f1231, %r1167;
	mul.ftz.f32 	%f3204, %f1229, %f1230;
	mul.ftz.f32 	%f3205, %f3204, %f1231;
	setp.lt.ftz.f32 	%p102, %f3205, 0f358637BD;
	mov.f32 	%f3672, %f3671;
	mov.f32 	%f3673, %f3671;
	@%p102 bra 	$L__BB0_190;

	mov.b32 	%f3206, %r1061;
	add.ftz.f32 	%f3207, %f1145, %f3206;
	add.ftz.f32 	%f3670, %f3670, %f3207;
	setp.lt.ftz.f32 	%p103, %f3670, %f1227;
	setp.ne.s32 	%p104, %r1061, 0;
	and.pred  	%p105, %p104, %p103;
	@%p105 bra 	$L__BB0_187;

	mov.f32 	%f3671, %f1229;
	mov.f32 	%f3672, %f1230;
	mov.f32 	%f3673, %f1231;

$L__BB0_190:
	setp.eq.ftz.f32 	%p106, %f3671, 0f00000000;
	setp.eq.ftz.f32 	%p107, %f3672, 0f00000000;
	setp.eq.ftz.f32 	%p108, %f3673, 0f00000000;
	and.pred  	%p109, %p107, %p106;
	and.pred  	%p110, %p108, %p109;
	@%p110 bra 	$L__BB0_192;

	mul.ftz.f32 	%f3208, %f3668, %f3668;
	fma.rn.ftz.f32 	%f3209, %f3669, %f3669, %f3208;
	div.approx.ftz.f32 	%f3210, %f3208, %f3209;
	mul.ftz.f32 	%f3211, %f1220, %f3210;
	div.approx.ftz.f32 	%f3212, %f3211, %f3668;
	mul.ftz.f32 	%f3213, %f1217, %f3671;
	mul.ftz.f32 	%f3214, %f1218, %f3672;
	mul.ftz.f32 	%f3215, %f1219, %f3673;
	ld.f32 	%f3216, [%rd45];
	fma.rn.ftz.f32 	%f3217, %f3213, %f3212, %f3216;
	st.f32 	[%rd45], %f3217;
	ld.f32 	%f3218, [%rd45+4];
	fma.rn.ftz.f32 	%f3219, %f3214, %f3212, %f3218;
	st.f32 	[%rd45+4], %f3219;
	ld.f32 	%f3220, [%rd45+8];
	fma.rn.ftz.f32 	%f3221, %f3215, %f3212, %f3220;
	st.f32 	[%rd45+8], %f3221;

$L__BB0_192:
	ret;

}

