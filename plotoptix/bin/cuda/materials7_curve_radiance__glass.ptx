//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30033411
// Cuda compilation tools, release 11.4, V11.4.48
// Based on NVVM 7.0.1
//

.version 7.4
.target sm_60
.address_size 64

	// .globl	__closesthit__curve_radiance__glass
.const .align 8 .b8 params[288];

.visible .entry __closesthit__curve_radiance__glass()
{
	.reg .pred 	%p<115>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<3657>;
	.reg .b32 	%r<1060>;
	.reg .b64 	%rd<792>;


	// begin inline asm
	call (%rd46), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	// begin inline asm
	call (%r43), _optix_read_primitive_idx, ();
	// end inline asm
	mov.u32 	%r44, 3;
	// begin inline asm
	call _optix_set_payload, (%r44, %r43);
	// end inline asm
	// begin inline asm
	call (%f1267), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f1268), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f1269), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%f1270), _optix_get_ray_tmax, ();
	// end inline asm
	// begin inline asm
	call (%f1271), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f1272), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f1273), _optix_get_world_ray_direction_z, ();
	// end inline asm
	fma.rn.ftz.f32 	%f1, %f1270, %f1271, %f1267;
	fma.rn.ftz.f32 	%f2, %f1270, %f1272, %f1268;
	fma.rn.ftz.f32 	%f3, %f1270, %f1273, %f1269;
	// begin inline asm
	call (%r46), _optix_get_hit_kind, ();
	// end inline asm
	// begin inline asm
	call (%r47), _optix_get_primitive_type_from_hit_kind, (%r46);
	// end inline asm
	setp.eq.s32 	%p1, %r47, 9473;
	@%p1 bra 	$L__BB0_97;

	setp.eq.s32 	%p2, %r47, 9474;
	@%p2 bra 	$L__BB0_50;

	setp.ne.s32 	%p3, %r47, 9475;
	@%p3 bra 	$L__BB0_144;

	// begin inline asm
	call (%rd47), _optix_get_gas_traversable_handle, ();
	// end inline asm
	// begin inline asm
	call (%r50), _optix_read_sbt_gas_idx, ();
	// end inline asm
	mov.f32 	%f1283, 0f00000000;
	// begin inline asm
	call (%f1275, %f1276, %f1277, %f1278,  %f1279, %f1280, %f1281, %f1282), _optix_get_linear_curve_vertex_data, (%rd47, %r43, %r50, %f1283);
	// end inline asm
	sub.ftz.f32 	%f13, %f1279, %f1275;
	sub.ftz.f32 	%f15, %f1280, %f1276;
	sub.ftz.f32 	%f17, %f1281, %f1277;
	// begin inline asm
	call (%r53), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p4, %r53, 0;
	@%p4 bra 	$L__BB0_23;

	// begin inline asm
	call (%r54), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1284), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p5, %r54, 0;
	@%p5 bra 	$L__BB0_22;

	mov.u32 	%r1049, 0;

$L__BB0_6:
	.pragma "nounroll";
	// begin inline asm
	call (%rd49), _optix_get_transform_list_handle, (%r1049);
	// end inline asm
	// begin inline asm
	call (%r57), _optix_get_transform_type_from_handle, (%rd49);
	// end inline asm
	or.b32  	%r58, %r57, 1;
	setp.eq.s32 	%p6, %r58, 3;
	@%p6 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_7;

$L__BB0_12:
	setp.eq.s32 	%p9, %r57, 2;
	@%p9 bra 	$L__BB0_16;
	bra.uni 	$L__BB0_13;

$L__BB0_16:
	// begin inline asm
	call (%rd121), _optix_get_matrix_motion_transform_from_handle, (%rd49);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd123, %rd121;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r146,%r147,%r148,%r149}, [%rd123];
	// end inline asm
	add.s64 	%rd127, %rd121, 16;
	// begin inline asm
	cvta.to.global.u64 %rd126, %rd127;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r150,%r151,%r152,%r153}, [%rd126];
	// end inline asm
	add.s64 	%rd130, %rd121, 32;
	// begin inline asm
	cvta.to.global.u64 %rd129, %rd130;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r154,%r155,%r156,%r157}, [%rd129];
	// end inline asm
	add.s64 	%rd133, %rd121, 48;
	// begin inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r158,%r159,%r160,%r161}, [%rd132];
	// end inline asm
	add.s64 	%rd136, %rd121, 64;
	// begin inline asm
	cvta.to.global.u64 %rd135, %rd136;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r162,%r163,%r164,%r165}, [%rd135];
	// end inline asm
	add.s64 	%rd139, %rd121, 80;
	// begin inline asm
	cvta.to.global.u64 %rd138, %rd139;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r166,%r167,%r168,%r169}, [%rd138];
	// end inline asm
	add.s64 	%rd142, %rd121, 96;
	// begin inline asm
	cvta.to.global.u64 %rd141, %rd142;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r170,%r171,%r172,%r173}, [%rd141];
	// end inline asm
	add.s64 	%rd145, %rd121, 112;
	// begin inline asm
	cvta.to.global.u64 %rd144, %rd145;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r174,%r175,%r176,%r177}, [%rd144];
	// end inline asm
	mov.b32 	%f1411, %r149;
	mov.b32 	%f1412, %r150;
	and.b32  	%r190, %r148, 65535;
	add.s32 	%r191, %r190, -1;
	cvt.rn.f32.s32 	%f1413, %r191;
	sub.ftz.f32 	%f1414, %f1284, %f1411;
	mul.ftz.f32 	%f1415, %f1414, %f1413;
	sub.ftz.f32 	%f1416, %f1412, %f1411;
	div.approx.ftz.f32 	%f1417, %f1415, %f1416;
	min.ftz.f32 	%f1418, %f1413, %f1417;
	mov.f32 	%f1419, 0f00000000;
	max.ftz.f32 	%f1420, %f1419, %f1418;
	cvt.rmi.ftz.f32.f32 	%f1421, %f1420;
	sub.ftz.f32 	%f104, %f1420, %f1421;
	cvt.rzi.ftz.s32.f32 	%r192, %f1421;
	cvt.s64.s32 	%rd8, %r192;
	mul.wide.s32 	%rd156, %r192, 48;
	add.s64 	%rd148, %rd130, %rd156;
	// begin inline asm
	cvta.to.global.u64 %rd147, %rd148;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r178,%r179,%r180,%r181}, [%rd147];
	// end inline asm
	mov.b32 	%f3230, %r178;
	mov.b32 	%f3229, %r179;
	mov.b32 	%f3228, %r180;
	mov.b32 	%f3227, %r181;
	add.s64 	%rd151, %rd148, 16;
	// begin inline asm
	cvta.to.global.u64 %rd150, %rd151;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r182,%r183,%r184,%r185}, [%rd150];
	// end inline asm
	mov.b32 	%f3234, %r182;
	mov.b32 	%f3233, %r183;
	mov.b32 	%f3232, %r184;
	mov.b32 	%f3231, %r185;
	add.s64 	%rd154, %rd148, 32;
	// begin inline asm
	cvta.to.global.u64 %rd153, %rd154;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r186,%r187,%r188,%r189}, [%rd153];
	// end inline asm
	mov.b32 	%f3238, %r186;
	mov.b32 	%f3237, %r187;
	mov.b32 	%f3236, %r188;
	mov.b32 	%f3235, %r189;
	setp.leu.ftz.f32 	%p11, %f104, 0f00000000;
	@%p11 bra 	$L__BB0_18;

	mov.f32 	%f1422, 0f3F800000;
	sub.ftz.f32 	%f1423, %f1422, %f104;
	mul.lo.s64 	%rd166, %rd8, 48;
	add.s64 	%rd167, %rd121, %rd166;
	add.s64 	%rd158, %rd167, 80;
	// begin inline asm
	cvta.to.global.u64 %rd157, %rd158;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r193,%r194,%r195,%r196}, [%rd157];
	// end inline asm
	mov.b32 	%f1424, %r193;
	mov.b32 	%f1425, %r194;
	mov.b32 	%f1426, %r195;
	mov.b32 	%f1427, %r196;
	mul.ftz.f32 	%f1428, %f104, %f1424;
	mul.ftz.f32 	%f1429, %f104, %f1425;
	mul.ftz.f32 	%f1430, %f104, %f1426;
	mul.ftz.f32 	%f1431, %f104, %f1427;
	fma.rn.ftz.f32 	%f3230, %f1423, %f3230, %f1428;
	fma.rn.ftz.f32 	%f3229, %f1423, %f3229, %f1429;
	fma.rn.ftz.f32 	%f3228, %f1423, %f3228, %f1430;
	fma.rn.ftz.f32 	%f3227, %f1423, %f3227, %f1431;
	add.s64 	%rd161, %rd167, 96;
	// begin inline asm
	cvta.to.global.u64 %rd160, %rd161;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r197,%r198,%r199,%r200}, [%rd160];
	// end inline asm
	mov.b32 	%f1432, %r197;
	mov.b32 	%f1433, %r198;
	mov.b32 	%f1434, %r199;
	mov.b32 	%f1435, %r200;
	mul.ftz.f32 	%f1436, %f104, %f1432;
	mul.ftz.f32 	%f1437, %f104, %f1433;
	mul.ftz.f32 	%f1438, %f104, %f1434;
	mul.ftz.f32 	%f1439, %f104, %f1435;
	fma.rn.ftz.f32 	%f3234, %f1423, %f3234, %f1436;
	fma.rn.ftz.f32 	%f3233, %f1423, %f3233, %f1437;
	fma.rn.ftz.f32 	%f3232, %f1423, %f3232, %f1438;
	fma.rn.ftz.f32 	%f3231, %f1423, %f3231, %f1439;
	add.s64 	%rd164, %rd167, 112;
	// begin inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r201,%r202,%r203,%r204}, [%rd163];
	// end inline asm
	mov.b32 	%f1440, %r201;
	mov.b32 	%f1441, %r202;
	mov.b32 	%f1442, %r203;
	mov.b32 	%f1443, %r204;
	mul.ftz.f32 	%f1444, %f104, %f1440;
	mul.ftz.f32 	%f1445, %f104, %f1441;
	mul.ftz.f32 	%f1446, %f104, %f1442;
	mul.ftz.f32 	%f1447, %f104, %f1443;
	fma.rn.ftz.f32 	%f3238, %f1423, %f3238, %f1444;
	fma.rn.ftz.f32 	%f3237, %f1423, %f3237, %f1445;
	fma.rn.ftz.f32 	%f3236, %f1423, %f3236, %f1446;
	fma.rn.ftz.f32 	%f3235, %f1423, %f3235, %f1447;
	bra.uni 	$L__BB0_18;

$L__BB0_7:
	mov.f32 	%f3242, 0f3F800000;
	setp.eq.s32 	%p7, %r57, 4;
	@%p7 bra 	$L__BB0_10;

	setp.ne.s32 	%p8, %r57, 1;
	mov.f32 	%f3239, %f1283;
	mov.f32 	%f3240, %f1283;
	mov.f32 	%f3241, %f1283;
	mov.f32 	%f3243, %f1283;
	mov.f32 	%f3244, %f1283;
	mov.f32 	%f3245, %f3242;
	mov.f32 	%f3246, %f1283;
	mov.f32 	%f3247, %f1283;
	mov.f32 	%f3248, %f3242;
	mov.f32 	%f3249, %f1283;
	mov.f32 	%f3250, %f1283;
	@%p8 bra 	$L__BB0_19;

	// begin inline asm
	call (%rd51), _optix_get_static_transform_from_handle, (%rd49);
	// end inline asm
	add.s64 	%rd786, %rd51, 64;
	bra.uni 	$L__BB0_11;

$L__BB0_13:
	// begin inline asm
	call (%rd64), _optix_get_srt_motion_transform_from_handle, (%rd49);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd66, %rd64;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r71,%r72,%r73,%r74}, [%rd66];
	// end inline asm
	add.s64 	%rd70, %rd64, 16;
	// begin inline asm
	cvta.to.global.u64 %rd69, %rd70;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r75,%r76,%r77,%r78}, [%rd69];
	// end inline asm
	add.s64 	%rd73, %rd64, 32;
	// begin inline asm
	cvta.to.global.u64 %rd72, %rd73;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r79,%r80,%r81,%r82}, [%rd72];
	// end inline asm
	add.s64 	%rd76, %rd64, 48;
	// begin inline asm
	cvta.to.global.u64 %rd75, %rd76;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r83,%r84,%r85,%r86}, [%rd75];
	// end inline asm
	add.s64 	%rd79, %rd64, 64;
	// begin inline asm
	cvta.to.global.u64 %rd78, %rd79;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r87,%r88,%r89,%r90}, [%rd78];
	// end inline asm
	add.s64 	%rd82, %rd64, 80;
	// begin inline asm
	cvta.to.global.u64 %rd81, %rd82;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r91,%r92,%r93,%r94}, [%rd81];
	// end inline asm
	add.s64 	%rd85, %rd64, 96;
	// begin inline asm
	cvta.to.global.u64 %rd84, %rd85;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r95,%r96,%r97,%r98}, [%rd84];
	// end inline asm
	add.s64 	%rd88, %rd64, 112;
	// begin inline asm
	cvta.to.global.u64 %rd87, %rd88;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r99,%r100,%r101,%r102}, [%rd87];
	// end inline asm
	add.s64 	%rd91, %rd64, 128;
	// begin inline asm
	cvta.to.global.u64 %rd90, %rd91;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r103,%r104,%r105,%r106}, [%rd90];
	// end inline asm
	add.s64 	%rd94, %rd64, 144;
	// begin inline asm
	cvta.to.global.u64 %rd93, %rd94;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r107,%r108,%r109,%r110}, [%rd93];
	// end inline asm
	mov.b32 	%f1299, %r74;
	mov.b32 	%f1300, %r75;
	and.b32  	%r127, %r73, 65535;
	add.s32 	%r128, %r127, -1;
	cvt.rn.f32.s32 	%f1301, %r128;
	sub.ftz.f32 	%f1302, %f1284, %f1299;
	mul.ftz.f32 	%f1303, %f1302, %f1301;
	sub.ftz.f32 	%f1304, %f1300, %f1299;
	div.approx.ftz.f32 	%f1305, %f1303, %f1304;
	min.ftz.f32 	%f1306, %f1301, %f1305;
	mov.f32 	%f1307, 0f00000000;
	max.ftz.f32 	%f1308, %f1307, %f1306;
	cvt.rmi.ftz.f32.f32 	%f1309, %f1308;
	sub.ftz.f32 	%f43, %f1308, %f1309;
	cvt.rzi.ftz.s32.f32 	%r129, %f1309;
	mul.wide.s32 	%rd108, %r129, 64;
	add.s64 	%rd97, %rd73, %rd108;
	// begin inline asm
	cvta.to.global.u64 %rd96, %rd97;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r111,%r112,%r113,%r114}, [%rd96];
	// end inline asm
	mov.b32 	%f3211, %r111;
	mov.b32 	%f3212, %r112;
	mov.b32 	%f3213, %r113;
	mov.b32 	%f3214, %r114;
	add.s64 	%rd100, %rd97, 16;
	// begin inline asm
	cvta.to.global.u64 %rd99, %rd100;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r115,%r116,%r117,%r118}, [%rd99];
	// end inline asm
	mov.b32 	%f3215, %r115;
	mov.b32 	%f3216, %r116;
	mov.b32 	%f3217, %r117;
	mov.b32 	%f3218, %r118;
	add.s64 	%rd103, %rd97, 32;
	// begin inline asm
	cvta.to.global.u64 %rd102, %rd103;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r119,%r120,%r121,%r122}, [%rd102];
	// end inline asm
	mov.b32 	%f3219, %r119;
	mov.b32 	%f3220, %r120;
	mov.b32 	%f3221, %r121;
	mov.b32 	%f3222, %r122;
	add.s64 	%rd106, %rd97, 48;
	// begin inline asm
	cvta.to.global.u64 %rd105, %rd106;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r123,%r124,%r125,%r126}, [%rd105];
	// end inline asm
	mov.b32 	%f3223, %r123;
	mov.b32 	%f3224, %r124;
	mov.b32 	%f3225, %r125;
	mov.b32 	%f3226, %r126;
	setp.leu.ftz.f32 	%p10, %f43, 0f00000000;
	@%p10 bra 	$L__BB0_15;

	mov.f32 	%f1310, 0f3F800000;
	sub.ftz.f32 	%f1311, %f1310, %f43;
	add.s64 	%rd110, %rd97, 64;
	// begin inline asm
	cvta.to.global.u64 %rd109, %rd110;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r130,%r131,%r132,%r133}, [%rd109];
	// end inline asm
	mov.b32 	%f1312, %r130;
	mov.b32 	%f1313, %r131;
	mov.b32 	%f1314, %r132;
	mov.b32 	%f1315, %r133;
	mul.ftz.f32 	%f1316, %f43, %f1312;
	mul.ftz.f32 	%f1317, %f43, %f1313;
	mul.ftz.f32 	%f1318, %f43, %f1314;
	mul.ftz.f32 	%f1319, %f43, %f1315;
	fma.rn.ftz.f32 	%f3211, %f1311, %f3211, %f1316;
	fma.rn.ftz.f32 	%f3212, %f1311, %f3212, %f1317;
	fma.rn.ftz.f32 	%f3213, %f1311, %f3213, %f1318;
	fma.rn.ftz.f32 	%f3214, %f1311, %f3214, %f1319;
	add.s64 	%rd113, %rd97, 80;
	// begin inline asm
	cvta.to.global.u64 %rd112, %rd113;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r134,%r135,%r136,%r137}, [%rd112];
	// end inline asm
	mov.b32 	%f1320, %r134;
	mov.b32 	%f1321, %r135;
	mov.b32 	%f1322, %r136;
	mov.b32 	%f1323, %r137;
	mul.ftz.f32 	%f1324, %f43, %f1320;
	mul.ftz.f32 	%f1325, %f43, %f1321;
	mul.ftz.f32 	%f1326, %f43, %f1322;
	mul.ftz.f32 	%f1327, %f43, %f1323;
	fma.rn.ftz.f32 	%f3215, %f1311, %f3215, %f1324;
	fma.rn.ftz.f32 	%f3216, %f1311, %f3216, %f1325;
	fma.rn.ftz.f32 	%f3217, %f1311, %f3217, %f1326;
	fma.rn.ftz.f32 	%f3218, %f1311, %f3218, %f1327;
	add.s64 	%rd116, %rd97, 96;
	// begin inline asm
	cvta.to.global.u64 %rd115, %rd116;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r138,%r139,%r140,%r141}, [%rd115];
	// end inline asm
	mov.b32 	%f1328, %r138;
	mov.b32 	%f1329, %r139;
	mov.b32 	%f1330, %r140;
	mov.b32 	%f1331, %r141;
	mul.ftz.f32 	%f1332, %f43, %f1328;
	mul.ftz.f32 	%f1333, %f43, %f1329;
	mul.ftz.f32 	%f1334, %f43, %f1330;
	mul.ftz.f32 	%f1335, %f43, %f1331;
	fma.rn.ftz.f32 	%f3219, %f1311, %f3219, %f1332;
	fma.rn.ftz.f32 	%f1336, %f1311, %f3220, %f1333;
	fma.rn.ftz.f32 	%f1337, %f1311, %f3221, %f1334;
	fma.rn.ftz.f32 	%f1338, %f1311, %f3222, %f1335;
	add.s64 	%rd119, %rd97, 112;
	// begin inline asm
	cvta.to.global.u64 %rd118, %rd119;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r142,%r143,%r144,%r145}, [%rd118];
	// end inline asm
	mov.b32 	%f1339, %r142;
	mov.b32 	%f1340, %r143;
	mov.b32 	%f1341, %r144;
	mov.b32 	%f1342, %r145;
	mul.ftz.f32 	%f1343, %f43, %f1339;
	mul.ftz.f32 	%f1344, %f43, %f1340;
	mul.ftz.f32 	%f1345, %f43, %f1341;
	mul.ftz.f32 	%f1346, %f43, %f1342;
	fma.rn.ftz.f32 	%f1347, %f1311, %f3223, %f1343;
	fma.rn.ftz.f32 	%f3224, %f1311, %f3224, %f1344;
	fma.rn.ftz.f32 	%f3225, %f1311, %f3225, %f1345;
	fma.rn.ftz.f32 	%f3226, %f1311, %f3226, %f1346;
	mul.ftz.f32 	%f1348, %f1337, %f1337;
	fma.rn.ftz.f32 	%f1349, %f1336, %f1336, %f1348;
	fma.rn.ftz.f32 	%f1350, %f1338, %f1338, %f1349;
	fma.rn.ftz.f32 	%f1351, %f1347, %f1347, %f1350;
	rsqrt.approx.ftz.f32 	%f1352, %f1351;
	mul.ftz.f32 	%f3220, %f1336, %f1352;
	mul.ftz.f32 	%f3221, %f1337, %f1352;
	mul.ftz.f32 	%f3222, %f1338, %f1352;
	mul.ftz.f32 	%f3223, %f1352, %f1347;

$L__BB0_15:
	mul.ftz.f32 	%f1353, %f3221, %f3221;
	fma.rn.ftz.f32 	%f1354, %f3220, %f3220, %f1353;
	fma.rn.ftz.f32 	%f1355, %f3222, %f3222, %f1354;
	fma.rn.ftz.f32 	%f1356, %f3223, %f3223, %f1355;
	rcp.approx.ftz.f32 	%f1357, %f1356;
	mul.ftz.f32 	%f1358, %f3220, %f1357;
	mul.ftz.f32 	%f1359, %f3221, %f1357;
	mul.ftz.f32 	%f1360, %f3222, %f1357;
	mul.ftz.f32 	%f1361, %f3223, %f1357;
	mul.ftz.f32 	%f1362, %f3220, %f1358;
	mul.ftz.f32 	%f1363, %f3221, %f1359;
	mul.ftz.f32 	%f1364, %f3222, %f1360;
	mul.ftz.f32 	%f1365, %f3220, %f1359;
	mul.ftz.f32 	%f1366, %f3222, %f1361;
	mul.ftz.f32 	%f1367, %f3220, %f1360;
	mul.ftz.f32 	%f1368, %f3221, %f1361;
	mul.ftz.f32 	%f1369, %f3221, %f1360;
	mul.ftz.f32 	%f1370, %f3220, %f1361;
	sub.ftz.f32 	%f1371, %f1362, %f1363;
	sub.ftz.f32 	%f1372, %f1371, %f1364;
	fma.rn.ftz.f32 	%f1373, %f3223, %f1361, %f1372;
	sub.ftz.f32 	%f1374, %f1365, %f1366;
	add.ftz.f32 	%f1375, %f1374, %f1374;
	add.ftz.f32 	%f1376, %f1367, %f1368;
	add.ftz.f32 	%f1377, %f1376, %f1376;
	add.ftz.f32 	%f1378, %f1365, %f1366;
	add.ftz.f32 	%f1379, %f1378, %f1378;
	sub.ftz.f32 	%f1380, %f1363, %f1362;
	sub.ftz.f32 	%f1381, %f1380, %f1364;
	fma.rn.ftz.f32 	%f1382, %f3223, %f1361, %f1381;
	sub.ftz.f32 	%f1383, %f1369, %f1370;
	add.ftz.f32 	%f1384, %f1383, %f1383;
	sub.ftz.f32 	%f1385, %f1367, %f1368;
	add.ftz.f32 	%f1386, %f1385, %f1385;
	add.ftz.f32 	%f1387, %f1369, %f1370;
	add.ftz.f32 	%f1388, %f1387, %f1387;
	neg.ftz.f32 	%f1389, %f1362;
	sub.ftz.f32 	%f1390, %f1389, %f1363;
	add.ftz.f32 	%f1391, %f1364, %f1390;
	fma.rn.ftz.f32 	%f1392, %f3223, %f1361, %f1391;
	mul.ftz.f32 	%f1393, %f3214, %f1373;
	fma.rn.ftz.f32 	%f1394, %f3217, %f1375, %f1393;
	fma.rn.ftz.f32 	%f1395, %f3219, %f1377, %f1394;
	add.ftz.f32 	%f3227, %f3224, %f1395;
	mul.ftz.f32 	%f1396, %f3217, %f1382;
	fma.rn.ftz.f32 	%f1397, %f3214, %f1379, %f1396;
	fma.rn.ftz.f32 	%f1398, %f3219, %f1384, %f1397;
	add.ftz.f32 	%f3231, %f3225, %f1398;
	mul.ftz.f32 	%f1399, %f3217, %f1388;
	fma.rn.ftz.f32 	%f1400, %f3214, %f1386, %f1399;
	fma.rn.ftz.f32 	%f1401, %f3219, %f1392, %f1400;
	add.ftz.f32 	%f3235, %f3226, %f1401;
	mul.ftz.f32 	%f1402, %f3213, %f1373;
	fma.rn.ftz.f32 	%f1403, %f3216, %f1375, %f1402;
	fma.rn.ftz.f32 	%f3228, %f3218, %f1377, %f1403;
	mul.ftz.f32 	%f1404, %f3216, %f1382;
	fma.rn.ftz.f32 	%f1405, %f3213, %f1379, %f1404;
	fma.rn.ftz.f32 	%f3232, %f3218, %f1384, %f1405;
	mul.ftz.f32 	%f1406, %f3216, %f1388;
	fma.rn.ftz.f32 	%f1407, %f3213, %f1386, %f1406;
	fma.rn.ftz.f32 	%f3236, %f3218, %f1392, %f1407;
	mul.ftz.f32 	%f1408, %f3212, %f1373;
	fma.rn.ftz.f32 	%f3229, %f3215, %f1375, %f1408;
	mul.ftz.f32 	%f1409, %f3215, %f1382;
	fma.rn.ftz.f32 	%f3233, %f3212, %f1379, %f1409;
	mul.ftz.f32 	%f1410, %f3215, %f1388;
	fma.rn.ftz.f32 	%f3237, %f3212, %f1386, %f1410;
	mul.ftz.f32 	%f3230, %f3211, %f1373;
	mul.ftz.f32 	%f3234, %f3211, %f1379;
	mul.ftz.f32 	%f3238, %f3211, %f1386;

$L__BB0_18:
	mul.ftz.f32 	%f1448, %f3232, %f3237;
	mul.ftz.f32 	%f1449, %f3233, %f3236;
	sub.ftz.f32 	%f1450, %f1449, %f1448;
	mul.ftz.f32 	%f1451, %f3230, %f1450;
	mul.ftz.f32 	%f1452, %f3232, %f3238;
	mul.ftz.f32 	%f1453, %f3234, %f3236;
	sub.ftz.f32 	%f1454, %f1453, %f1452;
	mul.ftz.f32 	%f1455, %f3229, %f1454;
	sub.ftz.f32 	%f1456, %f1451, %f1455;
	mul.ftz.f32 	%f1457, %f3233, %f3238;
	mul.ftz.f32 	%f1458, %f3234, %f3237;
	sub.ftz.f32 	%f1459, %f1458, %f1457;
	fma.rn.ftz.f32 	%f1460, %f3228, %f1459, %f1456;
	rcp.approx.ftz.f32 	%f1461, %f1460;
	mul.ftz.f32 	%f3242, %f1450, %f1461;
	mul.ftz.f32 	%f1462, %f3229, %f3236;
	mul.ftz.f32 	%f1463, %f3228, %f3237;
	sub.ftz.f32 	%f1464, %f1463, %f1462;
	mul.ftz.f32 	%f3241, %f1464, %f1461;
	mul.ftz.f32 	%f1465, %f3228, %f3233;
	mul.ftz.f32 	%f1466, %f3229, %f3232;
	sub.ftz.f32 	%f1467, %f1466, %f1465;
	mul.ftz.f32 	%f3240, %f1467, %f1461;
	sub.ftz.f32 	%f1468, %f1452, %f1453;
	mul.ftz.f32 	%f3246, %f1468, %f1461;
	mul.ftz.f32 	%f1469, %f3228, %f3238;
	mul.ftz.f32 	%f1470, %f3230, %f3236;
	sub.ftz.f32 	%f1471, %f1470, %f1469;
	mul.ftz.f32 	%f3245, %f1471, %f1461;
	mul.ftz.f32 	%f1472, %f3230, %f3232;
	mul.ftz.f32 	%f1473, %f3228, %f3234;
	sub.ftz.f32 	%f1474, %f1473, %f1472;
	mul.ftz.f32 	%f3244, %f1474, %f1461;
	mul.ftz.f32 	%f3250, %f1459, %f1461;
	mul.ftz.f32 	%f1475, %f3230, %f3237;
	mul.ftz.f32 	%f1476, %f3229, %f3238;
	sub.ftz.f32 	%f1477, %f1476, %f1475;
	mul.ftz.f32 	%f3249, %f1477, %f1461;
	mul.ftz.f32 	%f1478, %f3229, %f3234;
	mul.ftz.f32 	%f1479, %f3230, %f3233;
	sub.ftz.f32 	%f1480, %f1479, %f1478;
	mul.ftz.f32 	%f3248, %f1480, %f1461;
	mul.ftz.f32 	%f1481, %f3227, %f3242;
	neg.ftz.f32 	%f1482, %f1481;
	mul.ftz.f32 	%f1483, %f3231, %f3241;
	sub.ftz.f32 	%f1484, %f1482, %f1483;
	mul.ftz.f32 	%f1485, %f3235, %f3240;
	sub.ftz.f32 	%f3239, %f1484, %f1485;
	mul.ftz.f32 	%f1486, %f3227, %f3246;
	neg.ftz.f32 	%f1487, %f1486;
	mul.ftz.f32 	%f1488, %f3231, %f3245;
	sub.ftz.f32 	%f1489, %f1487, %f1488;
	mul.ftz.f32 	%f1490, %f3235, %f3244;
	sub.ftz.f32 	%f3243, %f1489, %f1490;
	mul.ftz.f32 	%f1491, %f3227, %f3250;
	neg.ftz.f32 	%f1492, %f1491;
	mul.ftz.f32 	%f1493, %f3231, %f3249;
	sub.ftz.f32 	%f1494, %f1492, %f1493;
	mul.ftz.f32 	%f1495, %f3235, %f3248;
	sub.ftz.f32 	%f3247, %f1494, %f1495;
	bra.uni 	$L__BB0_19;

$L__BB0_10:
	// begin inline asm
	call (%rd786), _optix_get_instance_inverse_transform_from_handle, (%rd49);
	// end inline asm

$L__BB0_11:
	// begin inline asm
	cvta.to.global.u64 %rd55, %rd786;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r59,%r60,%r61,%r62}, [%rd55];
	// end inline asm
	mov.b32 	%f3242, %r59;
	mov.b32 	%f3241, %r60;
	mov.b32 	%f3240, %r61;
	mov.b32 	%f3239, %r62;
	add.s64 	%rd59, %rd786, 16;
	// begin inline asm
	cvta.to.global.u64 %rd58, %rd59;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r63,%r64,%r65,%r66}, [%rd58];
	// end inline asm
	mov.b32 	%f3246, %r63;
	mov.b32 	%f3245, %r64;
	mov.b32 	%f3244, %r65;
	mov.b32 	%f3243, %r66;
	add.s64 	%rd62, %rd786, 32;
	// begin inline asm
	cvta.to.global.u64 %rd61, %rd62;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r67,%r68,%r69,%r70}, [%rd61];
	// end inline asm
	mov.b32 	%f3250, %r67;
	mov.b32 	%f3249, %r68;
	mov.b32 	%f3248, %r69;
	mov.b32 	%f3247, %r70;

$L__BB0_19:
	setp.eq.s32 	%p12, %r1049, 0;
	@%p12 bra 	$L__BB0_21;

	mul.ftz.f32 	%f1496, %f3207, %f3242;
	fma.rn.ftz.f32 	%f1497, %f3203, %f3241, %f1496;
	fma.rn.ftz.f32 	%f165, %f3199, %f3240, %f1497;
	mul.ftz.f32 	%f1498, %f3208, %f3242;
	fma.rn.ftz.f32 	%f1499, %f3204, %f3241, %f1498;
	fma.rn.ftz.f32 	%f166, %f3200, %f3240, %f1499;
	mul.ftz.f32 	%f1500, %f3209, %f3242;
	fma.rn.ftz.f32 	%f1501, %f3205, %f3241, %f1500;
	fma.rn.ftz.f32 	%f167, %f3201, %f3240, %f1501;
	mul.ftz.f32 	%f1502, %f3210, %f3242;
	fma.rn.ftz.f32 	%f1503, %f3206, %f3241, %f1502;
	fma.rn.ftz.f32 	%f1504, %f3202, %f3240, %f1503;
	add.ftz.f32 	%f3239, %f3239, %f1504;
	mul.ftz.f32 	%f1505, %f3207, %f3246;
	fma.rn.ftz.f32 	%f1506, %f3203, %f3245, %f1505;
	fma.rn.ftz.f32 	%f169, %f3199, %f3244, %f1506;
	mul.ftz.f32 	%f1507, %f3208, %f3246;
	fma.rn.ftz.f32 	%f1508, %f3204, %f3245, %f1507;
	fma.rn.ftz.f32 	%f170, %f3200, %f3244, %f1508;
	mul.ftz.f32 	%f1509, %f3209, %f3246;
	fma.rn.ftz.f32 	%f1510, %f3205, %f3245, %f1509;
	fma.rn.ftz.f32 	%f171, %f3201, %f3244, %f1510;
	mul.ftz.f32 	%f1511, %f3210, %f3246;
	fma.rn.ftz.f32 	%f1512, %f3206, %f3245, %f1511;
	fma.rn.ftz.f32 	%f1513, %f3202, %f3244, %f1512;
	add.ftz.f32 	%f3243, %f3243, %f1513;
	mul.ftz.f32 	%f1514, %f3207, %f3250;
	fma.rn.ftz.f32 	%f1515, %f3203, %f3249, %f1514;
	fma.rn.ftz.f32 	%f173, %f3199, %f3248, %f1515;
	mul.ftz.f32 	%f1516, %f3208, %f3250;
	fma.rn.ftz.f32 	%f1517, %f3204, %f3249, %f1516;
	fma.rn.ftz.f32 	%f174, %f3200, %f3248, %f1517;
	mul.ftz.f32 	%f1518, %f3209, %f3250;
	fma.rn.ftz.f32 	%f1519, %f3205, %f3249, %f1518;
	fma.rn.ftz.f32 	%f175, %f3201, %f3248, %f1519;
	mul.ftz.f32 	%f1520, %f3210, %f3250;
	fma.rn.ftz.f32 	%f1521, %f3206, %f3249, %f1520;
	fma.rn.ftz.f32 	%f1522, %f3202, %f3248, %f1521;
	add.ftz.f32 	%f3247, %f3247, %f1522;
	mov.f32 	%f3240, %f167;
	mov.f32 	%f3241, %f166;
	mov.f32 	%f3242, %f165;
	mov.f32 	%f3244, %f171;
	mov.f32 	%f3245, %f170;
	mov.f32 	%f3246, %f169;
	mov.f32 	%f3248, %f175;
	mov.f32 	%f3249, %f174;
	mov.f32 	%f3250, %f173;

$L__BB0_21:
	add.s32 	%r1049, %r1049, 1;
	setp.lt.u32 	%p13, %r1049, %r54;
	mov.f32 	%f3199, %f3250;
	mov.f32 	%f3200, %f3249;
	mov.f32 	%f3201, %f3248;
	mov.f32 	%f3202, %f3247;
	mov.f32 	%f3203, %f3246;
	mov.f32 	%f3204, %f3245;
	mov.f32 	%f3205, %f3244;
	mov.f32 	%f3206, %f3243;
	mov.f32 	%f3207, %f3242;
	mov.f32 	%f3208, %f3241;
	mov.f32 	%f3209, %f3240;
	mov.f32 	%f3210, %f3239;
	@%p13 bra 	$L__BB0_6;

$L__BB0_22:
	mul.ftz.f32 	%f1523, %f1, %f3242;
	fma.rn.ftz.f32 	%f1524, %f2, %f3241, %f1523;
	fma.rn.ftz.f32 	%f1525, %f3, %f3240, %f1524;
	mul.ftz.f32 	%f1526, %f1, %f3246;
	fma.rn.ftz.f32 	%f1527, %f2, %f3245, %f1526;
	fma.rn.ftz.f32 	%f1528, %f3, %f3244, %f1527;
	mul.ftz.f32 	%f1529, %f1, %f3250;
	fma.rn.ftz.f32 	%f1530, %f2, %f3249, %f1529;
	fma.rn.ftz.f32 	%f1531, %f3, %f3248, %f1530;
	add.ftz.f32 	%f209, %f3247, %f1531;
	add.ftz.f32 	%f208, %f3243, %f1528;
	add.ftz.f32 	%f207, %f3239, %f1525;
	bra.uni 	$L__BB0_24;

$L__BB0_50:
	// begin inline asm
	call (%rd287), _optix_get_gas_traversable_handle, ();
	// end inline asm
	// begin inline asm
	call (%r358), _optix_read_sbt_gas_idx, ();
	// end inline asm
	mov.f32 	%f1782, 0f00000000;
	// begin inline asm
	call (%f1766, %f1767, %f1768, %f1769,  %f1770, %f1771, %f1772, %f1773,  %f1774, %f1775, %f1776, %f1777,  %f1778, %f1779, %f1780, %f1781), _optix_get_cubic_bspline_vertex_data, (%rd287, %r43, %r358, %f1782);
	// end inline asm
	add.ftz.f32 	%f1783, %f1774, %f1766;
	add.ftz.f32 	%f1784, %f1775, %f1767;
	add.ftz.f32 	%f1785, %f1776, %f1768;
	add.ftz.f32 	%f1786, %f1777, %f1769;
	mul.ftz.f32 	%f1787, %f1783, 0f3E2AAAAB;
	mul.ftz.f32 	%f1788, %f1784, 0f3E2AAAAB;
	mul.ftz.f32 	%f1789, %f1785, 0f3E2AAAAB;
	mul.ftz.f32 	%f1790, %f1786, 0f3E2AAAAB;
	fma.rn.ftz.f32 	%f373, %f1770, 0f3F2AAAAB, %f1787;
	fma.rn.ftz.f32 	%f374, %f1771, 0f3F2AAAAB, %f1788;
	fma.rn.ftz.f32 	%f375, %f1772, 0f3F2AAAAB, %f1789;
	fma.rn.ftz.f32 	%f376, %f1773, 0f3F2AAAAB, %f1790;
	sub.ftz.f32 	%f377, %f1774, %f1766;
	sub.ftz.f32 	%f378, %f1775, %f1767;
	sub.ftz.f32 	%f379, %f1776, %f1768;
	sub.ftz.f32 	%f380, %f1777, %f1769;
	sub.ftz.f32 	%f381, %f1774, %f1770;
	sub.ftz.f32 	%f382, %f1775, %f1771;
	sub.ftz.f32 	%f383, %f1776, %f1772;
	sub.ftz.f32 	%f384, %f1777, %f1773;
	sub.ftz.f32 	%f385, %f1778, %f1770;
	sub.ftz.f32 	%f386, %f1779, %f1771;
	sub.ftz.f32 	%f387, %f1780, %f1772;
	sub.ftz.f32 	%f388, %f1781, %f1773;
	// begin inline asm
	call (%r361), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p26, %r361, 0;
	@%p26 bra 	$L__BB0_70;

	// begin inline asm
	call (%r362), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1791), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p27, %r362, 0;
	@%p27 bra 	$L__BB0_69;

	mov.u32 	%r1051, 0;

$L__BB0_53:
	.pragma "nounroll";
	// begin inline asm
	call (%rd289), _optix_get_transform_list_handle, (%r1051);
	// end inline asm
	// begin inline asm
	call (%r365), _optix_get_transform_type_from_handle, (%rd289);
	// end inline asm
	or.b32  	%r366, %r365, 1;
	setp.eq.s32 	%p28, %r366, 3;
	@%p28 bra 	$L__BB0_59;
	bra.uni 	$L__BB0_54;

$L__BB0_59:
	setp.eq.s32 	%p31, %r365, 2;
	@%p31 bra 	$L__BB0_63;
	bra.uni 	$L__BB0_60;

$L__BB0_63:
	// begin inline asm
	call (%rd361), _optix_get_matrix_motion_transform_from_handle, (%rd289);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd363, %rd361;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r454,%r455,%r456,%r457}, [%rd363];
	// end inline asm
	add.s64 	%rd367, %rd361, 16;
	// begin inline asm
	cvta.to.global.u64 %rd366, %rd367;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r458,%r459,%r460,%r461}, [%rd366];
	// end inline asm
	add.s64 	%rd370, %rd361, 32;
	// begin inline asm
	cvta.to.global.u64 %rd369, %rd370;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r462,%r463,%r464,%r465}, [%rd369];
	// end inline asm
	add.s64 	%rd373, %rd361, 48;
	// begin inline asm
	cvta.to.global.u64 %rd372, %rd373;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r466,%r467,%r468,%r469}, [%rd372];
	// end inline asm
	add.s64 	%rd376, %rd361, 64;
	// begin inline asm
	cvta.to.global.u64 %rd375, %rd376;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r470,%r471,%r472,%r473}, [%rd375];
	// end inline asm
	add.s64 	%rd379, %rd361, 80;
	// begin inline asm
	cvta.to.global.u64 %rd378, %rd379;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r474,%r475,%r476,%r477}, [%rd378];
	// end inline asm
	add.s64 	%rd382, %rd361, 96;
	// begin inline asm
	cvta.to.global.u64 %rd381, %rd382;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r478,%r479,%r480,%r481}, [%rd381];
	// end inline asm
	add.s64 	%rd385, %rd361, 112;
	// begin inline asm
	cvta.to.global.u64 %rd384, %rd385;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r482,%r483,%r484,%r485}, [%rd384];
	// end inline asm
	mov.b32 	%f1918, %r457;
	mov.b32 	%f1919, %r458;
	and.b32  	%r498, %r456, 65535;
	add.s32 	%r499, %r498, -1;
	cvt.rn.f32.s32 	%f1920, %r499;
	sub.ftz.f32 	%f1921, %f1791, %f1918;
	mul.ftz.f32 	%f1922, %f1921, %f1920;
	sub.ftz.f32 	%f1923, %f1919, %f1918;
	div.approx.ftz.f32 	%f1924, %f1922, %f1923;
	min.ftz.f32 	%f1925, %f1920, %f1924;
	mov.f32 	%f1926, 0f00000000;
	max.ftz.f32 	%f1927, %f1926, %f1925;
	cvt.rmi.ftz.f32.f32 	%f1928, %f1927;
	sub.ftz.f32 	%f475, %f1927, %f1928;
	cvt.rzi.ftz.s32.f32 	%r500, %f1928;
	cvt.s64.s32 	%rd22, %r500;
	mul.wide.s32 	%rd396, %r500, 48;
	add.s64 	%rd388, %rd370, %rd396;
	// begin inline asm
	cvta.to.global.u64 %rd387, %rd388;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r486,%r487,%r488,%r489}, [%rd387];
	// end inline asm
	mov.b32 	%f3372, %r486;
	mov.b32 	%f3373, %r487;
	mov.b32 	%f3374, %r488;
	mov.b32 	%f3375, %r489;
	add.s64 	%rd391, %rd388, 16;
	// begin inline asm
	cvta.to.global.u64 %rd390, %rd391;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r490,%r491,%r492,%r493}, [%rd390];
	// end inline asm
	mov.b32 	%f3368, %r490;
	mov.b32 	%f3369, %r491;
	mov.b32 	%f3370, %r492;
	mov.b32 	%f3371, %r493;
	add.s64 	%rd394, %rd388, 32;
	// begin inline asm
	cvta.to.global.u64 %rd393, %rd394;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r494,%r495,%r496,%r497}, [%rd393];
	// end inline asm
	mov.b32 	%f3364, %r494;
	mov.b32 	%f3365, %r495;
	mov.b32 	%f3366, %r496;
	mov.b32 	%f3367, %r497;
	setp.leu.ftz.f32 	%p33, %f475, 0f00000000;
	@%p33 bra 	$L__BB0_65;

	mov.f32 	%f1929, 0f3F800000;
	sub.ftz.f32 	%f1930, %f1929, %f475;
	mul.lo.s64 	%rd406, %rd22, 48;
	add.s64 	%rd407, %rd361, %rd406;
	add.s64 	%rd398, %rd407, 80;
	// begin inline asm
	cvta.to.global.u64 %rd397, %rd398;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r501,%r502,%r503,%r504}, [%rd397];
	// end inline asm
	mov.b32 	%f1931, %r501;
	mov.b32 	%f1932, %r502;
	mov.b32 	%f1933, %r503;
	mov.b32 	%f1934, %r504;
	mul.ftz.f32 	%f1935, %f475, %f1931;
	mul.ftz.f32 	%f1936, %f475, %f1932;
	mul.ftz.f32 	%f1937, %f475, %f1933;
	mul.ftz.f32 	%f1938, %f475, %f1934;
	fma.rn.ftz.f32 	%f3372, %f1930, %f3372, %f1935;
	fma.rn.ftz.f32 	%f3373, %f1930, %f3373, %f1936;
	fma.rn.ftz.f32 	%f3374, %f1930, %f3374, %f1937;
	fma.rn.ftz.f32 	%f3375, %f1930, %f3375, %f1938;
	add.s64 	%rd401, %rd407, 96;
	// begin inline asm
	cvta.to.global.u64 %rd400, %rd401;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r505,%r506,%r507,%r508}, [%rd400];
	// end inline asm
	mov.b32 	%f1939, %r505;
	mov.b32 	%f1940, %r506;
	mov.b32 	%f1941, %r507;
	mov.b32 	%f1942, %r508;
	mul.ftz.f32 	%f1943, %f475, %f1939;
	mul.ftz.f32 	%f1944, %f475, %f1940;
	mul.ftz.f32 	%f1945, %f475, %f1941;
	mul.ftz.f32 	%f1946, %f475, %f1942;
	fma.rn.ftz.f32 	%f3368, %f1930, %f3368, %f1943;
	fma.rn.ftz.f32 	%f3369, %f1930, %f3369, %f1944;
	fma.rn.ftz.f32 	%f3370, %f1930, %f3370, %f1945;
	fma.rn.ftz.f32 	%f3371, %f1930, %f3371, %f1946;
	add.s64 	%rd404, %rd407, 112;
	// begin inline asm
	cvta.to.global.u64 %rd403, %rd404;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r509,%r510,%r511,%r512}, [%rd403];
	// end inline asm
	mov.b32 	%f1947, %r509;
	mov.b32 	%f1948, %r510;
	mov.b32 	%f1949, %r511;
	mov.b32 	%f1950, %r512;
	mul.ftz.f32 	%f1951, %f475, %f1947;
	mul.ftz.f32 	%f1952, %f475, %f1948;
	mul.ftz.f32 	%f1953, %f475, %f1949;
	mul.ftz.f32 	%f1954, %f475, %f1950;
	fma.rn.ftz.f32 	%f3364, %f1930, %f3364, %f1951;
	fma.rn.ftz.f32 	%f3365, %f1930, %f3365, %f1952;
	fma.rn.ftz.f32 	%f3366, %f1930, %f3366, %f1953;
	fma.rn.ftz.f32 	%f3367, %f1930, %f3367, %f1954;
	bra.uni 	$L__BB0_65;

$L__BB0_54:
	mov.f32 	%f3378, 0f3F800000;
	setp.eq.s32 	%p29, %r365, 4;
	@%p29 bra 	$L__BB0_57;

	setp.ne.s32 	%p30, %r365, 1;
	mov.f32 	%f3376, %f1782;
	mov.f32 	%f3377, %f1782;
	mov.f32 	%f3379, %f1782;
	mov.f32 	%f3380, %f1782;
	mov.f32 	%f3381, %f3378;
	mov.f32 	%f3382, %f1782;
	mov.f32 	%f3383, %f1782;
	mov.f32 	%f3384, %f3378;
	mov.f32 	%f3385, %f1782;
	mov.f32 	%f3386, %f1782;
	mov.f32 	%f3387, %f1782;
	@%p30 bra 	$L__BB0_66;

	// begin inline asm
	call (%rd291), _optix_get_static_transform_from_handle, (%rd289);
	// end inline asm
	add.s64 	%rd788, %rd291, 64;
	bra.uni 	$L__BB0_58;

$L__BB0_60:
	// begin inline asm
	call (%rd304), _optix_get_srt_motion_transform_from_handle, (%rd289);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd306, %rd304;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r379,%r380,%r381,%r382}, [%rd306];
	// end inline asm
	add.s64 	%rd310, %rd304, 16;
	// begin inline asm
	cvta.to.global.u64 %rd309, %rd310;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r383,%r384,%r385,%r386}, [%rd309];
	// end inline asm
	add.s64 	%rd313, %rd304, 32;
	// begin inline asm
	cvta.to.global.u64 %rd312, %rd313;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r387,%r388,%r389,%r390}, [%rd312];
	// end inline asm
	add.s64 	%rd316, %rd304, 48;
	// begin inline asm
	cvta.to.global.u64 %rd315, %rd316;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r391,%r392,%r393,%r394}, [%rd315];
	// end inline asm
	add.s64 	%rd319, %rd304, 64;
	// begin inline asm
	cvta.to.global.u64 %rd318, %rd319;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r395,%r396,%r397,%r398}, [%rd318];
	// end inline asm
	add.s64 	%rd322, %rd304, 80;
	// begin inline asm
	cvta.to.global.u64 %rd321, %rd322;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r399,%r400,%r401,%r402}, [%rd321];
	// end inline asm
	add.s64 	%rd325, %rd304, 96;
	// begin inline asm
	cvta.to.global.u64 %rd324, %rd325;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r403,%r404,%r405,%r406}, [%rd324];
	// end inline asm
	add.s64 	%rd328, %rd304, 112;
	// begin inline asm
	cvta.to.global.u64 %rd327, %rd328;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r407,%r408,%r409,%r410}, [%rd327];
	// end inline asm
	add.s64 	%rd331, %rd304, 128;
	// begin inline asm
	cvta.to.global.u64 %rd330, %rd331;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r411,%r412,%r413,%r414}, [%rd330];
	// end inline asm
	add.s64 	%rd334, %rd304, 144;
	// begin inline asm
	cvta.to.global.u64 %rd333, %rd334;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r415,%r416,%r417,%r418}, [%rd333];
	// end inline asm
	mov.b32 	%f1806, %r382;
	mov.b32 	%f1807, %r383;
	and.b32  	%r435, %r381, 65535;
	add.s32 	%r436, %r435, -1;
	cvt.rn.f32.s32 	%f1808, %r436;
	sub.ftz.f32 	%f1809, %f1791, %f1806;
	mul.ftz.f32 	%f1810, %f1809, %f1808;
	sub.ftz.f32 	%f1811, %f1807, %f1806;
	div.approx.ftz.f32 	%f1812, %f1810, %f1811;
	min.ftz.f32 	%f1813, %f1808, %f1812;
	mov.f32 	%f1814, 0f00000000;
	max.ftz.f32 	%f1815, %f1814, %f1813;
	cvt.rmi.ftz.f32.f32 	%f1816, %f1815;
	sub.ftz.f32 	%f414, %f1815, %f1816;
	cvt.rzi.ftz.s32.f32 	%r437, %f1816;
	mul.wide.s32 	%rd348, %r437, 64;
	add.s64 	%rd337, %rd313, %rd348;
	// begin inline asm
	cvta.to.global.u64 %rd336, %rd337;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r419,%r420,%r421,%r422}, [%rd336];
	// end inline asm
	mov.b32 	%f3348, %r419;
	mov.b32 	%f3349, %r420;
	mov.b32 	%f3350, %r421;
	mov.b32 	%f3351, %r422;
	add.s64 	%rd340, %rd337, 16;
	// begin inline asm
	cvta.to.global.u64 %rd339, %rd340;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r423,%r424,%r425,%r426}, [%rd339];
	// end inline asm
	mov.b32 	%f3352, %r423;
	mov.b32 	%f3353, %r424;
	mov.b32 	%f3354, %r425;
	mov.b32 	%f3355, %r426;
	add.s64 	%rd343, %rd337, 32;
	// begin inline asm
	cvta.to.global.u64 %rd342, %rd343;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r427,%r428,%r429,%r430}, [%rd342];
	// end inline asm
	mov.b32 	%f3356, %r427;
	mov.b32 	%f3357, %r428;
	mov.b32 	%f3358, %r429;
	mov.b32 	%f3359, %r430;
	add.s64 	%rd346, %rd337, 48;
	// begin inline asm
	cvta.to.global.u64 %rd345, %rd346;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r431,%r432,%r433,%r434}, [%rd345];
	// end inline asm
	mov.b32 	%f3360, %r431;
	mov.b32 	%f3361, %r432;
	mov.b32 	%f3362, %r433;
	mov.b32 	%f3363, %r434;
	setp.leu.ftz.f32 	%p32, %f414, 0f00000000;
	@%p32 bra 	$L__BB0_62;

	mov.f32 	%f1817, 0f3F800000;
	sub.ftz.f32 	%f1818, %f1817, %f414;
	add.s64 	%rd350, %rd337, 64;
	// begin inline asm
	cvta.to.global.u64 %rd349, %rd350;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r438,%r439,%r440,%r441}, [%rd349];
	// end inline asm
	mov.b32 	%f1819, %r438;
	mov.b32 	%f1820, %r439;
	mov.b32 	%f1821, %r440;
	mov.b32 	%f1822, %r441;
	mul.ftz.f32 	%f1823, %f414, %f1819;
	mul.ftz.f32 	%f1824, %f414, %f1820;
	mul.ftz.f32 	%f1825, %f414, %f1821;
	mul.ftz.f32 	%f1826, %f414, %f1822;
	fma.rn.ftz.f32 	%f3348, %f1818, %f3348, %f1823;
	fma.rn.ftz.f32 	%f3349, %f1818, %f3349, %f1824;
	fma.rn.ftz.f32 	%f3350, %f1818, %f3350, %f1825;
	fma.rn.ftz.f32 	%f3351, %f1818, %f3351, %f1826;
	add.s64 	%rd353, %rd337, 80;
	// begin inline asm
	cvta.to.global.u64 %rd352, %rd353;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r442,%r443,%r444,%r445}, [%rd352];
	// end inline asm
	mov.b32 	%f1827, %r442;
	mov.b32 	%f1828, %r443;
	mov.b32 	%f1829, %r444;
	mov.b32 	%f1830, %r445;
	mul.ftz.f32 	%f1831, %f414, %f1827;
	mul.ftz.f32 	%f1832, %f414, %f1828;
	mul.ftz.f32 	%f1833, %f414, %f1829;
	mul.ftz.f32 	%f1834, %f414, %f1830;
	fma.rn.ftz.f32 	%f3352, %f1818, %f3352, %f1831;
	fma.rn.ftz.f32 	%f3353, %f1818, %f3353, %f1832;
	fma.rn.ftz.f32 	%f3354, %f1818, %f3354, %f1833;
	fma.rn.ftz.f32 	%f3355, %f1818, %f3355, %f1834;
	add.s64 	%rd356, %rd337, 96;
	// begin inline asm
	cvta.to.global.u64 %rd355, %rd356;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r446,%r447,%r448,%r449}, [%rd355];
	// end inline asm
	mov.b32 	%f1835, %r446;
	mov.b32 	%f1836, %r447;
	mov.b32 	%f1837, %r448;
	mov.b32 	%f1838, %r449;
	mul.ftz.f32 	%f1839, %f414, %f1835;
	mul.ftz.f32 	%f1840, %f414, %f1836;
	mul.ftz.f32 	%f1841, %f414, %f1837;
	mul.ftz.f32 	%f1842, %f414, %f1838;
	fma.rn.ftz.f32 	%f3356, %f1818, %f3356, %f1839;
	fma.rn.ftz.f32 	%f1843, %f1818, %f3357, %f1840;
	fma.rn.ftz.f32 	%f1844, %f1818, %f3358, %f1841;
	fma.rn.ftz.f32 	%f1845, %f1818, %f3359, %f1842;
	add.s64 	%rd359, %rd337, 112;
	// begin inline asm
	cvta.to.global.u64 %rd358, %rd359;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r450,%r451,%r452,%r453}, [%rd358];
	// end inline asm
	mov.b32 	%f1846, %r450;
	mov.b32 	%f1847, %r451;
	mov.b32 	%f1848, %r452;
	mov.b32 	%f1849, %r453;
	mul.ftz.f32 	%f1850, %f414, %f1846;
	mul.ftz.f32 	%f1851, %f414, %f1847;
	mul.ftz.f32 	%f1852, %f414, %f1848;
	mul.ftz.f32 	%f1853, %f414, %f1849;
	fma.rn.ftz.f32 	%f1854, %f1818, %f3360, %f1850;
	fma.rn.ftz.f32 	%f3361, %f1818, %f3361, %f1851;
	fma.rn.ftz.f32 	%f3362, %f1818, %f3362, %f1852;
	fma.rn.ftz.f32 	%f3363, %f1818, %f3363, %f1853;
	mul.ftz.f32 	%f1855, %f1844, %f1844;
	fma.rn.ftz.f32 	%f1856, %f1843, %f1843, %f1855;
	fma.rn.ftz.f32 	%f1857, %f1845, %f1845, %f1856;
	fma.rn.ftz.f32 	%f1858, %f1854, %f1854, %f1857;
	rsqrt.approx.ftz.f32 	%f1859, %f1858;
	mul.ftz.f32 	%f3357, %f1843, %f1859;
	mul.ftz.f32 	%f3358, %f1844, %f1859;
	mul.ftz.f32 	%f3359, %f1845, %f1859;
	mul.ftz.f32 	%f3360, %f1859, %f1854;

$L__BB0_62:
	mul.ftz.f32 	%f1860, %f3358, %f3358;
	fma.rn.ftz.f32 	%f1861, %f3357, %f3357, %f1860;
	fma.rn.ftz.f32 	%f1862, %f3359, %f3359, %f1861;
	fma.rn.ftz.f32 	%f1863, %f3360, %f3360, %f1862;
	rcp.approx.ftz.f32 	%f1864, %f1863;
	mul.ftz.f32 	%f1865, %f3357, %f1864;
	mul.ftz.f32 	%f1866, %f3358, %f1864;
	mul.ftz.f32 	%f1867, %f3359, %f1864;
	mul.ftz.f32 	%f1868, %f3360, %f1864;
	mul.ftz.f32 	%f1869, %f3357, %f1865;
	mul.ftz.f32 	%f1870, %f3358, %f1866;
	mul.ftz.f32 	%f1871, %f3359, %f1867;
	mul.ftz.f32 	%f1872, %f3357, %f1866;
	mul.ftz.f32 	%f1873, %f3359, %f1868;
	mul.ftz.f32 	%f1874, %f3357, %f1867;
	mul.ftz.f32 	%f1875, %f3358, %f1868;
	mul.ftz.f32 	%f1876, %f3358, %f1867;
	mul.ftz.f32 	%f1877, %f3357, %f1868;
	sub.ftz.f32 	%f1878, %f1869, %f1870;
	sub.ftz.f32 	%f1879, %f1878, %f1871;
	fma.rn.ftz.f32 	%f1880, %f3360, %f1868, %f1879;
	sub.ftz.f32 	%f1881, %f1872, %f1873;
	add.ftz.f32 	%f1882, %f1881, %f1881;
	add.ftz.f32 	%f1883, %f1874, %f1875;
	add.ftz.f32 	%f1884, %f1883, %f1883;
	add.ftz.f32 	%f1885, %f1872, %f1873;
	add.ftz.f32 	%f1886, %f1885, %f1885;
	sub.ftz.f32 	%f1887, %f1870, %f1869;
	sub.ftz.f32 	%f1888, %f1887, %f1871;
	fma.rn.ftz.f32 	%f1889, %f3360, %f1868, %f1888;
	sub.ftz.f32 	%f1890, %f1876, %f1877;
	add.ftz.f32 	%f1891, %f1890, %f1890;
	sub.ftz.f32 	%f1892, %f1874, %f1875;
	add.ftz.f32 	%f1893, %f1892, %f1892;
	add.ftz.f32 	%f1894, %f1876, %f1877;
	add.ftz.f32 	%f1895, %f1894, %f1894;
	neg.ftz.f32 	%f1896, %f1869;
	sub.ftz.f32 	%f1897, %f1896, %f1870;
	add.ftz.f32 	%f1898, %f1871, %f1897;
	fma.rn.ftz.f32 	%f1899, %f3360, %f1868, %f1898;
	mul.ftz.f32 	%f1900, %f3351, %f1880;
	fma.rn.ftz.f32 	%f1901, %f3354, %f1882, %f1900;
	fma.rn.ftz.f32 	%f1902, %f3356, %f1884, %f1901;
	add.ftz.f32 	%f3375, %f3361, %f1902;
	mul.ftz.f32 	%f1903, %f3354, %f1889;
	fma.rn.ftz.f32 	%f1904, %f3351, %f1886, %f1903;
	fma.rn.ftz.f32 	%f1905, %f3356, %f1891, %f1904;
	add.ftz.f32 	%f3371, %f3362, %f1905;
	mul.ftz.f32 	%f1906, %f3354, %f1895;
	fma.rn.ftz.f32 	%f1907, %f3351, %f1893, %f1906;
	fma.rn.ftz.f32 	%f1908, %f3356, %f1899, %f1907;
	add.ftz.f32 	%f3367, %f3363, %f1908;
	mul.ftz.f32 	%f1909, %f3350, %f1880;
	fma.rn.ftz.f32 	%f1910, %f3353, %f1882, %f1909;
	fma.rn.ftz.f32 	%f3374, %f3355, %f1884, %f1910;
	mul.ftz.f32 	%f1911, %f3353, %f1889;
	fma.rn.ftz.f32 	%f1912, %f3350, %f1886, %f1911;
	fma.rn.ftz.f32 	%f3370, %f3355, %f1891, %f1912;
	mul.ftz.f32 	%f1913, %f3353, %f1895;
	fma.rn.ftz.f32 	%f1914, %f3350, %f1893, %f1913;
	fma.rn.ftz.f32 	%f3366, %f3355, %f1899, %f1914;
	mul.ftz.f32 	%f1915, %f3349, %f1880;
	fma.rn.ftz.f32 	%f3373, %f3352, %f1882, %f1915;
	mul.ftz.f32 	%f1916, %f3352, %f1889;
	fma.rn.ftz.f32 	%f3369, %f3349, %f1886, %f1916;
	mul.ftz.f32 	%f1917, %f3352, %f1895;
	fma.rn.ftz.f32 	%f3365, %f3349, %f1893, %f1917;
	mul.ftz.f32 	%f3372, %f3348, %f1880;
	mul.ftz.f32 	%f3368, %f3348, %f1886;
	mul.ftz.f32 	%f3364, %f3348, %f1893;

$L__BB0_65:
	mul.ftz.f32 	%f1955, %f3365, %f3370;
	mul.ftz.f32 	%f1956, %f3366, %f3369;
	sub.ftz.f32 	%f1957, %f1956, %f1955;
	mul.ftz.f32 	%f1958, %f3372, %f1957;
	mul.ftz.f32 	%f1959, %f3364, %f3370;
	mul.ftz.f32 	%f1960, %f3366, %f3368;
	sub.ftz.f32 	%f1961, %f1960, %f1959;
	mul.ftz.f32 	%f1962, %f1961, %f3373;
	sub.ftz.f32 	%f1963, %f1958, %f1962;
	mul.ftz.f32 	%f1964, %f3364, %f3369;
	mul.ftz.f32 	%f1965, %f3365, %f3368;
	sub.ftz.f32 	%f1966, %f1965, %f1964;
	fma.rn.ftz.f32 	%f1967, %f1966, %f3374, %f1963;
	rcp.approx.ftz.f32 	%f1968, %f1967;
	mul.ftz.f32 	%f3384, %f1957, %f1968;
	mul.ftz.f32 	%f1969, %f3366, %f3373;
	mul.ftz.f32 	%f1970, %f3365, %f3374;
	sub.ftz.f32 	%f1971, %f1970, %f1969;
	mul.ftz.f32 	%f3385, %f1971, %f1968;
	mul.ftz.f32 	%f1972, %f3369, %f3374;
	mul.ftz.f32 	%f1973, %f3370, %f3373;
	sub.ftz.f32 	%f1974, %f1973, %f1972;
	mul.ftz.f32 	%f3386, %f1974, %f1968;
	sub.ftz.f32 	%f1975, %f1959, %f1960;
	mul.ftz.f32 	%f3380, %f1975, %f1968;
	mul.ftz.f32 	%f1976, %f3364, %f3374;
	mul.ftz.f32 	%f1977, %f3366, %f3372;
	sub.ftz.f32 	%f1978, %f1977, %f1976;
	mul.ftz.f32 	%f3381, %f1978, %f1968;
	mul.ftz.f32 	%f1979, %f3370, %f3372;
	mul.ftz.f32 	%f1980, %f3368, %f3374;
	sub.ftz.f32 	%f1981, %f1980, %f1979;
	mul.ftz.f32 	%f3382, %f1981, %f1968;
	mul.ftz.f32 	%f3376, %f1966, %f1968;
	mul.ftz.f32 	%f1982, %f3365, %f3372;
	mul.ftz.f32 	%f1983, %f3364, %f3373;
	sub.ftz.f32 	%f1984, %f1983, %f1982;
	mul.ftz.f32 	%f3377, %f1984, %f1968;
	mul.ftz.f32 	%f1985, %f3368, %f3373;
	mul.ftz.f32 	%f1986, %f3369, %f3372;
	sub.ftz.f32 	%f1987, %f1986, %f1985;
	mul.ftz.f32 	%f3378, %f1987, %f1968;
	mul.ftz.f32 	%f1988, %f3375, %f3384;
	neg.ftz.f32 	%f1989, %f1988;
	mul.ftz.f32 	%f1990, %f3371, %f3385;
	sub.ftz.f32 	%f1991, %f1989, %f1990;
	mul.ftz.f32 	%f1992, %f3367, %f3386;
	sub.ftz.f32 	%f3387, %f1991, %f1992;
	mul.ftz.f32 	%f1993, %f3375, %f3380;
	neg.ftz.f32 	%f1994, %f1993;
	mul.ftz.f32 	%f1995, %f3371, %f3381;
	sub.ftz.f32 	%f1996, %f1994, %f1995;
	mul.ftz.f32 	%f1997, %f3367, %f3382;
	sub.ftz.f32 	%f3383, %f1996, %f1997;
	mul.ftz.f32 	%f1998, %f3375, %f3376;
	neg.ftz.f32 	%f1999, %f1998;
	mul.ftz.f32 	%f2000, %f3371, %f3377;
	sub.ftz.f32 	%f2001, %f1999, %f2000;
	mul.ftz.f32 	%f2002, %f3367, %f3378;
	sub.ftz.f32 	%f3379, %f2001, %f2002;
	bra.uni 	$L__BB0_66;

$L__BB0_57:
	// begin inline asm
	call (%rd788), _optix_get_instance_inverse_transform_from_handle, (%rd289);
	// end inline asm

$L__BB0_58:
	// begin inline asm
	cvta.to.global.u64 %rd295, %rd788;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r367,%r368,%r369,%r370}, [%rd295];
	// end inline asm
	mov.b32 	%f3384, %r367;
	mov.b32 	%f3385, %r368;
	mov.b32 	%f3386, %r369;
	mov.b32 	%f3387, %r370;
	add.s64 	%rd299, %rd788, 16;
	// begin inline asm
	cvta.to.global.u64 %rd298, %rd299;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r371,%r372,%r373,%r374}, [%rd298];
	// end inline asm
	mov.b32 	%f3380, %r371;
	mov.b32 	%f3381, %r372;
	mov.b32 	%f3382, %r373;
	mov.b32 	%f3383, %r374;
	add.s64 	%rd302, %rd788, 32;
	// begin inline asm
	cvta.to.global.u64 %rd301, %rd302;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r375,%r376,%r377,%r378}, [%rd301];
	// end inline asm
	mov.b32 	%f3376, %r375;
	mov.b32 	%f3377, %r376;
	mov.b32 	%f3378, %r377;
	mov.b32 	%f3379, %r378;

$L__BB0_66:
	setp.eq.s32 	%p34, %r1051, 0;
	@%p34 bra 	$L__BB0_68;

	mul.ftz.f32 	%f2003, %f3343, %f3385;
	fma.rn.ftz.f32 	%f2004, %f3339, %f3384, %f2003;
	fma.rn.ftz.f32 	%f536, %f3347, %f3386, %f2004;
	mul.ftz.f32 	%f2005, %f3342, %f3385;
	fma.rn.ftz.f32 	%f2006, %f3338, %f3384, %f2005;
	fma.rn.ftz.f32 	%f537, %f3346, %f3386, %f2006;
	mul.ftz.f32 	%f2007, %f3341, %f3385;
	fma.rn.ftz.f32 	%f2008, %f3337, %f3384, %f2007;
	fma.rn.ftz.f32 	%f538, %f3345, %f3386, %f2008;
	mul.ftz.f32 	%f2009, %f3340, %f3385;
	fma.rn.ftz.f32 	%f2010, %f3336, %f3384, %f2009;
	fma.rn.ftz.f32 	%f2011, %f3344, %f3386, %f2010;
	add.ftz.f32 	%f3387, %f3387, %f2011;
	mul.ftz.f32 	%f2012, %f3343, %f3381;
	fma.rn.ftz.f32 	%f2013, %f3339, %f3380, %f2012;
	fma.rn.ftz.f32 	%f540, %f3347, %f3382, %f2013;
	mul.ftz.f32 	%f2014, %f3342, %f3381;
	fma.rn.ftz.f32 	%f2015, %f3338, %f3380, %f2014;
	fma.rn.ftz.f32 	%f541, %f3346, %f3382, %f2015;
	mul.ftz.f32 	%f2016, %f3341, %f3381;
	fma.rn.ftz.f32 	%f2017, %f3337, %f3380, %f2016;
	fma.rn.ftz.f32 	%f542, %f3345, %f3382, %f2017;
	mul.ftz.f32 	%f2018, %f3340, %f3381;
	fma.rn.ftz.f32 	%f2019, %f3336, %f3380, %f2018;
	fma.rn.ftz.f32 	%f2020, %f3344, %f3382, %f2019;
	add.ftz.f32 	%f3383, %f3383, %f2020;
	mul.ftz.f32 	%f2021, %f3343, %f3377;
	fma.rn.ftz.f32 	%f2022, %f3339, %f3376, %f2021;
	fma.rn.ftz.f32 	%f544, %f3347, %f3378, %f2022;
	mul.ftz.f32 	%f2023, %f3342, %f3377;
	fma.rn.ftz.f32 	%f2024, %f3338, %f3376, %f2023;
	fma.rn.ftz.f32 	%f545, %f3346, %f3378, %f2024;
	mul.ftz.f32 	%f2025, %f3341, %f3377;
	fma.rn.ftz.f32 	%f2026, %f3337, %f3376, %f2025;
	fma.rn.ftz.f32 	%f546, %f3345, %f3378, %f2026;
	mul.ftz.f32 	%f2027, %f3340, %f3377;
	fma.rn.ftz.f32 	%f2028, %f3336, %f3376, %f2027;
	fma.rn.ftz.f32 	%f2029, %f3344, %f3378, %f2028;
	add.ftz.f32 	%f3379, %f3379, %f2029;
	mov.f32 	%f3376, %f544;
	mov.f32 	%f3377, %f545;
	mov.f32 	%f3378, %f546;
	mov.f32 	%f3380, %f540;
	mov.f32 	%f3381, %f541;
	mov.f32 	%f3382, %f542;
	mov.f32 	%f3384, %f536;
	mov.f32 	%f3385, %f537;
	mov.f32 	%f3386, %f538;

$L__BB0_68:
	add.s32 	%r1051, %r1051, 1;
	setp.lt.u32 	%p35, %r1051, %r362;
	mov.f32 	%f3336, %f3387;
	mov.f32 	%f3337, %f3386;
	mov.f32 	%f3338, %f3385;
	mov.f32 	%f3339, %f3384;
	mov.f32 	%f3340, %f3383;
	mov.f32 	%f3341, %f3382;
	mov.f32 	%f3342, %f3381;
	mov.f32 	%f3343, %f3380;
	mov.f32 	%f3344, %f3379;
	mov.f32 	%f3345, %f3378;
	mov.f32 	%f3346, %f3377;
	mov.f32 	%f3347, %f3376;
	@%p35 bra 	$L__BB0_53;

$L__BB0_69:
	mul.ftz.f32 	%f2030, %f2, %f3385;
	fma.rn.ftz.f32 	%f2031, %f1, %f3384, %f2030;
	fma.rn.ftz.f32 	%f2032, %f3, %f3386, %f2031;
	mul.ftz.f32 	%f2033, %f2, %f3381;
	fma.rn.ftz.f32 	%f2034, %f1, %f3380, %f2033;
	fma.rn.ftz.f32 	%f2035, %f3, %f3382, %f2034;
	mul.ftz.f32 	%f2036, %f2, %f3377;
	fma.rn.ftz.f32 	%f2037, %f1, %f3376, %f2036;
	fma.rn.ftz.f32 	%f2038, %f3, %f3378, %f2037;
	add.ftz.f32 	%f3414, %f3379, %f2038;
	add.ftz.f32 	%f3413, %f3383, %f2035;
	add.ftz.f32 	%f3412, %f3387, %f2032;
	bra.uni 	$L__BB0_71;

$L__BB0_97:
	// begin inline asm
	call (%rd527), _optix_get_gas_traversable_handle, ();
	// end inline asm
	// begin inline asm
	call (%r666), _optix_read_sbt_gas_idx, ();
	// end inline asm
	mov.f32 	%f2365, 0f00000000;
	// begin inline asm
	call (%f2353, %f2354, %f2355, %f2356,  %f2357, %f2358, %f2359, %f2360,  %f2361, %f2362, %f2363, %f2364), _optix_get_quadratic_bspline_vertex_data, (%rd527, %r43, %r666, %f2365);
	// end inline asm
	mul.ftz.f32 	%f2366, %f2353, 0f3F000000;
	mul.ftz.f32 	%f2367, %f2354, 0f3F000000;
	mul.ftz.f32 	%f2368, %f2355, 0f3F000000;
	mul.ftz.f32 	%f2369, %f2356, 0f3F000000;
	fma.rn.ftz.f32 	%f744, %f2357, 0f3F000000, %f2366;
	fma.rn.ftz.f32 	%f745, %f2358, 0f3F000000, %f2367;
	fma.rn.ftz.f32 	%f746, %f2359, 0f3F000000, %f2368;
	fma.rn.ftz.f32 	%f747, %f2360, 0f3F000000, %f2369;
	sub.ftz.f32 	%f748, %f2357, %f2353;
	sub.ftz.f32 	%f749, %f2358, %f2354;
	sub.ftz.f32 	%f750, %f2359, %f2355;
	sub.ftz.f32 	%f751, %f2360, %f2356;
	sub.ftz.f32 	%f2370, %f2366, %f2357;
	sub.ftz.f32 	%f2371, %f2367, %f2358;
	sub.ftz.f32 	%f2372, %f2368, %f2359;
	sub.ftz.f32 	%f2373, %f2369, %f2360;
	fma.rn.ftz.f32 	%f752, %f2361, 0f3F000000, %f2370;
	fma.rn.ftz.f32 	%f753, %f2362, 0f3F000000, %f2371;
	fma.rn.ftz.f32 	%f754, %f2363, 0f3F000000, %f2372;
	fma.rn.ftz.f32 	%f755, %f2364, 0f3F000000, %f2373;
	// begin inline asm
	call (%r669), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p48, %r669, 0;
	@%p48 bra 	$L__BB0_117;

	// begin inline asm
	call (%r670), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f2374), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p49, %r670, 0;
	@%p49 bra 	$L__BB0_116;

	mov.u32 	%r1053, 0;

$L__BB0_100:
	.pragma "nounroll";
	// begin inline asm
	call (%rd529), _optix_get_transform_list_handle, (%r1053);
	// end inline asm
	// begin inline asm
	call (%r673), _optix_get_transform_type_from_handle, (%rd529);
	// end inline asm
	or.b32  	%r674, %r673, 1;
	setp.eq.s32 	%p50, %r674, 3;
	@%p50 bra 	$L__BB0_106;
	bra.uni 	$L__BB0_101;

$L__BB0_106:
	setp.eq.s32 	%p53, %r673, 2;
	@%p53 bra 	$L__BB0_110;
	bra.uni 	$L__BB0_107;

$L__BB0_110:
	// begin inline asm
	call (%rd601), _optix_get_matrix_motion_transform_from_handle, (%rd529);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd603, %rd601;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r762,%r763,%r764,%r765}, [%rd603];
	// end inline asm
	add.s64 	%rd607, %rd601, 16;
	// begin inline asm
	cvta.to.global.u64 %rd606, %rd607;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r766,%r767,%r768,%r769}, [%rd606];
	// end inline asm
	add.s64 	%rd610, %rd601, 32;
	// begin inline asm
	cvta.to.global.u64 %rd609, %rd610;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r770,%r771,%r772,%r773}, [%rd609];
	// end inline asm
	add.s64 	%rd613, %rd601, 48;
	// begin inline asm
	cvta.to.global.u64 %rd612, %rd613;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r774,%r775,%r776,%r777}, [%rd612];
	// end inline asm
	add.s64 	%rd616, %rd601, 64;
	// begin inline asm
	cvta.to.global.u64 %rd615, %rd616;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r778,%r779,%r780,%r781}, [%rd615];
	// end inline asm
	add.s64 	%rd619, %rd601, 80;
	// begin inline asm
	cvta.to.global.u64 %rd618, %rd619;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r782,%r783,%r784,%r785}, [%rd618];
	// end inline asm
	add.s64 	%rd622, %rd601, 96;
	// begin inline asm
	cvta.to.global.u64 %rd621, %rd622;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r786,%r787,%r788,%r789}, [%rd621];
	// end inline asm
	add.s64 	%rd625, %rd601, 112;
	// begin inline asm
	cvta.to.global.u64 %rd624, %rd625;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r790,%r791,%r792,%r793}, [%rd624];
	// end inline asm
	mov.b32 	%f2501, %r765;
	mov.b32 	%f2502, %r766;
	and.b32  	%r806, %r764, 65535;
	add.s32 	%r807, %r806, -1;
	cvt.rn.f32.s32 	%f2503, %r807;
	sub.ftz.f32 	%f2504, %f2374, %f2501;
	mul.ftz.f32 	%f2505, %f2504, %f2503;
	sub.ftz.f32 	%f2506, %f2502, %f2501;
	div.approx.ftz.f32 	%f2507, %f2505, %f2506;
	min.ftz.f32 	%f2508, %f2503, %f2507;
	mov.f32 	%f2509, 0f00000000;
	max.ftz.f32 	%f2510, %f2509, %f2508;
	cvt.rmi.ftz.f32.f32 	%f2511, %f2510;
	sub.ftz.f32 	%f842, %f2510, %f2511;
	cvt.rzi.ftz.s32.f32 	%r808, %f2511;
	cvt.s64.s32 	%rd36, %r808;
	mul.wide.s32 	%rd636, %r808, 48;
	add.s64 	%rd628, %rd610, %rd636;
	// begin inline asm
	cvta.to.global.u64 %rd627, %rd628;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r794,%r795,%r796,%r797}, [%rd627];
	// end inline asm
	mov.b32 	%f3509, %r794;
	mov.b32 	%f3510, %r795;
	mov.b32 	%f3511, %r796;
	mov.b32 	%f3512, %r797;
	add.s64 	%rd631, %rd628, 16;
	// begin inline asm
	cvta.to.global.u64 %rd630, %rd631;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r798,%r799,%r800,%r801}, [%rd630];
	// end inline asm
	mov.b32 	%f3505, %r798;
	mov.b32 	%f3506, %r799;
	mov.b32 	%f3507, %r800;
	mov.b32 	%f3508, %r801;
	add.s64 	%rd634, %rd628, 32;
	// begin inline asm
	cvta.to.global.u64 %rd633, %rd634;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r802,%r803,%r804,%r805}, [%rd633];
	// end inline asm
	mov.b32 	%f3501, %r802;
	mov.b32 	%f3502, %r803;
	mov.b32 	%f3503, %r804;
	mov.b32 	%f3504, %r805;
	setp.leu.ftz.f32 	%p55, %f842, 0f00000000;
	@%p55 bra 	$L__BB0_112;

	mov.f32 	%f2512, 0f3F800000;
	sub.ftz.f32 	%f2513, %f2512, %f842;
	mul.lo.s64 	%rd646, %rd36, 48;
	add.s64 	%rd647, %rd601, %rd646;
	add.s64 	%rd638, %rd647, 80;
	// begin inline asm
	cvta.to.global.u64 %rd637, %rd638;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r809,%r810,%r811,%r812}, [%rd637];
	// end inline asm
	mov.b32 	%f2514, %r809;
	mov.b32 	%f2515, %r810;
	mov.b32 	%f2516, %r811;
	mov.b32 	%f2517, %r812;
	mul.ftz.f32 	%f2518, %f842, %f2514;
	mul.ftz.f32 	%f2519, %f842, %f2515;
	mul.ftz.f32 	%f2520, %f842, %f2516;
	mul.ftz.f32 	%f2521, %f842, %f2517;
	fma.rn.ftz.f32 	%f3509, %f2513, %f3509, %f2518;
	fma.rn.ftz.f32 	%f3510, %f2513, %f3510, %f2519;
	fma.rn.ftz.f32 	%f3511, %f2513, %f3511, %f2520;
	fma.rn.ftz.f32 	%f3512, %f2513, %f3512, %f2521;
	add.s64 	%rd641, %rd647, 96;
	// begin inline asm
	cvta.to.global.u64 %rd640, %rd641;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r813,%r814,%r815,%r816}, [%rd640];
	// end inline asm
	mov.b32 	%f2522, %r813;
	mov.b32 	%f2523, %r814;
	mov.b32 	%f2524, %r815;
	mov.b32 	%f2525, %r816;
	mul.ftz.f32 	%f2526, %f842, %f2522;
	mul.ftz.f32 	%f2527, %f842, %f2523;
	mul.ftz.f32 	%f2528, %f842, %f2524;
	mul.ftz.f32 	%f2529, %f842, %f2525;
	fma.rn.ftz.f32 	%f3505, %f2513, %f3505, %f2526;
	fma.rn.ftz.f32 	%f3506, %f2513, %f3506, %f2527;
	fma.rn.ftz.f32 	%f3507, %f2513, %f3507, %f2528;
	fma.rn.ftz.f32 	%f3508, %f2513, %f3508, %f2529;
	add.s64 	%rd644, %rd647, 112;
	// begin inline asm
	cvta.to.global.u64 %rd643, %rd644;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r817,%r818,%r819,%r820}, [%rd643];
	// end inline asm
	mov.b32 	%f2530, %r817;
	mov.b32 	%f2531, %r818;
	mov.b32 	%f2532, %r819;
	mov.b32 	%f2533, %r820;
	mul.ftz.f32 	%f2534, %f842, %f2530;
	mul.ftz.f32 	%f2535, %f842, %f2531;
	mul.ftz.f32 	%f2536, %f842, %f2532;
	mul.ftz.f32 	%f2537, %f842, %f2533;
	fma.rn.ftz.f32 	%f3501, %f2513, %f3501, %f2534;
	fma.rn.ftz.f32 	%f3502, %f2513, %f3502, %f2535;
	fma.rn.ftz.f32 	%f3503, %f2513, %f3503, %f2536;
	fma.rn.ftz.f32 	%f3504, %f2513, %f3504, %f2537;
	bra.uni 	$L__BB0_112;

$L__BB0_101:
	mov.f32 	%f3515, 0f3F800000;
	setp.eq.s32 	%p51, %r673, 4;
	@%p51 bra 	$L__BB0_104;

	setp.ne.s32 	%p52, %r673, 1;
	mov.f32 	%f3513, %f2365;
	mov.f32 	%f3514, %f2365;
	mov.f32 	%f3516, %f2365;
	mov.f32 	%f3517, %f2365;
	mov.f32 	%f3518, %f3515;
	mov.f32 	%f3519, %f2365;
	mov.f32 	%f3520, %f2365;
	mov.f32 	%f3521, %f3515;
	mov.f32 	%f3522, %f2365;
	mov.f32 	%f3523, %f2365;
	mov.f32 	%f3524, %f2365;
	@%p52 bra 	$L__BB0_113;

	// begin inline asm
	call (%rd531), _optix_get_static_transform_from_handle, (%rd529);
	// end inline asm
	add.s64 	%rd790, %rd531, 64;
	bra.uni 	$L__BB0_105;

$L__BB0_107:
	// begin inline asm
	call (%rd544), _optix_get_srt_motion_transform_from_handle, (%rd529);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd546, %rd544;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r687,%r688,%r689,%r690}, [%rd546];
	// end inline asm
	add.s64 	%rd550, %rd544, 16;
	// begin inline asm
	cvta.to.global.u64 %rd549, %rd550;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r691,%r692,%r693,%r694}, [%rd549];
	// end inline asm
	add.s64 	%rd553, %rd544, 32;
	// begin inline asm
	cvta.to.global.u64 %rd552, %rd553;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r695,%r696,%r697,%r698}, [%rd552];
	// end inline asm
	add.s64 	%rd556, %rd544, 48;
	// begin inline asm
	cvta.to.global.u64 %rd555, %rd556;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r699,%r700,%r701,%r702}, [%rd555];
	// end inline asm
	add.s64 	%rd559, %rd544, 64;
	// begin inline asm
	cvta.to.global.u64 %rd558, %rd559;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r703,%r704,%r705,%r706}, [%rd558];
	// end inline asm
	add.s64 	%rd562, %rd544, 80;
	// begin inline asm
	cvta.to.global.u64 %rd561, %rd562;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r707,%r708,%r709,%r710}, [%rd561];
	// end inline asm
	add.s64 	%rd565, %rd544, 96;
	// begin inline asm
	cvta.to.global.u64 %rd564, %rd565;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r711,%r712,%r713,%r714}, [%rd564];
	// end inline asm
	add.s64 	%rd568, %rd544, 112;
	// begin inline asm
	cvta.to.global.u64 %rd567, %rd568;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r715,%r716,%r717,%r718}, [%rd567];
	// end inline asm
	add.s64 	%rd571, %rd544, 128;
	// begin inline asm
	cvta.to.global.u64 %rd570, %rd571;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r719,%r720,%r721,%r722}, [%rd570];
	// end inline asm
	add.s64 	%rd574, %rd544, 144;
	// begin inline asm
	cvta.to.global.u64 %rd573, %rd574;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r723,%r724,%r725,%r726}, [%rd573];
	// end inline asm
	mov.b32 	%f2389, %r690;
	mov.b32 	%f2390, %r691;
	and.b32  	%r743, %r689, 65535;
	add.s32 	%r744, %r743, -1;
	cvt.rn.f32.s32 	%f2391, %r744;
	sub.ftz.f32 	%f2392, %f2374, %f2389;
	mul.ftz.f32 	%f2393, %f2392, %f2391;
	sub.ftz.f32 	%f2394, %f2390, %f2389;
	div.approx.ftz.f32 	%f2395, %f2393, %f2394;
	min.ftz.f32 	%f2396, %f2391, %f2395;
	mov.f32 	%f2397, 0f00000000;
	max.ftz.f32 	%f2398, %f2397, %f2396;
	cvt.rmi.ftz.f32.f32 	%f2399, %f2398;
	sub.ftz.f32 	%f781, %f2398, %f2399;
	cvt.rzi.ftz.s32.f32 	%r745, %f2399;
	mul.wide.s32 	%rd588, %r745, 64;
	add.s64 	%rd577, %rd553, %rd588;
	// begin inline asm
	cvta.to.global.u64 %rd576, %rd577;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r727,%r728,%r729,%r730}, [%rd576];
	// end inline asm
	mov.b32 	%f3485, %r727;
	mov.b32 	%f3486, %r728;
	mov.b32 	%f3487, %r729;
	mov.b32 	%f3488, %r730;
	add.s64 	%rd580, %rd577, 16;
	// begin inline asm
	cvta.to.global.u64 %rd579, %rd580;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r731,%r732,%r733,%r734}, [%rd579];
	// end inline asm
	mov.b32 	%f3489, %r731;
	mov.b32 	%f3490, %r732;
	mov.b32 	%f3491, %r733;
	mov.b32 	%f3492, %r734;
	add.s64 	%rd583, %rd577, 32;
	// begin inline asm
	cvta.to.global.u64 %rd582, %rd583;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r735,%r736,%r737,%r738}, [%rd582];
	// end inline asm
	mov.b32 	%f3493, %r735;
	mov.b32 	%f3494, %r736;
	mov.b32 	%f3495, %r737;
	mov.b32 	%f3496, %r738;
	add.s64 	%rd586, %rd577, 48;
	// begin inline asm
	cvta.to.global.u64 %rd585, %rd586;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r739,%r740,%r741,%r742}, [%rd585];
	// end inline asm
	mov.b32 	%f3497, %r739;
	mov.b32 	%f3498, %r740;
	mov.b32 	%f3499, %r741;
	mov.b32 	%f3500, %r742;
	setp.leu.ftz.f32 	%p54, %f781, 0f00000000;
	@%p54 bra 	$L__BB0_109;

	mov.f32 	%f2400, 0f3F800000;
	sub.ftz.f32 	%f2401, %f2400, %f781;
	add.s64 	%rd590, %rd577, 64;
	// begin inline asm
	cvta.to.global.u64 %rd589, %rd590;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r746,%r747,%r748,%r749}, [%rd589];
	// end inline asm
	mov.b32 	%f2402, %r746;
	mov.b32 	%f2403, %r747;
	mov.b32 	%f2404, %r748;
	mov.b32 	%f2405, %r749;
	mul.ftz.f32 	%f2406, %f781, %f2402;
	mul.ftz.f32 	%f2407, %f781, %f2403;
	mul.ftz.f32 	%f2408, %f781, %f2404;
	mul.ftz.f32 	%f2409, %f781, %f2405;
	fma.rn.ftz.f32 	%f3485, %f2401, %f3485, %f2406;
	fma.rn.ftz.f32 	%f3486, %f2401, %f3486, %f2407;
	fma.rn.ftz.f32 	%f3487, %f2401, %f3487, %f2408;
	fma.rn.ftz.f32 	%f3488, %f2401, %f3488, %f2409;
	add.s64 	%rd593, %rd577, 80;
	// begin inline asm
	cvta.to.global.u64 %rd592, %rd593;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r750,%r751,%r752,%r753}, [%rd592];
	// end inline asm
	mov.b32 	%f2410, %r750;
	mov.b32 	%f2411, %r751;
	mov.b32 	%f2412, %r752;
	mov.b32 	%f2413, %r753;
	mul.ftz.f32 	%f2414, %f781, %f2410;
	mul.ftz.f32 	%f2415, %f781, %f2411;
	mul.ftz.f32 	%f2416, %f781, %f2412;
	mul.ftz.f32 	%f2417, %f781, %f2413;
	fma.rn.ftz.f32 	%f3489, %f2401, %f3489, %f2414;
	fma.rn.ftz.f32 	%f3490, %f2401, %f3490, %f2415;
	fma.rn.ftz.f32 	%f3491, %f2401, %f3491, %f2416;
	fma.rn.ftz.f32 	%f3492, %f2401, %f3492, %f2417;
	add.s64 	%rd596, %rd577, 96;
	// begin inline asm
	cvta.to.global.u64 %rd595, %rd596;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r754,%r755,%r756,%r757}, [%rd595];
	// end inline asm
	mov.b32 	%f2418, %r754;
	mov.b32 	%f2419, %r755;
	mov.b32 	%f2420, %r756;
	mov.b32 	%f2421, %r757;
	mul.ftz.f32 	%f2422, %f781, %f2418;
	mul.ftz.f32 	%f2423, %f781, %f2419;
	mul.ftz.f32 	%f2424, %f781, %f2420;
	mul.ftz.f32 	%f2425, %f781, %f2421;
	fma.rn.ftz.f32 	%f3493, %f2401, %f3493, %f2422;
	fma.rn.ftz.f32 	%f2426, %f2401, %f3494, %f2423;
	fma.rn.ftz.f32 	%f2427, %f2401, %f3495, %f2424;
	fma.rn.ftz.f32 	%f2428, %f2401, %f3496, %f2425;
	add.s64 	%rd599, %rd577, 112;
	// begin inline asm
	cvta.to.global.u64 %rd598, %rd599;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r758,%r759,%r760,%r761}, [%rd598];
	// end inline asm
	mov.b32 	%f2429, %r758;
	mov.b32 	%f2430, %r759;
	mov.b32 	%f2431, %r760;
	mov.b32 	%f2432, %r761;
	mul.ftz.f32 	%f2433, %f781, %f2429;
	mul.ftz.f32 	%f2434, %f781, %f2430;
	mul.ftz.f32 	%f2435, %f781, %f2431;
	mul.ftz.f32 	%f2436, %f781, %f2432;
	fma.rn.ftz.f32 	%f2437, %f2401, %f3497, %f2433;
	fma.rn.ftz.f32 	%f3498, %f2401, %f3498, %f2434;
	fma.rn.ftz.f32 	%f3499, %f2401, %f3499, %f2435;
	fma.rn.ftz.f32 	%f3500, %f2401, %f3500, %f2436;
	mul.ftz.f32 	%f2438, %f2427, %f2427;
	fma.rn.ftz.f32 	%f2439, %f2426, %f2426, %f2438;
	fma.rn.ftz.f32 	%f2440, %f2428, %f2428, %f2439;
	fma.rn.ftz.f32 	%f2441, %f2437, %f2437, %f2440;
	rsqrt.approx.ftz.f32 	%f2442, %f2441;
	mul.ftz.f32 	%f3494, %f2426, %f2442;
	mul.ftz.f32 	%f3495, %f2427, %f2442;
	mul.ftz.f32 	%f3496, %f2428, %f2442;
	mul.ftz.f32 	%f3497, %f2442, %f2437;

$L__BB0_109:
	mul.ftz.f32 	%f2443, %f3495, %f3495;
	fma.rn.ftz.f32 	%f2444, %f3494, %f3494, %f2443;
	fma.rn.ftz.f32 	%f2445, %f3496, %f3496, %f2444;
	fma.rn.ftz.f32 	%f2446, %f3497, %f3497, %f2445;
	rcp.approx.ftz.f32 	%f2447, %f2446;
	mul.ftz.f32 	%f2448, %f3494, %f2447;
	mul.ftz.f32 	%f2449, %f3495, %f2447;
	mul.ftz.f32 	%f2450, %f3496, %f2447;
	mul.ftz.f32 	%f2451, %f3497, %f2447;
	mul.ftz.f32 	%f2452, %f3494, %f2448;
	mul.ftz.f32 	%f2453, %f3495, %f2449;
	mul.ftz.f32 	%f2454, %f3496, %f2450;
	mul.ftz.f32 	%f2455, %f3494, %f2449;
	mul.ftz.f32 	%f2456, %f3496, %f2451;
	mul.ftz.f32 	%f2457, %f3494, %f2450;
	mul.ftz.f32 	%f2458, %f3495, %f2451;
	mul.ftz.f32 	%f2459, %f3495, %f2450;
	mul.ftz.f32 	%f2460, %f3494, %f2451;
	sub.ftz.f32 	%f2461, %f2452, %f2453;
	sub.ftz.f32 	%f2462, %f2461, %f2454;
	fma.rn.ftz.f32 	%f2463, %f3497, %f2451, %f2462;
	sub.ftz.f32 	%f2464, %f2455, %f2456;
	add.ftz.f32 	%f2465, %f2464, %f2464;
	add.ftz.f32 	%f2466, %f2457, %f2458;
	add.ftz.f32 	%f2467, %f2466, %f2466;
	add.ftz.f32 	%f2468, %f2455, %f2456;
	add.ftz.f32 	%f2469, %f2468, %f2468;
	sub.ftz.f32 	%f2470, %f2453, %f2452;
	sub.ftz.f32 	%f2471, %f2470, %f2454;
	fma.rn.ftz.f32 	%f2472, %f3497, %f2451, %f2471;
	sub.ftz.f32 	%f2473, %f2459, %f2460;
	add.ftz.f32 	%f2474, %f2473, %f2473;
	sub.ftz.f32 	%f2475, %f2457, %f2458;
	add.ftz.f32 	%f2476, %f2475, %f2475;
	add.ftz.f32 	%f2477, %f2459, %f2460;
	add.ftz.f32 	%f2478, %f2477, %f2477;
	neg.ftz.f32 	%f2479, %f2452;
	sub.ftz.f32 	%f2480, %f2479, %f2453;
	add.ftz.f32 	%f2481, %f2454, %f2480;
	fma.rn.ftz.f32 	%f2482, %f3497, %f2451, %f2481;
	mul.ftz.f32 	%f2483, %f3488, %f2463;
	fma.rn.ftz.f32 	%f2484, %f3491, %f2465, %f2483;
	fma.rn.ftz.f32 	%f2485, %f3493, %f2467, %f2484;
	add.ftz.f32 	%f3512, %f3498, %f2485;
	mul.ftz.f32 	%f2486, %f3491, %f2472;
	fma.rn.ftz.f32 	%f2487, %f3488, %f2469, %f2486;
	fma.rn.ftz.f32 	%f2488, %f3493, %f2474, %f2487;
	add.ftz.f32 	%f3508, %f3499, %f2488;
	mul.ftz.f32 	%f2489, %f3491, %f2478;
	fma.rn.ftz.f32 	%f2490, %f3488, %f2476, %f2489;
	fma.rn.ftz.f32 	%f2491, %f3493, %f2482, %f2490;
	add.ftz.f32 	%f3504, %f3500, %f2491;
	mul.ftz.f32 	%f2492, %f3487, %f2463;
	fma.rn.ftz.f32 	%f2493, %f3490, %f2465, %f2492;
	fma.rn.ftz.f32 	%f3511, %f3492, %f2467, %f2493;
	mul.ftz.f32 	%f2494, %f3490, %f2472;
	fma.rn.ftz.f32 	%f2495, %f3487, %f2469, %f2494;
	fma.rn.ftz.f32 	%f3507, %f3492, %f2474, %f2495;
	mul.ftz.f32 	%f2496, %f3490, %f2478;
	fma.rn.ftz.f32 	%f2497, %f3487, %f2476, %f2496;
	fma.rn.ftz.f32 	%f3503, %f3492, %f2482, %f2497;
	mul.ftz.f32 	%f2498, %f3486, %f2463;
	fma.rn.ftz.f32 	%f3510, %f3489, %f2465, %f2498;
	mul.ftz.f32 	%f2499, %f3489, %f2472;
	fma.rn.ftz.f32 	%f3506, %f3486, %f2469, %f2499;
	mul.ftz.f32 	%f2500, %f3489, %f2478;
	fma.rn.ftz.f32 	%f3502, %f3486, %f2476, %f2500;
	mul.ftz.f32 	%f3509, %f3485, %f2463;
	mul.ftz.f32 	%f3505, %f3485, %f2469;
	mul.ftz.f32 	%f3501, %f3485, %f2476;

$L__BB0_112:
	mul.ftz.f32 	%f2538, %f3502, %f3507;
	mul.ftz.f32 	%f2539, %f3503, %f3506;
	sub.ftz.f32 	%f2540, %f2539, %f2538;
	mul.ftz.f32 	%f2541, %f3509, %f2540;
	mul.ftz.f32 	%f2542, %f3501, %f3507;
	mul.ftz.f32 	%f2543, %f3503, %f3505;
	sub.ftz.f32 	%f2544, %f2543, %f2542;
	mul.ftz.f32 	%f2545, %f2544, %f3510;
	sub.ftz.f32 	%f2546, %f2541, %f2545;
	mul.ftz.f32 	%f2547, %f3501, %f3506;
	mul.ftz.f32 	%f2548, %f3502, %f3505;
	sub.ftz.f32 	%f2549, %f2548, %f2547;
	fma.rn.ftz.f32 	%f2550, %f2549, %f3511, %f2546;
	rcp.approx.ftz.f32 	%f2551, %f2550;
	mul.ftz.f32 	%f3521, %f2540, %f2551;
	mul.ftz.f32 	%f2552, %f3503, %f3510;
	mul.ftz.f32 	%f2553, %f3502, %f3511;
	sub.ftz.f32 	%f2554, %f2553, %f2552;
	mul.ftz.f32 	%f3522, %f2554, %f2551;
	mul.ftz.f32 	%f2555, %f3506, %f3511;
	mul.ftz.f32 	%f2556, %f3507, %f3510;
	sub.ftz.f32 	%f2557, %f2556, %f2555;
	mul.ftz.f32 	%f3523, %f2557, %f2551;
	sub.ftz.f32 	%f2558, %f2542, %f2543;
	mul.ftz.f32 	%f3517, %f2558, %f2551;
	mul.ftz.f32 	%f2559, %f3501, %f3511;
	mul.ftz.f32 	%f2560, %f3503, %f3509;
	sub.ftz.f32 	%f2561, %f2560, %f2559;
	mul.ftz.f32 	%f3518, %f2561, %f2551;
	mul.ftz.f32 	%f2562, %f3507, %f3509;
	mul.ftz.f32 	%f2563, %f3505, %f3511;
	sub.ftz.f32 	%f2564, %f2563, %f2562;
	mul.ftz.f32 	%f3519, %f2564, %f2551;
	mul.ftz.f32 	%f3513, %f2549, %f2551;
	mul.ftz.f32 	%f2565, %f3502, %f3509;
	mul.ftz.f32 	%f2566, %f3501, %f3510;
	sub.ftz.f32 	%f2567, %f2566, %f2565;
	mul.ftz.f32 	%f3514, %f2567, %f2551;
	mul.ftz.f32 	%f2568, %f3505, %f3510;
	mul.ftz.f32 	%f2569, %f3506, %f3509;
	sub.ftz.f32 	%f2570, %f2569, %f2568;
	mul.ftz.f32 	%f3515, %f2570, %f2551;
	mul.ftz.f32 	%f2571, %f3512, %f3521;
	neg.ftz.f32 	%f2572, %f2571;
	mul.ftz.f32 	%f2573, %f3508, %f3522;
	sub.ftz.f32 	%f2574, %f2572, %f2573;
	mul.ftz.f32 	%f2575, %f3504, %f3523;
	sub.ftz.f32 	%f3524, %f2574, %f2575;
	mul.ftz.f32 	%f2576, %f3512, %f3517;
	neg.ftz.f32 	%f2577, %f2576;
	mul.ftz.f32 	%f2578, %f3508, %f3518;
	sub.ftz.f32 	%f2579, %f2577, %f2578;
	mul.ftz.f32 	%f2580, %f3504, %f3519;
	sub.ftz.f32 	%f3520, %f2579, %f2580;
	mul.ftz.f32 	%f2581, %f3512, %f3513;
	neg.ftz.f32 	%f2582, %f2581;
	mul.ftz.f32 	%f2583, %f3508, %f3514;
	sub.ftz.f32 	%f2584, %f2582, %f2583;
	mul.ftz.f32 	%f2585, %f3504, %f3515;
	sub.ftz.f32 	%f3516, %f2584, %f2585;
	bra.uni 	$L__BB0_113;

$L__BB0_104:
	// begin inline asm
	call (%rd790), _optix_get_instance_inverse_transform_from_handle, (%rd529);
	// end inline asm

$L__BB0_105:
	// begin inline asm
	cvta.to.global.u64 %rd535, %rd790;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r675,%r676,%r677,%r678}, [%rd535];
	// end inline asm
	mov.b32 	%f3521, %r675;
	mov.b32 	%f3522, %r676;
	mov.b32 	%f3523, %r677;
	mov.b32 	%f3524, %r678;
	add.s64 	%rd539, %rd790, 16;
	// begin inline asm
	cvta.to.global.u64 %rd538, %rd539;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r679,%r680,%r681,%r682}, [%rd538];
	// end inline asm
	mov.b32 	%f3517, %r679;
	mov.b32 	%f3518, %r680;
	mov.b32 	%f3519, %r681;
	mov.b32 	%f3520, %r682;
	add.s64 	%rd542, %rd790, 32;
	// begin inline asm
	cvta.to.global.u64 %rd541, %rd542;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r683,%r684,%r685,%r686}, [%rd541];
	// end inline asm
	mov.b32 	%f3513, %r683;
	mov.b32 	%f3514, %r684;
	mov.b32 	%f3515, %r685;
	mov.b32 	%f3516, %r686;

$L__BB0_113:
	setp.eq.s32 	%p56, %r1053, 0;
	@%p56 bra 	$L__BB0_115;

	mul.ftz.f32 	%f2586, %f3480, %f3522;
	fma.rn.ftz.f32 	%f2587, %f3476, %f3521, %f2586;
	fma.rn.ftz.f32 	%f903, %f3484, %f3523, %f2587;
	mul.ftz.f32 	%f2588, %f3479, %f3522;
	fma.rn.ftz.f32 	%f2589, %f3475, %f3521, %f2588;
	fma.rn.ftz.f32 	%f904, %f3483, %f3523, %f2589;
	mul.ftz.f32 	%f2590, %f3478, %f3522;
	fma.rn.ftz.f32 	%f2591, %f3474, %f3521, %f2590;
	fma.rn.ftz.f32 	%f905, %f3482, %f3523, %f2591;
	mul.ftz.f32 	%f2592, %f3477, %f3522;
	fma.rn.ftz.f32 	%f2593, %f3473, %f3521, %f2592;
	fma.rn.ftz.f32 	%f2594, %f3481, %f3523, %f2593;
	add.ftz.f32 	%f3524, %f3524, %f2594;
	mul.ftz.f32 	%f2595, %f3480, %f3518;
	fma.rn.ftz.f32 	%f2596, %f3476, %f3517, %f2595;
	fma.rn.ftz.f32 	%f907, %f3484, %f3519, %f2596;
	mul.ftz.f32 	%f2597, %f3479, %f3518;
	fma.rn.ftz.f32 	%f2598, %f3475, %f3517, %f2597;
	fma.rn.ftz.f32 	%f908, %f3483, %f3519, %f2598;
	mul.ftz.f32 	%f2599, %f3478, %f3518;
	fma.rn.ftz.f32 	%f2600, %f3474, %f3517, %f2599;
	fma.rn.ftz.f32 	%f909, %f3482, %f3519, %f2600;
	mul.ftz.f32 	%f2601, %f3477, %f3518;
	fma.rn.ftz.f32 	%f2602, %f3473, %f3517, %f2601;
	fma.rn.ftz.f32 	%f2603, %f3481, %f3519, %f2602;
	add.ftz.f32 	%f3520, %f3520, %f2603;
	mul.ftz.f32 	%f2604, %f3480, %f3514;
	fma.rn.ftz.f32 	%f2605, %f3476, %f3513, %f2604;
	fma.rn.ftz.f32 	%f911, %f3484, %f3515, %f2605;
	mul.ftz.f32 	%f2606, %f3479, %f3514;
	fma.rn.ftz.f32 	%f2607, %f3475, %f3513, %f2606;
	fma.rn.ftz.f32 	%f912, %f3483, %f3515, %f2607;
	mul.ftz.f32 	%f2608, %f3478, %f3514;
	fma.rn.ftz.f32 	%f2609, %f3474, %f3513, %f2608;
	fma.rn.ftz.f32 	%f913, %f3482, %f3515, %f2609;
	mul.ftz.f32 	%f2610, %f3477, %f3514;
	fma.rn.ftz.f32 	%f2611, %f3473, %f3513, %f2610;
	fma.rn.ftz.f32 	%f2612, %f3481, %f3515, %f2611;
	add.ftz.f32 	%f3516, %f3516, %f2612;
	mov.f32 	%f3513, %f911;
	mov.f32 	%f3514, %f912;
	mov.f32 	%f3515, %f913;
	mov.f32 	%f3517, %f907;
	mov.f32 	%f3518, %f908;
	mov.f32 	%f3519, %f909;
	mov.f32 	%f3521, %f903;
	mov.f32 	%f3522, %f904;
	mov.f32 	%f3523, %f905;

$L__BB0_115:
	add.s32 	%r1053, %r1053, 1;
	setp.lt.u32 	%p57, %r1053, %r670;
	mov.f32 	%f3473, %f3524;
	mov.f32 	%f3474, %f3523;
	mov.f32 	%f3475, %f3522;
	mov.f32 	%f3476, %f3521;
	mov.f32 	%f3477, %f3520;
	mov.f32 	%f3478, %f3519;
	mov.f32 	%f3479, %f3518;
	mov.f32 	%f3480, %f3517;
	mov.f32 	%f3481, %f3516;
	mov.f32 	%f3482, %f3515;
	mov.f32 	%f3483, %f3514;
	mov.f32 	%f3484, %f3513;
	@%p57 bra 	$L__BB0_100;

$L__BB0_116:
	mul.ftz.f32 	%f2613, %f2, %f3522;
	fma.rn.ftz.f32 	%f2614, %f1, %f3521, %f2613;
	fma.rn.ftz.f32 	%f2615, %f3, %f3523, %f2614;
	mul.ftz.f32 	%f2616, %f2, %f3518;
	fma.rn.ftz.f32 	%f2617, %f1, %f3517, %f2616;
	fma.rn.ftz.f32 	%f2618, %f3, %f3519, %f2617;
	mul.ftz.f32 	%f2619, %f2, %f3514;
	fma.rn.ftz.f32 	%f2620, %f1, %f3513, %f2619;
	fma.rn.ftz.f32 	%f2621, %f3, %f3515, %f2620;
	add.ftz.f32 	%f3551, %f3516, %f2621;
	add.ftz.f32 	%f3550, %f3520, %f2618;
	add.ftz.f32 	%f3549, %f3524, %f2615;
	bra.uni 	$L__BB0_118;

$L__BB0_70:
	mov.f32 	%f3412, %f1;
	mov.f32 	%f3413, %f2;
	mov.f32 	%f3414, %f3;

$L__BB0_71:
	// begin inline asm
	call (%r513), _optix_get_attribute_0, ();
	// end inline asm
	mov.b32 	%f584, %r513;
	setp.eq.ftz.f32 	%p36, %f584, 0f00000000;
	@%p36 bra 	$L__BB0_75;
	bra.uni 	$L__BB0_72;

$L__BB0_75:
	mov.f32 	%f2143, 0f3F800000;
	sub.ftz.f32 	%f2144, %f2143, 0f358637BD;
	mul.ftz.f32 	%f2145, %f2144, 0f3F000000;
	mul.ftz.f32 	%f2146, %f2145, %f2144;
	add.ftz.f32 	%f2147, %f2144, %f2144;
	mul.ftz.f32 	%f2148, %f2147, 0f358637BD;
	mul.ftz.f32 	%f2149, %f381, %f2148;
	fma.rn.ftz.f32 	%f2150, %f377, %f2146, %f2149;
	mul.ftz.f32 	%f2151, %f382, %f2148;
	fma.rn.ftz.f32 	%f2152, %f378, %f2146, %f2151;
	mul.ftz.f32 	%f2153, %f383, %f2148;
	fma.rn.ftz.f32 	%f2154, %f379, %f2146, %f2153;
	fma.rn.ftz.f32 	%f2155, %f385, 0f2B0CBCCC, %f2150;
	fma.rn.ftz.f32 	%f2156, %f386, 0f2B0CBCCC, %f2152;
	fma.rn.ftz.f32 	%f2157, %f387, 0f2B0CBCCC, %f2154;
	neg.ftz.f32 	%f3415, %f2155;
	neg.ftz.f32 	%f3416, %f2156;
	neg.ftz.f32 	%f3417, %f2157;
	bra.uni 	$L__BB0_76;

$L__BB0_72:
	setp.eq.ftz.f32 	%p37, %f584, 0f3F800000;
	@%p37 bra 	$L__BB0_74;
	bra.uni 	$L__BB0_73;

$L__BB0_74:
	mov.f32 	%f2131, 0f3F800000;
	sub.ftz.f32 	%f2132, %f2131, 0f3F7FFFEF;
	mul.ftz.f32 	%f2133, %f2132, 0f3F000000;
	mul.ftz.f32 	%f2134, %f2133, %f2132;
	add.ftz.f32 	%f2135, %f2132, %f2132;
	mul.ftz.f32 	%f2136, %f2135, 0f3F7FFFEF;
	mul.ftz.f32 	%f2137, %f381, %f2136;
	fma.rn.ftz.f32 	%f2138, %f377, %f2134, %f2137;
	mul.ftz.f32 	%f2139, %f382, %f2136;
	fma.rn.ftz.f32 	%f2140, %f378, %f2134, %f2139;
	mul.ftz.f32 	%f2141, %f383, %f2136;
	fma.rn.ftz.f32 	%f2142, %f379, %f2134, %f2141;
	fma.rn.ftz.f32 	%f3415, %f385, 0f3EFFFFDE, %f2138;
	fma.rn.ftz.f32 	%f3416, %f386, 0f3EFFFFDE, %f2140;
	fma.rn.ftz.f32 	%f3417, %f387, 0f3EFFFFDE, %f2142;
	bra.uni 	$L__BB0_76;

$L__BB0_23:
	mov.f32 	%f207, %f1;
	mov.f32 	%f208, %f2;
	mov.f32 	%f209, %f3;

$L__BB0_24:
	// begin inline asm
	call (%r205), _optix_get_attribute_0, ();
	// end inline asm
	mov.b32 	%f213, %r205;
	setp.eq.ftz.f32 	%p14, %f213, 0f00000000;
	@%p14 bra 	$L__BB0_28;
	bra.uni 	$L__BB0_25;

$L__BB0_28:
	sub.ftz.f32 	%f3278, %f207, %f1275;
	sub.ftz.f32 	%f3279, %f208, %f1276;
	sub.ftz.f32 	%f3280, %f209, %f1277;
	bra.uni 	$L__BB0_29;

$L__BB0_117:
	mov.f32 	%f3549, %f1;
	mov.f32 	%f3550, %f2;
	mov.f32 	%f3551, %f3;

$L__BB0_118:
	// begin inline asm
	call (%r821), _optix_get_attribute_0, ();
	// end inline asm
	mov.b32 	%f951, %r821;
	setp.eq.ftz.f32 	%p58, %f951, 0f00000000;
	@%p58 bra 	$L__BB0_122;
	bra.uni 	$L__BB0_119;

$L__BB0_122:
	fma.rn.ftz.f32 	%f2671, %f752, 0f00000000, %f748;
	fma.rn.ftz.f32 	%f2672, %f753, 0f00000000, %f749;
	fma.rn.ftz.f32 	%f2673, %f754, 0f00000000, %f750;
	neg.ftz.f32 	%f3552, %f2671;
	neg.ftz.f32 	%f3553, %f2672;
	neg.ftz.f32 	%f3554, %f2673;
	bra.uni 	$L__BB0_123;

$L__BB0_25:
	setp.ltu.ftz.f32 	%p15, %f213, 0f3F800000;
	@%p15 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_26;

$L__BB0_27:
	sub.ftz.f32 	%f1535, %f1282, %f1278;
	fma.rn.ftz.f32 	%f1536, %f13, %f213, %f1275;
	fma.rn.ftz.f32 	%f1537, %f15, %f213, %f1276;
	fma.rn.ftz.f32 	%f1538, %f17, %f213, %f1277;
	fma.rn.ftz.f32 	%f1539, %f1535, %f213, %f1278;
	mul.ftz.f32 	%f1540, %f15, %f15;
	fma.rn.ftz.f32 	%f1541, %f13, %f13, %f1540;
	fma.rn.ftz.f32 	%f1542, %f17, %f17, %f1541;
	sub.ftz.f32 	%f1543, %f207, %f1536;
	sub.ftz.f32 	%f1544, %f208, %f1537;
	sub.ftz.f32 	%f1545, %f209, %f1538;
	mul.ftz.f32 	%f1546, %f15, %f1544;
	fma.rn.ftz.f32 	%f1547, %f13, %f1543, %f1546;
	fma.rn.ftz.f32 	%f1548, %f17, %f1545, %f1547;
	div.approx.ftz.f32 	%f1549, %f1548, %f1542;
	mul.ftz.f32 	%f1550, %f13, %f1549;
	mul.ftz.f32 	%f1551, %f15, %f1549;
	mul.ftz.f32 	%f1552, %f17, %f1549;
	sub.ftz.f32 	%f1553, %f1543, %f1550;
	sub.ftz.f32 	%f1554, %f1544, %f1551;
	sub.ftz.f32 	%f1555, %f1545, %f1552;
	mul.ftz.f32 	%f1556, %f1554, %f1554;
	fma.rn.ftz.f32 	%f1557, %f1553, %f1553, %f1556;
	fma.rn.ftz.f32 	%f1558, %f1555, %f1555, %f1557;
	sqrt.approx.ftz.f32 	%f1559, %f1558;
	div.approx.ftz.f32 	%f1560, %f1539, %f1559;
	mul.ftz.f32 	%f1561, %f1553, %f1560;
	mul.ftz.f32 	%f1562, %f1554, %f1560;
	mul.ftz.f32 	%f1563, %f1555, %f1560;
	mul.ftz.f32 	%f1564, %f1542, %f1561;
	mul.ftz.f32 	%f1565, %f1542, %f1562;
	mul.ftz.f32 	%f1566, %f1542, %f1563;
	mul.ftz.f32 	%f1567, %f1535, %f1539;
	mul.ftz.f32 	%f1568, %f13, %f1567;
	mul.ftz.f32 	%f1569, %f15, %f1567;
	mul.ftz.f32 	%f1570, %f17, %f1567;
	sub.ftz.f32 	%f3278, %f1564, %f1568;
	sub.ftz.f32 	%f3279, %f1565, %f1569;
	sub.ftz.f32 	%f3280, %f1566, %f1570;
	bra.uni 	$L__BB0_29;

$L__BB0_119:
	setp.eq.ftz.f32 	%p59, %f951, 0f3F800000;
	add.ftz.f32 	%f952, %f752, %f752;
	add.ftz.f32 	%f953, %f753, %f753;
	add.ftz.f32 	%f954, %f754, %f754;
	@%p59 bra 	$L__BB0_121;
	bra.uni 	$L__BB0_120;

$L__BB0_121:
	add.ftz.f32 	%f3552, %f748, %f952;
	add.ftz.f32 	%f3553, %f749, %f953;
	add.ftz.f32 	%f3554, %f750, %f954;
	bra.uni 	$L__BB0_123;

$L__BB0_26:
	add.ftz.f32 	%f1532, %f1275, %f13;
	sub.ftz.f32 	%f3278, %f207, %f1532;
	add.ftz.f32 	%f1533, %f1276, %f15;
	sub.ftz.f32 	%f3279, %f208, %f1533;
	add.ftz.f32 	%f1534, %f1277, %f17;
	sub.ftz.f32 	%f3280, %f209, %f1534;

$L__BB0_29:
	mul.ftz.f32 	%f1571, %f3279, %f3279;
	fma.rn.ftz.f32 	%f1572, %f3278, %f3278, %f1571;
	fma.rn.ftz.f32 	%f1573, %f3280, %f3280, %f1572;
	rsqrt.approx.ftz.f32 	%f1574, %f1573;
	mul.ftz.f32 	%f3615, %f3278, %f1574;
	mul.ftz.f32 	%f3614, %f3279, %f1574;
	mul.ftz.f32 	%f228, %f3280, %f1574;
	// begin inline asm
	call (%r206), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p16, %r206, 0;
	@%p16 bra 	$L__BB0_49;

	// begin inline asm
	call (%r207), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1575), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p17, %r207, 0;
	@%p17 bra 	$L__BB0_48;

	mov.u32 	%r1050, 0;

$L__BB0_32:
	.pragma "nounroll";
	// begin inline asm
	call (%rd168), _optix_get_transform_list_handle, (%r1050);
	// end inline asm
	// begin inline asm
	call (%r210), _optix_get_transform_type_from_handle, (%rd168);
	// end inline asm
	or.b32  	%r211, %r210, 1;
	setp.eq.s32 	%p18, %r211, 3;
	@%p18 bra 	$L__BB0_38;
	bra.uni 	$L__BB0_33;

$L__BB0_38:
	setp.eq.s32 	%p21, %r210, 2;
	@%p21 bra 	$L__BB0_42;
	bra.uni 	$L__BB0_39;

$L__BB0_42:
	// begin inline asm
	call (%rd240), _optix_get_matrix_motion_transform_from_handle, (%rd168);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd242, %rd240;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r299,%r300,%r301,%r302}, [%rd242];
	// end inline asm
	add.s64 	%rd246, %rd240, 16;
	// begin inline asm
	cvta.to.global.u64 %rd245, %rd246;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r303,%r304,%r305,%r306}, [%rd245];
	// end inline asm
	add.s64 	%rd249, %rd240, 32;
	// begin inline asm
	cvta.to.global.u64 %rd248, %rd249;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r307,%r308,%r309,%r310}, [%rd248];
	// end inline asm
	add.s64 	%rd252, %rd240, 48;
	// begin inline asm
	cvta.to.global.u64 %rd251, %rd252;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r311,%r312,%r313,%r314}, [%rd251];
	// end inline asm
	add.s64 	%rd255, %rd240, 64;
	// begin inline asm
	cvta.to.global.u64 %rd254, %rd255;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r315,%r316,%r317,%r318}, [%rd254];
	// end inline asm
	add.s64 	%rd258, %rd240, 80;
	// begin inline asm
	cvta.to.global.u64 %rd257, %rd258;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r319,%r320,%r321,%r322}, [%rd257];
	// end inline asm
	add.s64 	%rd261, %rd240, 96;
	// begin inline asm
	cvta.to.global.u64 %rd260, %rd261;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r323,%r324,%r325,%r326}, [%rd260];
	// end inline asm
	add.s64 	%rd264, %rd240, 112;
	// begin inline asm
	cvta.to.global.u64 %rd263, %rd264;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r327,%r328,%r329,%r330}, [%rd263];
	// end inline asm
	mov.b32 	%f1678, %r302;
	mov.b32 	%f1679, %r303;
	and.b32  	%r343, %r301, 65535;
	add.s32 	%r344, %r343, -1;
	cvt.rn.f32.s32 	%f1680, %r344;
	sub.ftz.f32 	%f1681, %f1575, %f1678;
	mul.ftz.f32 	%f1682, %f1681, %f1680;
	sub.ftz.f32 	%f1683, %f1679, %f1678;
	div.approx.ftz.f32 	%f1684, %f1682, %f1683;
	min.ftz.f32 	%f1685, %f1680, %f1684;
	mov.f32 	%f1686, 0f00000000;
	max.ftz.f32 	%f1687, %f1686, %f1685;
	cvt.rmi.ftz.f32.f32 	%f1688, %f1687;
	sub.ftz.f32 	%f288, %f1687, %f1688;
	cvt.rzi.ftz.s32.f32 	%r345, %f1688;
	cvt.s64.s32 	%rd15, %r345;
	mul.wide.s32 	%rd275, %r345, 48;
	add.s64 	%rd267, %rd249, %rd275;
	// begin inline asm
	cvta.to.global.u64 %rd266, %rd267;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r331,%r332,%r333,%r334}, [%rd266];
	// end inline asm
	mov.b32 	%f3306, %r331;
	mov.b32 	%f3307, %r332;
	mov.b32 	%f3308, %r333;
	add.s64 	%rd270, %rd267, 16;
	// begin inline asm
	cvta.to.global.u64 %rd269, %rd270;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r335,%r336,%r337,%r338}, [%rd269];
	// end inline asm
	mov.b32 	%f3303, %r335;
	mov.b32 	%f3304, %r336;
	mov.b32 	%f3305, %r337;
	add.s64 	%rd273, %rd267, 32;
	// begin inline asm
	cvta.to.global.u64 %rd272, %rd273;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r339,%r340,%r341,%r342}, [%rd272];
	// end inline asm
	mov.b32 	%f3300, %r339;
	mov.b32 	%f3301, %r340;
	mov.b32 	%f3302, %r341;
	setp.leu.ftz.f32 	%p23, %f288, 0f00000000;
	@%p23 bra 	$L__BB0_44;

	mov.f32 	%f1689, 0f3F800000;
	sub.ftz.f32 	%f1690, %f1689, %f288;
	mul.lo.s64 	%rd285, %rd15, 48;
	add.s64 	%rd286, %rd240, %rd285;
	add.s64 	%rd277, %rd286, 80;
	// begin inline asm
	cvta.to.global.u64 %rd276, %rd277;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r346,%r347,%r348,%r349}, [%rd276];
	// end inline asm
	mov.b32 	%f1691, %r346;
	mov.b32 	%f1692, %r347;
	mov.b32 	%f1693, %r348;
	mul.ftz.f32 	%f1694, %f288, %f1691;
	mul.ftz.f32 	%f1695, %f288, %f1692;
	mul.ftz.f32 	%f1696, %f288, %f1693;
	fma.rn.ftz.f32 	%f3306, %f1690, %f3306, %f1694;
	fma.rn.ftz.f32 	%f3307, %f1690, %f3307, %f1695;
	fma.rn.ftz.f32 	%f3308, %f1690, %f3308, %f1696;
	add.s64 	%rd280, %rd286, 96;
	// begin inline asm
	cvta.to.global.u64 %rd279, %rd280;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r350,%r351,%r352,%r353}, [%rd279];
	// end inline asm
	mov.b32 	%f1697, %r350;
	mov.b32 	%f1698, %r351;
	mov.b32 	%f1699, %r352;
	mul.ftz.f32 	%f1700, %f288, %f1697;
	mul.ftz.f32 	%f1701, %f288, %f1698;
	mul.ftz.f32 	%f1702, %f288, %f1699;
	fma.rn.ftz.f32 	%f3303, %f1690, %f3303, %f1700;
	fma.rn.ftz.f32 	%f3304, %f1690, %f3304, %f1701;
	fma.rn.ftz.f32 	%f3305, %f1690, %f3305, %f1702;
	add.s64 	%rd283, %rd286, 112;
	// begin inline asm
	cvta.to.global.u64 %rd282, %rd283;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r354,%r355,%r356,%r357}, [%rd282];
	// end inline asm
	mov.b32 	%f1703, %r354;
	mov.b32 	%f1704, %r355;
	mov.b32 	%f1705, %r356;
	mul.ftz.f32 	%f1706, %f288, %f1703;
	mul.ftz.f32 	%f1707, %f288, %f1704;
	mul.ftz.f32 	%f1708, %f288, %f1705;
	fma.rn.ftz.f32 	%f3300, %f1690, %f3300, %f1706;
	fma.rn.ftz.f32 	%f3301, %f1690, %f3301, %f1707;
	fma.rn.ftz.f32 	%f3302, %f1690, %f3302, %f1708;
	bra.uni 	$L__BB0_44;

$L__BB0_33:
	mov.f32 	%f3309, 0f00000000;
	mov.f32 	%f3311, 0f3F800000;
	setp.eq.s32 	%p19, %r210, 4;
	@%p19 bra 	$L__BB0_36;

	setp.ne.s32 	%p20, %r210, 1;
	mov.f32 	%f3310, %f3309;
	mov.f32 	%f3312, %f3309;
	mov.f32 	%f3313, %f3311;
	mov.f32 	%f3314, %f3309;
	mov.f32 	%f3315, %f3311;
	mov.f32 	%f3316, %f3309;
	mov.f32 	%f3317, %f3309;
	@%p20 bra 	$L__BB0_45;

	// begin inline asm
	call (%rd170), _optix_get_static_transform_from_handle, (%rd168);
	// end inline asm
	add.s64 	%rd787, %rd170, 64;
	bra.uni 	$L__BB0_37;

$L__BB0_39:
	// begin inline asm
	call (%rd183), _optix_get_srt_motion_transform_from_handle, (%rd168);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd185, %rd183;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r224,%r225,%r226,%r227}, [%rd185];
	// end inline asm
	add.s64 	%rd189, %rd183, 16;
	// begin inline asm
	cvta.to.global.u64 %rd188, %rd189;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r228,%r229,%r230,%r231}, [%rd188];
	// end inline asm
	add.s64 	%rd192, %rd183, 32;
	// begin inline asm
	cvta.to.global.u64 %rd191, %rd192;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r232,%r233,%r234,%r235}, [%rd191];
	// end inline asm
	add.s64 	%rd195, %rd183, 48;
	// begin inline asm
	cvta.to.global.u64 %rd194, %rd195;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r236,%r237,%r238,%r239}, [%rd194];
	// end inline asm
	add.s64 	%rd198, %rd183, 64;
	// begin inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r240,%r241,%r242,%r243}, [%rd197];
	// end inline asm
	add.s64 	%rd201, %rd183, 80;
	// begin inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r244,%r245,%r246,%r247}, [%rd200];
	// end inline asm
	add.s64 	%rd204, %rd183, 96;
	// begin inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r248,%r249,%r250,%r251}, [%rd203];
	// end inline asm
	add.s64 	%rd207, %rd183, 112;
	// begin inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r252,%r253,%r254,%r255}, [%rd206];
	// end inline asm
	add.s64 	%rd210, %rd183, 128;
	// begin inline asm
	cvta.to.global.u64 %rd209, %rd210;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r256,%r257,%r258,%r259}, [%rd209];
	// end inline asm
	add.s64 	%rd213, %rd183, 144;
	// begin inline asm
	cvta.to.global.u64 %rd212, %rd213;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r260,%r261,%r262,%r263}, [%rd212];
	// end inline asm
	mov.b32 	%f1587, %r227;
	mov.b32 	%f1588, %r228;
	and.b32  	%r280, %r226, 65535;
	add.s32 	%r281, %r280, -1;
	cvt.rn.f32.s32 	%f1589, %r281;
	sub.ftz.f32 	%f1590, %f1575, %f1587;
	mul.ftz.f32 	%f1591, %f1590, %f1589;
	sub.ftz.f32 	%f1592, %f1588, %f1587;
	div.approx.ftz.f32 	%f1593, %f1591, %f1592;
	min.ftz.f32 	%f1594, %f1589, %f1593;
	mov.f32 	%f1595, 0f00000000;
	max.ftz.f32 	%f1596, %f1595, %f1594;
	cvt.rmi.ftz.f32.f32 	%f1597, %f1596;
	sub.ftz.f32 	%f248, %f1596, %f1597;
	cvt.rzi.ftz.s32.f32 	%r282, %f1597;
	mul.wide.s32 	%rd227, %r282, 64;
	add.s64 	%rd216, %rd192, %rd227;
	// begin inline asm
	cvta.to.global.u64 %rd215, %rd216;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r264,%r265,%r266,%r267}, [%rd215];
	// end inline asm
	mov.b32 	%f3290, %r264;
	mov.b32 	%f3291, %r265;
	mov.b32 	%f3292, %r266;
	add.s64 	%rd219, %rd216, 16;
	// begin inline asm
	cvta.to.global.u64 %rd218, %rd219;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r268,%r269,%r270,%r271}, [%rd218];
	// end inline asm
	mov.b32 	%f3293, %r268;
	mov.b32 	%f3294, %r269;
	mov.b32 	%f3295, %r271;
	add.s64 	%rd222, %rd216, 32;
	// begin inline asm
	cvta.to.global.u64 %rd221, %rd222;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r272,%r273,%r274,%r275}, [%rd221];
	// end inline asm
	mov.b32 	%f3296, %r273;
	mov.b32 	%f3297, %r274;
	mov.b32 	%f3298, %r275;
	add.s64 	%rd225, %rd216, 48;
	// begin inline asm
	cvta.to.global.u64 %rd224, %rd225;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r276,%r277,%r278,%r279}, [%rd224];
	// end inline asm
	mov.b32 	%f3299, %r276;
	setp.leu.ftz.f32 	%p22, %f248, 0f00000000;
	@%p22 bra 	$L__BB0_41;

	mov.f32 	%f1598, 0f3F800000;
	sub.ftz.f32 	%f1599, %f1598, %f248;
	add.s64 	%rd229, %rd216, 64;
	// begin inline asm
	cvta.to.global.u64 %rd228, %rd229;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r283,%r284,%r285,%r286}, [%rd228];
	// end inline asm
	mov.b32 	%f1600, %r283;
	mov.b32 	%f1601, %r284;
	mov.b32 	%f1602, %r285;
	mul.ftz.f32 	%f1603, %f248, %f1600;
	mul.ftz.f32 	%f1604, %f248, %f1601;
	mul.ftz.f32 	%f1605, %f248, %f1602;
	fma.rn.ftz.f32 	%f3290, %f1599, %f3290, %f1603;
	fma.rn.ftz.f32 	%f3291, %f1599, %f3291, %f1604;
	fma.rn.ftz.f32 	%f3292, %f1599, %f3292, %f1605;
	add.s64 	%rd232, %rd216, 80;
	// begin inline asm
	cvta.to.global.u64 %rd231, %rd232;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r287,%r288,%r289,%r290}, [%rd231];
	// end inline asm
	mov.b32 	%f1606, %r287;
	mov.b32 	%f1607, %r288;
	mov.b32 	%f1608, %r290;
	mul.ftz.f32 	%f1609, %f248, %f1606;
	mul.ftz.f32 	%f1610, %f248, %f1607;
	mul.ftz.f32 	%f1611, %f248, %f1608;
	fma.rn.ftz.f32 	%f3293, %f1599, %f3293, %f1609;
	fma.rn.ftz.f32 	%f3294, %f1599, %f3294, %f1610;
	fma.rn.ftz.f32 	%f3295, %f1599, %f3295, %f1611;
	add.s64 	%rd235, %rd216, 96;
	// begin inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r291,%r292,%r293,%r294}, [%rd234];
	// end inline asm
	mov.b32 	%f1612, %r292;
	mov.b32 	%f1613, %r293;
	mov.b32 	%f1614, %r294;
	mul.ftz.f32 	%f1615, %f248, %f1612;
	mul.ftz.f32 	%f1616, %f248, %f1613;
	mul.ftz.f32 	%f1617, %f248, %f1614;
	fma.rn.ftz.f32 	%f1618, %f1599, %f3296, %f1615;
	fma.rn.ftz.f32 	%f1619, %f1599, %f3297, %f1616;
	fma.rn.ftz.f32 	%f1620, %f1599, %f3298, %f1617;
	add.s64 	%rd238, %rd216, 112;
	// begin inline asm
	cvta.to.global.u64 %rd237, %rd238;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r295,%r296,%r297,%r298}, [%rd237];
	// end inline asm
	mov.b32 	%f1621, %r295;
	mul.ftz.f32 	%f1622, %f248, %f1621;
	fma.rn.ftz.f32 	%f1623, %f1599, %f3299, %f1622;
	mul.ftz.f32 	%f1624, %f1619, %f1619;
	fma.rn.ftz.f32 	%f1625, %f1618, %f1618, %f1624;
	fma.rn.ftz.f32 	%f1626, %f1620, %f1620, %f1625;
	fma.rn.ftz.f32 	%f1627, %f1623, %f1623, %f1626;
	rsqrt.approx.ftz.f32 	%f1628, %f1627;
	mul.ftz.f32 	%f3296, %f1618, %f1628;
	mul.ftz.f32 	%f3297, %f1619, %f1628;
	mul.ftz.f32 	%f3298, %f1620, %f1628;
	mul.ftz.f32 	%f3299, %f1628, %f1623;

$L__BB0_41:
	mul.ftz.f32 	%f1629, %f3297, %f3297;
	fma.rn.ftz.f32 	%f1630, %f3296, %f3296, %f1629;
	fma.rn.ftz.f32 	%f1631, %f3298, %f3298, %f1630;
	fma.rn.ftz.f32 	%f1632, %f3299, %f3299, %f1631;
	rcp.approx.ftz.f32 	%f1633, %f1632;
	mul.ftz.f32 	%f1634, %f3296, %f1633;
	mul.ftz.f32 	%f1635, %f3297, %f1633;
	mul.ftz.f32 	%f1636, %f3298, %f1633;
	mul.ftz.f32 	%f1637, %f3299, %f1633;
	mul.ftz.f32 	%f1638, %f3296, %f1634;
	mul.ftz.f32 	%f1639, %f3297, %f1635;
	mul.ftz.f32 	%f1640, %f3298, %f1636;
	mul.ftz.f32 	%f1641, %f3296, %f1635;
	mul.ftz.f32 	%f1642, %f3298, %f1637;
	mul.ftz.f32 	%f1643, %f3296, %f1636;
	mul.ftz.f32 	%f1644, %f3297, %f1637;
	mul.ftz.f32 	%f1645, %f3297, %f1636;
	mul.ftz.f32 	%f1646, %f3296, %f1637;
	sub.ftz.f32 	%f1647, %f1638, %f1639;
	sub.ftz.f32 	%f1648, %f1647, %f1640;
	fma.rn.ftz.f32 	%f1649, %f3299, %f1637, %f1648;
	sub.ftz.f32 	%f1650, %f1641, %f1642;
	add.ftz.f32 	%f1651, %f1650, %f1650;
	add.ftz.f32 	%f1652, %f1643, %f1644;
	add.ftz.f32 	%f1653, %f1652, %f1652;
	add.ftz.f32 	%f1654, %f1641, %f1642;
	add.ftz.f32 	%f1655, %f1654, %f1654;
	sub.ftz.f32 	%f1656, %f1639, %f1638;
	sub.ftz.f32 	%f1657, %f1656, %f1640;
	fma.rn.ftz.f32 	%f1658, %f3299, %f1637, %f1657;
	sub.ftz.f32 	%f1659, %f1645, %f1646;
	add.ftz.f32 	%f1660, %f1659, %f1659;
	sub.ftz.f32 	%f1661, %f1643, %f1644;
	add.ftz.f32 	%f1662, %f1661, %f1661;
	add.ftz.f32 	%f1663, %f1645, %f1646;
	add.ftz.f32 	%f1664, %f1663, %f1663;
	neg.ftz.f32 	%f1665, %f1638;
	sub.ftz.f32 	%f1666, %f1665, %f1639;
	add.ftz.f32 	%f1667, %f1640, %f1666;
	fma.rn.ftz.f32 	%f1668, %f3299, %f1637, %f1667;
	mul.ftz.f32 	%f1669, %f3292, %f1649;
	fma.rn.ftz.f32 	%f1670, %f3294, %f1651, %f1669;
	fma.rn.ftz.f32 	%f3308, %f3295, %f1653, %f1670;
	mul.ftz.f32 	%f1671, %f3294, %f1658;
	fma.rn.ftz.f32 	%f1672, %f3292, %f1655, %f1671;
	fma.rn.ftz.f32 	%f3305, %f3295, %f1660, %f1672;
	mul.ftz.f32 	%f1673, %f3294, %f1664;
	fma.rn.ftz.f32 	%f1674, %f3292, %f1662, %f1673;
	fma.rn.ftz.f32 	%f3302, %f3295, %f1668, %f1674;
	mul.ftz.f32 	%f1675, %f3291, %f1649;
	fma.rn.ftz.f32 	%f3307, %f3293, %f1651, %f1675;
	mul.ftz.f32 	%f1676, %f3293, %f1658;
	fma.rn.ftz.f32 	%f3304, %f3291, %f1655, %f1676;
	mul.ftz.f32 	%f1677, %f3293, %f1664;
	fma.rn.ftz.f32 	%f3301, %f3291, %f1662, %f1677;
	mul.ftz.f32 	%f3306, %f3290, %f1649;
	mul.ftz.f32 	%f3303, %f3290, %f1655;
	mul.ftz.f32 	%f3300, %f3290, %f1662;

$L__BB0_44:
	mul.ftz.f32 	%f1709, %f3301, %f3305;
	mul.ftz.f32 	%f1710, %f3302, %f3304;
	sub.ftz.f32 	%f1711, %f1710, %f1709;
	mul.ftz.f32 	%f1712, %f3306, %f1711;
	mul.ftz.f32 	%f1713, %f3300, %f3305;
	mul.ftz.f32 	%f1714, %f3302, %f3303;
	sub.ftz.f32 	%f1715, %f1714, %f1713;
	mul.ftz.f32 	%f1716, %f1715, %f3307;
	sub.ftz.f32 	%f1717, %f1712, %f1716;
	mul.ftz.f32 	%f1718, %f3300, %f3304;
	mul.ftz.f32 	%f1719, %f3301, %f3303;
	sub.ftz.f32 	%f1720, %f1719, %f1718;
	fma.rn.ftz.f32 	%f1721, %f1720, %f3308, %f1717;
	rcp.approx.ftz.f32 	%f1722, %f1721;
	mul.ftz.f32 	%f3315, %f1711, %f1722;
	mul.ftz.f32 	%f1723, %f3302, %f3307;
	mul.ftz.f32 	%f1724, %f3301, %f3308;
	sub.ftz.f32 	%f1725, %f1724, %f1723;
	mul.ftz.f32 	%f3316, %f1725, %f1722;
	mul.ftz.f32 	%f1726, %f3304, %f3308;
	mul.ftz.f32 	%f1727, %f3305, %f3307;
	sub.ftz.f32 	%f1728, %f1727, %f1726;
	mul.ftz.f32 	%f3317, %f1728, %f1722;
	sub.ftz.f32 	%f1729, %f1713, %f1714;
	mul.ftz.f32 	%f3312, %f1729, %f1722;
	mul.ftz.f32 	%f1730, %f3300, %f3308;
	mul.ftz.f32 	%f1731, %f3302, %f3306;
	sub.ftz.f32 	%f1732, %f1731, %f1730;
	mul.ftz.f32 	%f3313, %f1732, %f1722;
	mul.ftz.f32 	%f1733, %f3305, %f3306;
	mul.ftz.f32 	%f1734, %f3303, %f3308;
	sub.ftz.f32 	%f1735, %f1734, %f1733;
	mul.ftz.f32 	%f3314, %f1735, %f1722;
	mul.ftz.f32 	%f3309, %f1720, %f1722;
	mul.ftz.f32 	%f1736, %f3301, %f3306;
	mul.ftz.f32 	%f1737, %f3300, %f3307;
	sub.ftz.f32 	%f1738, %f1737, %f1736;
	mul.ftz.f32 	%f3310, %f1738, %f1722;
	mul.ftz.f32 	%f1739, %f3303, %f3307;
	mul.ftz.f32 	%f1740, %f3304, %f3306;
	sub.ftz.f32 	%f1741, %f1740, %f1739;
	mul.ftz.f32 	%f3311, %f1741, %f1722;
	bra.uni 	$L__BB0_45;

$L__BB0_36:
	// begin inline asm
	call (%rd787), _optix_get_instance_inverse_transform_from_handle, (%rd168);
	// end inline asm

$L__BB0_37:
	// begin inline asm
	cvta.to.global.u64 %rd174, %rd787;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r212,%r213,%r214,%r215}, [%rd174];
	// end inline asm
	mov.b32 	%f3315, %r212;
	mov.b32 	%f3316, %r213;
	mov.b32 	%f3317, %r214;
	add.s64 	%rd178, %rd787, 16;
	// begin inline asm
	cvta.to.global.u64 %rd177, %rd178;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r216,%r217,%r218,%r219}, [%rd177];
	// end inline asm
	mov.b32 	%f3312, %r216;
	mov.b32 	%f3313, %r217;
	mov.b32 	%f3314, %r218;
	add.s64 	%rd181, %rd787, 32;
	// begin inline asm
	cvta.to.global.u64 %rd180, %rd181;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r220,%r221,%r222,%r223}, [%rd180];
	// end inline asm
	mov.b32 	%f3309, %r220;
	mov.b32 	%f3310, %r221;
	mov.b32 	%f3311, %r222;

$L__BB0_45:
	setp.eq.s32 	%p24, %r1050, 0;
	@%p24 bra 	$L__BB0_47;

	mul.ftz.f32 	%f1742, %f3286, %f3316;
	fma.rn.ftz.f32 	%f1743, %f3283, %f3315, %f1742;
	fma.rn.ftz.f32 	%f334, %f3289, %f3317, %f1743;
	mul.ftz.f32 	%f1744, %f3285, %f3316;
	fma.rn.ftz.f32 	%f1745, %f3282, %f3315, %f1744;
	fma.rn.ftz.f32 	%f335, %f3288, %f3317, %f1745;
	mul.ftz.f32 	%f1746, %f3284, %f3316;
	fma.rn.ftz.f32 	%f1747, %f3281, %f3315, %f1746;
	fma.rn.ftz.f32 	%f3317, %f3287, %f3317, %f1747;
	mul.ftz.f32 	%f1748, %f3286, %f3313;
	fma.rn.ftz.f32 	%f1749, %f3283, %f3312, %f1748;
	fma.rn.ftz.f32 	%f337, %f3289, %f3314, %f1749;
	mul.ftz.f32 	%f1750, %f3285, %f3313;
	fma.rn.ftz.f32 	%f1751, %f3282, %f3312, %f1750;
	fma.rn.ftz.f32 	%f338, %f3288, %f3314, %f1751;
	mul.ftz.f32 	%f1752, %f3284, %f3313;
	fma.rn.ftz.f32 	%f1753, %f3281, %f3312, %f1752;
	fma.rn.ftz.f32 	%f3314, %f3287, %f3314, %f1753;
	mul.ftz.f32 	%f1754, %f3286, %f3310;
	fma.rn.ftz.f32 	%f1755, %f3283, %f3309, %f1754;
	fma.rn.ftz.f32 	%f340, %f3289, %f3311, %f1755;
	mul.ftz.f32 	%f1756, %f3285, %f3310;
	fma.rn.ftz.f32 	%f1757, %f3282, %f3309, %f1756;
	fma.rn.ftz.f32 	%f341, %f3288, %f3311, %f1757;
	mul.ftz.f32 	%f1758, %f3284, %f3310;
	fma.rn.ftz.f32 	%f1759, %f3281, %f3309, %f1758;
	fma.rn.ftz.f32 	%f3311, %f3287, %f3311, %f1759;
	mov.f32 	%f3309, %f340;
	mov.f32 	%f3310, %f341;
	mov.f32 	%f3312, %f337;
	mov.f32 	%f3313, %f338;
	mov.f32 	%f3315, %f334;
	mov.f32 	%f3316, %f335;

$L__BB0_47:
	add.s32 	%r1050, %r1050, 1;
	setp.lt.u32 	%p25, %r1050, %r207;
	mov.f32 	%f3281, %f3317;
	mov.f32 	%f3282, %f3316;
	mov.f32 	%f3283, %f3315;
	mov.f32 	%f3284, %f3314;
	mov.f32 	%f3285, %f3313;
	mov.f32 	%f3286, %f3312;
	mov.f32 	%f3287, %f3311;
	mov.f32 	%f3288, %f3310;
	mov.f32 	%f3289, %f3309;
	@%p25 bra 	$L__BB0_32;

$L__BB0_48:
	mul.ftz.f32 	%f1760, %f3615, %f3315;
	fma.rn.ftz.f32 	%f1761, %f3614, %f3312, %f1760;
	mul.ftz.f32 	%f1762, %f3615, %f3316;
	fma.rn.ftz.f32 	%f1763, %f3614, %f3313, %f1762;
	mul.ftz.f32 	%f1764, %f3615, %f3317;
	fma.rn.ftz.f32 	%f1765, %f3614, %f3314, %f1764;
	fma.rn.ftz.f32 	%f3613, %f228, %f3311, %f1765;
	fma.rn.ftz.f32 	%f3614, %f228, %f3310, %f1763;
	fma.rn.ftz.f32 	%f3615, %f228, %f3309, %f1761;
	bra.uni 	$L__BB0_144;

$L__BB0_49:
	mov.f32 	%f3613, %f228;
	bra.uni 	$L__BB0_144;

$L__BB0_73:
	mul.ftz.f32 	%f2039, %f584, %f584;
	mul.ftz.f32 	%f2040, %f2039, 0f3E2AAAAB;
	mul.ftz.f32 	%f2041, %f2040, %f584;
	sub.ftz.f32 	%f2042, %f584, %f2039;
	fma.rn.ftz.f32 	%f2043, %f2042, 0f3F000000, %f2041;
	mul.ftz.f32 	%f2044, %f2041, 0f40800000;
	sub.ftz.f32 	%f2045, %f2039, %f2044;
	fma.rn.ftz.f32 	%f2046, %f377, %f2043, %f373;
	fma.rn.ftz.f32 	%f2047, %f378, %f2043, %f374;
	fma.rn.ftz.f32 	%f2048, %f379, %f2043, %f375;
	fma.rn.ftz.f32 	%f2049, %f380, %f2043, %f376;
	fma.rn.ftz.f32 	%f2050, %f381, %f2045, %f2046;
	fma.rn.ftz.f32 	%f2051, %f382, %f2045, %f2047;
	fma.rn.ftz.f32 	%f2052, %f383, %f2045, %f2048;
	fma.rn.ftz.f32 	%f2053, %f384, %f2045, %f2049;
	fma.rn.ftz.f32 	%f2054, %f385, %f2041, %f2050;
	fma.rn.ftz.f32 	%f2055, %f386, %f2041, %f2051;
	fma.rn.ftz.f32 	%f2056, %f387, %f2041, %f2052;
	fma.rn.ftz.f32 	%f2057, %f388, %f2041, %f2053;
	mov.f32 	%f2058, 0f3F800000;
	sub.ftz.f32 	%f2059, %f2058, %f584;
	mul.ftz.f32 	%f2060, %f2059, 0f3F000000;
	mul.ftz.f32 	%f2061, %f2059, %f2060;
	add.ftz.f32 	%f2062, %f2059, %f2059;
	mul.ftz.f32 	%f2063, %f2062, %f584;
	mul.ftz.f32 	%f2064, %f381, %f2063;
	mul.ftz.f32 	%f2065, %f382, %f2063;
	mul.ftz.f32 	%f2066, %f383, %f2063;
	mul.ftz.f32 	%f2067, %f384, %f2063;
	fma.rn.ftz.f32 	%f2068, %f377, %f2061, %f2064;
	fma.rn.ftz.f32 	%f2069, %f378, %f2061, %f2065;
	fma.rn.ftz.f32 	%f2070, %f379, %f2061, %f2066;
	fma.rn.ftz.f32 	%f2071, %f380, %f2061, %f2067;
	mul.ftz.f32 	%f2072, %f584, 0f3F000000;
	mul.ftz.f32 	%f2073, %f2072, %f584;
	fma.rn.ftz.f32 	%f2074, %f385, %f2073, %f2068;
	fma.rn.ftz.f32 	%f2075, %f386, %f2073, %f2069;
	fma.rn.ftz.f32 	%f2076, %f387, %f2073, %f2070;
	fma.rn.ftz.f32 	%f2077, %f388, %f2073, %f2071;
	mul.ftz.f32 	%f2078, %f2075, %f2075;
	fma.rn.ftz.f32 	%f2079, %f2074, %f2074, %f2078;
	fma.rn.ftz.f32 	%f2080, %f2076, %f2076, %f2079;
	sub.ftz.f32 	%f2081, %f3412, %f2054;
	sub.ftz.f32 	%f2082, %f3413, %f2055;
	sub.ftz.f32 	%f2083, %f3414, %f2056;
	mul.ftz.f32 	%f2084, %f2075, %f2082;
	fma.rn.ftz.f32 	%f2085, %f2074, %f2081, %f2084;
	fma.rn.ftz.f32 	%f2086, %f2076, %f2083, %f2085;
	div.approx.ftz.f32 	%f2087, %f2086, %f2080;
	mul.ftz.f32 	%f2088, %f2074, %f2087;
	mul.ftz.f32 	%f2089, %f2075, %f2087;
	mul.ftz.f32 	%f2090, %f2076, %f2087;
	sub.ftz.f32 	%f2091, %f2081, %f2088;
	sub.ftz.f32 	%f2092, %f2082, %f2089;
	sub.ftz.f32 	%f2093, %f2083, %f2090;
	mul.ftz.f32 	%f2094, %f2092, %f2092;
	fma.rn.ftz.f32 	%f2095, %f2091, %f2091, %f2094;
	fma.rn.ftz.f32 	%f2096, %f2093, %f2093, %f2095;
	sqrt.approx.ftz.f32 	%f2097, %f2096;
	div.approx.ftz.f32 	%f2098, %f2057, %f2097;
	mul.ftz.f32 	%f2099, %f2091, %f2098;
	mul.ftz.f32 	%f2100, %f2092, %f2098;
	mul.ftz.f32 	%f2101, %f2093, %f2098;
	add.ftz.f32 	%f2102, %f381, %f381;
	sub.ftz.f32 	%f2103, %f2102, %f377;
	add.ftz.f32 	%f2104, %f382, %f382;
	sub.ftz.f32 	%f2105, %f2104, %f378;
	add.ftz.f32 	%f2106, %f383, %f383;
	sub.ftz.f32 	%f2107, %f2106, %f379;
	mul.ftz.f32 	%f2108, %f381, 0f40800000;
	sub.ftz.f32 	%f2109, %f377, %f2108;
	mul.ftz.f32 	%f2110, %f382, 0f40800000;
	sub.ftz.f32 	%f2111, %f378, %f2110;
	mul.ftz.f32 	%f2112, %f383, 0f40800000;
	sub.ftz.f32 	%f2113, %f379, %f2112;
	add.ftz.f32 	%f2114, %f385, %f2109;
	add.ftz.f32 	%f2115, %f386, %f2111;
	add.ftz.f32 	%f2116, %f387, %f2113;
	fma.rn.ftz.f32 	%f2117, %f2114, %f584, %f2103;
	fma.rn.ftz.f32 	%f2118, %f2115, %f584, %f2105;
	fma.rn.ftz.f32 	%f2119, %f2116, %f584, %f2107;
	mul.ftz.f32 	%f2120, %f2118, %f2100;
	fma.rn.ftz.f32 	%f2121, %f2117, %f2099, %f2120;
	fma.rn.ftz.f32 	%f2122, %f2119, %f2101, %f2121;
	sub.ftz.f32 	%f2123, %f2080, %f2122;
	mul.ftz.f32 	%f2124, %f2099, %f2123;
	mul.ftz.f32 	%f2125, %f2100, %f2123;
	mul.ftz.f32 	%f2126, %f2101, %f2123;
	mul.ftz.f32 	%f2127, %f2077, %f2057;
	mul.ftz.f32 	%f2128, %f2074, %f2127;
	mul.ftz.f32 	%f2129, %f2075, %f2127;
	mul.ftz.f32 	%f2130, %f2076, %f2127;
	sub.ftz.f32 	%f3415, %f2124, %f2128;
	sub.ftz.f32 	%f3416, %f2125, %f2129;
	sub.ftz.f32 	%f3417, %f2126, %f2130;

$L__BB0_76:
	mul.ftz.f32 	%f2158, %f3416, %f3416;
	fma.rn.ftz.f32 	%f2159, %f3415, %f3415, %f2158;
	fma.rn.ftz.f32 	%f2160, %f3417, %f3417, %f2159;
	rsqrt.approx.ftz.f32 	%f2161, %f2160;
	mul.ftz.f32 	%f3615, %f3415, %f2161;
	mul.ftz.f32 	%f3614, %f3416, %f2161;
	mul.ftz.f32 	%f599, %f3417, %f2161;
	// begin inline asm
	call (%r514), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p38, %r514, 0;
	@%p38 bra 	$L__BB0_96;

	// begin inline asm
	call (%r515), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f2162), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p39, %r515, 0;
	@%p39 bra 	$L__BB0_95;

	mov.u32 	%r1052, 0;

$L__BB0_79:
	.pragma "nounroll";
	// begin inline asm
	call (%rd408), _optix_get_transform_list_handle, (%r1052);
	// end inline asm
	// begin inline asm
	call (%r518), _optix_get_transform_type_from_handle, (%rd408);
	// end inline asm
	or.b32  	%r519, %r518, 1;
	setp.eq.s32 	%p40, %r519, 3;
	@%p40 bra 	$L__BB0_85;
	bra.uni 	$L__BB0_80;

$L__BB0_85:
	setp.eq.s32 	%p43, %r518, 2;
	@%p43 bra 	$L__BB0_89;
	bra.uni 	$L__BB0_86;

$L__BB0_89:
	// begin inline asm
	call (%rd480), _optix_get_matrix_motion_transform_from_handle, (%rd408);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd482, %rd480;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r607,%r608,%r609,%r610}, [%rd482];
	// end inline asm
	add.s64 	%rd486, %rd480, 16;
	// begin inline asm
	cvta.to.global.u64 %rd485, %rd486;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r611,%r612,%r613,%r614}, [%rd485];
	// end inline asm
	add.s64 	%rd489, %rd480, 32;
	// begin inline asm
	cvta.to.global.u64 %rd488, %rd489;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r615,%r616,%r617,%r618}, [%rd488];
	// end inline asm
	add.s64 	%rd492, %rd480, 48;
	// begin inline asm
	cvta.to.global.u64 %rd491, %rd492;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r619,%r620,%r621,%r622}, [%rd491];
	// end inline asm
	add.s64 	%rd495, %rd480, 64;
	// begin inline asm
	cvta.to.global.u64 %rd494, %rd495;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r623,%r624,%r625,%r626}, [%rd494];
	// end inline asm
	add.s64 	%rd498, %rd480, 80;
	// begin inline asm
	cvta.to.global.u64 %rd497, %rd498;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r627,%r628,%r629,%r630}, [%rd497];
	// end inline asm
	add.s64 	%rd501, %rd480, 96;
	// begin inline asm
	cvta.to.global.u64 %rd500, %rd501;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r631,%r632,%r633,%r634}, [%rd500];
	// end inline asm
	add.s64 	%rd504, %rd480, 112;
	// begin inline asm
	cvta.to.global.u64 %rd503, %rd504;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r635,%r636,%r637,%r638}, [%rd503];
	// end inline asm
	mov.b32 	%f2265, %r610;
	mov.b32 	%f2266, %r611;
	and.b32  	%r651, %r609, 65535;
	add.s32 	%r652, %r651, -1;
	cvt.rn.f32.s32 	%f2267, %r652;
	sub.ftz.f32 	%f2268, %f2162, %f2265;
	mul.ftz.f32 	%f2269, %f2268, %f2267;
	sub.ftz.f32 	%f2270, %f2266, %f2265;
	div.approx.ftz.f32 	%f2271, %f2269, %f2270;
	min.ftz.f32 	%f2272, %f2267, %f2271;
	mov.f32 	%f2273, 0f00000000;
	max.ftz.f32 	%f2274, %f2273, %f2272;
	cvt.rmi.ftz.f32.f32 	%f2275, %f2274;
	sub.ftz.f32 	%f659, %f2274, %f2275;
	cvt.rzi.ftz.s32.f32 	%r653, %f2275;
	cvt.s64.s32 	%rd29, %r653;
	mul.wide.s32 	%rd515, %r653, 48;
	add.s64 	%rd507, %rd489, %rd515;
	// begin inline asm
	cvta.to.global.u64 %rd506, %rd507;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r639,%r640,%r641,%r642}, [%rd506];
	// end inline asm
	mov.b32 	%f3443, %r639;
	mov.b32 	%f3444, %r640;
	mov.b32 	%f3445, %r641;
	add.s64 	%rd510, %rd507, 16;
	// begin inline asm
	cvta.to.global.u64 %rd509, %rd510;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r643,%r644,%r645,%r646}, [%rd509];
	// end inline asm
	mov.b32 	%f3440, %r643;
	mov.b32 	%f3441, %r644;
	mov.b32 	%f3442, %r645;
	add.s64 	%rd513, %rd507, 32;
	// begin inline asm
	cvta.to.global.u64 %rd512, %rd513;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r647,%r648,%r649,%r650}, [%rd512];
	// end inline asm
	mov.b32 	%f3437, %r647;
	mov.b32 	%f3438, %r648;
	mov.b32 	%f3439, %r649;
	setp.leu.ftz.f32 	%p45, %f659, 0f00000000;
	@%p45 bra 	$L__BB0_91;

	mov.f32 	%f2276, 0f3F800000;
	sub.ftz.f32 	%f2277, %f2276, %f659;
	mul.lo.s64 	%rd525, %rd29, 48;
	add.s64 	%rd526, %rd480, %rd525;
	add.s64 	%rd517, %rd526, 80;
	// begin inline asm
	cvta.to.global.u64 %rd516, %rd517;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r654,%r655,%r656,%r657}, [%rd516];
	// end inline asm
	mov.b32 	%f2278, %r654;
	mov.b32 	%f2279, %r655;
	mov.b32 	%f2280, %r656;
	mul.ftz.f32 	%f2281, %f659, %f2278;
	mul.ftz.f32 	%f2282, %f659, %f2279;
	mul.ftz.f32 	%f2283, %f659, %f2280;
	fma.rn.ftz.f32 	%f3443, %f2277, %f3443, %f2281;
	fma.rn.ftz.f32 	%f3444, %f2277, %f3444, %f2282;
	fma.rn.ftz.f32 	%f3445, %f2277, %f3445, %f2283;
	add.s64 	%rd520, %rd526, 96;
	// begin inline asm
	cvta.to.global.u64 %rd519, %rd520;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r658,%r659,%r660,%r661}, [%rd519];
	// end inline asm
	mov.b32 	%f2284, %r658;
	mov.b32 	%f2285, %r659;
	mov.b32 	%f2286, %r660;
	mul.ftz.f32 	%f2287, %f659, %f2284;
	mul.ftz.f32 	%f2288, %f659, %f2285;
	mul.ftz.f32 	%f2289, %f659, %f2286;
	fma.rn.ftz.f32 	%f3440, %f2277, %f3440, %f2287;
	fma.rn.ftz.f32 	%f3441, %f2277, %f3441, %f2288;
	fma.rn.ftz.f32 	%f3442, %f2277, %f3442, %f2289;
	add.s64 	%rd523, %rd526, 112;
	// begin inline asm
	cvta.to.global.u64 %rd522, %rd523;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r662,%r663,%r664,%r665}, [%rd522];
	// end inline asm
	mov.b32 	%f2290, %r662;
	mov.b32 	%f2291, %r663;
	mov.b32 	%f2292, %r664;
	mul.ftz.f32 	%f2293, %f659, %f2290;
	mul.ftz.f32 	%f2294, %f659, %f2291;
	mul.ftz.f32 	%f2295, %f659, %f2292;
	fma.rn.ftz.f32 	%f3437, %f2277, %f3437, %f2293;
	fma.rn.ftz.f32 	%f3438, %f2277, %f3438, %f2294;
	fma.rn.ftz.f32 	%f3439, %f2277, %f3439, %f2295;
	bra.uni 	$L__BB0_91;

$L__BB0_80:
	mov.f32 	%f3446, 0f00000000;
	mov.f32 	%f3448, 0f3F800000;
	setp.eq.s32 	%p41, %r518, 4;
	@%p41 bra 	$L__BB0_83;

	setp.ne.s32 	%p42, %r518, 1;
	mov.f32 	%f3447, %f3446;
	mov.f32 	%f3449, %f3446;
	mov.f32 	%f3450, %f3448;
	mov.f32 	%f3451, %f3446;
	mov.f32 	%f3452, %f3448;
	mov.f32 	%f3453, %f3446;
	mov.f32 	%f3454, %f3446;
	@%p42 bra 	$L__BB0_92;

	// begin inline asm
	call (%rd410), _optix_get_static_transform_from_handle, (%rd408);
	// end inline asm
	add.s64 	%rd789, %rd410, 64;
	bra.uni 	$L__BB0_84;

$L__BB0_86:
	// begin inline asm
	call (%rd423), _optix_get_srt_motion_transform_from_handle, (%rd408);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd425, %rd423;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r532,%r533,%r534,%r535}, [%rd425];
	// end inline asm
	add.s64 	%rd429, %rd423, 16;
	// begin inline asm
	cvta.to.global.u64 %rd428, %rd429;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r536,%r537,%r538,%r539}, [%rd428];
	// end inline asm
	add.s64 	%rd432, %rd423, 32;
	// begin inline asm
	cvta.to.global.u64 %rd431, %rd432;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r540,%r541,%r542,%r543}, [%rd431];
	// end inline asm
	add.s64 	%rd435, %rd423, 48;
	// begin inline asm
	cvta.to.global.u64 %rd434, %rd435;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r544,%r545,%r546,%r547}, [%rd434];
	// end inline asm
	add.s64 	%rd438, %rd423, 64;
	// begin inline asm
	cvta.to.global.u64 %rd437, %rd438;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r548,%r549,%r550,%r551}, [%rd437];
	// end inline asm
	add.s64 	%rd441, %rd423, 80;
	// begin inline asm
	cvta.to.global.u64 %rd440, %rd441;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r552,%r553,%r554,%r555}, [%rd440];
	// end inline asm
	add.s64 	%rd444, %rd423, 96;
	// begin inline asm
	cvta.to.global.u64 %rd443, %rd444;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r556,%r557,%r558,%r559}, [%rd443];
	// end inline asm
	add.s64 	%rd447, %rd423, 112;
	// begin inline asm
	cvta.to.global.u64 %rd446, %rd447;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r560,%r561,%r562,%r563}, [%rd446];
	// end inline asm
	add.s64 	%rd450, %rd423, 128;
	// begin inline asm
	cvta.to.global.u64 %rd449, %rd450;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r564,%r565,%r566,%r567}, [%rd449];
	// end inline asm
	add.s64 	%rd453, %rd423, 144;
	// begin inline asm
	cvta.to.global.u64 %rd452, %rd453;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r568,%r569,%r570,%r571}, [%rd452];
	// end inline asm
	mov.b32 	%f2174, %r535;
	mov.b32 	%f2175, %r536;
	and.b32  	%r588, %r534, 65535;
	add.s32 	%r589, %r588, -1;
	cvt.rn.f32.s32 	%f2176, %r589;
	sub.ftz.f32 	%f2177, %f2162, %f2174;
	mul.ftz.f32 	%f2178, %f2177, %f2176;
	sub.ftz.f32 	%f2179, %f2175, %f2174;
	div.approx.ftz.f32 	%f2180, %f2178, %f2179;
	min.ftz.f32 	%f2181, %f2176, %f2180;
	mov.f32 	%f2182, 0f00000000;
	max.ftz.f32 	%f2183, %f2182, %f2181;
	cvt.rmi.ftz.f32.f32 	%f2184, %f2183;
	sub.ftz.f32 	%f619, %f2183, %f2184;
	cvt.rzi.ftz.s32.f32 	%r590, %f2184;
	mul.wide.s32 	%rd467, %r590, 64;
	add.s64 	%rd456, %rd432, %rd467;
	// begin inline asm
	cvta.to.global.u64 %rd455, %rd456;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r572,%r573,%r574,%r575}, [%rd455];
	// end inline asm
	mov.b32 	%f3427, %r572;
	mov.b32 	%f3428, %r573;
	mov.b32 	%f3429, %r574;
	add.s64 	%rd459, %rd456, 16;
	// begin inline asm
	cvta.to.global.u64 %rd458, %rd459;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r576,%r577,%r578,%r579}, [%rd458];
	// end inline asm
	mov.b32 	%f3430, %r576;
	mov.b32 	%f3431, %r577;
	mov.b32 	%f3432, %r579;
	add.s64 	%rd462, %rd456, 32;
	// begin inline asm
	cvta.to.global.u64 %rd461, %rd462;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r580,%r581,%r582,%r583}, [%rd461];
	// end inline asm
	mov.b32 	%f3433, %r581;
	mov.b32 	%f3434, %r582;
	mov.b32 	%f3435, %r583;
	add.s64 	%rd465, %rd456, 48;
	// begin inline asm
	cvta.to.global.u64 %rd464, %rd465;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r584,%r585,%r586,%r587}, [%rd464];
	// end inline asm
	mov.b32 	%f3436, %r584;
	setp.leu.ftz.f32 	%p44, %f619, 0f00000000;
	@%p44 bra 	$L__BB0_88;

	mov.f32 	%f2185, 0f3F800000;
	sub.ftz.f32 	%f2186, %f2185, %f619;
	add.s64 	%rd469, %rd456, 64;
	// begin inline asm
	cvta.to.global.u64 %rd468, %rd469;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r591,%r592,%r593,%r594}, [%rd468];
	// end inline asm
	mov.b32 	%f2187, %r591;
	mov.b32 	%f2188, %r592;
	mov.b32 	%f2189, %r593;
	mul.ftz.f32 	%f2190, %f619, %f2187;
	mul.ftz.f32 	%f2191, %f619, %f2188;
	mul.ftz.f32 	%f2192, %f619, %f2189;
	fma.rn.ftz.f32 	%f3427, %f2186, %f3427, %f2190;
	fma.rn.ftz.f32 	%f3428, %f2186, %f3428, %f2191;
	fma.rn.ftz.f32 	%f3429, %f2186, %f3429, %f2192;
	add.s64 	%rd472, %rd456, 80;
	// begin inline asm
	cvta.to.global.u64 %rd471, %rd472;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r595,%r596,%r597,%r598}, [%rd471];
	// end inline asm
	mov.b32 	%f2193, %r595;
	mov.b32 	%f2194, %r596;
	mov.b32 	%f2195, %r598;
	mul.ftz.f32 	%f2196, %f619, %f2193;
	mul.ftz.f32 	%f2197, %f619, %f2194;
	mul.ftz.f32 	%f2198, %f619, %f2195;
	fma.rn.ftz.f32 	%f3430, %f2186, %f3430, %f2196;
	fma.rn.ftz.f32 	%f3431, %f2186, %f3431, %f2197;
	fma.rn.ftz.f32 	%f3432, %f2186, %f3432, %f2198;
	add.s64 	%rd475, %rd456, 96;
	// begin inline asm
	cvta.to.global.u64 %rd474, %rd475;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r599,%r600,%r601,%r602}, [%rd474];
	// end inline asm
	mov.b32 	%f2199, %r600;
	mov.b32 	%f2200, %r601;
	mov.b32 	%f2201, %r602;
	mul.ftz.f32 	%f2202, %f619, %f2199;
	mul.ftz.f32 	%f2203, %f619, %f2200;
	mul.ftz.f32 	%f2204, %f619, %f2201;
	fma.rn.ftz.f32 	%f2205, %f2186, %f3433, %f2202;
	fma.rn.ftz.f32 	%f2206, %f2186, %f3434, %f2203;
	fma.rn.ftz.f32 	%f2207, %f2186, %f3435, %f2204;
	add.s64 	%rd478, %rd456, 112;
	// begin inline asm
	cvta.to.global.u64 %rd477, %rd478;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r603,%r604,%r605,%r606}, [%rd477];
	// end inline asm
	mov.b32 	%f2208, %r603;
	mul.ftz.f32 	%f2209, %f619, %f2208;
	fma.rn.ftz.f32 	%f2210, %f2186, %f3436, %f2209;
	mul.ftz.f32 	%f2211, %f2206, %f2206;
	fma.rn.ftz.f32 	%f2212, %f2205, %f2205, %f2211;
	fma.rn.ftz.f32 	%f2213, %f2207, %f2207, %f2212;
	fma.rn.ftz.f32 	%f2214, %f2210, %f2210, %f2213;
	rsqrt.approx.ftz.f32 	%f2215, %f2214;
	mul.ftz.f32 	%f3433, %f2205, %f2215;
	mul.ftz.f32 	%f3434, %f2206, %f2215;
	mul.ftz.f32 	%f3435, %f2207, %f2215;
	mul.ftz.f32 	%f3436, %f2215, %f2210;

$L__BB0_88:
	mul.ftz.f32 	%f2216, %f3434, %f3434;
	fma.rn.ftz.f32 	%f2217, %f3433, %f3433, %f2216;
	fma.rn.ftz.f32 	%f2218, %f3435, %f3435, %f2217;
	fma.rn.ftz.f32 	%f2219, %f3436, %f3436, %f2218;
	rcp.approx.ftz.f32 	%f2220, %f2219;
	mul.ftz.f32 	%f2221, %f3433, %f2220;
	mul.ftz.f32 	%f2222, %f3434, %f2220;
	mul.ftz.f32 	%f2223, %f3435, %f2220;
	mul.ftz.f32 	%f2224, %f3436, %f2220;
	mul.ftz.f32 	%f2225, %f3433, %f2221;
	mul.ftz.f32 	%f2226, %f3434, %f2222;
	mul.ftz.f32 	%f2227, %f3435, %f2223;
	mul.ftz.f32 	%f2228, %f3433, %f2222;
	mul.ftz.f32 	%f2229, %f3435, %f2224;
	mul.ftz.f32 	%f2230, %f3433, %f2223;
	mul.ftz.f32 	%f2231, %f3434, %f2224;
	mul.ftz.f32 	%f2232, %f3434, %f2223;
	mul.ftz.f32 	%f2233, %f3433, %f2224;
	sub.ftz.f32 	%f2234, %f2225, %f2226;
	sub.ftz.f32 	%f2235, %f2234, %f2227;
	fma.rn.ftz.f32 	%f2236, %f3436, %f2224, %f2235;
	sub.ftz.f32 	%f2237, %f2228, %f2229;
	add.ftz.f32 	%f2238, %f2237, %f2237;
	add.ftz.f32 	%f2239, %f2230, %f2231;
	add.ftz.f32 	%f2240, %f2239, %f2239;
	add.ftz.f32 	%f2241, %f2228, %f2229;
	add.ftz.f32 	%f2242, %f2241, %f2241;
	sub.ftz.f32 	%f2243, %f2226, %f2225;
	sub.ftz.f32 	%f2244, %f2243, %f2227;
	fma.rn.ftz.f32 	%f2245, %f3436, %f2224, %f2244;
	sub.ftz.f32 	%f2246, %f2232, %f2233;
	add.ftz.f32 	%f2247, %f2246, %f2246;
	sub.ftz.f32 	%f2248, %f2230, %f2231;
	add.ftz.f32 	%f2249, %f2248, %f2248;
	add.ftz.f32 	%f2250, %f2232, %f2233;
	add.ftz.f32 	%f2251, %f2250, %f2250;
	neg.ftz.f32 	%f2252, %f2225;
	sub.ftz.f32 	%f2253, %f2252, %f2226;
	add.ftz.f32 	%f2254, %f2227, %f2253;
	fma.rn.ftz.f32 	%f2255, %f3436, %f2224, %f2254;
	mul.ftz.f32 	%f2256, %f3429, %f2236;
	fma.rn.ftz.f32 	%f2257, %f3431, %f2238, %f2256;
	fma.rn.ftz.f32 	%f3445, %f3432, %f2240, %f2257;
	mul.ftz.f32 	%f2258, %f3431, %f2245;
	fma.rn.ftz.f32 	%f2259, %f3429, %f2242, %f2258;
	fma.rn.ftz.f32 	%f3442, %f3432, %f2247, %f2259;
	mul.ftz.f32 	%f2260, %f3431, %f2251;
	fma.rn.ftz.f32 	%f2261, %f3429, %f2249, %f2260;
	fma.rn.ftz.f32 	%f3439, %f3432, %f2255, %f2261;
	mul.ftz.f32 	%f2262, %f3428, %f2236;
	fma.rn.ftz.f32 	%f3444, %f3430, %f2238, %f2262;
	mul.ftz.f32 	%f2263, %f3430, %f2245;
	fma.rn.ftz.f32 	%f3441, %f3428, %f2242, %f2263;
	mul.ftz.f32 	%f2264, %f3430, %f2251;
	fma.rn.ftz.f32 	%f3438, %f3428, %f2249, %f2264;
	mul.ftz.f32 	%f3443, %f3427, %f2236;
	mul.ftz.f32 	%f3440, %f3427, %f2242;
	mul.ftz.f32 	%f3437, %f3427, %f2249;

$L__BB0_91:
	mul.ftz.f32 	%f2296, %f3438, %f3442;
	mul.ftz.f32 	%f2297, %f3439, %f3441;
	sub.ftz.f32 	%f2298, %f2297, %f2296;
	mul.ftz.f32 	%f2299, %f3443, %f2298;
	mul.ftz.f32 	%f2300, %f3437, %f3442;
	mul.ftz.f32 	%f2301, %f3439, %f3440;
	sub.ftz.f32 	%f2302, %f2301, %f2300;
	mul.ftz.f32 	%f2303, %f2302, %f3444;
	sub.ftz.f32 	%f2304, %f2299, %f2303;
	mul.ftz.f32 	%f2305, %f3437, %f3441;
	mul.ftz.f32 	%f2306, %f3438, %f3440;
	sub.ftz.f32 	%f2307, %f2306, %f2305;
	fma.rn.ftz.f32 	%f2308, %f2307, %f3445, %f2304;
	rcp.approx.ftz.f32 	%f2309, %f2308;
	mul.ftz.f32 	%f3452, %f2298, %f2309;
	mul.ftz.f32 	%f2310, %f3439, %f3444;
	mul.ftz.f32 	%f2311, %f3438, %f3445;
	sub.ftz.f32 	%f2312, %f2311, %f2310;
	mul.ftz.f32 	%f3453, %f2312, %f2309;
	mul.ftz.f32 	%f2313, %f3441, %f3445;
	mul.ftz.f32 	%f2314, %f3442, %f3444;
	sub.ftz.f32 	%f2315, %f2314, %f2313;
	mul.ftz.f32 	%f3454, %f2315, %f2309;
	sub.ftz.f32 	%f2316, %f2300, %f2301;
	mul.ftz.f32 	%f3449, %f2316, %f2309;
	mul.ftz.f32 	%f2317, %f3437, %f3445;
	mul.ftz.f32 	%f2318, %f3439, %f3443;
	sub.ftz.f32 	%f2319, %f2318, %f2317;
	mul.ftz.f32 	%f3450, %f2319, %f2309;
	mul.ftz.f32 	%f2320, %f3442, %f3443;
	mul.ftz.f32 	%f2321, %f3440, %f3445;
	sub.ftz.f32 	%f2322, %f2321, %f2320;
	mul.ftz.f32 	%f3451, %f2322, %f2309;
	mul.ftz.f32 	%f3446, %f2307, %f2309;
	mul.ftz.f32 	%f2323, %f3438, %f3443;
	mul.ftz.f32 	%f2324, %f3437, %f3444;
	sub.ftz.f32 	%f2325, %f2324, %f2323;
	mul.ftz.f32 	%f3447, %f2325, %f2309;
	mul.ftz.f32 	%f2326, %f3440, %f3444;
	mul.ftz.f32 	%f2327, %f3441, %f3443;
	sub.ftz.f32 	%f2328, %f2327, %f2326;
	mul.ftz.f32 	%f3448, %f2328, %f2309;
	bra.uni 	$L__BB0_92;

$L__BB0_83:
	// begin inline asm
	call (%rd789), _optix_get_instance_inverse_transform_from_handle, (%rd408);
	// end inline asm

$L__BB0_84:
	// begin inline asm
	cvta.to.global.u64 %rd414, %rd789;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r520,%r521,%r522,%r523}, [%rd414];
	// end inline asm
	mov.b32 	%f3452, %r520;
	mov.b32 	%f3453, %r521;
	mov.b32 	%f3454, %r522;
	add.s64 	%rd418, %rd789, 16;
	// begin inline asm
	cvta.to.global.u64 %rd417, %rd418;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r524,%r525,%r526,%r527}, [%rd417];
	// end inline asm
	mov.b32 	%f3449, %r524;
	mov.b32 	%f3450, %r525;
	mov.b32 	%f3451, %r526;
	add.s64 	%rd421, %rd789, 32;
	// begin inline asm
	cvta.to.global.u64 %rd420, %rd421;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r528,%r529,%r530,%r531}, [%rd420];
	// end inline asm
	mov.b32 	%f3446, %r528;
	mov.b32 	%f3447, %r529;
	mov.b32 	%f3448, %r530;

$L__BB0_92:
	setp.eq.s32 	%p46, %r1052, 0;
	@%p46 bra 	$L__BB0_94;

	mul.ftz.f32 	%f2329, %f3423, %f3453;
	fma.rn.ftz.f32 	%f2330, %f3420, %f3452, %f2329;
	fma.rn.ftz.f32 	%f705, %f3426, %f3454, %f2330;
	mul.ftz.f32 	%f2331, %f3422, %f3453;
	fma.rn.ftz.f32 	%f2332, %f3419, %f3452, %f2331;
	fma.rn.ftz.f32 	%f706, %f3425, %f3454, %f2332;
	mul.ftz.f32 	%f2333, %f3421, %f3453;
	fma.rn.ftz.f32 	%f2334, %f3418, %f3452, %f2333;
	fma.rn.ftz.f32 	%f3454, %f3424, %f3454, %f2334;
	mul.ftz.f32 	%f2335, %f3423, %f3450;
	fma.rn.ftz.f32 	%f2336, %f3420, %f3449, %f2335;
	fma.rn.ftz.f32 	%f708, %f3426, %f3451, %f2336;
	mul.ftz.f32 	%f2337, %f3422, %f3450;
	fma.rn.ftz.f32 	%f2338, %f3419, %f3449, %f2337;
	fma.rn.ftz.f32 	%f709, %f3425, %f3451, %f2338;
	mul.ftz.f32 	%f2339, %f3421, %f3450;
	fma.rn.ftz.f32 	%f2340, %f3418, %f3449, %f2339;
	fma.rn.ftz.f32 	%f3451, %f3424, %f3451, %f2340;
	mul.ftz.f32 	%f2341, %f3423, %f3447;
	fma.rn.ftz.f32 	%f2342, %f3420, %f3446, %f2341;
	fma.rn.ftz.f32 	%f711, %f3426, %f3448, %f2342;
	mul.ftz.f32 	%f2343, %f3422, %f3447;
	fma.rn.ftz.f32 	%f2344, %f3419, %f3446, %f2343;
	fma.rn.ftz.f32 	%f712, %f3425, %f3448, %f2344;
	mul.ftz.f32 	%f2345, %f3421, %f3447;
	fma.rn.ftz.f32 	%f2346, %f3418, %f3446, %f2345;
	fma.rn.ftz.f32 	%f3448, %f3424, %f3448, %f2346;
	mov.f32 	%f3446, %f711;
	mov.f32 	%f3447, %f712;
	mov.f32 	%f3449, %f708;
	mov.f32 	%f3450, %f709;
	mov.f32 	%f3452, %f705;
	mov.f32 	%f3453, %f706;

$L__BB0_94:
	add.s32 	%r1052, %r1052, 1;
	setp.lt.u32 	%p47, %r1052, %r515;
	mov.f32 	%f3418, %f3454;
	mov.f32 	%f3419, %f3453;
	mov.f32 	%f3420, %f3452;
	mov.f32 	%f3421, %f3451;
	mov.f32 	%f3422, %f3450;
	mov.f32 	%f3423, %f3449;
	mov.f32 	%f3424, %f3448;
	mov.f32 	%f3425, %f3447;
	mov.f32 	%f3426, %f3446;
	@%p47 bra 	$L__BB0_79;

$L__BB0_95:
	mul.ftz.f32 	%f2347, %f3615, %f3452;
	fma.rn.ftz.f32 	%f2348, %f3614, %f3449, %f2347;
	mul.ftz.f32 	%f2349, %f3615, %f3453;
	fma.rn.ftz.f32 	%f2350, %f3614, %f3450, %f2349;
	mul.ftz.f32 	%f2351, %f3615, %f3454;
	fma.rn.ftz.f32 	%f2352, %f3614, %f3451, %f2351;
	fma.rn.ftz.f32 	%f3613, %f599, %f3448, %f2352;
	fma.rn.ftz.f32 	%f3614, %f599, %f3447, %f2350;
	fma.rn.ftz.f32 	%f3615, %f599, %f3446, %f2348;
	bra.uni 	$L__BB0_144;

$L__BB0_96:
	mov.f32 	%f3613, %f599;
	bra.uni 	$L__BB0_144;

$L__BB0_120:
	fma.rn.ftz.f32 	%f2622, %f748, %f951, %f744;
	fma.rn.ftz.f32 	%f2623, %f749, %f951, %f745;
	fma.rn.ftz.f32 	%f2624, %f750, %f951, %f746;
	fma.rn.ftz.f32 	%f2625, %f751, %f951, %f747;
	mul.ftz.f32 	%f2626, %f951, %f951;
	fma.rn.ftz.f32 	%f2627, %f752, %f2626, %f2622;
	fma.rn.ftz.f32 	%f2628, %f753, %f2626, %f2623;
	fma.rn.ftz.f32 	%f2629, %f754, %f2626, %f2624;
	fma.rn.ftz.f32 	%f2630, %f755, %f2626, %f2625;
	add.ftz.f32 	%f2631, %f951, %f951;
	fma.rn.ftz.f32 	%f2632, %f752, %f2631, %f748;
	fma.rn.ftz.f32 	%f2633, %f753, %f2631, %f749;
	fma.rn.ftz.f32 	%f2634, %f754, %f2631, %f750;
	fma.rn.ftz.f32 	%f2635, %f755, %f2631, %f751;
	mul.ftz.f32 	%f2636, %f2633, %f2633;
	fma.rn.ftz.f32 	%f2637, %f2632, %f2632, %f2636;
	fma.rn.ftz.f32 	%f2638, %f2634, %f2634, %f2637;
	sub.ftz.f32 	%f2639, %f3549, %f2627;
	sub.ftz.f32 	%f2640, %f3550, %f2628;
	sub.ftz.f32 	%f2641, %f3551, %f2629;
	mul.ftz.f32 	%f2642, %f2633, %f2640;
	fma.rn.ftz.f32 	%f2643, %f2632, %f2639, %f2642;
	fma.rn.ftz.f32 	%f2644, %f2634, %f2641, %f2643;
	div.approx.ftz.f32 	%f2645, %f2644, %f2638;
	mul.ftz.f32 	%f2646, %f2632, %f2645;
	mul.ftz.f32 	%f2647, %f2633, %f2645;
	mul.ftz.f32 	%f2648, %f2634, %f2645;
	sub.ftz.f32 	%f2649, %f2639, %f2646;
	sub.ftz.f32 	%f2650, %f2640, %f2647;
	sub.ftz.f32 	%f2651, %f2641, %f2648;
	mul.ftz.f32 	%f2652, %f2650, %f2650;
	fma.rn.ftz.f32 	%f2653, %f2649, %f2649, %f2652;
	fma.rn.ftz.f32 	%f2654, %f2651, %f2651, %f2653;
	sqrt.approx.ftz.f32 	%f2655, %f2654;
	div.approx.ftz.f32 	%f2656, %f2630, %f2655;
	mul.ftz.f32 	%f2657, %f2649, %f2656;
	mul.ftz.f32 	%f2658, %f2650, %f2656;
	mul.ftz.f32 	%f2659, %f2651, %f2656;
	mul.ftz.f32 	%f2660, %f953, %f2658;
	fma.rn.ftz.f32 	%f2661, %f952, %f2657, %f2660;
	fma.rn.ftz.f32 	%f2662, %f954, %f2659, %f2661;
	sub.ftz.f32 	%f2663, %f2638, %f2662;
	mul.ftz.f32 	%f2664, %f2657, %f2663;
	mul.ftz.f32 	%f2665, %f2658, %f2663;
	mul.ftz.f32 	%f2666, %f2659, %f2663;
	mul.ftz.f32 	%f2667, %f2635, %f2630;
	mul.ftz.f32 	%f2668, %f2632, %f2667;
	mul.ftz.f32 	%f2669, %f2633, %f2667;
	mul.ftz.f32 	%f2670, %f2634, %f2667;
	sub.ftz.f32 	%f3552, %f2664, %f2668;
	sub.ftz.f32 	%f3553, %f2665, %f2669;
	sub.ftz.f32 	%f3554, %f2666, %f2670;

$L__BB0_123:
	mul.ftz.f32 	%f2674, %f3553, %f3553;
	fma.rn.ftz.f32 	%f2675, %f3552, %f3552, %f2674;
	fma.rn.ftz.f32 	%f2676, %f3554, %f3554, %f2675;
	rsqrt.approx.ftz.f32 	%f2677, %f2676;
	mul.ftz.f32 	%f3615, %f3552, %f2677;
	mul.ftz.f32 	%f3614, %f3553, %f2677;
	mul.ftz.f32 	%f969, %f3554, %f2677;
	// begin inline asm
	call (%r822), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p60, %r822, 0;
	@%p60 bra 	$L__BB0_143;

	// begin inline asm
	call (%r823), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f2678), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p61, %r823, 0;
	@%p61 bra 	$L__BB0_142;

	mov.u32 	%r1054, 0;

$L__BB0_126:
	.pragma "nounroll";
	// begin inline asm
	call (%rd648), _optix_get_transform_list_handle, (%r1054);
	// end inline asm
	// begin inline asm
	call (%r826), _optix_get_transform_type_from_handle, (%rd648);
	// end inline asm
	or.b32  	%r827, %r826, 1;
	setp.eq.s32 	%p62, %r827, 3;
	@%p62 bra 	$L__BB0_132;
	bra.uni 	$L__BB0_127;

$L__BB0_132:
	setp.eq.s32 	%p65, %r826, 2;
	@%p65 bra 	$L__BB0_136;
	bra.uni 	$L__BB0_133;

$L__BB0_136:
	// begin inline asm
	call (%rd720), _optix_get_matrix_motion_transform_from_handle, (%rd648);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd722, %rd720;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r915,%r916,%r917,%r918}, [%rd722];
	// end inline asm
	add.s64 	%rd726, %rd720, 16;
	// begin inline asm
	cvta.to.global.u64 %rd725, %rd726;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r919,%r920,%r921,%r922}, [%rd725];
	// end inline asm
	add.s64 	%rd729, %rd720, 32;
	// begin inline asm
	cvta.to.global.u64 %rd728, %rd729;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r923,%r924,%r925,%r926}, [%rd728];
	// end inline asm
	add.s64 	%rd732, %rd720, 48;
	// begin inline asm
	cvta.to.global.u64 %rd731, %rd732;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r927,%r928,%r929,%r930}, [%rd731];
	// end inline asm
	add.s64 	%rd735, %rd720, 64;
	// begin inline asm
	cvta.to.global.u64 %rd734, %rd735;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r931,%r932,%r933,%r934}, [%rd734];
	// end inline asm
	add.s64 	%rd738, %rd720, 80;
	// begin inline asm
	cvta.to.global.u64 %rd737, %rd738;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r935,%r936,%r937,%r938}, [%rd737];
	// end inline asm
	add.s64 	%rd741, %rd720, 96;
	// begin inline asm
	cvta.to.global.u64 %rd740, %rd741;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r939,%r940,%r941,%r942}, [%rd740];
	// end inline asm
	add.s64 	%rd744, %rd720, 112;
	// begin inline asm
	cvta.to.global.u64 %rd743, %rd744;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r943,%r944,%r945,%r946}, [%rd743];
	// end inline asm
	mov.b32 	%f2781, %r918;
	mov.b32 	%f2782, %r919;
	and.b32  	%r959, %r917, 65535;
	add.s32 	%r960, %r959, -1;
	cvt.rn.f32.s32 	%f2783, %r960;
	sub.ftz.f32 	%f2784, %f2678, %f2781;
	mul.ftz.f32 	%f2785, %f2784, %f2783;
	sub.ftz.f32 	%f2786, %f2782, %f2781;
	div.approx.ftz.f32 	%f2787, %f2785, %f2786;
	min.ftz.f32 	%f2788, %f2783, %f2787;
	mov.f32 	%f2789, 0f00000000;
	max.ftz.f32 	%f2790, %f2789, %f2788;
	cvt.rmi.ftz.f32.f32 	%f2791, %f2790;
	sub.ftz.f32 	%f1029, %f2790, %f2791;
	cvt.rzi.ftz.s32.f32 	%r961, %f2791;
	cvt.s64.s32 	%rd43, %r961;
	mul.wide.s32 	%rd755, %r961, 48;
	add.s64 	%rd747, %rd729, %rd755;
	// begin inline asm
	cvta.to.global.u64 %rd746, %rd747;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r947,%r948,%r949,%r950}, [%rd746];
	// end inline asm
	mov.b32 	%f3580, %r947;
	mov.b32 	%f3581, %r948;
	mov.b32 	%f3582, %r949;
	add.s64 	%rd750, %rd747, 16;
	// begin inline asm
	cvta.to.global.u64 %rd749, %rd750;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r951,%r952,%r953,%r954}, [%rd749];
	// end inline asm
	mov.b32 	%f3577, %r951;
	mov.b32 	%f3578, %r952;
	mov.b32 	%f3579, %r953;
	add.s64 	%rd753, %rd747, 32;
	// begin inline asm
	cvta.to.global.u64 %rd752, %rd753;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r955,%r956,%r957,%r958}, [%rd752];
	// end inline asm
	mov.b32 	%f3574, %r955;
	mov.b32 	%f3575, %r956;
	mov.b32 	%f3576, %r957;
	setp.leu.ftz.f32 	%p67, %f1029, 0f00000000;
	@%p67 bra 	$L__BB0_138;

	mov.f32 	%f2792, 0f3F800000;
	sub.ftz.f32 	%f2793, %f2792, %f1029;
	mul.lo.s64 	%rd765, %rd43, 48;
	add.s64 	%rd766, %rd720, %rd765;
	add.s64 	%rd757, %rd766, 80;
	// begin inline asm
	cvta.to.global.u64 %rd756, %rd757;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r962,%r963,%r964,%r965}, [%rd756];
	// end inline asm
	mov.b32 	%f2794, %r962;
	mov.b32 	%f2795, %r963;
	mov.b32 	%f2796, %r964;
	mul.ftz.f32 	%f2797, %f1029, %f2794;
	mul.ftz.f32 	%f2798, %f1029, %f2795;
	mul.ftz.f32 	%f2799, %f1029, %f2796;
	fma.rn.ftz.f32 	%f3580, %f2793, %f3580, %f2797;
	fma.rn.ftz.f32 	%f3581, %f2793, %f3581, %f2798;
	fma.rn.ftz.f32 	%f3582, %f2793, %f3582, %f2799;
	add.s64 	%rd760, %rd766, 96;
	// begin inline asm
	cvta.to.global.u64 %rd759, %rd760;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r966,%r967,%r968,%r969}, [%rd759];
	// end inline asm
	mov.b32 	%f2800, %r966;
	mov.b32 	%f2801, %r967;
	mov.b32 	%f2802, %r968;
	mul.ftz.f32 	%f2803, %f1029, %f2800;
	mul.ftz.f32 	%f2804, %f1029, %f2801;
	mul.ftz.f32 	%f2805, %f1029, %f2802;
	fma.rn.ftz.f32 	%f3577, %f2793, %f3577, %f2803;
	fma.rn.ftz.f32 	%f3578, %f2793, %f3578, %f2804;
	fma.rn.ftz.f32 	%f3579, %f2793, %f3579, %f2805;
	add.s64 	%rd763, %rd766, 112;
	// begin inline asm
	cvta.to.global.u64 %rd762, %rd763;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r970,%r971,%r972,%r973}, [%rd762];
	// end inline asm
	mov.b32 	%f2806, %r970;
	mov.b32 	%f2807, %r971;
	mov.b32 	%f2808, %r972;
	mul.ftz.f32 	%f2809, %f1029, %f2806;
	mul.ftz.f32 	%f2810, %f1029, %f2807;
	mul.ftz.f32 	%f2811, %f1029, %f2808;
	fma.rn.ftz.f32 	%f3574, %f2793, %f3574, %f2809;
	fma.rn.ftz.f32 	%f3575, %f2793, %f3575, %f2810;
	fma.rn.ftz.f32 	%f3576, %f2793, %f3576, %f2811;
	bra.uni 	$L__BB0_138;

$L__BB0_127:
	mov.f32 	%f3583, 0f00000000;
	mov.f32 	%f3585, 0f3F800000;
	setp.eq.s32 	%p63, %r826, 4;
	@%p63 bra 	$L__BB0_130;

	setp.ne.s32 	%p64, %r826, 1;
	mov.f32 	%f3584, %f3583;
	mov.f32 	%f3586, %f3583;
	mov.f32 	%f3587, %f3585;
	mov.f32 	%f3588, %f3583;
	mov.f32 	%f3589, %f3585;
	mov.f32 	%f3590, %f3583;
	mov.f32 	%f3591, %f3583;
	@%p64 bra 	$L__BB0_139;

	// begin inline asm
	call (%rd650), _optix_get_static_transform_from_handle, (%rd648);
	// end inline asm
	add.s64 	%rd791, %rd650, 64;
	bra.uni 	$L__BB0_131;

$L__BB0_133:
	// begin inline asm
	call (%rd663), _optix_get_srt_motion_transform_from_handle, (%rd648);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd665, %rd663;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r840,%r841,%r842,%r843}, [%rd665];
	// end inline asm
	add.s64 	%rd669, %rd663, 16;
	// begin inline asm
	cvta.to.global.u64 %rd668, %rd669;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r844,%r845,%r846,%r847}, [%rd668];
	// end inline asm
	add.s64 	%rd672, %rd663, 32;
	// begin inline asm
	cvta.to.global.u64 %rd671, %rd672;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r848,%r849,%r850,%r851}, [%rd671];
	// end inline asm
	add.s64 	%rd675, %rd663, 48;
	// begin inline asm
	cvta.to.global.u64 %rd674, %rd675;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r852,%r853,%r854,%r855}, [%rd674];
	// end inline asm
	add.s64 	%rd678, %rd663, 64;
	// begin inline asm
	cvta.to.global.u64 %rd677, %rd678;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r856,%r857,%r858,%r859}, [%rd677];
	// end inline asm
	add.s64 	%rd681, %rd663, 80;
	// begin inline asm
	cvta.to.global.u64 %rd680, %rd681;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r860,%r861,%r862,%r863}, [%rd680];
	// end inline asm
	add.s64 	%rd684, %rd663, 96;
	// begin inline asm
	cvta.to.global.u64 %rd683, %rd684;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r864,%r865,%r866,%r867}, [%rd683];
	// end inline asm
	add.s64 	%rd687, %rd663, 112;
	// begin inline asm
	cvta.to.global.u64 %rd686, %rd687;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r868,%r869,%r870,%r871}, [%rd686];
	// end inline asm
	add.s64 	%rd690, %rd663, 128;
	// begin inline asm
	cvta.to.global.u64 %rd689, %rd690;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r872,%r873,%r874,%r875}, [%rd689];
	// end inline asm
	add.s64 	%rd693, %rd663, 144;
	// begin inline asm
	cvta.to.global.u64 %rd692, %rd693;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r876,%r877,%r878,%r879}, [%rd692];
	// end inline asm
	mov.b32 	%f2690, %r843;
	mov.b32 	%f2691, %r844;
	and.b32  	%r896, %r842, 65535;
	add.s32 	%r897, %r896, -1;
	cvt.rn.f32.s32 	%f2692, %r897;
	sub.ftz.f32 	%f2693, %f2678, %f2690;
	mul.ftz.f32 	%f2694, %f2693, %f2692;
	sub.ftz.f32 	%f2695, %f2691, %f2690;
	div.approx.ftz.f32 	%f2696, %f2694, %f2695;
	min.ftz.f32 	%f2697, %f2692, %f2696;
	mov.f32 	%f2698, 0f00000000;
	max.ftz.f32 	%f2699, %f2698, %f2697;
	cvt.rmi.ftz.f32.f32 	%f2700, %f2699;
	sub.ftz.f32 	%f989, %f2699, %f2700;
	cvt.rzi.ftz.s32.f32 	%r898, %f2700;
	mul.wide.s32 	%rd707, %r898, 64;
	add.s64 	%rd696, %rd672, %rd707;
	// begin inline asm
	cvta.to.global.u64 %rd695, %rd696;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r880,%r881,%r882,%r883}, [%rd695];
	// end inline asm
	mov.b32 	%f3564, %r880;
	mov.b32 	%f3565, %r881;
	mov.b32 	%f3566, %r882;
	add.s64 	%rd699, %rd696, 16;
	// begin inline asm
	cvta.to.global.u64 %rd698, %rd699;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r884,%r885,%r886,%r887}, [%rd698];
	// end inline asm
	mov.b32 	%f3567, %r884;
	mov.b32 	%f3568, %r885;
	mov.b32 	%f3569, %r887;
	add.s64 	%rd702, %rd696, 32;
	// begin inline asm
	cvta.to.global.u64 %rd701, %rd702;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r888,%r889,%r890,%r891}, [%rd701];
	// end inline asm
	mov.b32 	%f3570, %r889;
	mov.b32 	%f3571, %r890;
	mov.b32 	%f3572, %r891;
	add.s64 	%rd705, %rd696, 48;
	// begin inline asm
	cvta.to.global.u64 %rd704, %rd705;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r892,%r893,%r894,%r895}, [%rd704];
	// end inline asm
	mov.b32 	%f3573, %r892;
	setp.leu.ftz.f32 	%p66, %f989, 0f00000000;
	@%p66 bra 	$L__BB0_135;

	mov.f32 	%f2701, 0f3F800000;
	sub.ftz.f32 	%f2702, %f2701, %f989;
	add.s64 	%rd709, %rd696, 64;
	// begin inline asm
	cvta.to.global.u64 %rd708, %rd709;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r899,%r900,%r901,%r902}, [%rd708];
	// end inline asm
	mov.b32 	%f2703, %r899;
	mov.b32 	%f2704, %r900;
	mov.b32 	%f2705, %r901;
	mul.ftz.f32 	%f2706, %f989, %f2703;
	mul.ftz.f32 	%f2707, %f989, %f2704;
	mul.ftz.f32 	%f2708, %f989, %f2705;
	fma.rn.ftz.f32 	%f3564, %f2702, %f3564, %f2706;
	fma.rn.ftz.f32 	%f3565, %f2702, %f3565, %f2707;
	fma.rn.ftz.f32 	%f3566, %f2702, %f3566, %f2708;
	add.s64 	%rd712, %rd696, 80;
	// begin inline asm
	cvta.to.global.u64 %rd711, %rd712;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r903,%r904,%r905,%r906}, [%rd711];
	// end inline asm
	mov.b32 	%f2709, %r903;
	mov.b32 	%f2710, %r904;
	mov.b32 	%f2711, %r906;
	mul.ftz.f32 	%f2712, %f989, %f2709;
	mul.ftz.f32 	%f2713, %f989, %f2710;
	mul.ftz.f32 	%f2714, %f989, %f2711;
	fma.rn.ftz.f32 	%f3567, %f2702, %f3567, %f2712;
	fma.rn.ftz.f32 	%f3568, %f2702, %f3568, %f2713;
	fma.rn.ftz.f32 	%f3569, %f2702, %f3569, %f2714;
	add.s64 	%rd715, %rd696, 96;
	// begin inline asm
	cvta.to.global.u64 %rd714, %rd715;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r907,%r908,%r909,%r910}, [%rd714];
	// end inline asm
	mov.b32 	%f2715, %r908;
	mov.b32 	%f2716, %r909;
	mov.b32 	%f2717, %r910;
	mul.ftz.f32 	%f2718, %f989, %f2715;
	mul.ftz.f32 	%f2719, %f989, %f2716;
	mul.ftz.f32 	%f2720, %f989, %f2717;
	fma.rn.ftz.f32 	%f2721, %f2702, %f3570, %f2718;
	fma.rn.ftz.f32 	%f2722, %f2702, %f3571, %f2719;
	fma.rn.ftz.f32 	%f2723, %f2702, %f3572, %f2720;
	add.s64 	%rd718, %rd696, 112;
	// begin inline asm
	cvta.to.global.u64 %rd717, %rd718;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r911,%r912,%r913,%r914}, [%rd717];
	// end inline asm
	mov.b32 	%f2724, %r911;
	mul.ftz.f32 	%f2725, %f989, %f2724;
	fma.rn.ftz.f32 	%f2726, %f2702, %f3573, %f2725;
	mul.ftz.f32 	%f2727, %f2722, %f2722;
	fma.rn.ftz.f32 	%f2728, %f2721, %f2721, %f2727;
	fma.rn.ftz.f32 	%f2729, %f2723, %f2723, %f2728;
	fma.rn.ftz.f32 	%f2730, %f2726, %f2726, %f2729;
	rsqrt.approx.ftz.f32 	%f2731, %f2730;
	mul.ftz.f32 	%f3570, %f2721, %f2731;
	mul.ftz.f32 	%f3571, %f2722, %f2731;
	mul.ftz.f32 	%f3572, %f2723, %f2731;
	mul.ftz.f32 	%f3573, %f2731, %f2726;

$L__BB0_135:
	mul.ftz.f32 	%f2732, %f3571, %f3571;
	fma.rn.ftz.f32 	%f2733, %f3570, %f3570, %f2732;
	fma.rn.ftz.f32 	%f2734, %f3572, %f3572, %f2733;
	fma.rn.ftz.f32 	%f2735, %f3573, %f3573, %f2734;
	rcp.approx.ftz.f32 	%f2736, %f2735;
	mul.ftz.f32 	%f2737, %f3570, %f2736;
	mul.ftz.f32 	%f2738, %f3571, %f2736;
	mul.ftz.f32 	%f2739, %f3572, %f2736;
	mul.ftz.f32 	%f2740, %f3573, %f2736;
	mul.ftz.f32 	%f2741, %f3570, %f2737;
	mul.ftz.f32 	%f2742, %f3571, %f2738;
	mul.ftz.f32 	%f2743, %f3572, %f2739;
	mul.ftz.f32 	%f2744, %f3570, %f2738;
	mul.ftz.f32 	%f2745, %f3572, %f2740;
	mul.ftz.f32 	%f2746, %f3570, %f2739;
	mul.ftz.f32 	%f2747, %f3571, %f2740;
	mul.ftz.f32 	%f2748, %f3571, %f2739;
	mul.ftz.f32 	%f2749, %f3570, %f2740;
	sub.ftz.f32 	%f2750, %f2741, %f2742;
	sub.ftz.f32 	%f2751, %f2750, %f2743;
	fma.rn.ftz.f32 	%f2752, %f3573, %f2740, %f2751;
	sub.ftz.f32 	%f2753, %f2744, %f2745;
	add.ftz.f32 	%f2754, %f2753, %f2753;
	add.ftz.f32 	%f2755, %f2746, %f2747;
	add.ftz.f32 	%f2756, %f2755, %f2755;
	add.ftz.f32 	%f2757, %f2744, %f2745;
	add.ftz.f32 	%f2758, %f2757, %f2757;
	sub.ftz.f32 	%f2759, %f2742, %f2741;
	sub.ftz.f32 	%f2760, %f2759, %f2743;
	fma.rn.ftz.f32 	%f2761, %f3573, %f2740, %f2760;
	sub.ftz.f32 	%f2762, %f2748, %f2749;
	add.ftz.f32 	%f2763, %f2762, %f2762;
	sub.ftz.f32 	%f2764, %f2746, %f2747;
	add.ftz.f32 	%f2765, %f2764, %f2764;
	add.ftz.f32 	%f2766, %f2748, %f2749;
	add.ftz.f32 	%f2767, %f2766, %f2766;
	neg.ftz.f32 	%f2768, %f2741;
	sub.ftz.f32 	%f2769, %f2768, %f2742;
	add.ftz.f32 	%f2770, %f2743, %f2769;
	fma.rn.ftz.f32 	%f2771, %f3573, %f2740, %f2770;
	mul.ftz.f32 	%f2772, %f3566, %f2752;
	fma.rn.ftz.f32 	%f2773, %f3568, %f2754, %f2772;
	fma.rn.ftz.f32 	%f3582, %f3569, %f2756, %f2773;
	mul.ftz.f32 	%f2774, %f3568, %f2761;
	fma.rn.ftz.f32 	%f2775, %f3566, %f2758, %f2774;
	fma.rn.ftz.f32 	%f3579, %f3569, %f2763, %f2775;
	mul.ftz.f32 	%f2776, %f3568, %f2767;
	fma.rn.ftz.f32 	%f2777, %f3566, %f2765, %f2776;
	fma.rn.ftz.f32 	%f3576, %f3569, %f2771, %f2777;
	mul.ftz.f32 	%f2778, %f3565, %f2752;
	fma.rn.ftz.f32 	%f3581, %f3567, %f2754, %f2778;
	mul.ftz.f32 	%f2779, %f3567, %f2761;
	fma.rn.ftz.f32 	%f3578, %f3565, %f2758, %f2779;
	mul.ftz.f32 	%f2780, %f3567, %f2767;
	fma.rn.ftz.f32 	%f3575, %f3565, %f2765, %f2780;
	mul.ftz.f32 	%f3580, %f3564, %f2752;
	mul.ftz.f32 	%f3577, %f3564, %f2758;
	mul.ftz.f32 	%f3574, %f3564, %f2765;

$L__BB0_138:
	mul.ftz.f32 	%f2812, %f3575, %f3579;
	mul.ftz.f32 	%f2813, %f3576, %f3578;
	sub.ftz.f32 	%f2814, %f2813, %f2812;
	mul.ftz.f32 	%f2815, %f3580, %f2814;
	mul.ftz.f32 	%f2816, %f3574, %f3579;
	mul.ftz.f32 	%f2817, %f3576, %f3577;
	sub.ftz.f32 	%f2818, %f2817, %f2816;
	mul.ftz.f32 	%f2819, %f2818, %f3581;
	sub.ftz.f32 	%f2820, %f2815, %f2819;
	mul.ftz.f32 	%f2821, %f3574, %f3578;
	mul.ftz.f32 	%f2822, %f3575, %f3577;
	sub.ftz.f32 	%f2823, %f2822, %f2821;
	fma.rn.ftz.f32 	%f2824, %f2823, %f3582, %f2820;
	rcp.approx.ftz.f32 	%f2825, %f2824;
	mul.ftz.f32 	%f3589, %f2814, %f2825;
	mul.ftz.f32 	%f2826, %f3576, %f3581;
	mul.ftz.f32 	%f2827, %f3575, %f3582;
	sub.ftz.f32 	%f2828, %f2827, %f2826;
	mul.ftz.f32 	%f3590, %f2828, %f2825;
	mul.ftz.f32 	%f2829, %f3578, %f3582;
	mul.ftz.f32 	%f2830, %f3579, %f3581;
	sub.ftz.f32 	%f2831, %f2830, %f2829;
	mul.ftz.f32 	%f3591, %f2831, %f2825;
	sub.ftz.f32 	%f2832, %f2816, %f2817;
	mul.ftz.f32 	%f3586, %f2832, %f2825;
	mul.ftz.f32 	%f2833, %f3574, %f3582;
	mul.ftz.f32 	%f2834, %f3576, %f3580;
	sub.ftz.f32 	%f2835, %f2834, %f2833;
	mul.ftz.f32 	%f3587, %f2835, %f2825;
	mul.ftz.f32 	%f2836, %f3579, %f3580;
	mul.ftz.f32 	%f2837, %f3577, %f3582;
	sub.ftz.f32 	%f2838, %f2837, %f2836;
	mul.ftz.f32 	%f3588, %f2838, %f2825;
	mul.ftz.f32 	%f3583, %f2823, %f2825;
	mul.ftz.f32 	%f2839, %f3575, %f3580;
	mul.ftz.f32 	%f2840, %f3574, %f3581;
	sub.ftz.f32 	%f2841, %f2840, %f2839;
	mul.ftz.f32 	%f3584, %f2841, %f2825;
	mul.ftz.f32 	%f2842, %f3577, %f3581;
	mul.ftz.f32 	%f2843, %f3578, %f3580;
	sub.ftz.f32 	%f2844, %f2843, %f2842;
	mul.ftz.f32 	%f3585, %f2844, %f2825;
	bra.uni 	$L__BB0_139;

$L__BB0_130:
	// begin inline asm
	call (%rd791), _optix_get_instance_inverse_transform_from_handle, (%rd648);
	// end inline asm

$L__BB0_131:
	// begin inline asm
	cvta.to.global.u64 %rd654, %rd791;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r828,%r829,%r830,%r831}, [%rd654];
	// end inline asm
	mov.b32 	%f3589, %r828;
	mov.b32 	%f3590, %r829;
	mov.b32 	%f3591, %r830;
	add.s64 	%rd658, %rd791, 16;
	// begin inline asm
	cvta.to.global.u64 %rd657, %rd658;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r832,%r833,%r834,%r835}, [%rd657];
	// end inline asm
	mov.b32 	%f3586, %r832;
	mov.b32 	%f3587, %r833;
	mov.b32 	%f3588, %r834;
	add.s64 	%rd661, %rd791, 32;
	// begin inline asm
	cvta.to.global.u64 %rd660, %rd661;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r836,%r837,%r838,%r839}, [%rd660];
	// end inline asm
	mov.b32 	%f3583, %r836;
	mov.b32 	%f3584, %r837;
	mov.b32 	%f3585, %r838;

$L__BB0_139:
	setp.eq.s32 	%p68, %r1054, 0;
	@%p68 bra 	$L__BB0_141;

	mul.ftz.f32 	%f2845, %f3560, %f3590;
	fma.rn.ftz.f32 	%f2846, %f3557, %f3589, %f2845;
	fma.rn.ftz.f32 	%f1075, %f3563, %f3591, %f2846;
	mul.ftz.f32 	%f2847, %f3559, %f3590;
	fma.rn.ftz.f32 	%f2848, %f3556, %f3589, %f2847;
	fma.rn.ftz.f32 	%f1076, %f3562, %f3591, %f2848;
	mul.ftz.f32 	%f2849, %f3558, %f3590;
	fma.rn.ftz.f32 	%f2850, %f3555, %f3589, %f2849;
	fma.rn.ftz.f32 	%f3591, %f3561, %f3591, %f2850;
	mul.ftz.f32 	%f2851, %f3560, %f3587;
	fma.rn.ftz.f32 	%f2852, %f3557, %f3586, %f2851;
	fma.rn.ftz.f32 	%f1078, %f3563, %f3588, %f2852;
	mul.ftz.f32 	%f2853, %f3559, %f3587;
	fma.rn.ftz.f32 	%f2854, %f3556, %f3586, %f2853;
	fma.rn.ftz.f32 	%f1079, %f3562, %f3588, %f2854;
	mul.ftz.f32 	%f2855, %f3558, %f3587;
	fma.rn.ftz.f32 	%f2856, %f3555, %f3586, %f2855;
	fma.rn.ftz.f32 	%f3588, %f3561, %f3588, %f2856;
	mul.ftz.f32 	%f2857, %f3560, %f3584;
	fma.rn.ftz.f32 	%f2858, %f3557, %f3583, %f2857;
	fma.rn.ftz.f32 	%f1081, %f3563, %f3585, %f2858;
	mul.ftz.f32 	%f2859, %f3559, %f3584;
	fma.rn.ftz.f32 	%f2860, %f3556, %f3583, %f2859;
	fma.rn.ftz.f32 	%f1082, %f3562, %f3585, %f2860;
	mul.ftz.f32 	%f2861, %f3558, %f3584;
	fma.rn.ftz.f32 	%f2862, %f3555, %f3583, %f2861;
	fma.rn.ftz.f32 	%f3585, %f3561, %f3585, %f2862;
	mov.f32 	%f3583, %f1081;
	mov.f32 	%f3584, %f1082;
	mov.f32 	%f3586, %f1078;
	mov.f32 	%f3587, %f1079;
	mov.f32 	%f3589, %f1075;
	mov.f32 	%f3590, %f1076;

$L__BB0_141:
	add.s32 	%r1054, %r1054, 1;
	setp.lt.u32 	%p69, %r1054, %r823;
	mov.f32 	%f3555, %f3591;
	mov.f32 	%f3556, %f3590;
	mov.f32 	%f3557, %f3589;
	mov.f32 	%f3558, %f3588;
	mov.f32 	%f3559, %f3587;
	mov.f32 	%f3560, %f3586;
	mov.f32 	%f3561, %f3585;
	mov.f32 	%f3562, %f3584;
	mov.f32 	%f3563, %f3583;
	@%p69 bra 	$L__BB0_126;

$L__BB0_142:
	mul.ftz.f32 	%f2863, %f3615, %f3589;
	fma.rn.ftz.f32 	%f2864, %f3614, %f3586, %f2863;
	mul.ftz.f32 	%f2865, %f3615, %f3590;
	fma.rn.ftz.f32 	%f2866, %f3614, %f3587, %f2865;
	mul.ftz.f32 	%f2867, %f3615, %f3591;
	fma.rn.ftz.f32 	%f2868, %f3614, %f3588, %f2867;
	fma.rn.ftz.f32 	%f3613, %f969, %f3585, %f2868;
	fma.rn.ftz.f32 	%f3614, %f969, %f3584, %f2866;
	fma.rn.ftz.f32 	%f3615, %f969, %f3583, %f2864;
	bra.uni 	$L__BB0_144;

$L__BB0_143:
	mov.f32 	%f3613, %f969;

$L__BB0_144:
	ld.u32 	%r974, [%rd46+100];
	setp.eq.s32 	%p70, %r974, 14;
	@%p70 bra 	$L__BB0_146;
	bra.uni 	$L__BB0_145;

$L__BB0_146:
	ld.u64 	%rd767, [%rd46+24];
	mul.wide.u32 	%rd768, %r43, 8;
	add.s64 	%rd769, %rd767, %rd768;
	ld.v2.u32 	{%r30, %r29}, [%rd769];
	bra.uni 	$L__BB0_147;

$L__BB0_145:
	add.s32 	%r29, %r43, 1;
	mov.u32 	%r30, %r43;

$L__BB0_147:
	// begin inline asm
	call (%r977), _optix_get_attribute_0, ();
	// end inline asm
	mov.b32 	%f1117, %r977;
	ld.u32 	%r980, [%rd46+96];
	and.b32  	%r981, %r980, 1073741823;
	setp.gt.ftz.f32 	%p71, %f1117, 0f3F000000;
	or.b32  	%r982, %r981, 1073741824;
	selp.b32 	%r979, %r982, %r981, %p71;
	mov.u32 	%r978, 2;
	// begin inline asm
	call _optix_set_payload, (%r978, %r979);
	// end inline asm
	ld.f32 	%f1118, [%rd46+156];
	ld.v4.f32 	{%f2869, %f2870, %f2871, %f2872}, [%rd46+112];
	ld.f32 	%f3618, [%rd46+80];
	setp.lt.ftz.f32 	%p72, %f3618, 0f00000000;
	@%p72 bra 	$L__BB0_149;
	bra.uni 	$L__BB0_148;

$L__BB0_149:
	ld.u64 	%rd44, [%rd46+8];
	ld.u8 	%rs1, [%rd46+188];
	and.b16  	%rs2, %rs1, 64;
	setp.eq.s16 	%p73, %rs2, 0;
	@%p73 bra 	$L__BB0_151;
	bra.uni 	$L__BB0_150;

$L__BB0_151:
	mul.wide.s32 	%rd772, %r29, 12;
	add.s64 	%rd773, %rd44, %rd772;
	mul.wide.s32 	%rd774, %r30, 12;
	add.s64 	%rd775, %rd44, %rd774;
	ld.f32 	%f2873, [%rd775];
	ld.f32 	%f2874, [%rd773];
	sub.ftz.f32 	%f2875, %f2874, %f2873;
	ld.f32 	%f2876, [%rd775+4];
	ld.f32 	%f2877, [%rd773+4];
	sub.ftz.f32 	%f2878, %f2877, %f2876;
	ld.f32 	%f2879, [%rd775+8];
	ld.f32 	%f2880, [%rd773+8];
	sub.ftz.f32 	%f2881, %f2880, %f2879;
	fma.rn.ftz.f32 	%f3618, %f2875, %f1117, %f2873;
	fma.rn.ftz.f32 	%f3617, %f2878, %f1117, %f2876;
	fma.rn.ftz.f32 	%f3616, %f2881, %f1117, %f2879;
	bra.uni 	$L__BB0_152;

$L__BB0_148:
	ld.f32 	%f3617, [%rd46+84];
	ld.f32 	%f3616, [%rd46+88];
	bra.uni 	$L__BB0_152;

$L__BB0_150:
	mul.wide.u32 	%rd770, %r43, 12;
	add.s64 	%rd771, %rd44, %rd770;
	ld.f32 	%f3618, [%rd771];
	ld.f32 	%f3617, [%rd771+4];
	ld.f32 	%f3616, [%rd771+8];

$L__BB0_152:
	mov.u32 	%r984, 0;
	mul.ftz.f32 	%f1135, %f2869, %f3618;
	mov.u32 	%r986, 1;
	mul.ftz.f32 	%f1136, %f2870, %f3617;
	mul.ftz.f32 	%f3654, %f2871, %f3616;
	// begin inline asm
	call (%r983), _optix_get_payload, (%r984);
	// end inline asm
	// begin inline asm
	call (%r985), _optix_get_payload, (%r986);
	// end inline asm
	cvt.u64.u32 	%rd776, %r983;
	cvt.u64.u32 	%rd777, %r985;
	bfi.b64 	%rd45, %rd776, %rd777, 32, 32;
	// begin inline asm
	call (%f2882), _optix_get_ray_tmax, ();
	// end inline asm
	mul.ftz.f32 	%f2886, %f3615, %f3615;
	fma.rn.ftz.f32 	%f2887, %f3614, %f3614, %f2886;
	fma.rn.ftz.f32 	%f2888, %f3613, %f3613, %f2887;
	rsqrt.approx.ftz.f32 	%f2889, %f2888;
	mov.f32 	%f3620, 0f3F800000;
	mul.ftz.f32 	%f2890, %f3615, %f2889;
	mul.ftz.f32 	%f2891, %f3614, %f2889;
	mul.ftz.f32 	%f2892, %f3613, %f2889;
	ld.u32 	%r987, [%rd45+12];
	and.b32  	%r988, %r987, -3;
	st.f32 	[%rd45+108], %f2882;
	ld.u32 	%r989, [%rd46+188];
	or.b32  	%r990, %r988, %r989;
	ld.f32 	%f2893, [%rd45+112];
	ld.f32 	%f2894, [%rd45+116];
	mul.ftz.f32 	%f2895, %f2891, %f2894;
	fma.rn.ftz.f32 	%f2896, %f2890, %f2893, %f2895;
	ld.f32 	%f2897, [%rd45+120];
	fma.rn.ftz.f32 	%f2898, %f2892, %f2897, %f2896;
	setp.ge.ftz.f32 	%p74, %f2898, 0f00000000;
	selp.b32 	%r991, 16, 0, %p74;
	or.b32  	%r992, %r991, %r990;
	st.u32 	[%rd45+12], %r992;
	and.b32  	%r993, %r992, 16;
	setp.eq.s32 	%p75, %r993, 0;
	neg.ftz.f32 	%f2899, %f2890;
	neg.ftz.f32 	%f2900, %f2891;
	neg.ftz.f32 	%f2901, %f2892;
	selp.f32 	%f1138, %f2901, %f2892, %p75;
	selp.f32 	%f1139, %f2900, %f2891, %p75;
	selp.f32 	%f1140, %f2899, %f2890, %p75;
	mov.f32 	%f3632, 0f00000000;
	st.v2.f32 	[%rd45], {%f3632, %f3632};
	st.u32 	[%rd45+8], %r984;
	ld.v4.f32 	{%f2903, %f1154, %f2905, %f2906}, [%rd46+144];
	setp.eq.ftz.f32 	%p76, %f2903, %f1154;
	setp.eq.ftz.f32 	%p77, %f2903, %f2905;
	and.pred  	%p78, %p76, %p77;
	mov.f32 	%f3621, %f3620;
	mov.f32 	%f3622, %f3620;
	@%p78 bra 	$L__BB0_160;

	ld.f32 	%f1144, [%rd45+140];
	setp.lt.ftz.f32 	%p79, %f1144, 0f00000000;
	@%p79 bra 	$L__BB0_157;
	bra.uni 	$L__BB0_154;

$L__BB0_157:
	ld.u32 	%r994, [%rd45+28];
	mad.lo.s32 	%r995, %r994, 1664525, 1013904223;
	st.u32 	[%rd45+28], %r995;
	and.b32  	%r996, %r995, 16777215;
	cvt.rn.f32.u32 	%f2916, %r996;
	mov.f32 	%f2917, 0f4B800000;
	div.approx.ftz.f32 	%f2918, %f2916, %f2917;
	add.ftz.f32 	%f1147, %f2918, %f2918;
	st.f32 	[%rd45+140], %f1147;
	setp.gt.ftz.f32 	%p81, %f1147, 0f3F800000;
	@%p81 bra 	$L__BB0_159;
	bra.uni 	$L__BB0_158;

$L__BB0_159:
	add.ftz.f32 	%f2924, %f1147, 0fBF800000;
	add.ftz.f32 	%f2925, %f2924, %f2924;
	mov.f32 	%f2926, 0f40000000;
	sub.ftz.f32 	%f2927, %f2905, %f1154;
	fma.rn.ftz.f32 	%f1154, %f2927, %f2924, %f1154;
	sub.ftz.f32 	%f3621, %f2926, %f2925;
	add.ftz.f32 	%f3620, %f2925, %f2925;
	mov.f32 	%f3622, 0f00000000;
	bra.uni 	$L__BB0_160;

$L__BB0_154:
	setp.gt.ftz.f32 	%p80, %f1144, 0f3F800000;
	@%p80 bra 	$L__BB0_156;
	bra.uni 	$L__BB0_155;

$L__BB0_156:
	add.ftz.f32 	%f2914, %f1144, 0fBF800000;
	sub.ftz.f32 	%f2915, %f2905, %f1154;
	fma.rn.ftz.f32 	%f1154, %f2915, %f2914, %f1154;
	mov.f32 	%f3621, %f3620;
	mov.f32 	%f3622, %f3620;
	bra.uni 	$L__BB0_160;

$L__BB0_158:
	add.ftz.f32 	%f3621, %f1147, %f1147;
	mov.f32 	%f2920, 0f40000000;
	sub.ftz.f32 	%f2921, %f1154, %f2903;
	fma.rn.ftz.f32 	%f1154, %f2921, %f1147, %f2903;
	sub.ftz.f32 	%f2922, %f2920, %f3621;
	add.ftz.f32 	%f3622, %f2922, %f2922;
	mov.f32 	%f3620, 0f00000000;
	bra.uni 	$L__BB0_160;

$L__BB0_155:
	sub.ftz.f32 	%f2910, %f1154, %f2903;
	fma.rn.ftz.f32 	%f1154, %f2910, %f1144, %f2903;
	mov.f32 	%f3621, %f3620;
	mov.f32 	%f3622, %f3620;

$L__BB0_160:
	ld.v4.f32 	{%f2928, %f2929, %f2930, %f2931}, [%rd46+128];
	ld.u32 	%r31, [%rd45+12];
	and.b32  	%r997, %r31, 16777216;
	setp.eq.s32 	%p82, %r997, 0;
	@%p82 bra 	$L__BB0_162;

	ld.f32 	%f2932, [%rd45+16];
	mul.ftz.f32 	%f2933, %f2928, %f2932;
	st.f32 	[%rd45+16], %f2933;
	ld.f32 	%f2934, [%rd45+20];
	mul.ftz.f32 	%f2935, %f2929, %f2934;
	st.f32 	[%rd45+20], %f2935;
	ld.f32 	%f2936, [%rd45+24];
	mul.ftz.f32 	%f2937, %f2930, %f2936;
	st.f32 	[%rd45+24], %f2937;

$L__BB0_162:
	ld.u32 	%r32, [%rd45+44];
	setp.ne.s32 	%p83, %r32, 0;
	@%p83 bra 	$L__BB0_164;

	ld.const.v2.f32 	{%f2938, %f2939}, [params+144];
	mul.ftz.f32 	%f2942, %f1139, %f2939;
	fma.rn.ftz.f32 	%f2943, %f1140, %f2938, %f2942;
	ld.const.f32 	%f2944, [params+152];
	ld.const.v2.f32 	{%f2945, %f2946}, [params+160];
	mul.ftz.f32 	%f2949, %f1139, %f2946;
	fma.rn.ftz.f32 	%f2950, %f1140, %f2945, %f2949;
	ld.const.f32 	%f2951, [params+168];
	ld.const.v2.f32 	{%f2952, %f2953}, [params+176];
	mul.ftz.f32 	%f2956, %f1139, %f2953;
	fma.rn.ftz.f32 	%f2957, %f1140, %f2952, %f2956;
	ld.const.f32 	%f2958, [params+184];
	fma.rn.ftz.f32 	%f2959, %f1138, %f2958, %f2957;
	fma.rn.ftz.f32 	%f2960, %f1138, %f2951, %f2950;
	fma.rn.ftz.f32 	%f2961, %f1138, %f2944, %f2943;
	st.v2.f32 	[%rd45+32], {%f2961, %f2960};
	st.f32 	[%rd45+40], %f2959;

$L__BB0_164:
	setp.leu.ftz.f32 	%p84, %f1118, 0f00000000;
	mov.f32 	%f1166, %f1138;
	mov.f32 	%f1167, %f1139;
	mov.f32 	%f1168, %f1140;
	@%p84 bra 	$L__BB0_166;

	ld.u32 	%r998, [%rd45+28];
	mad.lo.s32 	%r999, %r998, 1664525, 1013904223;
	and.b32  	%r1000, %r999, 16777215;
	cvt.rn.f32.u32 	%f2962, %r1000;
	mov.f32 	%f2963, 0f4B800000;
	div.approx.ftz.f32 	%f2964, %f2962, %f2963;
	mad.lo.s32 	%r1001, %r999, 1664525, 1013904223;
	and.b32  	%r1002, %r1001, 16777215;
	cvt.rn.f32.u32 	%f2965, %r1002;
	div.approx.ftz.f32 	%f2966, %f2965, %f2963;
	mad.lo.s32 	%r1003, %r1001, 1664525, 1013904223;
	st.u32 	[%rd45+28], %r1003;
	and.b32  	%r1004, %r1003, 16777215;
	cvt.rn.f32.u32 	%f2967, %r1004;
	div.approx.ftz.f32 	%f2968, %f2967, %f2963;
	lg2.approx.ftz.f32 	%f2969, %f2964;
	mul.ftz.f32 	%f2970, %f2969, 0f3F317218;
	mul.ftz.f32 	%f2971, %f2970, 0fC0000000;
	sqrt.approx.ftz.f32 	%f2972, %f2971;
	mul.ftz.f32 	%f2973, %f2966, 0f40490FDB;
	mul.ftz.f32 	%f2974, %f1118, %f2972;
	sin.approx.ftz.f32 	%f2975, %f2973;
	mul.ftz.f32 	%f2976, %f2974, %f2975;
	sqrt.approx.ftz.f32 	%f2977, %f2976;
	mul.ftz.f32 	%f2978, %f2968, 0f40C90FDB;
	cos.approx.ftz.f32 	%f2979, %f2978;
	sin.approx.ftz.f32 	%f2980, %f2978;
	mov.b32 	%r1005, %f1138;
	and.b32  	%r1006, %r1005, -2147483648;
	or.b32  	%r1007, %r1006, 1065353216;
	mov.b32 	%f2981, %r1007;
	mul.ftz.f32 	%f2982, %f2981, 0f00000000;
	add.ftz.f32 	%f2983, %f1138, %f2981;
	mul.ftz.f32 	%f2984, %f1139, %f2980;
	fma.rn.ftz.f32 	%f2985, %f1140, %f2979, %f2984;
	fma.rn.ftz.f32 	%f2986, %f2982, %f2983, %f2985;
	abs.ftz.f32 	%f2987, %f1138;
	add.ftz.f32 	%f2988, %f2987, 0f3F800000;
	div.approx.ftz.f32 	%f2989, %f2986, %f2988;
	mul.ftz.f32 	%f2990, %f1140, %f2989;
	mul.ftz.f32 	%f2991, %f1139, %f2989;
	mul.ftz.f32 	%f2992, %f2983, %f2989;
	sub.ftz.f32 	%f2993, %f2990, %f2979;
	sub.ftz.f32 	%f2994, %f2991, %f2980;
	sub.ftz.f32 	%f2995, %f2992, %f2982;
	fma.rn.ftz.f32 	%f2996, %f2977, %f2993, %f1140;
	fma.rn.ftz.f32 	%f2997, %f2977, %f2994, %f1139;
	fma.rn.ftz.f32 	%f2998, %f2977, %f2995, %f1138;
	mul.ftz.f32 	%f2999, %f2997, %f2997;
	fma.rn.ftz.f32 	%f3000, %f2996, %f2996, %f2999;
	fma.rn.ftz.f32 	%f3001, %f2998, %f2998, %f3000;
	rsqrt.approx.ftz.f32 	%f3002, %f3001;
	mul.ftz.f32 	%f1168, %f3002, %f2996;
	mul.ftz.f32 	%f1167, %f3002, %f2997;
	mul.ftz.f32 	%f1166, %f3002, %f2998;

$L__BB0_166:
	st.v4.f32 	[%rd45+144], {%f1135, %f1136, %f3654, %f1154};
	ld.v4.f32 	{%f3003, %f3004, %f3005, %f3006}, [%rd46+160];
	st.v2.f32 	[%rd45+80], {%f3003, %f3004};
	st.f32 	[%rd45+88], %f3005;
	ld.f32 	%f3010, [%rd46+140];
	st.f32 	[%rd45+92], %f3010;
	ld.f32 	%f3011, [%rd46+172];
	st.f32 	[%rd45+76], %f3011;
	mov.u32 	%r1008, 1065353216;
	mov.f32 	%f3637, 0f3F800000;
	st.v2.f32 	[%rd45+48], {%f3637, %f3637};
	st.u32 	[%rd45+56], %r1008;
	and.b32  	%r1009, %r31, 536870912;
	setp.eq.s32 	%p85, %r1009, 0;
	and.b32  	%r33, %r31, 48;
	@%p85 bra 	$L__BB0_187;
	bra.uni 	$L__BB0_167;

$L__BB0_187:
	and.b32  	%r1017, %r31, 268435456;
	setp.eq.s32 	%p96, %r1017, 0;
	@%p96 bra 	$L__BB0_202;
	bra.uni 	$L__BB0_188;

$L__BB0_202:
	setp.eq.s32 	%p103, %r33, 0;
	@%p103 bra 	$L__BB0_204;

	ld.f32 	%f3112, [%rd45+160];
	div.approx.ftz.f32 	%f3642, %f1154, %f3112;
	bra.uni 	$L__BB0_205;

$L__BB0_167:
	setp.eq.s32 	%p86, %r33, 0;
	@%p86 bra 	$L__BB0_169;

	ld.f32 	%f3013, [%rd45+160];
	div.approx.ftz.f32 	%f3626, %f1154, %f3013;
	bra.uni 	$L__BB0_170;

$L__BB0_188:
	setp.eq.s32 	%p97, %r33, 0;
	@%p97 bra 	$L__BB0_190;

	ld.f32 	%f3069, [%rd45+160];
	div.approx.ftz.f32 	%f3638, %f1154, %f3069;
	bra.uni 	$L__BB0_191;

$L__BB0_169:
	ld.f32 	%f3014, [%rd45+164];
	div.approx.ftz.f32 	%f3626, %f3014, %f1154;

$L__BB0_170:
	ld.f32 	%f1172, [%rd45+112];
	neg.ftz.f32 	%f1173, %f1172;
	ld.f32 	%f1174, [%rd45+116];
	neg.ftz.f32 	%f1175, %f1174;
	ld.f32 	%f1176, [%rd45+120];
	neg.ftz.f32 	%f1177, %f1176;
	mul.ftz.f32 	%f3015, %f1168, %f1173;
	mul.ftz.f32 	%f3016, %f1167, %f1174;
	sub.ftz.f32 	%f3017, %f3015, %f3016;
	mul.ftz.f32 	%f3018, %f1166, %f1176;
	sub.ftz.f32 	%f3630, %f3017, %f3018;
	setp.gt.ftz.f32 	%p87, %f3630, 0f00000000;
	@%p87 bra 	$L__BB0_172;
	bra.uni 	$L__BB0_171;

$L__BB0_172:
	neg.ftz.f32 	%f3627, %f1168;
	neg.ftz.f32 	%f1167, %f1167;
	neg.ftz.f32 	%f3629, %f1166;
	neg.ftz.f32 	%f3630, %f3630;
	mov.f32 	%f3631, %f3626;
	bra.uni 	$L__BB0_173;

$L__BB0_171:
	rcp.approx.ftz.f32 	%f3631, %f3626;
	mov.f32 	%f3627, %f1168;
	mov.f32 	%f3629, %f1166;

$L__BB0_173:
	mul.ftz.f32 	%f3022, %f3630, %f3630;
	sub.ftz.f32 	%f3024, %f3637, %f3022;
	mul.ftz.f32 	%f3025, %f3631, %f3631;
	mul.ftz.f32 	%f3026, %f3025, %f3024;
	sub.ftz.f32 	%f1189, %f3637, %f3026;
	setp.lt.ftz.f32 	%p88, %f1189, 0f00000000;
	mov.f32 	%f3633, %f3632;
	mov.f32 	%f3634, %f3632;
	@%p88 bra 	$L__BB0_175;

	mul.ftz.f32 	%f3027, %f3631, %f1173;
	sqrt.approx.ftz.f32 	%f3028, %f1189;
	fma.rn.ftz.f32 	%f3029, %f3630, %f3631, %f3028;
	mul.ftz.f32 	%f3030, %f3627, %f3029;
	mul.ftz.f32 	%f3031, %f1167, %f3029;
	mul.ftz.f32 	%f3032, %f3629, %f3029;
	sub.ftz.f32 	%f3033, %f3027, %f3030;
	mul.ftz.f32 	%f3034, %f3631, %f1175;
	sub.ftz.f32 	%f3035, %f3034, %f3031;
	mul.ftz.f32 	%f3036, %f3631, %f1177;
	sub.ftz.f32 	%f3037, %f3036, %f3032;
	mul.ftz.f32 	%f3038, %f3035, %f3035;
	fma.rn.ftz.f32 	%f3039, %f3033, %f3033, %f3038;
	fma.rn.ftz.f32 	%f3040, %f3037, %f3037, %f3039;
	rsqrt.approx.ftz.f32 	%f3041, %f3040;
	mul.ftz.f32 	%f3632, %f3041, %f3033;
	mul.ftz.f32 	%f3633, %f3041, %f3035;
	mul.ftz.f32 	%f3634, %f3041, %f3037;

$L__BB0_175:
	st.f32 	[%rd45+128], %f3632;
	st.f32 	[%rd45+132], %f3633;
	st.f32 	[%rd45+136], %f3634;
	and.b32  	%r34, %r31, 32;
	@%p88 bra 	$L__BB0_184;

	setp.eq.s32 	%p90, %r34, 0;
	@%p90 bra 	$L__BB0_178;

	st.v2.f32 	[%rd45+128], {%f1173, %f1175};
	st.f32 	[%rd45+136], %f1177;

$L__BB0_178:
	fma.rn.ftz.f32 	%f3045, %f1168, %f1172, %f3016;
	fma.rn.ftz.f32 	%f3046, %f1166, %f1176, %f3045;
	abs.ftz.f32 	%f1196, %f3046;
	mul.ftz.f32 	%f3047, %f1196, %f1196;
	mov.f32 	%f3637, 0f3F800000;
	sub.ftz.f32 	%f1197, %f3637, %f3047;
	setp.leu.ftz.f32 	%p91, %f1197, 0f00000000;
	mov.f32 	%f3635, 0f00000000;
	@%p91 bra 	$L__BB0_180;

	sqrt.approx.ftz.f32 	%f3049, %f1197;
	div.approx.ftz.f32 	%f3635, %f3049, %f3626;

$L__BB0_180:
	setp.gt.ftz.f32 	%p92, %f3635, 0f3F800000;
	@%p92 bra 	$L__BB0_184;

	mul.ftz.f32 	%f3052, %f3635, %f3635;
	mov.f32 	%f3053, 0f3F800000;
	sub.ftz.f32 	%f1200, %f3053, %f3052;
	setp.leu.ftz.f32 	%p93, %f1200, 0f00000000;
	mov.f32 	%f3636, 0f00000000;
	@%p93 bra 	$L__BB0_183;

	sqrt.approx.ftz.f32 	%f3636, %f1200;

$L__BB0_183:
	mul.ftz.f32 	%f3054, %f3626, %f3636;
	sub.ftz.f32 	%f3055, %f1196, %f3054;
	add.ftz.f32 	%f3056, %f1196, %f3054;
	div.approx.ftz.f32 	%f3057, %f3055, %f3056;
	mul.ftz.f32 	%f3058, %f3626, %f1196;
	sub.ftz.f32 	%f3059, %f3058, %f3636;
	add.ftz.f32 	%f3060, %f3058, %f3636;
	div.approx.ftz.f32 	%f3061, %f3059, %f3060;
	mul.ftz.f32 	%f3062, %f3061, %f3061;
	fma.rn.ftz.f32 	%f3063, %f3057, %f3057, %f3062;
	mul.ftz.f32 	%f3064, %f3063, 0f3F000000;
	min.ftz.f32 	%f3637, %f3064, 0f3F800000;

$L__BB0_184:
	setp.ne.s32 	%p94, %r34, 0;
	@%p94 bra 	$L__BB0_186;

	and.b32  	%r1010, %r31, 8;
	setp.eq.s32 	%p95, %r1010, 0;
	selp.u32 	%r1011, 1, 0, %p95;
	add.s32 	%r1012, %r32, %r1011;
	st.u32 	[%rd45+44], %r1012;
	shl.b32 	%r1013, %r31, 28;
	not.b32 	%r1014, %r1013;
	and.b32  	%r1015, %r1014, -2147483648;
	or.b32  	%r1016, %r31, %r1015;
	or.b32  	%r31, %r1016, 256;
	st.u32 	[%rd45+12], %r31;

$L__BB0_186:
	mov.f32 	%f3654, 0f3F800000;
	sub.ftz.f32 	%f3068, %f3654, %f3637;
	st.f32 	[%rd45+124], %f3068;
	mov.f32 	%f3655, %f3654;
	mov.f32 	%f3656, %f3654;

$L__BB0_225:
	mul.ftz.f32 	%f3178, %f3622, %f3656;
	st.f32 	[%rd45+48], %f3178;
	mul.ftz.f32 	%f3179, %f3621, %f3655;
	st.f32 	[%rd45+52], %f3179;
	mul.ftz.f32 	%f3180, %f3620, %f3654;
	st.f32 	[%rd45+56], %f3180;
	st.u32 	[%rd45+60], %r1008;
	and.b32  	%r1048, %r31, 288;
	setp.eq.s32 	%p114, %r1048, 0;
	ld.const.f32 	%f3181, [params+76];
	neg.ftz.f32 	%f3182, %f3181;
	selp.f32 	%f3183, %f3181, %f3182, %p114;
	fma.rn.ftz.f32 	%f3184, %f1138, %f3183, %f3;
	fma.rn.ftz.f32 	%f3185, %f1139, %f3183, %f2;
	fma.rn.ftz.f32 	%f3186, %f1140, %f3183, %f1;
	st.v2.f32 	[%rd45+96], {%f3186, %f3185};
	st.f32 	[%rd45+104], %f3184;
	ret;

$L__BB0_204:
	ld.f32 	%f3113, [%rd45+164];
	div.approx.ftz.f32 	%f3642, %f3113, %f1154;

$L__BB0_205:
	ld.f32 	%f1224, [%rd45+112];
	neg.ftz.f32 	%f1225, %f1224;
	ld.f32 	%f1226, [%rd45+116];
	neg.ftz.f32 	%f1227, %f1226;
	ld.f32 	%f1228, [%rd45+120];
	neg.ftz.f32 	%f1229, %f1228;
	mul.ftz.f32 	%f3114, %f1168, %f1225;
	mul.ftz.f32 	%f3115, %f1167, %f1226;
	sub.ftz.f32 	%f3116, %f3114, %f3115;
	mul.ftz.f32 	%f3117, %f1166, %f1228;
	sub.ftz.f32 	%f1230, %f3116, %f3117;
	setp.gt.ftz.f32 	%p104, %f1230, 0f00000000;
	@%p104 bra 	$L__BB0_207;
	bra.uni 	$L__BB0_206;

$L__BB0_207:
	neg.ftz.f32 	%f3643, %f1168;
	neg.ftz.f32 	%f3644, %f1167;
	neg.ftz.f32 	%f3645, %f1166;
	neg.ftz.f32 	%f3646, %f1230;
	mov.f32 	%f3647, %f3642;
	bra.uni 	$L__BB0_208;

$L__BB0_206:
	rcp.approx.ftz.f32 	%f3647, %f3642;
	mov.f32 	%f3643, %f1168;
	mov.f32 	%f3644, %f1167;
	mov.f32 	%f3645, %f1166;
	mov.f32 	%f3646, %f1230;

$L__BB0_208:
	mul.ftz.f32 	%f3121, %f3646, %f3646;
	mov.f32 	%f3653, 0f3F800000;
	sub.ftz.f32 	%f3123, %f3653, %f3121;
	mul.ftz.f32 	%f3124, %f3647, %f3647;
	mul.ftz.f32 	%f3125, %f3124, %f3123;
	sub.ftz.f32 	%f1241, %f3653, %f3125;
	setp.lt.ftz.f32 	%p105, %f1241, 0f00000000;
	mov.f32 	%f3648, 0f00000000;
	mov.f32 	%f3649, %f3648;
	mov.f32 	%f3650, %f3648;
	@%p105 bra 	$L__BB0_210;

	mul.ftz.f32 	%f3126, %f3647, %f1225;
	sqrt.approx.ftz.f32 	%f3127, %f1241;
	fma.rn.ftz.f32 	%f3128, %f3646, %f3647, %f3127;
	mul.ftz.f32 	%f3129, %f3643, %f3128;
	mul.ftz.f32 	%f3130, %f3644, %f3128;
	mul.ftz.f32 	%f3131, %f3645, %f3128;
	sub.ftz.f32 	%f3132, %f3126, %f3129;
	mul.ftz.f32 	%f3133, %f3647, %f1227;
	sub.ftz.f32 	%f3134, %f3133, %f3130;
	mul.ftz.f32 	%f3135, %f3647, %f1229;
	sub.ftz.f32 	%f3136, %f3135, %f3131;
	mul.ftz.f32 	%f3137, %f3134, %f3134;
	fma.rn.ftz.f32 	%f3138, %f3132, %f3132, %f3137;
	fma.rn.ftz.f32 	%f3139, %f3136, %f3136, %f3138;
	rsqrt.approx.ftz.f32 	%f3140, %f3139;
	mul.ftz.f32 	%f3648, %f3140, %f3132;
	mul.ftz.f32 	%f3649, %f3140, %f3134;
	mul.ftz.f32 	%f3650, %f3140, %f3136;

$L__BB0_210:
	st.f32 	[%rd45+128], %f3648;
	st.f32 	[%rd45+132], %f3649;
	st.f32 	[%rd45+136], %f3650;
	and.b32  	%r39, %r31, 32;
	@%p105 bra 	$L__BB0_219;

	setp.eq.s32 	%p107, %r39, 0;
	@%p107 bra 	$L__BB0_213;

	st.v2.f32 	[%rd45+128], {%f1225, %f1227};
	st.f32 	[%rd45+136], %f1229;

$L__BB0_213:
	fma.rn.ftz.f32 	%f3144, %f1168, %f1224, %f3115;
	fma.rn.ftz.f32 	%f3145, %f1166, %f1228, %f3144;
	abs.ftz.f32 	%f1248, %f3145;
	mul.ftz.f32 	%f3146, %f1248, %f1248;
	mov.f32 	%f3653, 0f3F800000;
	sub.ftz.f32 	%f1249, %f3653, %f3146;
	setp.leu.ftz.f32 	%p108, %f1249, 0f00000000;
	mov.f32 	%f3651, 0f00000000;
	@%p108 bra 	$L__BB0_215;

	sqrt.approx.ftz.f32 	%f3148, %f1249;
	div.approx.ftz.f32 	%f3651, %f3148, %f3642;

$L__BB0_215:
	setp.gt.ftz.f32 	%p109, %f3651, 0f3F800000;
	@%p109 bra 	$L__BB0_219;

	mul.ftz.f32 	%f3151, %f3651, %f3651;
	mov.f32 	%f3152, 0f3F800000;
	sub.ftz.f32 	%f1252, %f3152, %f3151;
	setp.leu.ftz.f32 	%p110, %f1252, 0f00000000;
	mov.f32 	%f3652, 0f00000000;
	@%p110 bra 	$L__BB0_218;

	sqrt.approx.ftz.f32 	%f3652, %f1252;

$L__BB0_218:
	mul.ftz.f32 	%f3153, %f3642, %f3652;
	sub.ftz.f32 	%f3154, %f1248, %f3153;
	add.ftz.f32 	%f3155, %f1248, %f3153;
	div.approx.ftz.f32 	%f3156, %f3154, %f3155;
	mul.ftz.f32 	%f3157, %f3642, %f1248;
	sub.ftz.f32 	%f3158, %f3157, %f3652;
	add.ftz.f32 	%f3159, %f3157, %f3652;
	div.approx.ftz.f32 	%f3160, %f3158, %f3159;
	mul.ftz.f32 	%f3161, %f3160, %f3160;
	fma.rn.ftz.f32 	%f3162, %f3156, %f3156, %f3161;
	mul.ftz.f32 	%f3163, %f3162, 0f3F000000;
	min.ftz.f32 	%f3653, %f3163, 0f3F800000;

$L__BB0_219:
	ld.u32 	%r1029, [%rd45+28];
	mad.lo.s32 	%r1030, %r1029, 1664525, 1013904223;
	st.u32 	[%rd45+28], %r1030;
	and.b32  	%r1031, %r1030, 16777215;
	cvt.rn.f32.u32 	%f3164, %r1031;
	mov.f32 	%f3165, 0f4B800000;
	div.approx.ftz.f32 	%f3166, %f3164, %f3165;
	setp.lt.ftz.f32 	%p111, %f3166, %f3653;
	mul.ftz.f32 	%f3167, %f1166, 0fC0000000;
	fma.rn.ftz.f32 	%f1257, %f3167, %f1230, %f1229;
	add.ftz.f32 	%f3168, %f1167, %f1167;
	mul.ftz.f32 	%f3169, %f3168, %f1230;
	sub.ftz.f32 	%f1258, %f1227, %f3169;
	add.ftz.f32 	%f3170, %f1168, %f1168;
	mul.ftz.f32 	%f3171, %f3170, %f1230;
	sub.ftz.f32 	%f1259, %f1225, %f3171;
	@%p111 bra 	$L__BB0_222;
	bra.uni 	$L__BB0_220;

$L__BB0_222:
	setp.eq.s32 	%p113, %r39, 0;
	shl.b32 	%r1036, %r31, 29;
	not.b32 	%r1037, %r1036;
	and.b32  	%r1038, %r1037, -2147483648;
	or.b32  	%r31, %r31, %r1038;
	st.u32 	[%rd45+12], %r31;
	st.v2.f32 	[%rd45+128], {%f1259, %f1258};
	st.f32 	[%rd45+136], %f1257;
	@%p113 bra 	$L__BB0_224;
	bra.uni 	$L__BB0_223;

$L__BB0_224:
	mov.b32 	%r1043, %f2928;
	mov.b32 	%r1044, %f2929;
	st.v2.f32 	[%rd45+48], {%f2928, %f2929};
	st.f32 	[%rd45+56], %f2930;
	mov.b64 	%rd784, {%r1043, %r1044};
	cvt.u32.u64 	%r1045, %rd784;
	mov.b32 	%f3656, %r1045;
	shr.u64 	%rd785, %rd784, 32;
	cvt.u32.u64 	%r1046, %rd785;
	mov.b32 	%f3655, %r1046;
	mov.f32 	%f3654, %f2930;
	bra.uni 	$L__BB0_225;

$L__BB0_220:
	setp.ne.s32 	%p112, %r39, 0;
	mov.f32 	%f3654, 0f3F800000;
	mov.f32 	%f3655, %f3654;
	mov.f32 	%f3656, %f3654;
	@%p112 bra 	$L__BB0_225;

	shl.b32 	%r1032, %r31, 28;
	not.b32 	%r1033, %r1032;
	and.b32  	%r1034, %r1033, -2147483648;
	or.b32  	%r1035, %r31, %r1034;
	or.b32  	%r31, %r1035, 256;
	st.u32 	[%rd45+12], %r31;
	mov.f32 	%f3655, %f3654;
	mov.f32 	%f3656, %f3654;
	bra.uni 	$L__BB0_225;

$L__BB0_190:
	ld.f32 	%f3070, [%rd45+164];
	div.approx.ftz.f32 	%f3638, %f3070, %f1154;

$L__BB0_191:
	and.b32  	%r1018, %r31, 4;
	setp.ne.s32 	%p98, %r1018, 0;
	@%p98 bra 	$L__BB0_193;

	add.s32 	%r1019, %r32, 1;
	st.u32 	[%rd45+44], %r1019;
	or.b32  	%r31, %r31, -2147483648;
	st.u32 	[%rd45+12], %r31;

$L__BB0_193:
	ld.f32 	%f3072, [%rd45+112];
	neg.ftz.f32 	%f3073, %f3072;
	ld.f32 	%f3074, [%rd45+116];
	neg.ftz.f32 	%f3075, %f3074;
	ld.f32 	%f3076, [%rd45+120];
	neg.ftz.f32 	%f3077, %f3076;
	mul.ftz.f32 	%f3078, %f1168, %f3073;
	mul.ftz.f32 	%f3079, %f1167, %f3074;
	sub.ftz.f32 	%f3080, %f3078, %f3079;
	mul.ftz.f32 	%f3081, %f1166, %f3076;
	sub.ftz.f32 	%f3082, %f3080, %f3081;
	add.ftz.f32 	%f3083, %f1168, %f1168;
	mul.ftz.f32 	%f3084, %f3083, %f3082;
	add.ftz.f32 	%f3085, %f1167, %f1167;
	mul.ftz.f32 	%f3086, %f3085, %f3082;
	add.ftz.f32 	%f3087, %f1166, %f1166;
	mul.ftz.f32 	%f3088, %f3087, %f3082;
	sub.ftz.f32 	%f3089, %f3077, %f3088;
	sub.ftz.f32 	%f3090, %f3075, %f3086;
	sub.ftz.f32 	%f3091, %f3073, %f3084;
	st.v2.f32 	[%rd45+128], {%f3091, %f3090};
	st.f32 	[%rd45+136], %f3089;
	fma.rn.ftz.f32 	%f3092, %f1168, %f3072, %f3079;
	fma.rn.ftz.f32 	%f3093, %f1166, %f3076, %f3092;
	abs.ftz.f32 	%f1208, %f3093;
	mul.ftz.f32 	%f3094, %f1208, %f1208;
	mov.f32 	%f3641, 0f3F800000;
	sub.ftz.f32 	%f1209, %f3641, %f3094;
	setp.leu.ftz.f32 	%p99, %f1209, 0f00000000;
	mov.f32 	%f3639, 0f00000000;
	@%p99 bra 	$L__BB0_195;

	sqrt.approx.ftz.f32 	%f3096, %f1209;
	div.approx.ftz.f32 	%f3639, %f3096, %f3638;

$L__BB0_195:
	setp.gt.ftz.f32 	%p100, %f3639, 0f3F800000;
	@%p100 bra 	$L__BB0_199;

	mul.ftz.f32 	%f3099, %f3639, %f3639;
	mov.f32 	%f3100, 0f3F800000;
	sub.ftz.f32 	%f1212, %f3100, %f3099;
	setp.leu.ftz.f32 	%p101, %f1212, 0f00000000;
	mov.f32 	%f3640, 0f00000000;
	@%p101 bra 	$L__BB0_198;

	sqrt.approx.ftz.f32 	%f3640, %f1212;

$L__BB0_198:
	mul.ftz.f32 	%f3101, %f3638, %f3640;
	sub.ftz.f32 	%f3102, %f1208, %f3101;
	add.ftz.f32 	%f3103, %f1208, %f3101;
	div.approx.ftz.f32 	%f3104, %f3102, %f3103;
	mul.ftz.f32 	%f3105, %f3638, %f1208;
	sub.ftz.f32 	%f3106, %f3105, %f3640;
	add.ftz.f32 	%f3107, %f3105, %f3640;
	div.approx.ftz.f32 	%f3108, %f3106, %f3107;
	mul.ftz.f32 	%f3109, %f3108, %f3108;
	fma.rn.ftz.f32 	%f3110, %f3104, %f3104, %f3109;
	mul.ftz.f32 	%f3111, %f3110, 0f3F000000;
	min.ftz.f32 	%f3641, %f3111, 0f3F800000;

$L__BB0_199:
	st.f32 	[%rd45+124], %f3641;
	and.b32  	%r1020, %r31, 32;
	setp.eq.s32 	%p102, %r1020, 0;
	@%p102 bra 	$L__BB0_201;
	bra.uni 	$L__BB0_200;

$L__BB0_201:
	mov.b32 	%r1025, %f2928;
	mov.b32 	%r1026, %f2929;
	st.v2.f32 	[%rd45+48], {%f2928, %f2929};
	st.f32 	[%rd45+56], %f2930;
	mov.b64 	%rd780, {%r1025, %r1026};
	cvt.u32.u64 	%r1027, %rd780;
	mov.b32 	%f3656, %r1027;
	shr.u64 	%rd781, %rd780, 32;
	cvt.u32.u64 	%r1028, %rd781;
	mov.b32 	%f3655, %r1028;
	mov.f32 	%f3654, %f2930;
	bra.uni 	$L__BB0_225;

$L__BB0_200:
	mov.b32 	%r1021, %f1136;
	mov.b32 	%r1022, %f1135;
	st.v2.f32 	[%rd45+48], {%f1135, %f1136};
	st.f32 	[%rd45+56], %f3654;
	mov.b64 	%rd778, {%r1022, %r1021};
	cvt.u32.u64 	%r1023, %rd778;
	mov.b32 	%f3656, %r1023;
	shr.u64 	%rd779, %rd778, 32;
	cvt.u32.u64 	%r1024, %rd779;
	mov.b32 	%f3655, %r1024;
	bra.uni 	$L__BB0_225;

$L__BB0_223:
	mov.b32 	%r1039, %f1136;
	mov.b32 	%r1040, %f1135;
	st.v2.f32 	[%rd45+48], {%f1135, %f1136};
	st.f32 	[%rd45+56], %f3654;
	mov.b64 	%rd782, {%r1040, %r1039};
	cvt.u32.u64 	%r1041, %rd782;
	mov.b32 	%f3656, %r1041;
	shr.u64 	%rd783, %rd782, 32;
	cvt.u32.u64 	%r1042, %rd783;
	mov.b32 	%f3655, %r1042;
	bra.uni 	$L__BB0_225;

}

