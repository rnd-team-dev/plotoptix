//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30033411
// Cuda compilation tools, release 11.4, V11.4.48
// Based on NVVM 7.0.1
//

.version 7.4
.target sm_50
.address_size 64

	// .globl	__closesthit__curve_radiance__reflective_masked
.const .align 8 .b8 params[288];

.visible .entry __closesthit__curve_radiance__reflective_masked()
{
	.reg .pred 	%p<154>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<4164>;
	.reg .b32 	%r<1355>;
	.reg .b64 	%rd<804>;


	// begin inline asm
	call (%rd54), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	// begin inline asm
	call (%r115), _optix_read_primitive_idx, ();
	// end inline asm
	mov.u32 	%r116, 3;
	// begin inline asm
	call _optix_set_payload, (%r116, %r115);
	// end inline asm
	// begin inline asm
	call (%f1339), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f1340), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f1341), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%f1342), _optix_get_ray_tmax, ();
	// end inline asm
	// begin inline asm
	call (%f1343), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f1344), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f1345), _optix_get_world_ray_direction_z, ();
	// end inline asm
	fma.rn.ftz.f32 	%f1, %f1342, %f1343, %f1339;
	fma.rn.ftz.f32 	%f2, %f1342, %f1344, %f1340;
	fma.rn.ftz.f32 	%f3, %f1342, %f1345, %f1341;
	// begin inline asm
	call (%r118), _optix_get_hit_kind, ();
	// end inline asm
	// begin inline asm
	call (%r119), _optix_get_primitive_type_from_hit_kind, (%r118);
	// end inline asm
	setp.eq.s32 	%p1, %r119, 9473;
	@%p1 bra 	$L__BB0_97;

	setp.eq.s32 	%p2, %r119, 9474;
	@%p2 bra 	$L__BB0_50;

	setp.ne.s32 	%p3, %r119, 9475;
	@%p3 bra 	$L__BB0_144;

	// begin inline asm
	call (%rd55), _optix_get_gas_traversable_handle, ();
	// end inline asm
	// begin inline asm
	call (%r122), _optix_read_sbt_gas_idx, ();
	// end inline asm
	mov.f32 	%f1355, 0f00000000;
	// begin inline asm
	call (%f1347, %f1348, %f1349, %f1350,  %f1351, %f1352, %f1353, %f1354), _optix_get_linear_curve_vertex_data, (%rd55, %r115, %r122, %f1355);
	// end inline asm
	sub.ftz.f32 	%f13, %f1351, %f1347;
	sub.ftz.f32 	%f15, %f1352, %f1348;
	sub.ftz.f32 	%f17, %f1353, %f1349;
	// begin inline asm
	call (%r125), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p4, %r125, 0;
	@%p4 bra 	$L__BB0_23;

	// begin inline asm
	call (%r126), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1356), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p5, %r126, 0;
	@%p5 bra 	$L__BB0_22;

	mov.u32 	%r1341, 0;

$L__BB0_6:
	.pragma "nounroll";
	// begin inline asm
	call (%rd57), _optix_get_transform_list_handle, (%r1341);
	// end inline asm
	// begin inline asm
	call (%r129), _optix_get_transform_type_from_handle, (%rd57);
	// end inline asm
	or.b32  	%r130, %r129, 1;
	setp.eq.s32 	%p6, %r130, 3;
	@%p6 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_7;

$L__BB0_12:
	setp.eq.s32 	%p9, %r129, 2;
	@%p9 bra 	$L__BB0_16;
	bra.uni 	$L__BB0_13;

$L__BB0_16:
	// begin inline asm
	call (%rd129), _optix_get_matrix_motion_transform_from_handle, (%rd57);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd131, %rd129;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r218,%r219,%r220,%r221}, [%rd131];
	// end inline asm
	add.s64 	%rd135, %rd129, 16;
	// begin inline asm
	cvta.to.global.u64 %rd134, %rd135;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r222,%r223,%r224,%r225}, [%rd134];
	// end inline asm
	add.s64 	%rd138, %rd129, 32;
	// begin inline asm
	cvta.to.global.u64 %rd137, %rd138;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r226,%r227,%r228,%r229}, [%rd137];
	// end inline asm
	add.s64 	%rd141, %rd129, 48;
	// begin inline asm
	cvta.to.global.u64 %rd140, %rd141;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r230,%r231,%r232,%r233}, [%rd140];
	// end inline asm
	add.s64 	%rd144, %rd129, 64;
	// begin inline asm
	cvta.to.global.u64 %rd143, %rd144;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r234,%r235,%r236,%r237}, [%rd143];
	// end inline asm
	add.s64 	%rd147, %rd129, 80;
	// begin inline asm
	cvta.to.global.u64 %rd146, %rd147;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd146];
	// end inline asm
	add.s64 	%rd150, %rd129, 96;
	// begin inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd149];
	// end inline asm
	add.s64 	%rd153, %rd129, 112;
	// begin inline asm
	cvta.to.global.u64 %rd152, %rd153;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd152];
	// end inline asm
	mov.b32 	%f1483, %r221;
	mov.b32 	%f1484, %r222;
	and.b32  	%r262, %r220, 65535;
	add.s32 	%r263, %r262, -1;
	cvt.rn.f32.s32 	%f1485, %r263;
	sub.ftz.f32 	%f1486, %f1356, %f1483;
	mul.ftz.f32 	%f1487, %f1486, %f1485;
	sub.ftz.f32 	%f1488, %f1484, %f1483;
	div.approx.ftz.f32 	%f1489, %f1487, %f1488;
	min.ftz.f32 	%f1490, %f1485, %f1489;
	mov.f32 	%f1491, 0f00000000;
	max.ftz.f32 	%f1492, %f1491, %f1490;
	cvt.rmi.ftz.f32.f32 	%f1493, %f1492;
	sub.ftz.f32 	%f104, %f1492, %f1493;
	cvt.rzi.ftz.s32.f32 	%r264, %f1493;
	cvt.s64.s32 	%rd8, %r264;
	mul.wide.s32 	%rd164, %r264, 48;
	add.s64 	%rd156, %rd138, %rd164;
	// begin inline asm
	cvta.to.global.u64 %rd155, %rd156;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd155];
	// end inline asm
	mov.b32 	%f3738, %r250;
	mov.b32 	%f3737, %r251;
	mov.b32 	%f3736, %r252;
	mov.b32 	%f3735, %r253;
	add.s64 	%rd159, %rd156, 16;
	// begin inline asm
	cvta.to.global.u64 %rd158, %rd159;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd158];
	// end inline asm
	mov.b32 	%f3742, %r254;
	mov.b32 	%f3741, %r255;
	mov.b32 	%f3740, %r256;
	mov.b32 	%f3739, %r257;
	add.s64 	%rd162, %rd156, 32;
	// begin inline asm
	cvta.to.global.u64 %rd161, %rd162;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r258,%r259,%r260,%r261}, [%rd161];
	// end inline asm
	mov.b32 	%f3746, %r258;
	mov.b32 	%f3745, %r259;
	mov.b32 	%f3744, %r260;
	mov.b32 	%f3743, %r261;
	setp.leu.ftz.f32 	%p11, %f104, 0f00000000;
	@%p11 bra 	$L__BB0_18;

	mov.f32 	%f1494, 0f3F800000;
	sub.ftz.f32 	%f1495, %f1494, %f104;
	mul.lo.s64 	%rd174, %rd8, 48;
	add.s64 	%rd175, %rd129, %rd174;
	add.s64 	%rd166, %rd175, 80;
	// begin inline asm
	cvta.to.global.u64 %rd165, %rd166;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r265,%r266,%r267,%r268}, [%rd165];
	// end inline asm
	mov.b32 	%f1496, %r265;
	mov.b32 	%f1497, %r266;
	mov.b32 	%f1498, %r267;
	mov.b32 	%f1499, %r268;
	mul.ftz.f32 	%f1500, %f104, %f1496;
	mul.ftz.f32 	%f1501, %f104, %f1497;
	mul.ftz.f32 	%f1502, %f104, %f1498;
	mul.ftz.f32 	%f1503, %f104, %f1499;
	fma.rn.ftz.f32 	%f3738, %f1495, %f3738, %f1500;
	fma.rn.ftz.f32 	%f3737, %f1495, %f3737, %f1501;
	fma.rn.ftz.f32 	%f3736, %f1495, %f3736, %f1502;
	fma.rn.ftz.f32 	%f3735, %f1495, %f3735, %f1503;
	add.s64 	%rd169, %rd175, 96;
	// begin inline asm
	cvta.to.global.u64 %rd168, %rd169;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r269,%r270,%r271,%r272}, [%rd168];
	// end inline asm
	mov.b32 	%f1504, %r269;
	mov.b32 	%f1505, %r270;
	mov.b32 	%f1506, %r271;
	mov.b32 	%f1507, %r272;
	mul.ftz.f32 	%f1508, %f104, %f1504;
	mul.ftz.f32 	%f1509, %f104, %f1505;
	mul.ftz.f32 	%f1510, %f104, %f1506;
	mul.ftz.f32 	%f1511, %f104, %f1507;
	fma.rn.ftz.f32 	%f3742, %f1495, %f3742, %f1508;
	fma.rn.ftz.f32 	%f3741, %f1495, %f3741, %f1509;
	fma.rn.ftz.f32 	%f3740, %f1495, %f3740, %f1510;
	fma.rn.ftz.f32 	%f3739, %f1495, %f3739, %f1511;
	add.s64 	%rd172, %rd175, 112;
	// begin inline asm
	cvta.to.global.u64 %rd171, %rd172;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r273,%r274,%r275,%r276}, [%rd171];
	// end inline asm
	mov.b32 	%f1512, %r273;
	mov.b32 	%f1513, %r274;
	mov.b32 	%f1514, %r275;
	mov.b32 	%f1515, %r276;
	mul.ftz.f32 	%f1516, %f104, %f1512;
	mul.ftz.f32 	%f1517, %f104, %f1513;
	mul.ftz.f32 	%f1518, %f104, %f1514;
	mul.ftz.f32 	%f1519, %f104, %f1515;
	fma.rn.ftz.f32 	%f3746, %f1495, %f3746, %f1516;
	fma.rn.ftz.f32 	%f3745, %f1495, %f3745, %f1517;
	fma.rn.ftz.f32 	%f3744, %f1495, %f3744, %f1518;
	fma.rn.ftz.f32 	%f3743, %f1495, %f3743, %f1519;
	bra.uni 	$L__BB0_18;

$L__BB0_7:
	mov.f32 	%f3750, 0f3F800000;
	setp.eq.s32 	%p7, %r129, 4;
	@%p7 bra 	$L__BB0_10;

	setp.ne.s32 	%p8, %r129, 1;
	mov.f32 	%f3747, %f1355;
	mov.f32 	%f3748, %f1355;
	mov.f32 	%f3749, %f1355;
	mov.f32 	%f3751, %f1355;
	mov.f32 	%f3752, %f1355;
	mov.f32 	%f3753, %f3750;
	mov.f32 	%f3754, %f1355;
	mov.f32 	%f3755, %f1355;
	mov.f32 	%f3756, %f3750;
	mov.f32 	%f3757, %f1355;
	mov.f32 	%f3758, %f1355;
	@%p8 bra 	$L__BB0_19;

	// begin inline asm
	call (%rd59), _optix_get_static_transform_from_handle, (%rd57);
	// end inline asm
	add.s64 	%rd796, %rd59, 64;
	bra.uni 	$L__BB0_11;

$L__BB0_13:
	// begin inline asm
	call (%rd72), _optix_get_srt_motion_transform_from_handle, (%rd57);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd74, %rd72;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r143,%r144,%r145,%r146}, [%rd74];
	// end inline asm
	add.s64 	%rd78, %rd72, 16;
	// begin inline asm
	cvta.to.global.u64 %rd77, %rd78;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r147,%r148,%r149,%r150}, [%rd77];
	// end inline asm
	add.s64 	%rd81, %rd72, 32;
	// begin inline asm
	cvta.to.global.u64 %rd80, %rd81;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r151,%r152,%r153,%r154}, [%rd80];
	// end inline asm
	add.s64 	%rd84, %rd72, 48;
	// begin inline asm
	cvta.to.global.u64 %rd83, %rd84;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r155,%r156,%r157,%r158}, [%rd83];
	// end inline asm
	add.s64 	%rd87, %rd72, 64;
	// begin inline asm
	cvta.to.global.u64 %rd86, %rd87;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r159,%r160,%r161,%r162}, [%rd86];
	// end inline asm
	add.s64 	%rd90, %rd72, 80;
	// begin inline asm
	cvta.to.global.u64 %rd89, %rd90;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r163,%r164,%r165,%r166}, [%rd89];
	// end inline asm
	add.s64 	%rd93, %rd72, 96;
	// begin inline asm
	cvta.to.global.u64 %rd92, %rd93;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd92];
	// end inline asm
	add.s64 	%rd96, %rd72, 112;
	// begin inline asm
	cvta.to.global.u64 %rd95, %rd96;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r171,%r172,%r173,%r174}, [%rd95];
	// end inline asm
	add.s64 	%rd99, %rd72, 128;
	// begin inline asm
	cvta.to.global.u64 %rd98, %rd99;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r175,%r176,%r177,%r178}, [%rd98];
	// end inline asm
	add.s64 	%rd102, %rd72, 144;
	// begin inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r179,%r180,%r181,%r182}, [%rd101];
	// end inline asm
	mov.b32 	%f1371, %r146;
	mov.b32 	%f1372, %r147;
	and.b32  	%r199, %r145, 65535;
	add.s32 	%r200, %r199, -1;
	cvt.rn.f32.s32 	%f1373, %r200;
	sub.ftz.f32 	%f1374, %f1356, %f1371;
	mul.ftz.f32 	%f1375, %f1374, %f1373;
	sub.ftz.f32 	%f1376, %f1372, %f1371;
	div.approx.ftz.f32 	%f1377, %f1375, %f1376;
	min.ftz.f32 	%f1378, %f1373, %f1377;
	mov.f32 	%f1379, 0f00000000;
	max.ftz.f32 	%f1380, %f1379, %f1378;
	cvt.rmi.ftz.f32.f32 	%f1381, %f1380;
	sub.ftz.f32 	%f43, %f1380, %f1381;
	cvt.rzi.ftz.s32.f32 	%r201, %f1381;
	mul.wide.s32 	%rd116, %r201, 64;
	add.s64 	%rd105, %rd81, %rd116;
	// begin inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r183,%r184,%r185,%r186}, [%rd104];
	// end inline asm
	mov.b32 	%f3730, %r183;
	mov.b32 	%f3729, %r184;
	mov.b32 	%f3728, %r185;
	mov.b32 	%f3727, %r186;
	add.s64 	%rd108, %rd105, 16;
	// begin inline asm
	cvta.to.global.u64 %rd107, %rd108;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r187,%r188,%r189,%r190}, [%rd107];
	// end inline asm
	mov.b32 	%f3726, %r187;
	mov.b32 	%f3725, %r188;
	mov.b32 	%f3724, %r189;
	mov.b32 	%f3723, %r190;
	add.s64 	%rd111, %rd105, 32;
	// begin inline asm
	cvta.to.global.u64 %rd110, %rd111;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r191,%r192,%r193,%r194}, [%rd110];
	// end inline asm
	mov.b32 	%f3722, %r191;
	mov.b32 	%f3721, %r192;
	mov.b32 	%f3720, %r193;
	mov.b32 	%f3719, %r194;
	add.s64 	%rd114, %rd105, 48;
	// begin inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r195,%r196,%r197,%r198}, [%rd113];
	// end inline asm
	mov.b32 	%f3731, %r195;
	mov.b32 	%f3732, %r196;
	mov.b32 	%f3733, %r197;
	mov.b32 	%f3734, %r198;
	setp.leu.ftz.f32 	%p10, %f43, 0f00000000;
	@%p10 bra 	$L__BB0_15;

	mov.f32 	%f1382, 0f3F800000;
	sub.ftz.f32 	%f1383, %f1382, %f43;
	add.s64 	%rd118, %rd105, 64;
	// begin inline asm
	cvta.to.global.u64 %rd117, %rd118;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r202,%r203,%r204,%r205}, [%rd117];
	// end inline asm
	mov.b32 	%f1384, %r202;
	mov.b32 	%f1385, %r203;
	mov.b32 	%f1386, %r204;
	mov.b32 	%f1387, %r205;
	mul.ftz.f32 	%f1388, %f43, %f1384;
	mul.ftz.f32 	%f1389, %f43, %f1385;
	mul.ftz.f32 	%f1390, %f43, %f1386;
	mul.ftz.f32 	%f1391, %f43, %f1387;
	fma.rn.ftz.f32 	%f3730, %f1383, %f3730, %f1388;
	fma.rn.ftz.f32 	%f3729, %f1383, %f3729, %f1389;
	fma.rn.ftz.f32 	%f3728, %f1383, %f3728, %f1390;
	fma.rn.ftz.f32 	%f3727, %f1383, %f3727, %f1391;
	add.s64 	%rd121, %rd105, 80;
	// begin inline asm
	cvta.to.global.u64 %rd120, %rd121;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r206,%r207,%r208,%r209}, [%rd120];
	// end inline asm
	mov.b32 	%f1392, %r206;
	mov.b32 	%f1393, %r207;
	mov.b32 	%f1394, %r208;
	mov.b32 	%f1395, %r209;
	mul.ftz.f32 	%f1396, %f43, %f1392;
	mul.ftz.f32 	%f1397, %f43, %f1393;
	mul.ftz.f32 	%f1398, %f43, %f1394;
	mul.ftz.f32 	%f1399, %f43, %f1395;
	fma.rn.ftz.f32 	%f3726, %f1383, %f3726, %f1396;
	fma.rn.ftz.f32 	%f3725, %f1383, %f3725, %f1397;
	fma.rn.ftz.f32 	%f3724, %f1383, %f3724, %f1398;
	fma.rn.ftz.f32 	%f3723, %f1383, %f3723, %f1399;
	add.s64 	%rd124, %rd105, 96;
	// begin inline asm
	cvta.to.global.u64 %rd123, %rd124;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r210,%r211,%r212,%r213}, [%rd123];
	// end inline asm
	mov.b32 	%f1400, %r210;
	mov.b32 	%f1401, %r211;
	mov.b32 	%f1402, %r212;
	mov.b32 	%f1403, %r213;
	mul.ftz.f32 	%f1404, %f43, %f1400;
	mul.ftz.f32 	%f1405, %f43, %f1401;
	mul.ftz.f32 	%f1406, %f43, %f1402;
	mul.ftz.f32 	%f1407, %f43, %f1403;
	fma.rn.ftz.f32 	%f3722, %f1383, %f3722, %f1404;
	fma.rn.ftz.f32 	%f1408, %f1383, %f3721, %f1405;
	fma.rn.ftz.f32 	%f1409, %f1383, %f3720, %f1406;
	fma.rn.ftz.f32 	%f1410, %f1383, %f3719, %f1407;
	add.s64 	%rd127, %rd105, 112;
	// begin inline asm
	cvta.to.global.u64 %rd126, %rd127;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r214,%r215,%r216,%r217}, [%rd126];
	// end inline asm
	mov.b32 	%f1411, %r214;
	mov.b32 	%f1412, %r215;
	mov.b32 	%f1413, %r216;
	mov.b32 	%f1414, %r217;
	mul.ftz.f32 	%f1415, %f43, %f1411;
	mul.ftz.f32 	%f1416, %f43, %f1412;
	mul.ftz.f32 	%f1417, %f43, %f1413;
	mul.ftz.f32 	%f1418, %f43, %f1414;
	fma.rn.ftz.f32 	%f1419, %f1383, %f3731, %f1415;
	fma.rn.ftz.f32 	%f3732, %f1383, %f3732, %f1416;
	fma.rn.ftz.f32 	%f3733, %f1383, %f3733, %f1417;
	fma.rn.ftz.f32 	%f3734, %f1383, %f3734, %f1418;
	mul.ftz.f32 	%f1420, %f1409, %f1409;
	fma.rn.ftz.f32 	%f1421, %f1408, %f1408, %f1420;
	fma.rn.ftz.f32 	%f1422, %f1410, %f1410, %f1421;
	fma.rn.ftz.f32 	%f1423, %f1419, %f1419, %f1422;
	rsqrt.approx.ftz.f32 	%f1424, %f1423;
	mul.ftz.f32 	%f3721, %f1408, %f1424;
	mul.ftz.f32 	%f3720, %f1409, %f1424;
	mul.ftz.f32 	%f3719, %f1410, %f1424;
	mul.ftz.f32 	%f3731, %f1424, %f1419;

$L__BB0_15:
	mul.ftz.f32 	%f1425, %f3721, %f3721;
	fma.rn.ftz.f32 	%f1426, %f3720, %f3720, %f1425;
	fma.rn.ftz.f32 	%f1427, %f3719, %f3719, %f1426;
	fma.rn.ftz.f32 	%f1428, %f3731, %f3731, %f1427;
	rcp.approx.ftz.f32 	%f1429, %f1428;
	mul.ftz.f32 	%f1430, %f3721, %f1429;
	mul.ftz.f32 	%f1431, %f3720, %f1429;
	mul.ftz.f32 	%f1432, %f3719, %f1429;
	mul.ftz.f32 	%f1433, %f3731, %f1429;
	mul.ftz.f32 	%f1434, %f3721, %f1430;
	mul.ftz.f32 	%f1435, %f3720, %f1431;
	mul.ftz.f32 	%f1436, %f3719, %f1432;
	mul.ftz.f32 	%f1437, %f3721, %f1431;
	mul.ftz.f32 	%f1438, %f3719, %f1433;
	mul.ftz.f32 	%f1439, %f3721, %f1432;
	mul.ftz.f32 	%f1440, %f3720, %f1433;
	mul.ftz.f32 	%f1441, %f3720, %f1432;
	mul.ftz.f32 	%f1442, %f3721, %f1433;
	sub.ftz.f32 	%f1443, %f1434, %f1435;
	sub.ftz.f32 	%f1444, %f1443, %f1436;
	fma.rn.ftz.f32 	%f1445, %f3731, %f1433, %f1444;
	sub.ftz.f32 	%f1446, %f1437, %f1438;
	add.ftz.f32 	%f1447, %f1446, %f1446;
	add.ftz.f32 	%f1448, %f1439, %f1440;
	add.ftz.f32 	%f1449, %f1448, %f1448;
	add.ftz.f32 	%f1450, %f1437, %f1438;
	add.ftz.f32 	%f1451, %f1450, %f1450;
	sub.ftz.f32 	%f1452, %f1435, %f1434;
	sub.ftz.f32 	%f1453, %f1452, %f1436;
	fma.rn.ftz.f32 	%f1454, %f3731, %f1433, %f1453;
	sub.ftz.f32 	%f1455, %f1441, %f1442;
	add.ftz.f32 	%f1456, %f1455, %f1455;
	sub.ftz.f32 	%f1457, %f1439, %f1440;
	add.ftz.f32 	%f1458, %f1457, %f1457;
	add.ftz.f32 	%f1459, %f1441, %f1442;
	add.ftz.f32 	%f1460, %f1459, %f1459;
	neg.ftz.f32 	%f1461, %f1434;
	sub.ftz.f32 	%f1462, %f1461, %f1435;
	add.ftz.f32 	%f1463, %f1436, %f1462;
	fma.rn.ftz.f32 	%f1464, %f3731, %f1433, %f1463;
	mul.ftz.f32 	%f1465, %f3727, %f1445;
	fma.rn.ftz.f32 	%f1466, %f3724, %f1447, %f1465;
	fma.rn.ftz.f32 	%f1467, %f3722, %f1449, %f1466;
	add.ftz.f32 	%f3735, %f3732, %f1467;
	mul.ftz.f32 	%f1468, %f3724, %f1454;
	fma.rn.ftz.f32 	%f1469, %f3727, %f1451, %f1468;
	fma.rn.ftz.f32 	%f1470, %f3722, %f1456, %f1469;
	add.ftz.f32 	%f3739, %f3733, %f1470;
	mul.ftz.f32 	%f1471, %f3724, %f1460;
	fma.rn.ftz.f32 	%f1472, %f3727, %f1458, %f1471;
	fma.rn.ftz.f32 	%f1473, %f3722, %f1464, %f1472;
	add.ftz.f32 	%f3743, %f3734, %f1473;
	mul.ftz.f32 	%f1474, %f3728, %f1445;
	fma.rn.ftz.f32 	%f1475, %f3725, %f1447, %f1474;
	fma.rn.ftz.f32 	%f3736, %f3723, %f1449, %f1475;
	mul.ftz.f32 	%f1476, %f3725, %f1454;
	fma.rn.ftz.f32 	%f1477, %f3728, %f1451, %f1476;
	fma.rn.ftz.f32 	%f3740, %f3723, %f1456, %f1477;
	mul.ftz.f32 	%f1478, %f3725, %f1460;
	fma.rn.ftz.f32 	%f1479, %f3728, %f1458, %f1478;
	fma.rn.ftz.f32 	%f3744, %f3723, %f1464, %f1479;
	mul.ftz.f32 	%f1480, %f3729, %f1445;
	fma.rn.ftz.f32 	%f3737, %f3726, %f1447, %f1480;
	mul.ftz.f32 	%f1481, %f3726, %f1454;
	fma.rn.ftz.f32 	%f3741, %f3729, %f1451, %f1481;
	mul.ftz.f32 	%f1482, %f3726, %f1460;
	fma.rn.ftz.f32 	%f3745, %f3729, %f1458, %f1482;
	mul.ftz.f32 	%f3738, %f3730, %f1445;
	mul.ftz.f32 	%f3742, %f3730, %f1451;
	mul.ftz.f32 	%f3746, %f3730, %f1458;

$L__BB0_18:
	mul.ftz.f32 	%f1520, %f3740, %f3745;
	mul.ftz.f32 	%f1521, %f3741, %f3744;
	sub.ftz.f32 	%f1522, %f1521, %f1520;
	mul.ftz.f32 	%f1523, %f3738, %f1522;
	mul.ftz.f32 	%f1524, %f3740, %f3746;
	mul.ftz.f32 	%f1525, %f3742, %f3744;
	sub.ftz.f32 	%f1526, %f1525, %f1524;
	mul.ftz.f32 	%f1527, %f3737, %f1526;
	sub.ftz.f32 	%f1528, %f1523, %f1527;
	mul.ftz.f32 	%f1529, %f3741, %f3746;
	mul.ftz.f32 	%f1530, %f3742, %f3745;
	sub.ftz.f32 	%f1531, %f1530, %f1529;
	fma.rn.ftz.f32 	%f1532, %f3736, %f1531, %f1528;
	rcp.approx.ftz.f32 	%f1533, %f1532;
	mul.ftz.f32 	%f3750, %f1522, %f1533;
	mul.ftz.f32 	%f1534, %f3737, %f3744;
	mul.ftz.f32 	%f1535, %f3736, %f3745;
	sub.ftz.f32 	%f1536, %f1535, %f1534;
	mul.ftz.f32 	%f3749, %f1536, %f1533;
	mul.ftz.f32 	%f1537, %f3736, %f3741;
	mul.ftz.f32 	%f1538, %f3737, %f3740;
	sub.ftz.f32 	%f1539, %f1538, %f1537;
	mul.ftz.f32 	%f3748, %f1539, %f1533;
	sub.ftz.f32 	%f1540, %f1524, %f1525;
	mul.ftz.f32 	%f3754, %f1540, %f1533;
	mul.ftz.f32 	%f1541, %f3736, %f3746;
	mul.ftz.f32 	%f1542, %f3738, %f3744;
	sub.ftz.f32 	%f1543, %f1542, %f1541;
	mul.ftz.f32 	%f3753, %f1543, %f1533;
	mul.ftz.f32 	%f1544, %f3738, %f3740;
	mul.ftz.f32 	%f1545, %f3736, %f3742;
	sub.ftz.f32 	%f1546, %f1545, %f1544;
	mul.ftz.f32 	%f3752, %f1546, %f1533;
	mul.ftz.f32 	%f3758, %f1531, %f1533;
	mul.ftz.f32 	%f1547, %f3738, %f3745;
	mul.ftz.f32 	%f1548, %f3737, %f3746;
	sub.ftz.f32 	%f1549, %f1548, %f1547;
	mul.ftz.f32 	%f3757, %f1549, %f1533;
	mul.ftz.f32 	%f1550, %f3737, %f3742;
	mul.ftz.f32 	%f1551, %f3738, %f3741;
	sub.ftz.f32 	%f1552, %f1551, %f1550;
	mul.ftz.f32 	%f3756, %f1552, %f1533;
	mul.ftz.f32 	%f1553, %f3735, %f3750;
	neg.ftz.f32 	%f1554, %f1553;
	mul.ftz.f32 	%f1555, %f3739, %f3749;
	sub.ftz.f32 	%f1556, %f1554, %f1555;
	mul.ftz.f32 	%f1557, %f3743, %f3748;
	sub.ftz.f32 	%f3747, %f1556, %f1557;
	mul.ftz.f32 	%f1558, %f3735, %f3754;
	neg.ftz.f32 	%f1559, %f1558;
	mul.ftz.f32 	%f1560, %f3739, %f3753;
	sub.ftz.f32 	%f1561, %f1559, %f1560;
	mul.ftz.f32 	%f1562, %f3743, %f3752;
	sub.ftz.f32 	%f3751, %f1561, %f1562;
	mul.ftz.f32 	%f1563, %f3735, %f3758;
	neg.ftz.f32 	%f1564, %f1563;
	mul.ftz.f32 	%f1565, %f3739, %f3757;
	sub.ftz.f32 	%f1566, %f1564, %f1565;
	mul.ftz.f32 	%f1567, %f3743, %f3756;
	sub.ftz.f32 	%f3755, %f1566, %f1567;
	bra.uni 	$L__BB0_19;

$L__BB0_10:
	// begin inline asm
	call (%rd796), _optix_get_instance_inverse_transform_from_handle, (%rd57);
	// end inline asm

$L__BB0_11:
	// begin inline asm
	cvta.to.global.u64 %rd63, %rd796;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r131,%r132,%r133,%r134}, [%rd63];
	// end inline asm
	mov.b32 	%f3750, %r131;
	mov.b32 	%f3749, %r132;
	mov.b32 	%f3748, %r133;
	mov.b32 	%f3747, %r134;
	add.s64 	%rd67, %rd796, 16;
	// begin inline asm
	cvta.to.global.u64 %rd66, %rd67;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r135,%r136,%r137,%r138}, [%rd66];
	// end inline asm
	mov.b32 	%f3754, %r135;
	mov.b32 	%f3753, %r136;
	mov.b32 	%f3752, %r137;
	mov.b32 	%f3751, %r138;
	add.s64 	%rd70, %rd796, 32;
	// begin inline asm
	cvta.to.global.u64 %rd69, %rd70;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r139,%r140,%r141,%r142}, [%rd69];
	// end inline asm
	mov.b32 	%f3758, %r139;
	mov.b32 	%f3757, %r140;
	mov.b32 	%f3756, %r141;
	mov.b32 	%f3755, %r142;

$L__BB0_19:
	setp.eq.s32 	%p12, %r1341, 0;
	@%p12 bra 	$L__BB0_21;

	mul.ftz.f32 	%f1568, %f3715, %f3750;
	fma.rn.ftz.f32 	%f1569, %f3711, %f3749, %f1568;
	fma.rn.ftz.f32 	%f165, %f3707, %f3748, %f1569;
	mul.ftz.f32 	%f1570, %f3716, %f3750;
	fma.rn.ftz.f32 	%f1571, %f3712, %f3749, %f1570;
	fma.rn.ftz.f32 	%f166, %f3708, %f3748, %f1571;
	mul.ftz.f32 	%f1572, %f3717, %f3750;
	fma.rn.ftz.f32 	%f1573, %f3713, %f3749, %f1572;
	fma.rn.ftz.f32 	%f167, %f3709, %f3748, %f1573;
	mul.ftz.f32 	%f1574, %f3718, %f3750;
	fma.rn.ftz.f32 	%f1575, %f3714, %f3749, %f1574;
	fma.rn.ftz.f32 	%f1576, %f3710, %f3748, %f1575;
	add.ftz.f32 	%f3747, %f3747, %f1576;
	mul.ftz.f32 	%f1577, %f3715, %f3754;
	fma.rn.ftz.f32 	%f1578, %f3711, %f3753, %f1577;
	fma.rn.ftz.f32 	%f169, %f3707, %f3752, %f1578;
	mul.ftz.f32 	%f1579, %f3716, %f3754;
	fma.rn.ftz.f32 	%f1580, %f3712, %f3753, %f1579;
	fma.rn.ftz.f32 	%f170, %f3708, %f3752, %f1580;
	mul.ftz.f32 	%f1581, %f3717, %f3754;
	fma.rn.ftz.f32 	%f1582, %f3713, %f3753, %f1581;
	fma.rn.ftz.f32 	%f171, %f3709, %f3752, %f1582;
	mul.ftz.f32 	%f1583, %f3718, %f3754;
	fma.rn.ftz.f32 	%f1584, %f3714, %f3753, %f1583;
	fma.rn.ftz.f32 	%f1585, %f3710, %f3752, %f1584;
	add.ftz.f32 	%f3751, %f3751, %f1585;
	mul.ftz.f32 	%f1586, %f3715, %f3758;
	fma.rn.ftz.f32 	%f1587, %f3711, %f3757, %f1586;
	fma.rn.ftz.f32 	%f173, %f3707, %f3756, %f1587;
	mul.ftz.f32 	%f1588, %f3716, %f3758;
	fma.rn.ftz.f32 	%f1589, %f3712, %f3757, %f1588;
	fma.rn.ftz.f32 	%f174, %f3708, %f3756, %f1589;
	mul.ftz.f32 	%f1590, %f3717, %f3758;
	fma.rn.ftz.f32 	%f1591, %f3713, %f3757, %f1590;
	fma.rn.ftz.f32 	%f175, %f3709, %f3756, %f1591;
	mul.ftz.f32 	%f1592, %f3718, %f3758;
	fma.rn.ftz.f32 	%f1593, %f3714, %f3757, %f1592;
	fma.rn.ftz.f32 	%f1594, %f3710, %f3756, %f1593;
	add.ftz.f32 	%f3755, %f3755, %f1594;
	mov.f32 	%f3748, %f167;
	mov.f32 	%f3749, %f166;
	mov.f32 	%f3750, %f165;
	mov.f32 	%f3752, %f171;
	mov.f32 	%f3753, %f170;
	mov.f32 	%f3754, %f169;
	mov.f32 	%f3756, %f175;
	mov.f32 	%f3757, %f174;
	mov.f32 	%f3758, %f173;

$L__BB0_21:
	add.s32 	%r1341, %r1341, 1;
	setp.lt.u32 	%p13, %r1341, %r126;
	mov.f32 	%f3707, %f3758;
	mov.f32 	%f3708, %f3757;
	mov.f32 	%f3709, %f3756;
	mov.f32 	%f3710, %f3755;
	mov.f32 	%f3711, %f3754;
	mov.f32 	%f3712, %f3753;
	mov.f32 	%f3713, %f3752;
	mov.f32 	%f3714, %f3751;
	mov.f32 	%f3715, %f3750;
	mov.f32 	%f3716, %f3749;
	mov.f32 	%f3717, %f3748;
	mov.f32 	%f3718, %f3747;
	@%p13 bra 	$L__BB0_6;

$L__BB0_22:
	mul.ftz.f32 	%f1595, %f1, %f3750;
	fma.rn.ftz.f32 	%f1596, %f2, %f3749, %f1595;
	fma.rn.ftz.f32 	%f1597, %f3, %f3748, %f1596;
	mul.ftz.f32 	%f1598, %f1, %f3754;
	fma.rn.ftz.f32 	%f1599, %f2, %f3753, %f1598;
	fma.rn.ftz.f32 	%f1600, %f3, %f3752, %f1599;
	mul.ftz.f32 	%f1601, %f1, %f3758;
	fma.rn.ftz.f32 	%f1602, %f2, %f3757, %f1601;
	fma.rn.ftz.f32 	%f1603, %f3, %f3756, %f1602;
	add.ftz.f32 	%f209, %f3755, %f1603;
	add.ftz.f32 	%f208, %f3751, %f1600;
	add.ftz.f32 	%f207, %f3747, %f1597;
	bra.uni 	$L__BB0_24;

$L__BB0_97:
	// begin inline asm
	call (%rd535), _optix_get_gas_traversable_handle, ();
	// end inline asm
	// begin inline asm
	call (%r738), _optix_read_sbt_gas_idx, ();
	// end inline asm
	mov.f32 	%f2437, 0f00000000;
	// begin inline asm
	call (%f2425, %f2426, %f2427, %f2428,  %f2429, %f2430, %f2431, %f2432,  %f2433, %f2434, %f2435, %f2436), _optix_get_quadratic_bspline_vertex_data, (%rd535, %r115, %r738, %f2437);
	// end inline asm
	mul.ftz.f32 	%f2438, %f2425, 0f3F000000;
	mul.ftz.f32 	%f2439, %f2426, 0f3F000000;
	mul.ftz.f32 	%f2440, %f2427, 0f3F000000;
	mul.ftz.f32 	%f2441, %f2428, 0f3F000000;
	fma.rn.ftz.f32 	%f744, %f2429, 0f3F000000, %f2438;
	fma.rn.ftz.f32 	%f745, %f2430, 0f3F000000, %f2439;
	fma.rn.ftz.f32 	%f746, %f2431, 0f3F000000, %f2440;
	fma.rn.ftz.f32 	%f747, %f2432, 0f3F000000, %f2441;
	sub.ftz.f32 	%f748, %f2429, %f2425;
	sub.ftz.f32 	%f749, %f2430, %f2426;
	sub.ftz.f32 	%f750, %f2431, %f2427;
	sub.ftz.f32 	%f751, %f2432, %f2428;
	sub.ftz.f32 	%f2442, %f2438, %f2429;
	sub.ftz.f32 	%f2443, %f2439, %f2430;
	sub.ftz.f32 	%f2444, %f2440, %f2431;
	sub.ftz.f32 	%f2445, %f2441, %f2432;
	fma.rn.ftz.f32 	%f752, %f2433, 0f3F000000, %f2442;
	fma.rn.ftz.f32 	%f753, %f2434, 0f3F000000, %f2443;
	fma.rn.ftz.f32 	%f754, %f2435, 0f3F000000, %f2444;
	fma.rn.ftz.f32 	%f755, %f2436, 0f3F000000, %f2445;
	// begin inline asm
	call (%r741), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p48, %r741, 0;
	@%p48 bra 	$L__BB0_117;

	// begin inline asm
	call (%r742), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f2446), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p49, %r742, 0;
	@%p49 bra 	$L__BB0_116;

	mov.u32 	%r1345, 0;

$L__BB0_100:
	.pragma "nounroll";
	// begin inline asm
	call (%rd537), _optix_get_transform_list_handle, (%r1345);
	// end inline asm
	// begin inline asm
	call (%r745), _optix_get_transform_type_from_handle, (%rd537);
	// end inline asm
	or.b32  	%r746, %r745, 1;
	setp.eq.s32 	%p50, %r746, 3;
	@%p50 bra 	$L__BB0_106;
	bra.uni 	$L__BB0_101;

$L__BB0_106:
	setp.eq.s32 	%p53, %r745, 2;
	@%p53 bra 	$L__BB0_110;
	bra.uni 	$L__BB0_107;

$L__BB0_110:
	// begin inline asm
	call (%rd609), _optix_get_matrix_motion_transform_from_handle, (%rd537);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd611, %rd609;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r834,%r835,%r836,%r837}, [%rd611];
	// end inline asm
	add.s64 	%rd615, %rd609, 16;
	// begin inline asm
	cvta.to.global.u64 %rd614, %rd615;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r838,%r839,%r840,%r841}, [%rd614];
	// end inline asm
	add.s64 	%rd618, %rd609, 32;
	// begin inline asm
	cvta.to.global.u64 %rd617, %rd618;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r842,%r843,%r844,%r845}, [%rd617];
	// end inline asm
	add.s64 	%rd621, %rd609, 48;
	// begin inline asm
	cvta.to.global.u64 %rd620, %rd621;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r846,%r847,%r848,%r849}, [%rd620];
	// end inline asm
	add.s64 	%rd624, %rd609, 64;
	// begin inline asm
	cvta.to.global.u64 %rd623, %rd624;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r850,%r851,%r852,%r853}, [%rd623];
	// end inline asm
	add.s64 	%rd627, %rd609, 80;
	// begin inline asm
	cvta.to.global.u64 %rd626, %rd627;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r854,%r855,%r856,%r857}, [%rd626];
	// end inline asm
	add.s64 	%rd630, %rd609, 96;
	// begin inline asm
	cvta.to.global.u64 %rd629, %rd630;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r858,%r859,%r860,%r861}, [%rd629];
	// end inline asm
	add.s64 	%rd633, %rd609, 112;
	// begin inline asm
	cvta.to.global.u64 %rd632, %rd633;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r862,%r863,%r864,%r865}, [%rd632];
	// end inline asm
	mov.b32 	%f2573, %r837;
	mov.b32 	%f2574, %r838;
	and.b32  	%r878, %r836, 65535;
	add.s32 	%r879, %r878, -1;
	cvt.rn.f32.s32 	%f2575, %r879;
	sub.ftz.f32 	%f2576, %f2446, %f2573;
	mul.ftz.f32 	%f2577, %f2576, %f2575;
	sub.ftz.f32 	%f2578, %f2574, %f2573;
	div.approx.ftz.f32 	%f2579, %f2577, %f2578;
	min.ftz.f32 	%f2580, %f2575, %f2579;
	mov.f32 	%f2581, 0f00000000;
	max.ftz.f32 	%f2582, %f2581, %f2580;
	cvt.rmi.ftz.f32.f32 	%f2583, %f2582;
	sub.ftz.f32 	%f842, %f2582, %f2583;
	cvt.rzi.ftz.s32.f32 	%r880, %f2583;
	cvt.s64.s32 	%rd36, %r880;
	mul.wide.s32 	%rd644, %r880, 48;
	add.s64 	%rd636, %rd618, %rd644;
	// begin inline asm
	cvta.to.global.u64 %rd635, %rd636;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r866,%r867,%r868,%r869}, [%rd635];
	// end inline asm
	mov.b32 	%f4017, %r866;
	mov.b32 	%f4018, %r867;
	mov.b32 	%f4019, %r868;
	mov.b32 	%f4020, %r869;
	add.s64 	%rd639, %rd636, 16;
	// begin inline asm
	cvta.to.global.u64 %rd638, %rd639;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r870,%r871,%r872,%r873}, [%rd638];
	// end inline asm
	mov.b32 	%f4013, %r870;
	mov.b32 	%f4014, %r871;
	mov.b32 	%f4015, %r872;
	mov.b32 	%f4016, %r873;
	add.s64 	%rd642, %rd636, 32;
	// begin inline asm
	cvta.to.global.u64 %rd641, %rd642;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r874,%r875,%r876,%r877}, [%rd641];
	// end inline asm
	mov.b32 	%f4009, %r874;
	mov.b32 	%f4010, %r875;
	mov.b32 	%f4011, %r876;
	mov.b32 	%f4012, %r877;
	setp.leu.ftz.f32 	%p55, %f842, 0f00000000;
	@%p55 bra 	$L__BB0_112;

	mov.f32 	%f2584, 0f3F800000;
	sub.ftz.f32 	%f2585, %f2584, %f842;
	mul.lo.s64 	%rd654, %rd36, 48;
	add.s64 	%rd655, %rd609, %rd654;
	add.s64 	%rd646, %rd655, 80;
	// begin inline asm
	cvta.to.global.u64 %rd645, %rd646;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r881,%r882,%r883,%r884}, [%rd645];
	// end inline asm
	mov.b32 	%f2586, %r881;
	mov.b32 	%f2587, %r882;
	mov.b32 	%f2588, %r883;
	mov.b32 	%f2589, %r884;
	mul.ftz.f32 	%f2590, %f842, %f2586;
	mul.ftz.f32 	%f2591, %f842, %f2587;
	mul.ftz.f32 	%f2592, %f842, %f2588;
	mul.ftz.f32 	%f2593, %f842, %f2589;
	fma.rn.ftz.f32 	%f4017, %f2585, %f4017, %f2590;
	fma.rn.ftz.f32 	%f4018, %f2585, %f4018, %f2591;
	fma.rn.ftz.f32 	%f4019, %f2585, %f4019, %f2592;
	fma.rn.ftz.f32 	%f4020, %f2585, %f4020, %f2593;
	add.s64 	%rd649, %rd655, 96;
	// begin inline asm
	cvta.to.global.u64 %rd648, %rd649;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r885,%r886,%r887,%r888}, [%rd648];
	// end inline asm
	mov.b32 	%f2594, %r885;
	mov.b32 	%f2595, %r886;
	mov.b32 	%f2596, %r887;
	mov.b32 	%f2597, %r888;
	mul.ftz.f32 	%f2598, %f842, %f2594;
	mul.ftz.f32 	%f2599, %f842, %f2595;
	mul.ftz.f32 	%f2600, %f842, %f2596;
	mul.ftz.f32 	%f2601, %f842, %f2597;
	fma.rn.ftz.f32 	%f4013, %f2585, %f4013, %f2598;
	fma.rn.ftz.f32 	%f4014, %f2585, %f4014, %f2599;
	fma.rn.ftz.f32 	%f4015, %f2585, %f4015, %f2600;
	fma.rn.ftz.f32 	%f4016, %f2585, %f4016, %f2601;
	add.s64 	%rd652, %rd655, 112;
	// begin inline asm
	cvta.to.global.u64 %rd651, %rd652;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r889,%r890,%r891,%r892}, [%rd651];
	// end inline asm
	mov.b32 	%f2602, %r889;
	mov.b32 	%f2603, %r890;
	mov.b32 	%f2604, %r891;
	mov.b32 	%f2605, %r892;
	mul.ftz.f32 	%f2606, %f842, %f2602;
	mul.ftz.f32 	%f2607, %f842, %f2603;
	mul.ftz.f32 	%f2608, %f842, %f2604;
	mul.ftz.f32 	%f2609, %f842, %f2605;
	fma.rn.ftz.f32 	%f4009, %f2585, %f4009, %f2606;
	fma.rn.ftz.f32 	%f4010, %f2585, %f4010, %f2607;
	fma.rn.ftz.f32 	%f4011, %f2585, %f4011, %f2608;
	fma.rn.ftz.f32 	%f4012, %f2585, %f4012, %f2609;
	bra.uni 	$L__BB0_112;

$L__BB0_101:
	mov.f32 	%f4023, 0f3F800000;
	setp.eq.s32 	%p51, %r745, 4;
	@%p51 bra 	$L__BB0_104;

	setp.ne.s32 	%p52, %r745, 1;
	mov.f32 	%f4021, %f2437;
	mov.f32 	%f4022, %f2437;
	mov.f32 	%f4024, %f2437;
	mov.f32 	%f4025, %f2437;
	mov.f32 	%f4026, %f4023;
	mov.f32 	%f4027, %f2437;
	mov.f32 	%f4028, %f2437;
	mov.f32 	%f4029, %f4023;
	mov.f32 	%f4030, %f2437;
	mov.f32 	%f4031, %f2437;
	mov.f32 	%f4032, %f2437;
	@%p52 bra 	$L__BB0_113;

	// begin inline asm
	call (%rd539), _optix_get_static_transform_from_handle, (%rd537);
	// end inline asm
	add.s64 	%rd800, %rd539, 64;
	bra.uni 	$L__BB0_105;

$L__BB0_107:
	// begin inline asm
	call (%rd552), _optix_get_srt_motion_transform_from_handle, (%rd537);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd554, %rd552;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r759,%r760,%r761,%r762}, [%rd554];
	// end inline asm
	add.s64 	%rd558, %rd552, 16;
	// begin inline asm
	cvta.to.global.u64 %rd557, %rd558;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r763,%r764,%r765,%r766}, [%rd557];
	// end inline asm
	add.s64 	%rd561, %rd552, 32;
	// begin inline asm
	cvta.to.global.u64 %rd560, %rd561;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r767,%r768,%r769,%r770}, [%rd560];
	// end inline asm
	add.s64 	%rd564, %rd552, 48;
	// begin inline asm
	cvta.to.global.u64 %rd563, %rd564;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r771,%r772,%r773,%r774}, [%rd563];
	// end inline asm
	add.s64 	%rd567, %rd552, 64;
	// begin inline asm
	cvta.to.global.u64 %rd566, %rd567;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r775,%r776,%r777,%r778}, [%rd566];
	// end inline asm
	add.s64 	%rd570, %rd552, 80;
	// begin inline asm
	cvta.to.global.u64 %rd569, %rd570;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r779,%r780,%r781,%r782}, [%rd569];
	// end inline asm
	add.s64 	%rd573, %rd552, 96;
	// begin inline asm
	cvta.to.global.u64 %rd572, %rd573;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r783,%r784,%r785,%r786}, [%rd572];
	// end inline asm
	add.s64 	%rd576, %rd552, 112;
	// begin inline asm
	cvta.to.global.u64 %rd575, %rd576;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r787,%r788,%r789,%r790}, [%rd575];
	// end inline asm
	add.s64 	%rd579, %rd552, 128;
	// begin inline asm
	cvta.to.global.u64 %rd578, %rd579;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r791,%r792,%r793,%r794}, [%rd578];
	// end inline asm
	add.s64 	%rd582, %rd552, 144;
	// begin inline asm
	cvta.to.global.u64 %rd581, %rd582;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r795,%r796,%r797,%r798}, [%rd581];
	// end inline asm
	mov.b32 	%f2461, %r762;
	mov.b32 	%f2462, %r763;
	and.b32  	%r815, %r761, 65535;
	add.s32 	%r816, %r815, -1;
	cvt.rn.f32.s32 	%f2463, %r816;
	sub.ftz.f32 	%f2464, %f2446, %f2461;
	mul.ftz.f32 	%f2465, %f2464, %f2463;
	sub.ftz.f32 	%f2466, %f2462, %f2461;
	div.approx.ftz.f32 	%f2467, %f2465, %f2466;
	min.ftz.f32 	%f2468, %f2463, %f2467;
	mov.f32 	%f2469, 0f00000000;
	max.ftz.f32 	%f2470, %f2469, %f2468;
	cvt.rmi.ftz.f32.f32 	%f2471, %f2470;
	sub.ftz.f32 	%f781, %f2470, %f2471;
	cvt.rzi.ftz.s32.f32 	%r817, %f2471;
	mul.wide.s32 	%rd596, %r817, 64;
	add.s64 	%rd585, %rd561, %rd596;
	// begin inline asm
	cvta.to.global.u64 %rd584, %rd585;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r799,%r800,%r801,%r802}, [%rd584];
	// end inline asm
	mov.b32 	%f4004, %r799;
	mov.b32 	%f4003, %r800;
	mov.b32 	%f4002, %r801;
	mov.b32 	%f4001, %r802;
	add.s64 	%rd588, %rd585, 16;
	// begin inline asm
	cvta.to.global.u64 %rd587, %rd588;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r803,%r804,%r805,%r806}, [%rd587];
	// end inline asm
	mov.b32 	%f4000, %r803;
	mov.b32 	%f3999, %r804;
	mov.b32 	%f3998, %r805;
	mov.b32 	%f3997, %r806;
	add.s64 	%rd591, %rd585, 32;
	// begin inline asm
	cvta.to.global.u64 %rd590, %rd591;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r807,%r808,%r809,%r810}, [%rd590];
	// end inline asm
	mov.b32 	%f3996, %r807;
	mov.b32 	%f3995, %r808;
	mov.b32 	%f3994, %r809;
	mov.b32 	%f3993, %r810;
	add.s64 	%rd594, %rd585, 48;
	// begin inline asm
	cvta.to.global.u64 %rd593, %rd594;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r811,%r812,%r813,%r814}, [%rd593];
	// end inline asm
	mov.b32 	%f4005, %r811;
	mov.b32 	%f4006, %r812;
	mov.b32 	%f4007, %r813;
	mov.b32 	%f4008, %r814;
	setp.leu.ftz.f32 	%p54, %f781, 0f00000000;
	@%p54 bra 	$L__BB0_109;

	mov.f32 	%f2472, 0f3F800000;
	sub.ftz.f32 	%f2473, %f2472, %f781;
	add.s64 	%rd598, %rd585, 64;
	// begin inline asm
	cvta.to.global.u64 %rd597, %rd598;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r818,%r819,%r820,%r821}, [%rd597];
	// end inline asm
	mov.b32 	%f2474, %r818;
	mov.b32 	%f2475, %r819;
	mov.b32 	%f2476, %r820;
	mov.b32 	%f2477, %r821;
	mul.ftz.f32 	%f2478, %f781, %f2474;
	mul.ftz.f32 	%f2479, %f781, %f2475;
	mul.ftz.f32 	%f2480, %f781, %f2476;
	mul.ftz.f32 	%f2481, %f781, %f2477;
	fma.rn.ftz.f32 	%f4004, %f2473, %f4004, %f2478;
	fma.rn.ftz.f32 	%f4003, %f2473, %f4003, %f2479;
	fma.rn.ftz.f32 	%f4002, %f2473, %f4002, %f2480;
	fma.rn.ftz.f32 	%f4001, %f2473, %f4001, %f2481;
	add.s64 	%rd601, %rd585, 80;
	// begin inline asm
	cvta.to.global.u64 %rd600, %rd601;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r822,%r823,%r824,%r825}, [%rd600];
	// end inline asm
	mov.b32 	%f2482, %r822;
	mov.b32 	%f2483, %r823;
	mov.b32 	%f2484, %r824;
	mov.b32 	%f2485, %r825;
	mul.ftz.f32 	%f2486, %f781, %f2482;
	mul.ftz.f32 	%f2487, %f781, %f2483;
	mul.ftz.f32 	%f2488, %f781, %f2484;
	mul.ftz.f32 	%f2489, %f781, %f2485;
	fma.rn.ftz.f32 	%f4000, %f2473, %f4000, %f2486;
	fma.rn.ftz.f32 	%f3999, %f2473, %f3999, %f2487;
	fma.rn.ftz.f32 	%f3998, %f2473, %f3998, %f2488;
	fma.rn.ftz.f32 	%f3997, %f2473, %f3997, %f2489;
	add.s64 	%rd604, %rd585, 96;
	// begin inline asm
	cvta.to.global.u64 %rd603, %rd604;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r826,%r827,%r828,%r829}, [%rd603];
	// end inline asm
	mov.b32 	%f2490, %r826;
	mov.b32 	%f2491, %r827;
	mov.b32 	%f2492, %r828;
	mov.b32 	%f2493, %r829;
	mul.ftz.f32 	%f2494, %f781, %f2490;
	mul.ftz.f32 	%f2495, %f781, %f2491;
	mul.ftz.f32 	%f2496, %f781, %f2492;
	mul.ftz.f32 	%f2497, %f781, %f2493;
	fma.rn.ftz.f32 	%f3996, %f2473, %f3996, %f2494;
	fma.rn.ftz.f32 	%f2498, %f2473, %f3995, %f2495;
	fma.rn.ftz.f32 	%f2499, %f2473, %f3994, %f2496;
	fma.rn.ftz.f32 	%f2500, %f2473, %f3993, %f2497;
	add.s64 	%rd607, %rd585, 112;
	// begin inline asm
	cvta.to.global.u64 %rd606, %rd607;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r830,%r831,%r832,%r833}, [%rd606];
	// end inline asm
	mov.b32 	%f2501, %r830;
	mov.b32 	%f2502, %r831;
	mov.b32 	%f2503, %r832;
	mov.b32 	%f2504, %r833;
	mul.ftz.f32 	%f2505, %f781, %f2501;
	mul.ftz.f32 	%f2506, %f781, %f2502;
	mul.ftz.f32 	%f2507, %f781, %f2503;
	mul.ftz.f32 	%f2508, %f781, %f2504;
	fma.rn.ftz.f32 	%f2509, %f2473, %f4005, %f2505;
	fma.rn.ftz.f32 	%f4006, %f2473, %f4006, %f2506;
	fma.rn.ftz.f32 	%f4007, %f2473, %f4007, %f2507;
	fma.rn.ftz.f32 	%f4008, %f2473, %f4008, %f2508;
	mul.ftz.f32 	%f2510, %f2499, %f2499;
	fma.rn.ftz.f32 	%f2511, %f2498, %f2498, %f2510;
	fma.rn.ftz.f32 	%f2512, %f2500, %f2500, %f2511;
	fma.rn.ftz.f32 	%f2513, %f2509, %f2509, %f2512;
	rsqrt.approx.ftz.f32 	%f2514, %f2513;
	mul.ftz.f32 	%f3995, %f2498, %f2514;
	mul.ftz.f32 	%f3994, %f2499, %f2514;
	mul.ftz.f32 	%f3993, %f2500, %f2514;
	mul.ftz.f32 	%f4005, %f2514, %f2509;

$L__BB0_109:
	mul.ftz.f32 	%f2515, %f3995, %f3995;
	fma.rn.ftz.f32 	%f2516, %f3994, %f3994, %f2515;
	fma.rn.ftz.f32 	%f2517, %f3993, %f3993, %f2516;
	fma.rn.ftz.f32 	%f2518, %f4005, %f4005, %f2517;
	rcp.approx.ftz.f32 	%f2519, %f2518;
	mul.ftz.f32 	%f2520, %f3995, %f2519;
	mul.ftz.f32 	%f2521, %f3994, %f2519;
	mul.ftz.f32 	%f2522, %f3993, %f2519;
	mul.ftz.f32 	%f2523, %f4005, %f2519;
	mul.ftz.f32 	%f2524, %f3995, %f2520;
	mul.ftz.f32 	%f2525, %f3994, %f2521;
	mul.ftz.f32 	%f2526, %f3993, %f2522;
	mul.ftz.f32 	%f2527, %f3995, %f2521;
	mul.ftz.f32 	%f2528, %f3993, %f2523;
	mul.ftz.f32 	%f2529, %f3995, %f2522;
	mul.ftz.f32 	%f2530, %f3994, %f2523;
	mul.ftz.f32 	%f2531, %f3994, %f2522;
	mul.ftz.f32 	%f2532, %f3995, %f2523;
	sub.ftz.f32 	%f2533, %f2524, %f2525;
	sub.ftz.f32 	%f2534, %f2533, %f2526;
	fma.rn.ftz.f32 	%f2535, %f4005, %f2523, %f2534;
	sub.ftz.f32 	%f2536, %f2527, %f2528;
	add.ftz.f32 	%f2537, %f2536, %f2536;
	add.ftz.f32 	%f2538, %f2529, %f2530;
	add.ftz.f32 	%f2539, %f2538, %f2538;
	add.ftz.f32 	%f2540, %f2527, %f2528;
	add.ftz.f32 	%f2541, %f2540, %f2540;
	sub.ftz.f32 	%f2542, %f2525, %f2524;
	sub.ftz.f32 	%f2543, %f2542, %f2526;
	fma.rn.ftz.f32 	%f2544, %f4005, %f2523, %f2543;
	sub.ftz.f32 	%f2545, %f2531, %f2532;
	add.ftz.f32 	%f2546, %f2545, %f2545;
	sub.ftz.f32 	%f2547, %f2529, %f2530;
	add.ftz.f32 	%f2548, %f2547, %f2547;
	add.ftz.f32 	%f2549, %f2531, %f2532;
	add.ftz.f32 	%f2550, %f2549, %f2549;
	neg.ftz.f32 	%f2551, %f2524;
	sub.ftz.f32 	%f2552, %f2551, %f2525;
	add.ftz.f32 	%f2553, %f2526, %f2552;
	fma.rn.ftz.f32 	%f2554, %f4005, %f2523, %f2553;
	mul.ftz.f32 	%f2555, %f4001, %f2535;
	fma.rn.ftz.f32 	%f2556, %f3998, %f2537, %f2555;
	fma.rn.ftz.f32 	%f2557, %f3996, %f2539, %f2556;
	add.ftz.f32 	%f4020, %f4006, %f2557;
	mul.ftz.f32 	%f2558, %f3998, %f2544;
	fma.rn.ftz.f32 	%f2559, %f4001, %f2541, %f2558;
	fma.rn.ftz.f32 	%f2560, %f3996, %f2546, %f2559;
	add.ftz.f32 	%f4016, %f4007, %f2560;
	mul.ftz.f32 	%f2561, %f3998, %f2550;
	fma.rn.ftz.f32 	%f2562, %f4001, %f2548, %f2561;
	fma.rn.ftz.f32 	%f2563, %f3996, %f2554, %f2562;
	add.ftz.f32 	%f4012, %f4008, %f2563;
	mul.ftz.f32 	%f2564, %f4002, %f2535;
	fma.rn.ftz.f32 	%f2565, %f3999, %f2537, %f2564;
	fma.rn.ftz.f32 	%f4019, %f3997, %f2539, %f2565;
	mul.ftz.f32 	%f2566, %f3999, %f2544;
	fma.rn.ftz.f32 	%f2567, %f4002, %f2541, %f2566;
	fma.rn.ftz.f32 	%f4015, %f3997, %f2546, %f2567;
	mul.ftz.f32 	%f2568, %f3999, %f2550;
	fma.rn.ftz.f32 	%f2569, %f4002, %f2548, %f2568;
	fma.rn.ftz.f32 	%f4011, %f3997, %f2554, %f2569;
	mul.ftz.f32 	%f2570, %f4003, %f2535;
	fma.rn.ftz.f32 	%f4018, %f4000, %f2537, %f2570;
	mul.ftz.f32 	%f2571, %f4000, %f2544;
	fma.rn.ftz.f32 	%f4014, %f4003, %f2541, %f2571;
	mul.ftz.f32 	%f2572, %f4000, %f2550;
	fma.rn.ftz.f32 	%f4010, %f4003, %f2548, %f2572;
	mul.ftz.f32 	%f4017, %f4004, %f2535;
	mul.ftz.f32 	%f4013, %f4004, %f2541;
	mul.ftz.f32 	%f4009, %f4004, %f2548;

$L__BB0_112:
	mul.ftz.f32 	%f2610, %f4010, %f4015;
	mul.ftz.f32 	%f2611, %f4011, %f4014;
	sub.ftz.f32 	%f2612, %f2611, %f2610;
	mul.ftz.f32 	%f2613, %f4017, %f2612;
	mul.ftz.f32 	%f2614, %f4009, %f4015;
	mul.ftz.f32 	%f2615, %f4011, %f4013;
	sub.ftz.f32 	%f2616, %f2615, %f2614;
	mul.ftz.f32 	%f2617, %f2616, %f4018;
	sub.ftz.f32 	%f2618, %f2613, %f2617;
	mul.ftz.f32 	%f2619, %f4009, %f4014;
	mul.ftz.f32 	%f2620, %f4010, %f4013;
	sub.ftz.f32 	%f2621, %f2620, %f2619;
	fma.rn.ftz.f32 	%f2622, %f2621, %f4019, %f2618;
	rcp.approx.ftz.f32 	%f2623, %f2622;
	mul.ftz.f32 	%f4029, %f2612, %f2623;
	mul.ftz.f32 	%f2624, %f4011, %f4018;
	mul.ftz.f32 	%f2625, %f4010, %f4019;
	sub.ftz.f32 	%f2626, %f2625, %f2624;
	mul.ftz.f32 	%f4030, %f2626, %f2623;
	mul.ftz.f32 	%f2627, %f4014, %f4019;
	mul.ftz.f32 	%f2628, %f4015, %f4018;
	sub.ftz.f32 	%f2629, %f2628, %f2627;
	mul.ftz.f32 	%f4031, %f2629, %f2623;
	sub.ftz.f32 	%f2630, %f2614, %f2615;
	mul.ftz.f32 	%f4025, %f2630, %f2623;
	mul.ftz.f32 	%f2631, %f4009, %f4019;
	mul.ftz.f32 	%f2632, %f4011, %f4017;
	sub.ftz.f32 	%f2633, %f2632, %f2631;
	mul.ftz.f32 	%f4026, %f2633, %f2623;
	mul.ftz.f32 	%f2634, %f4015, %f4017;
	mul.ftz.f32 	%f2635, %f4013, %f4019;
	sub.ftz.f32 	%f2636, %f2635, %f2634;
	mul.ftz.f32 	%f4027, %f2636, %f2623;
	mul.ftz.f32 	%f4021, %f2621, %f2623;
	mul.ftz.f32 	%f2637, %f4010, %f4017;
	mul.ftz.f32 	%f2638, %f4009, %f4018;
	sub.ftz.f32 	%f2639, %f2638, %f2637;
	mul.ftz.f32 	%f4022, %f2639, %f2623;
	mul.ftz.f32 	%f2640, %f4013, %f4018;
	mul.ftz.f32 	%f2641, %f4014, %f4017;
	sub.ftz.f32 	%f2642, %f2641, %f2640;
	mul.ftz.f32 	%f4023, %f2642, %f2623;
	mul.ftz.f32 	%f2643, %f4020, %f4029;
	neg.ftz.f32 	%f2644, %f2643;
	mul.ftz.f32 	%f2645, %f4016, %f4030;
	sub.ftz.f32 	%f2646, %f2644, %f2645;
	mul.ftz.f32 	%f2647, %f4012, %f4031;
	sub.ftz.f32 	%f4032, %f2646, %f2647;
	mul.ftz.f32 	%f2648, %f4020, %f4025;
	neg.ftz.f32 	%f2649, %f2648;
	mul.ftz.f32 	%f2650, %f4016, %f4026;
	sub.ftz.f32 	%f2651, %f2649, %f2650;
	mul.ftz.f32 	%f2652, %f4012, %f4027;
	sub.ftz.f32 	%f4028, %f2651, %f2652;
	mul.ftz.f32 	%f2653, %f4020, %f4021;
	neg.ftz.f32 	%f2654, %f2653;
	mul.ftz.f32 	%f2655, %f4016, %f4022;
	sub.ftz.f32 	%f2656, %f2654, %f2655;
	mul.ftz.f32 	%f2657, %f4012, %f4023;
	sub.ftz.f32 	%f4024, %f2656, %f2657;
	bra.uni 	$L__BB0_113;

$L__BB0_104:
	// begin inline asm
	call (%rd800), _optix_get_instance_inverse_transform_from_handle, (%rd537);
	// end inline asm

$L__BB0_105:
	// begin inline asm
	cvta.to.global.u64 %rd543, %rd800;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r747,%r748,%r749,%r750}, [%rd543];
	// end inline asm
	mov.b32 	%f4029, %r747;
	mov.b32 	%f4030, %r748;
	mov.b32 	%f4031, %r749;
	mov.b32 	%f4032, %r750;
	add.s64 	%rd547, %rd800, 16;
	// begin inline asm
	cvta.to.global.u64 %rd546, %rd547;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r751,%r752,%r753,%r754}, [%rd546];
	// end inline asm
	mov.b32 	%f4025, %r751;
	mov.b32 	%f4026, %r752;
	mov.b32 	%f4027, %r753;
	mov.b32 	%f4028, %r754;
	add.s64 	%rd550, %rd800, 32;
	// begin inline asm
	cvta.to.global.u64 %rd549, %rd550;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r755,%r756,%r757,%r758}, [%rd549];
	// end inline asm
	mov.b32 	%f4021, %r755;
	mov.b32 	%f4022, %r756;
	mov.b32 	%f4023, %r757;
	mov.b32 	%f4024, %r758;

$L__BB0_113:
	setp.eq.s32 	%p56, %r1345, 0;
	@%p56 bra 	$L__BB0_115;

	mul.ftz.f32 	%f2658, %f3988, %f4030;
	fma.rn.ftz.f32 	%f2659, %f3984, %f4029, %f2658;
	fma.rn.ftz.f32 	%f903, %f3992, %f4031, %f2659;
	mul.ftz.f32 	%f2660, %f3987, %f4030;
	fma.rn.ftz.f32 	%f2661, %f3983, %f4029, %f2660;
	fma.rn.ftz.f32 	%f904, %f3991, %f4031, %f2661;
	mul.ftz.f32 	%f2662, %f3986, %f4030;
	fma.rn.ftz.f32 	%f2663, %f3982, %f4029, %f2662;
	fma.rn.ftz.f32 	%f905, %f3990, %f4031, %f2663;
	mul.ftz.f32 	%f2664, %f3985, %f4030;
	fma.rn.ftz.f32 	%f2665, %f3981, %f4029, %f2664;
	fma.rn.ftz.f32 	%f2666, %f3989, %f4031, %f2665;
	add.ftz.f32 	%f4032, %f4032, %f2666;
	mul.ftz.f32 	%f2667, %f3988, %f4026;
	fma.rn.ftz.f32 	%f2668, %f3984, %f4025, %f2667;
	fma.rn.ftz.f32 	%f907, %f3992, %f4027, %f2668;
	mul.ftz.f32 	%f2669, %f3987, %f4026;
	fma.rn.ftz.f32 	%f2670, %f3983, %f4025, %f2669;
	fma.rn.ftz.f32 	%f908, %f3991, %f4027, %f2670;
	mul.ftz.f32 	%f2671, %f3986, %f4026;
	fma.rn.ftz.f32 	%f2672, %f3982, %f4025, %f2671;
	fma.rn.ftz.f32 	%f909, %f3990, %f4027, %f2672;
	mul.ftz.f32 	%f2673, %f3985, %f4026;
	fma.rn.ftz.f32 	%f2674, %f3981, %f4025, %f2673;
	fma.rn.ftz.f32 	%f2675, %f3989, %f4027, %f2674;
	add.ftz.f32 	%f4028, %f4028, %f2675;
	mul.ftz.f32 	%f2676, %f3988, %f4022;
	fma.rn.ftz.f32 	%f2677, %f3984, %f4021, %f2676;
	fma.rn.ftz.f32 	%f911, %f3992, %f4023, %f2677;
	mul.ftz.f32 	%f2678, %f3987, %f4022;
	fma.rn.ftz.f32 	%f2679, %f3983, %f4021, %f2678;
	fma.rn.ftz.f32 	%f912, %f3991, %f4023, %f2679;
	mul.ftz.f32 	%f2680, %f3986, %f4022;
	fma.rn.ftz.f32 	%f2681, %f3982, %f4021, %f2680;
	fma.rn.ftz.f32 	%f913, %f3990, %f4023, %f2681;
	mul.ftz.f32 	%f2682, %f3985, %f4022;
	fma.rn.ftz.f32 	%f2683, %f3981, %f4021, %f2682;
	fma.rn.ftz.f32 	%f2684, %f3989, %f4023, %f2683;
	add.ftz.f32 	%f4024, %f4024, %f2684;
	mov.f32 	%f4021, %f911;
	mov.f32 	%f4022, %f912;
	mov.f32 	%f4023, %f913;
	mov.f32 	%f4025, %f907;
	mov.f32 	%f4026, %f908;
	mov.f32 	%f4027, %f909;
	mov.f32 	%f4029, %f903;
	mov.f32 	%f4030, %f904;
	mov.f32 	%f4031, %f905;

$L__BB0_115:
	add.s32 	%r1345, %r1345, 1;
	setp.lt.u32 	%p57, %r1345, %r742;
	mov.f32 	%f3981, %f4032;
	mov.f32 	%f3982, %f4031;
	mov.f32 	%f3983, %f4030;
	mov.f32 	%f3984, %f4029;
	mov.f32 	%f3985, %f4028;
	mov.f32 	%f3986, %f4027;
	mov.f32 	%f3987, %f4026;
	mov.f32 	%f3988, %f4025;
	mov.f32 	%f3989, %f4024;
	mov.f32 	%f3990, %f4023;
	mov.f32 	%f3991, %f4022;
	mov.f32 	%f3992, %f4021;
	@%p57 bra 	$L__BB0_100;

$L__BB0_116:
	mul.ftz.f32 	%f2685, %f2, %f4030;
	fma.rn.ftz.f32 	%f2686, %f1, %f4029, %f2685;
	fma.rn.ftz.f32 	%f2687, %f3, %f4031, %f2686;
	mul.ftz.f32 	%f2688, %f2, %f4026;
	fma.rn.ftz.f32 	%f2689, %f1, %f4025, %f2688;
	fma.rn.ftz.f32 	%f2690, %f3, %f4027, %f2689;
	mul.ftz.f32 	%f2691, %f2, %f4022;
	fma.rn.ftz.f32 	%f2692, %f1, %f4021, %f2691;
	fma.rn.ftz.f32 	%f2693, %f3, %f4023, %f2692;
	add.ftz.f32 	%f4059, %f4024, %f2693;
	add.ftz.f32 	%f4058, %f4028, %f2690;
	add.ftz.f32 	%f4057, %f4032, %f2687;
	bra.uni 	$L__BB0_118;

$L__BB0_50:
	// begin inline asm
	call (%rd295), _optix_get_gas_traversable_handle, ();
	// end inline asm
	// begin inline asm
	call (%r430), _optix_read_sbt_gas_idx, ();
	// end inline asm
	mov.f32 	%f1854, 0f00000000;
	// begin inline asm
	call (%f1838, %f1839, %f1840, %f1841,  %f1842, %f1843, %f1844, %f1845,  %f1846, %f1847, %f1848, %f1849,  %f1850, %f1851, %f1852, %f1853), _optix_get_cubic_bspline_vertex_data, (%rd295, %r115, %r430, %f1854);
	// end inline asm
	add.ftz.f32 	%f1855, %f1846, %f1838;
	add.ftz.f32 	%f1856, %f1847, %f1839;
	add.ftz.f32 	%f1857, %f1848, %f1840;
	add.ftz.f32 	%f1858, %f1849, %f1841;
	mul.ftz.f32 	%f1859, %f1855, 0f3E2AAAAB;
	mul.ftz.f32 	%f1860, %f1856, 0f3E2AAAAB;
	mul.ftz.f32 	%f1861, %f1857, 0f3E2AAAAB;
	mul.ftz.f32 	%f1862, %f1858, 0f3E2AAAAB;
	fma.rn.ftz.f32 	%f373, %f1842, 0f3F2AAAAB, %f1859;
	fma.rn.ftz.f32 	%f374, %f1843, 0f3F2AAAAB, %f1860;
	fma.rn.ftz.f32 	%f375, %f1844, 0f3F2AAAAB, %f1861;
	fma.rn.ftz.f32 	%f376, %f1845, 0f3F2AAAAB, %f1862;
	sub.ftz.f32 	%f377, %f1846, %f1838;
	sub.ftz.f32 	%f378, %f1847, %f1839;
	sub.ftz.f32 	%f379, %f1848, %f1840;
	sub.ftz.f32 	%f380, %f1849, %f1841;
	sub.ftz.f32 	%f381, %f1846, %f1842;
	sub.ftz.f32 	%f382, %f1847, %f1843;
	sub.ftz.f32 	%f383, %f1848, %f1844;
	sub.ftz.f32 	%f384, %f1849, %f1845;
	sub.ftz.f32 	%f385, %f1850, %f1842;
	sub.ftz.f32 	%f386, %f1851, %f1843;
	sub.ftz.f32 	%f387, %f1852, %f1844;
	sub.ftz.f32 	%f388, %f1853, %f1845;
	// begin inline asm
	call (%r433), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p26, %r433, 0;
	@%p26 bra 	$L__BB0_70;

	// begin inline asm
	call (%r434), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1863), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p27, %r434, 0;
	@%p27 bra 	$L__BB0_69;

	mov.u32 	%r1343, 0;

$L__BB0_53:
	.pragma "nounroll";
	// begin inline asm
	call (%rd297), _optix_get_transform_list_handle, (%r1343);
	// end inline asm
	// begin inline asm
	call (%r437), _optix_get_transform_type_from_handle, (%rd297);
	// end inline asm
	or.b32  	%r438, %r437, 1;
	setp.eq.s32 	%p28, %r438, 3;
	@%p28 bra 	$L__BB0_59;
	bra.uni 	$L__BB0_54;

$L__BB0_59:
	setp.eq.s32 	%p31, %r437, 2;
	@%p31 bra 	$L__BB0_63;
	bra.uni 	$L__BB0_60;

$L__BB0_63:
	// begin inline asm
	call (%rd369), _optix_get_matrix_motion_transform_from_handle, (%rd297);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd371, %rd369;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r526,%r527,%r528,%r529}, [%rd371];
	// end inline asm
	add.s64 	%rd375, %rd369, 16;
	// begin inline asm
	cvta.to.global.u64 %rd374, %rd375;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r530,%r531,%r532,%r533}, [%rd374];
	// end inline asm
	add.s64 	%rd378, %rd369, 32;
	// begin inline asm
	cvta.to.global.u64 %rd377, %rd378;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r534,%r535,%r536,%r537}, [%rd377];
	// end inline asm
	add.s64 	%rd381, %rd369, 48;
	// begin inline asm
	cvta.to.global.u64 %rd380, %rd381;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r538,%r539,%r540,%r541}, [%rd380];
	// end inline asm
	add.s64 	%rd384, %rd369, 64;
	// begin inline asm
	cvta.to.global.u64 %rd383, %rd384;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r542,%r543,%r544,%r545}, [%rd383];
	// end inline asm
	add.s64 	%rd387, %rd369, 80;
	// begin inline asm
	cvta.to.global.u64 %rd386, %rd387;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r546,%r547,%r548,%r549}, [%rd386];
	// end inline asm
	add.s64 	%rd390, %rd369, 96;
	// begin inline asm
	cvta.to.global.u64 %rd389, %rd390;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r550,%r551,%r552,%r553}, [%rd389];
	// end inline asm
	add.s64 	%rd393, %rd369, 112;
	// begin inline asm
	cvta.to.global.u64 %rd392, %rd393;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r554,%r555,%r556,%r557}, [%rd392];
	// end inline asm
	mov.b32 	%f1990, %r529;
	mov.b32 	%f1991, %r530;
	and.b32  	%r570, %r528, 65535;
	add.s32 	%r571, %r570, -1;
	cvt.rn.f32.s32 	%f1992, %r571;
	sub.ftz.f32 	%f1993, %f1863, %f1990;
	mul.ftz.f32 	%f1994, %f1993, %f1992;
	sub.ftz.f32 	%f1995, %f1991, %f1990;
	div.approx.ftz.f32 	%f1996, %f1994, %f1995;
	min.ftz.f32 	%f1997, %f1992, %f1996;
	mov.f32 	%f1998, 0f00000000;
	max.ftz.f32 	%f1999, %f1998, %f1997;
	cvt.rmi.ftz.f32.f32 	%f2000, %f1999;
	sub.ftz.f32 	%f475, %f1999, %f2000;
	cvt.rzi.ftz.s32.f32 	%r572, %f2000;
	cvt.s64.s32 	%rd22, %r572;
	mul.wide.s32 	%rd404, %r572, 48;
	add.s64 	%rd396, %rd378, %rd404;
	// begin inline asm
	cvta.to.global.u64 %rd395, %rd396;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r558,%r559,%r560,%r561}, [%rd395];
	// end inline asm
	mov.b32 	%f3880, %r558;
	mov.b32 	%f3881, %r559;
	mov.b32 	%f3882, %r560;
	mov.b32 	%f3883, %r561;
	add.s64 	%rd399, %rd396, 16;
	// begin inline asm
	cvta.to.global.u64 %rd398, %rd399;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r562,%r563,%r564,%r565}, [%rd398];
	// end inline asm
	mov.b32 	%f3876, %r562;
	mov.b32 	%f3877, %r563;
	mov.b32 	%f3878, %r564;
	mov.b32 	%f3879, %r565;
	add.s64 	%rd402, %rd396, 32;
	// begin inline asm
	cvta.to.global.u64 %rd401, %rd402;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r566,%r567,%r568,%r569}, [%rd401];
	// end inline asm
	mov.b32 	%f3872, %r566;
	mov.b32 	%f3873, %r567;
	mov.b32 	%f3874, %r568;
	mov.b32 	%f3875, %r569;
	setp.leu.ftz.f32 	%p33, %f475, 0f00000000;
	@%p33 bra 	$L__BB0_65;

	mov.f32 	%f2001, 0f3F800000;
	sub.ftz.f32 	%f2002, %f2001, %f475;
	mul.lo.s64 	%rd414, %rd22, 48;
	add.s64 	%rd415, %rd369, %rd414;
	add.s64 	%rd406, %rd415, 80;
	// begin inline asm
	cvta.to.global.u64 %rd405, %rd406;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r573,%r574,%r575,%r576}, [%rd405];
	// end inline asm
	mov.b32 	%f2003, %r573;
	mov.b32 	%f2004, %r574;
	mov.b32 	%f2005, %r575;
	mov.b32 	%f2006, %r576;
	mul.ftz.f32 	%f2007, %f475, %f2003;
	mul.ftz.f32 	%f2008, %f475, %f2004;
	mul.ftz.f32 	%f2009, %f475, %f2005;
	mul.ftz.f32 	%f2010, %f475, %f2006;
	fma.rn.ftz.f32 	%f3880, %f2002, %f3880, %f2007;
	fma.rn.ftz.f32 	%f3881, %f2002, %f3881, %f2008;
	fma.rn.ftz.f32 	%f3882, %f2002, %f3882, %f2009;
	fma.rn.ftz.f32 	%f3883, %f2002, %f3883, %f2010;
	add.s64 	%rd409, %rd415, 96;
	// begin inline asm
	cvta.to.global.u64 %rd408, %rd409;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r577,%r578,%r579,%r580}, [%rd408];
	// end inline asm
	mov.b32 	%f2011, %r577;
	mov.b32 	%f2012, %r578;
	mov.b32 	%f2013, %r579;
	mov.b32 	%f2014, %r580;
	mul.ftz.f32 	%f2015, %f475, %f2011;
	mul.ftz.f32 	%f2016, %f475, %f2012;
	mul.ftz.f32 	%f2017, %f475, %f2013;
	mul.ftz.f32 	%f2018, %f475, %f2014;
	fma.rn.ftz.f32 	%f3876, %f2002, %f3876, %f2015;
	fma.rn.ftz.f32 	%f3877, %f2002, %f3877, %f2016;
	fma.rn.ftz.f32 	%f3878, %f2002, %f3878, %f2017;
	fma.rn.ftz.f32 	%f3879, %f2002, %f3879, %f2018;
	add.s64 	%rd412, %rd415, 112;
	// begin inline asm
	cvta.to.global.u64 %rd411, %rd412;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r581,%r582,%r583,%r584}, [%rd411];
	// end inline asm
	mov.b32 	%f2019, %r581;
	mov.b32 	%f2020, %r582;
	mov.b32 	%f2021, %r583;
	mov.b32 	%f2022, %r584;
	mul.ftz.f32 	%f2023, %f475, %f2019;
	mul.ftz.f32 	%f2024, %f475, %f2020;
	mul.ftz.f32 	%f2025, %f475, %f2021;
	mul.ftz.f32 	%f2026, %f475, %f2022;
	fma.rn.ftz.f32 	%f3872, %f2002, %f3872, %f2023;
	fma.rn.ftz.f32 	%f3873, %f2002, %f3873, %f2024;
	fma.rn.ftz.f32 	%f3874, %f2002, %f3874, %f2025;
	fma.rn.ftz.f32 	%f3875, %f2002, %f3875, %f2026;
	bra.uni 	$L__BB0_65;

$L__BB0_54:
	mov.f32 	%f3886, 0f3F800000;
	setp.eq.s32 	%p29, %r437, 4;
	@%p29 bra 	$L__BB0_57;

	setp.ne.s32 	%p30, %r437, 1;
	mov.f32 	%f3884, %f1854;
	mov.f32 	%f3885, %f1854;
	mov.f32 	%f3887, %f1854;
	mov.f32 	%f3888, %f1854;
	mov.f32 	%f3889, %f3886;
	mov.f32 	%f3890, %f1854;
	mov.f32 	%f3891, %f1854;
	mov.f32 	%f3892, %f3886;
	mov.f32 	%f3893, %f1854;
	mov.f32 	%f3894, %f1854;
	mov.f32 	%f3895, %f1854;
	@%p30 bra 	$L__BB0_66;

	// begin inline asm
	call (%rd299), _optix_get_static_transform_from_handle, (%rd297);
	// end inline asm
	add.s64 	%rd798, %rd299, 64;
	bra.uni 	$L__BB0_58;

$L__BB0_60:
	// begin inline asm
	call (%rd312), _optix_get_srt_motion_transform_from_handle, (%rd297);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd314, %rd312;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r451,%r452,%r453,%r454}, [%rd314];
	// end inline asm
	add.s64 	%rd318, %rd312, 16;
	// begin inline asm
	cvta.to.global.u64 %rd317, %rd318;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r455,%r456,%r457,%r458}, [%rd317];
	// end inline asm
	add.s64 	%rd321, %rd312, 32;
	// begin inline asm
	cvta.to.global.u64 %rd320, %rd321;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r459,%r460,%r461,%r462}, [%rd320];
	// end inline asm
	add.s64 	%rd324, %rd312, 48;
	// begin inline asm
	cvta.to.global.u64 %rd323, %rd324;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r463,%r464,%r465,%r466}, [%rd323];
	// end inline asm
	add.s64 	%rd327, %rd312, 64;
	// begin inline asm
	cvta.to.global.u64 %rd326, %rd327;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r467,%r468,%r469,%r470}, [%rd326];
	// end inline asm
	add.s64 	%rd330, %rd312, 80;
	// begin inline asm
	cvta.to.global.u64 %rd329, %rd330;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r471,%r472,%r473,%r474}, [%rd329];
	// end inline asm
	add.s64 	%rd333, %rd312, 96;
	// begin inline asm
	cvta.to.global.u64 %rd332, %rd333;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r475,%r476,%r477,%r478}, [%rd332];
	// end inline asm
	add.s64 	%rd336, %rd312, 112;
	// begin inline asm
	cvta.to.global.u64 %rd335, %rd336;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r479,%r480,%r481,%r482}, [%rd335];
	// end inline asm
	add.s64 	%rd339, %rd312, 128;
	// begin inline asm
	cvta.to.global.u64 %rd338, %rd339;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r483,%r484,%r485,%r486}, [%rd338];
	// end inline asm
	add.s64 	%rd342, %rd312, 144;
	// begin inline asm
	cvta.to.global.u64 %rd341, %rd342;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r487,%r488,%r489,%r490}, [%rd341];
	// end inline asm
	mov.b32 	%f1878, %r454;
	mov.b32 	%f1879, %r455;
	and.b32  	%r507, %r453, 65535;
	add.s32 	%r508, %r507, -1;
	cvt.rn.f32.s32 	%f1880, %r508;
	sub.ftz.f32 	%f1881, %f1863, %f1878;
	mul.ftz.f32 	%f1882, %f1881, %f1880;
	sub.ftz.f32 	%f1883, %f1879, %f1878;
	div.approx.ftz.f32 	%f1884, %f1882, %f1883;
	min.ftz.f32 	%f1885, %f1880, %f1884;
	mov.f32 	%f1886, 0f00000000;
	max.ftz.f32 	%f1887, %f1886, %f1885;
	cvt.rmi.ftz.f32.f32 	%f1888, %f1887;
	sub.ftz.f32 	%f414, %f1887, %f1888;
	cvt.rzi.ftz.s32.f32 	%r509, %f1888;
	mul.wide.s32 	%rd356, %r509, 64;
	add.s64 	%rd345, %rd321, %rd356;
	// begin inline asm
	cvta.to.global.u64 %rd344, %rd345;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r491,%r492,%r493,%r494}, [%rd344];
	// end inline asm
	mov.b32 	%f3867, %r491;
	mov.b32 	%f3866, %r492;
	mov.b32 	%f3865, %r493;
	mov.b32 	%f3864, %r494;
	add.s64 	%rd348, %rd345, 16;
	// begin inline asm
	cvta.to.global.u64 %rd347, %rd348;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r495,%r496,%r497,%r498}, [%rd347];
	// end inline asm
	mov.b32 	%f3863, %r495;
	mov.b32 	%f3862, %r496;
	mov.b32 	%f3861, %r497;
	mov.b32 	%f3860, %r498;
	add.s64 	%rd351, %rd345, 32;
	// begin inline asm
	cvta.to.global.u64 %rd350, %rd351;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r499,%r500,%r501,%r502}, [%rd350];
	// end inline asm
	mov.b32 	%f3859, %r499;
	mov.b32 	%f3858, %r500;
	mov.b32 	%f3857, %r501;
	mov.b32 	%f3856, %r502;
	add.s64 	%rd354, %rd345, 48;
	// begin inline asm
	cvta.to.global.u64 %rd353, %rd354;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r503,%r504,%r505,%r506}, [%rd353];
	// end inline asm
	mov.b32 	%f3868, %r503;
	mov.b32 	%f3869, %r504;
	mov.b32 	%f3870, %r505;
	mov.b32 	%f3871, %r506;
	setp.leu.ftz.f32 	%p32, %f414, 0f00000000;
	@%p32 bra 	$L__BB0_62;

	mov.f32 	%f1889, 0f3F800000;
	sub.ftz.f32 	%f1890, %f1889, %f414;
	add.s64 	%rd358, %rd345, 64;
	// begin inline asm
	cvta.to.global.u64 %rd357, %rd358;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r510,%r511,%r512,%r513}, [%rd357];
	// end inline asm
	mov.b32 	%f1891, %r510;
	mov.b32 	%f1892, %r511;
	mov.b32 	%f1893, %r512;
	mov.b32 	%f1894, %r513;
	mul.ftz.f32 	%f1895, %f414, %f1891;
	mul.ftz.f32 	%f1896, %f414, %f1892;
	mul.ftz.f32 	%f1897, %f414, %f1893;
	mul.ftz.f32 	%f1898, %f414, %f1894;
	fma.rn.ftz.f32 	%f3867, %f1890, %f3867, %f1895;
	fma.rn.ftz.f32 	%f3866, %f1890, %f3866, %f1896;
	fma.rn.ftz.f32 	%f3865, %f1890, %f3865, %f1897;
	fma.rn.ftz.f32 	%f3864, %f1890, %f3864, %f1898;
	add.s64 	%rd361, %rd345, 80;
	// begin inline asm
	cvta.to.global.u64 %rd360, %rd361;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r514,%r515,%r516,%r517}, [%rd360];
	// end inline asm
	mov.b32 	%f1899, %r514;
	mov.b32 	%f1900, %r515;
	mov.b32 	%f1901, %r516;
	mov.b32 	%f1902, %r517;
	mul.ftz.f32 	%f1903, %f414, %f1899;
	mul.ftz.f32 	%f1904, %f414, %f1900;
	mul.ftz.f32 	%f1905, %f414, %f1901;
	mul.ftz.f32 	%f1906, %f414, %f1902;
	fma.rn.ftz.f32 	%f3863, %f1890, %f3863, %f1903;
	fma.rn.ftz.f32 	%f3862, %f1890, %f3862, %f1904;
	fma.rn.ftz.f32 	%f3861, %f1890, %f3861, %f1905;
	fma.rn.ftz.f32 	%f3860, %f1890, %f3860, %f1906;
	add.s64 	%rd364, %rd345, 96;
	// begin inline asm
	cvta.to.global.u64 %rd363, %rd364;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r518,%r519,%r520,%r521}, [%rd363];
	// end inline asm
	mov.b32 	%f1907, %r518;
	mov.b32 	%f1908, %r519;
	mov.b32 	%f1909, %r520;
	mov.b32 	%f1910, %r521;
	mul.ftz.f32 	%f1911, %f414, %f1907;
	mul.ftz.f32 	%f1912, %f414, %f1908;
	mul.ftz.f32 	%f1913, %f414, %f1909;
	mul.ftz.f32 	%f1914, %f414, %f1910;
	fma.rn.ftz.f32 	%f3859, %f1890, %f3859, %f1911;
	fma.rn.ftz.f32 	%f1915, %f1890, %f3858, %f1912;
	fma.rn.ftz.f32 	%f1916, %f1890, %f3857, %f1913;
	fma.rn.ftz.f32 	%f1917, %f1890, %f3856, %f1914;
	add.s64 	%rd367, %rd345, 112;
	// begin inline asm
	cvta.to.global.u64 %rd366, %rd367;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r522,%r523,%r524,%r525}, [%rd366];
	// end inline asm
	mov.b32 	%f1918, %r522;
	mov.b32 	%f1919, %r523;
	mov.b32 	%f1920, %r524;
	mov.b32 	%f1921, %r525;
	mul.ftz.f32 	%f1922, %f414, %f1918;
	mul.ftz.f32 	%f1923, %f414, %f1919;
	mul.ftz.f32 	%f1924, %f414, %f1920;
	mul.ftz.f32 	%f1925, %f414, %f1921;
	fma.rn.ftz.f32 	%f1926, %f1890, %f3868, %f1922;
	fma.rn.ftz.f32 	%f3869, %f1890, %f3869, %f1923;
	fma.rn.ftz.f32 	%f3870, %f1890, %f3870, %f1924;
	fma.rn.ftz.f32 	%f3871, %f1890, %f3871, %f1925;
	mul.ftz.f32 	%f1927, %f1916, %f1916;
	fma.rn.ftz.f32 	%f1928, %f1915, %f1915, %f1927;
	fma.rn.ftz.f32 	%f1929, %f1917, %f1917, %f1928;
	fma.rn.ftz.f32 	%f1930, %f1926, %f1926, %f1929;
	rsqrt.approx.ftz.f32 	%f1931, %f1930;
	mul.ftz.f32 	%f3858, %f1915, %f1931;
	mul.ftz.f32 	%f3857, %f1916, %f1931;
	mul.ftz.f32 	%f3856, %f1917, %f1931;
	mul.ftz.f32 	%f3868, %f1931, %f1926;

$L__BB0_62:
	mul.ftz.f32 	%f1932, %f3858, %f3858;
	fma.rn.ftz.f32 	%f1933, %f3857, %f3857, %f1932;
	fma.rn.ftz.f32 	%f1934, %f3856, %f3856, %f1933;
	fma.rn.ftz.f32 	%f1935, %f3868, %f3868, %f1934;
	rcp.approx.ftz.f32 	%f1936, %f1935;
	mul.ftz.f32 	%f1937, %f3858, %f1936;
	mul.ftz.f32 	%f1938, %f3857, %f1936;
	mul.ftz.f32 	%f1939, %f3856, %f1936;
	mul.ftz.f32 	%f1940, %f3868, %f1936;
	mul.ftz.f32 	%f1941, %f3858, %f1937;
	mul.ftz.f32 	%f1942, %f3857, %f1938;
	mul.ftz.f32 	%f1943, %f3856, %f1939;
	mul.ftz.f32 	%f1944, %f3858, %f1938;
	mul.ftz.f32 	%f1945, %f3856, %f1940;
	mul.ftz.f32 	%f1946, %f3858, %f1939;
	mul.ftz.f32 	%f1947, %f3857, %f1940;
	mul.ftz.f32 	%f1948, %f3857, %f1939;
	mul.ftz.f32 	%f1949, %f3858, %f1940;
	sub.ftz.f32 	%f1950, %f1941, %f1942;
	sub.ftz.f32 	%f1951, %f1950, %f1943;
	fma.rn.ftz.f32 	%f1952, %f3868, %f1940, %f1951;
	sub.ftz.f32 	%f1953, %f1944, %f1945;
	add.ftz.f32 	%f1954, %f1953, %f1953;
	add.ftz.f32 	%f1955, %f1946, %f1947;
	add.ftz.f32 	%f1956, %f1955, %f1955;
	add.ftz.f32 	%f1957, %f1944, %f1945;
	add.ftz.f32 	%f1958, %f1957, %f1957;
	sub.ftz.f32 	%f1959, %f1942, %f1941;
	sub.ftz.f32 	%f1960, %f1959, %f1943;
	fma.rn.ftz.f32 	%f1961, %f3868, %f1940, %f1960;
	sub.ftz.f32 	%f1962, %f1948, %f1949;
	add.ftz.f32 	%f1963, %f1962, %f1962;
	sub.ftz.f32 	%f1964, %f1946, %f1947;
	add.ftz.f32 	%f1965, %f1964, %f1964;
	add.ftz.f32 	%f1966, %f1948, %f1949;
	add.ftz.f32 	%f1967, %f1966, %f1966;
	neg.ftz.f32 	%f1968, %f1941;
	sub.ftz.f32 	%f1969, %f1968, %f1942;
	add.ftz.f32 	%f1970, %f1943, %f1969;
	fma.rn.ftz.f32 	%f1971, %f3868, %f1940, %f1970;
	mul.ftz.f32 	%f1972, %f3864, %f1952;
	fma.rn.ftz.f32 	%f1973, %f3861, %f1954, %f1972;
	fma.rn.ftz.f32 	%f1974, %f3859, %f1956, %f1973;
	add.ftz.f32 	%f3883, %f3869, %f1974;
	mul.ftz.f32 	%f1975, %f3861, %f1961;
	fma.rn.ftz.f32 	%f1976, %f3864, %f1958, %f1975;
	fma.rn.ftz.f32 	%f1977, %f3859, %f1963, %f1976;
	add.ftz.f32 	%f3879, %f3870, %f1977;
	mul.ftz.f32 	%f1978, %f3861, %f1967;
	fma.rn.ftz.f32 	%f1979, %f3864, %f1965, %f1978;
	fma.rn.ftz.f32 	%f1980, %f3859, %f1971, %f1979;
	add.ftz.f32 	%f3875, %f3871, %f1980;
	mul.ftz.f32 	%f1981, %f3865, %f1952;
	fma.rn.ftz.f32 	%f1982, %f3862, %f1954, %f1981;
	fma.rn.ftz.f32 	%f3882, %f3860, %f1956, %f1982;
	mul.ftz.f32 	%f1983, %f3862, %f1961;
	fma.rn.ftz.f32 	%f1984, %f3865, %f1958, %f1983;
	fma.rn.ftz.f32 	%f3878, %f3860, %f1963, %f1984;
	mul.ftz.f32 	%f1985, %f3862, %f1967;
	fma.rn.ftz.f32 	%f1986, %f3865, %f1965, %f1985;
	fma.rn.ftz.f32 	%f3874, %f3860, %f1971, %f1986;
	mul.ftz.f32 	%f1987, %f3866, %f1952;
	fma.rn.ftz.f32 	%f3881, %f3863, %f1954, %f1987;
	mul.ftz.f32 	%f1988, %f3863, %f1961;
	fma.rn.ftz.f32 	%f3877, %f3866, %f1958, %f1988;
	mul.ftz.f32 	%f1989, %f3863, %f1967;
	fma.rn.ftz.f32 	%f3873, %f3866, %f1965, %f1989;
	mul.ftz.f32 	%f3880, %f3867, %f1952;
	mul.ftz.f32 	%f3876, %f3867, %f1958;
	mul.ftz.f32 	%f3872, %f3867, %f1965;

$L__BB0_65:
	mul.ftz.f32 	%f2027, %f3873, %f3878;
	mul.ftz.f32 	%f2028, %f3874, %f3877;
	sub.ftz.f32 	%f2029, %f2028, %f2027;
	mul.ftz.f32 	%f2030, %f3880, %f2029;
	mul.ftz.f32 	%f2031, %f3872, %f3878;
	mul.ftz.f32 	%f2032, %f3874, %f3876;
	sub.ftz.f32 	%f2033, %f2032, %f2031;
	mul.ftz.f32 	%f2034, %f2033, %f3881;
	sub.ftz.f32 	%f2035, %f2030, %f2034;
	mul.ftz.f32 	%f2036, %f3872, %f3877;
	mul.ftz.f32 	%f2037, %f3873, %f3876;
	sub.ftz.f32 	%f2038, %f2037, %f2036;
	fma.rn.ftz.f32 	%f2039, %f2038, %f3882, %f2035;
	rcp.approx.ftz.f32 	%f2040, %f2039;
	mul.ftz.f32 	%f3892, %f2029, %f2040;
	mul.ftz.f32 	%f2041, %f3874, %f3881;
	mul.ftz.f32 	%f2042, %f3873, %f3882;
	sub.ftz.f32 	%f2043, %f2042, %f2041;
	mul.ftz.f32 	%f3893, %f2043, %f2040;
	mul.ftz.f32 	%f2044, %f3877, %f3882;
	mul.ftz.f32 	%f2045, %f3878, %f3881;
	sub.ftz.f32 	%f2046, %f2045, %f2044;
	mul.ftz.f32 	%f3894, %f2046, %f2040;
	sub.ftz.f32 	%f2047, %f2031, %f2032;
	mul.ftz.f32 	%f3888, %f2047, %f2040;
	mul.ftz.f32 	%f2048, %f3872, %f3882;
	mul.ftz.f32 	%f2049, %f3874, %f3880;
	sub.ftz.f32 	%f2050, %f2049, %f2048;
	mul.ftz.f32 	%f3889, %f2050, %f2040;
	mul.ftz.f32 	%f2051, %f3878, %f3880;
	mul.ftz.f32 	%f2052, %f3876, %f3882;
	sub.ftz.f32 	%f2053, %f2052, %f2051;
	mul.ftz.f32 	%f3890, %f2053, %f2040;
	mul.ftz.f32 	%f3884, %f2038, %f2040;
	mul.ftz.f32 	%f2054, %f3873, %f3880;
	mul.ftz.f32 	%f2055, %f3872, %f3881;
	sub.ftz.f32 	%f2056, %f2055, %f2054;
	mul.ftz.f32 	%f3885, %f2056, %f2040;
	mul.ftz.f32 	%f2057, %f3876, %f3881;
	mul.ftz.f32 	%f2058, %f3877, %f3880;
	sub.ftz.f32 	%f2059, %f2058, %f2057;
	mul.ftz.f32 	%f3886, %f2059, %f2040;
	mul.ftz.f32 	%f2060, %f3883, %f3892;
	neg.ftz.f32 	%f2061, %f2060;
	mul.ftz.f32 	%f2062, %f3879, %f3893;
	sub.ftz.f32 	%f2063, %f2061, %f2062;
	mul.ftz.f32 	%f2064, %f3875, %f3894;
	sub.ftz.f32 	%f3895, %f2063, %f2064;
	mul.ftz.f32 	%f2065, %f3883, %f3888;
	neg.ftz.f32 	%f2066, %f2065;
	mul.ftz.f32 	%f2067, %f3879, %f3889;
	sub.ftz.f32 	%f2068, %f2066, %f2067;
	mul.ftz.f32 	%f2069, %f3875, %f3890;
	sub.ftz.f32 	%f3891, %f2068, %f2069;
	mul.ftz.f32 	%f2070, %f3883, %f3884;
	neg.ftz.f32 	%f2071, %f2070;
	mul.ftz.f32 	%f2072, %f3879, %f3885;
	sub.ftz.f32 	%f2073, %f2071, %f2072;
	mul.ftz.f32 	%f2074, %f3875, %f3886;
	sub.ftz.f32 	%f3887, %f2073, %f2074;
	bra.uni 	$L__BB0_66;

$L__BB0_57:
	// begin inline asm
	call (%rd798), _optix_get_instance_inverse_transform_from_handle, (%rd297);
	// end inline asm

$L__BB0_58:
	// begin inline asm
	cvta.to.global.u64 %rd303, %rd798;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r439,%r440,%r441,%r442}, [%rd303];
	// end inline asm
	mov.b32 	%f3892, %r439;
	mov.b32 	%f3893, %r440;
	mov.b32 	%f3894, %r441;
	mov.b32 	%f3895, %r442;
	add.s64 	%rd307, %rd798, 16;
	// begin inline asm
	cvta.to.global.u64 %rd306, %rd307;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r443,%r444,%r445,%r446}, [%rd306];
	// end inline asm
	mov.b32 	%f3888, %r443;
	mov.b32 	%f3889, %r444;
	mov.b32 	%f3890, %r445;
	mov.b32 	%f3891, %r446;
	add.s64 	%rd310, %rd798, 32;
	// begin inline asm
	cvta.to.global.u64 %rd309, %rd310;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r447,%r448,%r449,%r450}, [%rd309];
	// end inline asm
	mov.b32 	%f3884, %r447;
	mov.b32 	%f3885, %r448;
	mov.b32 	%f3886, %r449;
	mov.b32 	%f3887, %r450;

$L__BB0_66:
	setp.eq.s32 	%p34, %r1343, 0;
	@%p34 bra 	$L__BB0_68;

	mul.ftz.f32 	%f2075, %f3851, %f3893;
	fma.rn.ftz.f32 	%f2076, %f3847, %f3892, %f2075;
	fma.rn.ftz.f32 	%f536, %f3855, %f3894, %f2076;
	mul.ftz.f32 	%f2077, %f3850, %f3893;
	fma.rn.ftz.f32 	%f2078, %f3846, %f3892, %f2077;
	fma.rn.ftz.f32 	%f537, %f3854, %f3894, %f2078;
	mul.ftz.f32 	%f2079, %f3849, %f3893;
	fma.rn.ftz.f32 	%f2080, %f3845, %f3892, %f2079;
	fma.rn.ftz.f32 	%f538, %f3853, %f3894, %f2080;
	mul.ftz.f32 	%f2081, %f3848, %f3893;
	fma.rn.ftz.f32 	%f2082, %f3844, %f3892, %f2081;
	fma.rn.ftz.f32 	%f2083, %f3852, %f3894, %f2082;
	add.ftz.f32 	%f3895, %f3895, %f2083;
	mul.ftz.f32 	%f2084, %f3851, %f3889;
	fma.rn.ftz.f32 	%f2085, %f3847, %f3888, %f2084;
	fma.rn.ftz.f32 	%f540, %f3855, %f3890, %f2085;
	mul.ftz.f32 	%f2086, %f3850, %f3889;
	fma.rn.ftz.f32 	%f2087, %f3846, %f3888, %f2086;
	fma.rn.ftz.f32 	%f541, %f3854, %f3890, %f2087;
	mul.ftz.f32 	%f2088, %f3849, %f3889;
	fma.rn.ftz.f32 	%f2089, %f3845, %f3888, %f2088;
	fma.rn.ftz.f32 	%f542, %f3853, %f3890, %f2089;
	mul.ftz.f32 	%f2090, %f3848, %f3889;
	fma.rn.ftz.f32 	%f2091, %f3844, %f3888, %f2090;
	fma.rn.ftz.f32 	%f2092, %f3852, %f3890, %f2091;
	add.ftz.f32 	%f3891, %f3891, %f2092;
	mul.ftz.f32 	%f2093, %f3851, %f3885;
	fma.rn.ftz.f32 	%f2094, %f3847, %f3884, %f2093;
	fma.rn.ftz.f32 	%f544, %f3855, %f3886, %f2094;
	mul.ftz.f32 	%f2095, %f3850, %f3885;
	fma.rn.ftz.f32 	%f2096, %f3846, %f3884, %f2095;
	fma.rn.ftz.f32 	%f545, %f3854, %f3886, %f2096;
	mul.ftz.f32 	%f2097, %f3849, %f3885;
	fma.rn.ftz.f32 	%f2098, %f3845, %f3884, %f2097;
	fma.rn.ftz.f32 	%f546, %f3853, %f3886, %f2098;
	mul.ftz.f32 	%f2099, %f3848, %f3885;
	fma.rn.ftz.f32 	%f2100, %f3844, %f3884, %f2099;
	fma.rn.ftz.f32 	%f2101, %f3852, %f3886, %f2100;
	add.ftz.f32 	%f3887, %f3887, %f2101;
	mov.f32 	%f3884, %f544;
	mov.f32 	%f3885, %f545;
	mov.f32 	%f3886, %f546;
	mov.f32 	%f3888, %f540;
	mov.f32 	%f3889, %f541;
	mov.f32 	%f3890, %f542;
	mov.f32 	%f3892, %f536;
	mov.f32 	%f3893, %f537;
	mov.f32 	%f3894, %f538;

$L__BB0_68:
	add.s32 	%r1343, %r1343, 1;
	setp.lt.u32 	%p35, %r1343, %r434;
	mov.f32 	%f3844, %f3895;
	mov.f32 	%f3845, %f3894;
	mov.f32 	%f3846, %f3893;
	mov.f32 	%f3847, %f3892;
	mov.f32 	%f3848, %f3891;
	mov.f32 	%f3849, %f3890;
	mov.f32 	%f3850, %f3889;
	mov.f32 	%f3851, %f3888;
	mov.f32 	%f3852, %f3887;
	mov.f32 	%f3853, %f3886;
	mov.f32 	%f3854, %f3885;
	mov.f32 	%f3855, %f3884;
	@%p35 bra 	$L__BB0_53;

$L__BB0_69:
	mul.ftz.f32 	%f2102, %f2, %f3893;
	fma.rn.ftz.f32 	%f2103, %f1, %f3892, %f2102;
	fma.rn.ftz.f32 	%f2104, %f3, %f3894, %f2103;
	mul.ftz.f32 	%f2105, %f2, %f3889;
	fma.rn.ftz.f32 	%f2106, %f1, %f3888, %f2105;
	fma.rn.ftz.f32 	%f2107, %f3, %f3890, %f2106;
	mul.ftz.f32 	%f2108, %f2, %f3885;
	fma.rn.ftz.f32 	%f2109, %f1, %f3884, %f2108;
	fma.rn.ftz.f32 	%f2110, %f3, %f3886, %f2109;
	add.ftz.f32 	%f3922, %f3887, %f2110;
	add.ftz.f32 	%f3921, %f3891, %f2107;
	add.ftz.f32 	%f3920, %f3895, %f2104;
	bra.uni 	$L__BB0_71;

$L__BB0_23:
	mov.f32 	%f207, %f1;
	mov.f32 	%f208, %f2;
	mov.f32 	%f209, %f3;

$L__BB0_24:
	// begin inline asm
	call (%r277), _optix_get_attribute_0, ();
	// end inline asm
	mov.b32 	%f213, %r277;
	setp.eq.ftz.f32 	%p14, %f213, 0f00000000;
	@%p14 bra 	$L__BB0_28;
	bra.uni 	$L__BB0_25;

$L__BB0_28:
	sub.ftz.f32 	%f3786, %f207, %f1347;
	sub.ftz.f32 	%f3787, %f208, %f1348;
	sub.ftz.f32 	%f3788, %f209, %f1349;
	bra.uni 	$L__BB0_29;

$L__BB0_117:
	mov.f32 	%f4057, %f1;
	mov.f32 	%f4058, %f2;
	mov.f32 	%f4059, %f3;

$L__BB0_118:
	// begin inline asm
	call (%r893), _optix_get_attribute_0, ();
	// end inline asm
	mov.b32 	%f951, %r893;
	setp.eq.ftz.f32 	%p58, %f951, 0f00000000;
	@%p58 bra 	$L__BB0_122;
	bra.uni 	$L__BB0_119;

$L__BB0_122:
	fma.rn.ftz.f32 	%f2743, %f752, 0f00000000, %f748;
	fma.rn.ftz.f32 	%f2744, %f753, 0f00000000, %f749;
	fma.rn.ftz.f32 	%f2745, %f754, 0f00000000, %f750;
	neg.ftz.f32 	%f4060, %f2743;
	neg.ftz.f32 	%f4061, %f2744;
	neg.ftz.f32 	%f4062, %f2745;
	bra.uni 	$L__BB0_123;

$L__BB0_70:
	mov.f32 	%f3920, %f1;
	mov.f32 	%f3921, %f2;
	mov.f32 	%f3922, %f3;

$L__BB0_71:
	// begin inline asm
	call (%r585), _optix_get_attribute_0, ();
	// end inline asm
	mov.b32 	%f584, %r585;
	setp.eq.ftz.f32 	%p36, %f584, 0f00000000;
	@%p36 bra 	$L__BB0_75;
	bra.uni 	$L__BB0_72;

$L__BB0_75:
	mov.f32 	%f2215, 0f3F800000;
	sub.ftz.f32 	%f2216, %f2215, 0f358637BD;
	mul.ftz.f32 	%f2217, %f2216, 0f3F000000;
	mul.ftz.f32 	%f2218, %f2217, %f2216;
	add.ftz.f32 	%f2219, %f2216, %f2216;
	mul.ftz.f32 	%f2220, %f2219, 0f358637BD;
	mul.ftz.f32 	%f2221, %f381, %f2220;
	fma.rn.ftz.f32 	%f2222, %f377, %f2218, %f2221;
	mul.ftz.f32 	%f2223, %f382, %f2220;
	fma.rn.ftz.f32 	%f2224, %f378, %f2218, %f2223;
	mul.ftz.f32 	%f2225, %f383, %f2220;
	fma.rn.ftz.f32 	%f2226, %f379, %f2218, %f2225;
	fma.rn.ftz.f32 	%f2227, %f385, 0f2B0CBCCC, %f2222;
	fma.rn.ftz.f32 	%f2228, %f386, 0f2B0CBCCC, %f2224;
	fma.rn.ftz.f32 	%f2229, %f387, 0f2B0CBCCC, %f2226;
	neg.ftz.f32 	%f3923, %f2227;
	neg.ftz.f32 	%f3924, %f2228;
	neg.ftz.f32 	%f3925, %f2229;
	bra.uni 	$L__BB0_76;

$L__BB0_25:
	setp.ltu.ftz.f32 	%p15, %f213, 0f3F800000;
	@%p15 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_26;

$L__BB0_27:
	sub.ftz.f32 	%f1607, %f1354, %f1350;
	fma.rn.ftz.f32 	%f1608, %f13, %f213, %f1347;
	fma.rn.ftz.f32 	%f1609, %f15, %f213, %f1348;
	fma.rn.ftz.f32 	%f1610, %f17, %f213, %f1349;
	fma.rn.ftz.f32 	%f1611, %f1607, %f213, %f1350;
	mul.ftz.f32 	%f1612, %f15, %f15;
	fma.rn.ftz.f32 	%f1613, %f13, %f13, %f1612;
	fma.rn.ftz.f32 	%f1614, %f17, %f17, %f1613;
	sub.ftz.f32 	%f1615, %f207, %f1608;
	sub.ftz.f32 	%f1616, %f208, %f1609;
	sub.ftz.f32 	%f1617, %f209, %f1610;
	mul.ftz.f32 	%f1618, %f15, %f1616;
	fma.rn.ftz.f32 	%f1619, %f13, %f1615, %f1618;
	fma.rn.ftz.f32 	%f1620, %f17, %f1617, %f1619;
	div.approx.ftz.f32 	%f1621, %f1620, %f1614;
	mul.ftz.f32 	%f1622, %f13, %f1621;
	mul.ftz.f32 	%f1623, %f15, %f1621;
	mul.ftz.f32 	%f1624, %f17, %f1621;
	sub.ftz.f32 	%f1625, %f1615, %f1622;
	sub.ftz.f32 	%f1626, %f1616, %f1623;
	sub.ftz.f32 	%f1627, %f1617, %f1624;
	mul.ftz.f32 	%f1628, %f1626, %f1626;
	fma.rn.ftz.f32 	%f1629, %f1625, %f1625, %f1628;
	fma.rn.ftz.f32 	%f1630, %f1627, %f1627, %f1629;
	sqrt.approx.ftz.f32 	%f1631, %f1630;
	div.approx.ftz.f32 	%f1632, %f1611, %f1631;
	mul.ftz.f32 	%f1633, %f1625, %f1632;
	mul.ftz.f32 	%f1634, %f1626, %f1632;
	mul.ftz.f32 	%f1635, %f1627, %f1632;
	mul.ftz.f32 	%f1636, %f1614, %f1633;
	mul.ftz.f32 	%f1637, %f1614, %f1634;
	mul.ftz.f32 	%f1638, %f1614, %f1635;
	mul.ftz.f32 	%f1639, %f1607, %f1611;
	mul.ftz.f32 	%f1640, %f13, %f1639;
	mul.ftz.f32 	%f1641, %f15, %f1639;
	mul.ftz.f32 	%f1642, %f17, %f1639;
	sub.ftz.f32 	%f3786, %f1636, %f1640;
	sub.ftz.f32 	%f3787, %f1637, %f1641;
	sub.ftz.f32 	%f3788, %f1638, %f1642;
	bra.uni 	$L__BB0_29;

$L__BB0_119:
	setp.eq.ftz.f32 	%p59, %f951, 0f3F800000;
	add.ftz.f32 	%f952, %f752, %f752;
	add.ftz.f32 	%f953, %f753, %f753;
	add.ftz.f32 	%f954, %f754, %f754;
	@%p59 bra 	$L__BB0_121;
	bra.uni 	$L__BB0_120;

$L__BB0_121:
	add.ftz.f32 	%f4060, %f748, %f952;
	add.ftz.f32 	%f4061, %f749, %f953;
	add.ftz.f32 	%f4062, %f750, %f954;
	bra.uni 	$L__BB0_123;

$L__BB0_72:
	setp.eq.ftz.f32 	%p37, %f584, 0f3F800000;
	@%p37 bra 	$L__BB0_74;
	bra.uni 	$L__BB0_73;

$L__BB0_74:
	mov.f32 	%f2203, 0f3F800000;
	sub.ftz.f32 	%f2204, %f2203, 0f3F7FFFEF;
	mul.ftz.f32 	%f2205, %f2204, 0f3F000000;
	mul.ftz.f32 	%f2206, %f2205, %f2204;
	add.ftz.f32 	%f2207, %f2204, %f2204;
	mul.ftz.f32 	%f2208, %f2207, 0f3F7FFFEF;
	mul.ftz.f32 	%f2209, %f381, %f2208;
	fma.rn.ftz.f32 	%f2210, %f377, %f2206, %f2209;
	mul.ftz.f32 	%f2211, %f382, %f2208;
	fma.rn.ftz.f32 	%f2212, %f378, %f2206, %f2211;
	mul.ftz.f32 	%f2213, %f383, %f2208;
	fma.rn.ftz.f32 	%f2214, %f379, %f2206, %f2213;
	fma.rn.ftz.f32 	%f3923, %f385, 0f3EFFFFDE, %f2210;
	fma.rn.ftz.f32 	%f3924, %f386, 0f3EFFFFDE, %f2212;
	fma.rn.ftz.f32 	%f3925, %f387, 0f3EFFFFDE, %f2214;
	bra.uni 	$L__BB0_76;

$L__BB0_26:
	add.ftz.f32 	%f1604, %f1347, %f13;
	sub.ftz.f32 	%f3786, %f207, %f1604;
	add.ftz.f32 	%f1605, %f1348, %f15;
	sub.ftz.f32 	%f3787, %f208, %f1605;
	add.ftz.f32 	%f1606, %f1349, %f17;
	sub.ftz.f32 	%f3788, %f209, %f1606;

$L__BB0_29:
	mul.ftz.f32 	%f1643, %f3787, %f3787;
	fma.rn.ftz.f32 	%f1644, %f3786, %f3786, %f1643;
	fma.rn.ftz.f32 	%f1645, %f3788, %f3788, %f1644;
	rsqrt.approx.ftz.f32 	%f1646, %f1645;
	mul.ftz.f32 	%f4123, %f3786, %f1646;
	mul.ftz.f32 	%f4122, %f3787, %f1646;
	mul.ftz.f32 	%f228, %f3788, %f1646;
	// begin inline asm
	call (%r278), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p16, %r278, 0;
	@%p16 bra 	$L__BB0_49;

	// begin inline asm
	call (%r279), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1647), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p17, %r279, 0;
	@%p17 bra 	$L__BB0_48;

	mov.u32 	%r1342, 0;

$L__BB0_32:
	.pragma "nounroll";
	// begin inline asm
	call (%rd176), _optix_get_transform_list_handle, (%r1342);
	// end inline asm
	// begin inline asm
	call (%r282), _optix_get_transform_type_from_handle, (%rd176);
	// end inline asm
	or.b32  	%r283, %r282, 1;
	setp.eq.s32 	%p18, %r283, 3;
	@%p18 bra 	$L__BB0_38;
	bra.uni 	$L__BB0_33;

$L__BB0_38:
	setp.eq.s32 	%p21, %r282, 2;
	@%p21 bra 	$L__BB0_42;
	bra.uni 	$L__BB0_39;

$L__BB0_42:
	// begin inline asm
	call (%rd248), _optix_get_matrix_motion_transform_from_handle, (%rd176);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd250, %rd248;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r371,%r372,%r373,%r374}, [%rd250];
	// end inline asm
	add.s64 	%rd254, %rd248, 16;
	// begin inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r375,%r376,%r377,%r378}, [%rd253];
	// end inline asm
	add.s64 	%rd257, %rd248, 32;
	// begin inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r379,%r380,%r381,%r382}, [%rd256];
	// end inline asm
	add.s64 	%rd260, %rd248, 48;
	// begin inline asm
	cvta.to.global.u64 %rd259, %rd260;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r383,%r384,%r385,%r386}, [%rd259];
	// end inline asm
	add.s64 	%rd263, %rd248, 64;
	// begin inline asm
	cvta.to.global.u64 %rd262, %rd263;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r387,%r388,%r389,%r390}, [%rd262];
	// end inline asm
	add.s64 	%rd266, %rd248, 80;
	// begin inline asm
	cvta.to.global.u64 %rd265, %rd266;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r391,%r392,%r393,%r394}, [%rd265];
	// end inline asm
	add.s64 	%rd269, %rd248, 96;
	// begin inline asm
	cvta.to.global.u64 %rd268, %rd269;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r395,%r396,%r397,%r398}, [%rd268];
	// end inline asm
	add.s64 	%rd272, %rd248, 112;
	// begin inline asm
	cvta.to.global.u64 %rd271, %rd272;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r399,%r400,%r401,%r402}, [%rd271];
	// end inline asm
	mov.b32 	%f1750, %r374;
	mov.b32 	%f1751, %r375;
	and.b32  	%r415, %r373, 65535;
	add.s32 	%r416, %r415, -1;
	cvt.rn.f32.s32 	%f1752, %r416;
	sub.ftz.f32 	%f1753, %f1647, %f1750;
	mul.ftz.f32 	%f1754, %f1753, %f1752;
	sub.ftz.f32 	%f1755, %f1751, %f1750;
	div.approx.ftz.f32 	%f1756, %f1754, %f1755;
	min.ftz.f32 	%f1757, %f1752, %f1756;
	mov.f32 	%f1758, 0f00000000;
	max.ftz.f32 	%f1759, %f1758, %f1757;
	cvt.rmi.ftz.f32.f32 	%f1760, %f1759;
	sub.ftz.f32 	%f288, %f1759, %f1760;
	cvt.rzi.ftz.s32.f32 	%r417, %f1760;
	cvt.s64.s32 	%rd15, %r417;
	mul.wide.s32 	%rd283, %r417, 48;
	add.s64 	%rd275, %rd257, %rd283;
	// begin inline asm
	cvta.to.global.u64 %rd274, %rd275;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r403,%r404,%r405,%r406}, [%rd274];
	// end inline asm
	mov.b32 	%f3814, %r403;
	mov.b32 	%f3815, %r404;
	mov.b32 	%f3816, %r405;
	add.s64 	%rd278, %rd275, 16;
	// begin inline asm
	cvta.to.global.u64 %rd277, %rd278;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r407,%r408,%r409,%r410}, [%rd277];
	// end inline asm
	mov.b32 	%f3811, %r407;
	mov.b32 	%f3812, %r408;
	mov.b32 	%f3813, %r409;
	add.s64 	%rd281, %rd275, 32;
	// begin inline asm
	cvta.to.global.u64 %rd280, %rd281;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r411,%r412,%r413,%r414}, [%rd280];
	// end inline asm
	mov.b32 	%f3808, %r411;
	mov.b32 	%f3809, %r412;
	mov.b32 	%f3810, %r413;
	setp.leu.ftz.f32 	%p23, %f288, 0f00000000;
	@%p23 bra 	$L__BB0_44;

	mov.f32 	%f1761, 0f3F800000;
	sub.ftz.f32 	%f1762, %f1761, %f288;
	mul.lo.s64 	%rd293, %rd15, 48;
	add.s64 	%rd294, %rd248, %rd293;
	add.s64 	%rd285, %rd294, 80;
	// begin inline asm
	cvta.to.global.u64 %rd284, %rd285;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r418,%r419,%r420,%r421}, [%rd284];
	// end inline asm
	mov.b32 	%f1763, %r418;
	mov.b32 	%f1764, %r419;
	mov.b32 	%f1765, %r420;
	mul.ftz.f32 	%f1766, %f288, %f1763;
	mul.ftz.f32 	%f1767, %f288, %f1764;
	mul.ftz.f32 	%f1768, %f288, %f1765;
	fma.rn.ftz.f32 	%f3814, %f1762, %f3814, %f1766;
	fma.rn.ftz.f32 	%f3815, %f1762, %f3815, %f1767;
	fma.rn.ftz.f32 	%f3816, %f1762, %f3816, %f1768;
	add.s64 	%rd288, %rd294, 96;
	// begin inline asm
	cvta.to.global.u64 %rd287, %rd288;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r422,%r423,%r424,%r425}, [%rd287];
	// end inline asm
	mov.b32 	%f1769, %r422;
	mov.b32 	%f1770, %r423;
	mov.b32 	%f1771, %r424;
	mul.ftz.f32 	%f1772, %f288, %f1769;
	mul.ftz.f32 	%f1773, %f288, %f1770;
	mul.ftz.f32 	%f1774, %f288, %f1771;
	fma.rn.ftz.f32 	%f3811, %f1762, %f3811, %f1772;
	fma.rn.ftz.f32 	%f3812, %f1762, %f3812, %f1773;
	fma.rn.ftz.f32 	%f3813, %f1762, %f3813, %f1774;
	add.s64 	%rd291, %rd294, 112;
	// begin inline asm
	cvta.to.global.u64 %rd290, %rd291;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r426,%r427,%r428,%r429}, [%rd290];
	// end inline asm
	mov.b32 	%f1775, %r426;
	mov.b32 	%f1776, %r427;
	mov.b32 	%f1777, %r428;
	mul.ftz.f32 	%f1778, %f288, %f1775;
	mul.ftz.f32 	%f1779, %f288, %f1776;
	mul.ftz.f32 	%f1780, %f288, %f1777;
	fma.rn.ftz.f32 	%f3808, %f1762, %f3808, %f1778;
	fma.rn.ftz.f32 	%f3809, %f1762, %f3809, %f1779;
	fma.rn.ftz.f32 	%f3810, %f1762, %f3810, %f1780;
	bra.uni 	$L__BB0_44;

$L__BB0_33:
	mov.f32 	%f3817, 0f00000000;
	mov.f32 	%f3819, 0f3F800000;
	setp.eq.s32 	%p19, %r282, 4;
	@%p19 bra 	$L__BB0_36;

	setp.ne.s32 	%p20, %r282, 1;
	mov.f32 	%f3818, %f3817;
	mov.f32 	%f3820, %f3817;
	mov.f32 	%f3821, %f3819;
	mov.f32 	%f3822, %f3817;
	mov.f32 	%f3823, %f3819;
	mov.f32 	%f3824, %f3817;
	mov.f32 	%f3825, %f3817;
	@%p20 bra 	$L__BB0_45;

	// begin inline asm
	call (%rd178), _optix_get_static_transform_from_handle, (%rd176);
	// end inline asm
	add.s64 	%rd797, %rd178, 64;
	bra.uni 	$L__BB0_37;

$L__BB0_39:
	// begin inline asm
	call (%rd191), _optix_get_srt_motion_transform_from_handle, (%rd176);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd193, %rd191;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r296,%r297,%r298,%r299}, [%rd193];
	// end inline asm
	add.s64 	%rd197, %rd191, 16;
	// begin inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r300,%r301,%r302,%r303}, [%rd196];
	// end inline asm
	add.s64 	%rd200, %rd191, 32;
	// begin inline asm
	cvta.to.global.u64 %rd199, %rd200;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r304,%r305,%r306,%r307}, [%rd199];
	// end inline asm
	add.s64 	%rd203, %rd191, 48;
	// begin inline asm
	cvta.to.global.u64 %rd202, %rd203;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r308,%r309,%r310,%r311}, [%rd202];
	// end inline asm
	add.s64 	%rd206, %rd191, 64;
	// begin inline asm
	cvta.to.global.u64 %rd205, %rd206;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r312,%r313,%r314,%r315}, [%rd205];
	// end inline asm
	add.s64 	%rd209, %rd191, 80;
	// begin inline asm
	cvta.to.global.u64 %rd208, %rd209;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r316,%r317,%r318,%r319}, [%rd208];
	// end inline asm
	add.s64 	%rd212, %rd191, 96;
	// begin inline asm
	cvta.to.global.u64 %rd211, %rd212;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r320,%r321,%r322,%r323}, [%rd211];
	// end inline asm
	add.s64 	%rd215, %rd191, 112;
	// begin inline asm
	cvta.to.global.u64 %rd214, %rd215;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r324,%r325,%r326,%r327}, [%rd214];
	// end inline asm
	add.s64 	%rd218, %rd191, 128;
	// begin inline asm
	cvta.to.global.u64 %rd217, %rd218;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r328,%r329,%r330,%r331}, [%rd217];
	// end inline asm
	add.s64 	%rd221, %rd191, 144;
	// begin inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r332,%r333,%r334,%r335}, [%rd220];
	// end inline asm
	mov.b32 	%f1659, %r299;
	mov.b32 	%f1660, %r300;
	and.b32  	%r352, %r298, 65535;
	add.s32 	%r353, %r352, -1;
	cvt.rn.f32.s32 	%f1661, %r353;
	sub.ftz.f32 	%f1662, %f1647, %f1659;
	mul.ftz.f32 	%f1663, %f1662, %f1661;
	sub.ftz.f32 	%f1664, %f1660, %f1659;
	div.approx.ftz.f32 	%f1665, %f1663, %f1664;
	min.ftz.f32 	%f1666, %f1661, %f1665;
	mov.f32 	%f1667, 0f00000000;
	max.ftz.f32 	%f1668, %f1667, %f1666;
	cvt.rmi.ftz.f32.f32 	%f1669, %f1668;
	sub.ftz.f32 	%f248, %f1668, %f1669;
	cvt.rzi.ftz.s32.f32 	%r354, %f1669;
	mul.wide.s32 	%rd235, %r354, 64;
	add.s64 	%rd224, %rd200, %rd235;
	// begin inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r336,%r337,%r338,%r339}, [%rd223];
	// end inline asm
	mov.b32 	%f3806, %r336;
	mov.b32 	%f3805, %r337;
	mov.b32 	%f3804, %r338;
	add.s64 	%rd227, %rd224, 16;
	// begin inline asm
	cvta.to.global.u64 %rd226, %rd227;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r340,%r341,%r342,%r343}, [%rd226];
	// end inline asm
	mov.b32 	%f3803, %r340;
	mov.b32 	%f3802, %r341;
	mov.b32 	%f3801, %r343;
	add.s64 	%rd230, %rd224, 32;
	// begin inline asm
	cvta.to.global.u64 %rd229, %rd230;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r344,%r345,%r346,%r347}, [%rd229];
	// end inline asm
	mov.b32 	%f3800, %r345;
	mov.b32 	%f3799, %r346;
	mov.b32 	%f3798, %r347;
	add.s64 	%rd233, %rd224, 48;
	// begin inline asm
	cvta.to.global.u64 %rd232, %rd233;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r348,%r349,%r350,%r351}, [%rd232];
	// end inline asm
	mov.b32 	%f3807, %r348;
	setp.leu.ftz.f32 	%p22, %f248, 0f00000000;
	@%p22 bra 	$L__BB0_41;

	mov.f32 	%f1670, 0f3F800000;
	sub.ftz.f32 	%f1671, %f1670, %f248;
	add.s64 	%rd237, %rd224, 64;
	// begin inline asm
	cvta.to.global.u64 %rd236, %rd237;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r355,%r356,%r357,%r358}, [%rd236];
	// end inline asm
	mov.b32 	%f1672, %r355;
	mov.b32 	%f1673, %r356;
	mov.b32 	%f1674, %r357;
	mul.ftz.f32 	%f1675, %f248, %f1672;
	mul.ftz.f32 	%f1676, %f248, %f1673;
	mul.ftz.f32 	%f1677, %f248, %f1674;
	fma.rn.ftz.f32 	%f3806, %f1671, %f3806, %f1675;
	fma.rn.ftz.f32 	%f3805, %f1671, %f3805, %f1676;
	fma.rn.ftz.f32 	%f3804, %f1671, %f3804, %f1677;
	add.s64 	%rd240, %rd224, 80;
	// begin inline asm
	cvta.to.global.u64 %rd239, %rd240;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r359,%r360,%r361,%r362}, [%rd239];
	// end inline asm
	mov.b32 	%f1678, %r359;
	mov.b32 	%f1679, %r360;
	mov.b32 	%f1680, %r362;
	mul.ftz.f32 	%f1681, %f248, %f1678;
	mul.ftz.f32 	%f1682, %f248, %f1679;
	mul.ftz.f32 	%f1683, %f248, %f1680;
	fma.rn.ftz.f32 	%f3803, %f1671, %f3803, %f1681;
	fma.rn.ftz.f32 	%f3802, %f1671, %f3802, %f1682;
	fma.rn.ftz.f32 	%f3801, %f1671, %f3801, %f1683;
	add.s64 	%rd243, %rd224, 96;
	// begin inline asm
	cvta.to.global.u64 %rd242, %rd243;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r363,%r364,%r365,%r366}, [%rd242];
	// end inline asm
	mov.b32 	%f1684, %r364;
	mov.b32 	%f1685, %r365;
	mov.b32 	%f1686, %r366;
	mul.ftz.f32 	%f1687, %f248, %f1684;
	mul.ftz.f32 	%f1688, %f248, %f1685;
	mul.ftz.f32 	%f1689, %f248, %f1686;
	fma.rn.ftz.f32 	%f1690, %f1671, %f3800, %f1687;
	fma.rn.ftz.f32 	%f1691, %f1671, %f3799, %f1688;
	fma.rn.ftz.f32 	%f1692, %f1671, %f3798, %f1689;
	add.s64 	%rd246, %rd224, 112;
	// begin inline asm
	cvta.to.global.u64 %rd245, %rd246;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r367,%r368,%r369,%r370}, [%rd245];
	// end inline asm
	mov.b32 	%f1693, %r367;
	mul.ftz.f32 	%f1694, %f248, %f1693;
	fma.rn.ftz.f32 	%f1695, %f1671, %f3807, %f1694;
	mul.ftz.f32 	%f1696, %f1691, %f1691;
	fma.rn.ftz.f32 	%f1697, %f1690, %f1690, %f1696;
	fma.rn.ftz.f32 	%f1698, %f1692, %f1692, %f1697;
	fma.rn.ftz.f32 	%f1699, %f1695, %f1695, %f1698;
	rsqrt.approx.ftz.f32 	%f1700, %f1699;
	mul.ftz.f32 	%f3800, %f1690, %f1700;
	mul.ftz.f32 	%f3799, %f1691, %f1700;
	mul.ftz.f32 	%f3798, %f1692, %f1700;
	mul.ftz.f32 	%f3807, %f1700, %f1695;

$L__BB0_41:
	mul.ftz.f32 	%f1701, %f3800, %f3800;
	fma.rn.ftz.f32 	%f1702, %f3799, %f3799, %f1701;
	fma.rn.ftz.f32 	%f1703, %f3798, %f3798, %f1702;
	fma.rn.ftz.f32 	%f1704, %f3807, %f3807, %f1703;
	rcp.approx.ftz.f32 	%f1705, %f1704;
	mul.ftz.f32 	%f1706, %f3800, %f1705;
	mul.ftz.f32 	%f1707, %f3799, %f1705;
	mul.ftz.f32 	%f1708, %f3798, %f1705;
	mul.ftz.f32 	%f1709, %f3807, %f1705;
	mul.ftz.f32 	%f1710, %f3800, %f1706;
	mul.ftz.f32 	%f1711, %f3799, %f1707;
	mul.ftz.f32 	%f1712, %f3798, %f1708;
	mul.ftz.f32 	%f1713, %f3800, %f1707;
	mul.ftz.f32 	%f1714, %f3798, %f1709;
	mul.ftz.f32 	%f1715, %f3800, %f1708;
	mul.ftz.f32 	%f1716, %f3799, %f1709;
	mul.ftz.f32 	%f1717, %f3799, %f1708;
	mul.ftz.f32 	%f1718, %f3800, %f1709;
	sub.ftz.f32 	%f1719, %f1710, %f1711;
	sub.ftz.f32 	%f1720, %f1719, %f1712;
	fma.rn.ftz.f32 	%f1721, %f3807, %f1709, %f1720;
	sub.ftz.f32 	%f1722, %f1713, %f1714;
	add.ftz.f32 	%f1723, %f1722, %f1722;
	add.ftz.f32 	%f1724, %f1715, %f1716;
	add.ftz.f32 	%f1725, %f1724, %f1724;
	add.ftz.f32 	%f1726, %f1713, %f1714;
	add.ftz.f32 	%f1727, %f1726, %f1726;
	sub.ftz.f32 	%f1728, %f1711, %f1710;
	sub.ftz.f32 	%f1729, %f1728, %f1712;
	fma.rn.ftz.f32 	%f1730, %f3807, %f1709, %f1729;
	sub.ftz.f32 	%f1731, %f1717, %f1718;
	add.ftz.f32 	%f1732, %f1731, %f1731;
	sub.ftz.f32 	%f1733, %f1715, %f1716;
	add.ftz.f32 	%f1734, %f1733, %f1733;
	add.ftz.f32 	%f1735, %f1717, %f1718;
	add.ftz.f32 	%f1736, %f1735, %f1735;
	neg.ftz.f32 	%f1737, %f1710;
	sub.ftz.f32 	%f1738, %f1737, %f1711;
	add.ftz.f32 	%f1739, %f1712, %f1738;
	fma.rn.ftz.f32 	%f1740, %f3807, %f1709, %f1739;
	mul.ftz.f32 	%f1741, %f3804, %f1721;
	fma.rn.ftz.f32 	%f1742, %f3802, %f1723, %f1741;
	fma.rn.ftz.f32 	%f3816, %f3801, %f1725, %f1742;
	mul.ftz.f32 	%f1743, %f3802, %f1730;
	fma.rn.ftz.f32 	%f1744, %f3804, %f1727, %f1743;
	fma.rn.ftz.f32 	%f3813, %f3801, %f1732, %f1744;
	mul.ftz.f32 	%f1745, %f3802, %f1736;
	fma.rn.ftz.f32 	%f1746, %f3804, %f1734, %f1745;
	fma.rn.ftz.f32 	%f3810, %f3801, %f1740, %f1746;
	mul.ftz.f32 	%f1747, %f3805, %f1721;
	fma.rn.ftz.f32 	%f3815, %f3803, %f1723, %f1747;
	mul.ftz.f32 	%f1748, %f3803, %f1730;
	fma.rn.ftz.f32 	%f3812, %f3805, %f1727, %f1748;
	mul.ftz.f32 	%f1749, %f3803, %f1736;
	fma.rn.ftz.f32 	%f3809, %f3805, %f1734, %f1749;
	mul.ftz.f32 	%f3814, %f3806, %f1721;
	mul.ftz.f32 	%f3811, %f3806, %f1727;
	mul.ftz.f32 	%f3808, %f3806, %f1734;

$L__BB0_44:
	mul.ftz.f32 	%f1781, %f3809, %f3813;
	mul.ftz.f32 	%f1782, %f3810, %f3812;
	sub.ftz.f32 	%f1783, %f1782, %f1781;
	mul.ftz.f32 	%f1784, %f3814, %f1783;
	mul.ftz.f32 	%f1785, %f3808, %f3813;
	mul.ftz.f32 	%f1786, %f3810, %f3811;
	sub.ftz.f32 	%f1787, %f1786, %f1785;
	mul.ftz.f32 	%f1788, %f1787, %f3815;
	sub.ftz.f32 	%f1789, %f1784, %f1788;
	mul.ftz.f32 	%f1790, %f3808, %f3812;
	mul.ftz.f32 	%f1791, %f3809, %f3811;
	sub.ftz.f32 	%f1792, %f1791, %f1790;
	fma.rn.ftz.f32 	%f1793, %f1792, %f3816, %f1789;
	rcp.approx.ftz.f32 	%f1794, %f1793;
	mul.ftz.f32 	%f3823, %f1783, %f1794;
	mul.ftz.f32 	%f1795, %f3810, %f3815;
	mul.ftz.f32 	%f1796, %f3809, %f3816;
	sub.ftz.f32 	%f1797, %f1796, %f1795;
	mul.ftz.f32 	%f3824, %f1797, %f1794;
	mul.ftz.f32 	%f1798, %f3812, %f3816;
	mul.ftz.f32 	%f1799, %f3813, %f3815;
	sub.ftz.f32 	%f1800, %f1799, %f1798;
	mul.ftz.f32 	%f3825, %f1800, %f1794;
	sub.ftz.f32 	%f1801, %f1785, %f1786;
	mul.ftz.f32 	%f3820, %f1801, %f1794;
	mul.ftz.f32 	%f1802, %f3808, %f3816;
	mul.ftz.f32 	%f1803, %f3810, %f3814;
	sub.ftz.f32 	%f1804, %f1803, %f1802;
	mul.ftz.f32 	%f3821, %f1804, %f1794;
	mul.ftz.f32 	%f1805, %f3813, %f3814;
	mul.ftz.f32 	%f1806, %f3811, %f3816;
	sub.ftz.f32 	%f1807, %f1806, %f1805;
	mul.ftz.f32 	%f3822, %f1807, %f1794;
	mul.ftz.f32 	%f3817, %f1792, %f1794;
	mul.ftz.f32 	%f1808, %f3809, %f3814;
	mul.ftz.f32 	%f1809, %f3808, %f3815;
	sub.ftz.f32 	%f1810, %f1809, %f1808;
	mul.ftz.f32 	%f3818, %f1810, %f1794;
	mul.ftz.f32 	%f1811, %f3811, %f3815;
	mul.ftz.f32 	%f1812, %f3812, %f3814;
	sub.ftz.f32 	%f1813, %f1812, %f1811;
	mul.ftz.f32 	%f3819, %f1813, %f1794;
	bra.uni 	$L__BB0_45;

$L__BB0_36:
	// begin inline asm
	call (%rd797), _optix_get_instance_inverse_transform_from_handle, (%rd176);
	// end inline asm

$L__BB0_37:
	// begin inline asm
	cvta.to.global.u64 %rd182, %rd797;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r284,%r285,%r286,%r287}, [%rd182];
	// end inline asm
	mov.b32 	%f3823, %r284;
	mov.b32 	%f3824, %r285;
	mov.b32 	%f3825, %r286;
	add.s64 	%rd186, %rd797, 16;
	// begin inline asm
	cvta.to.global.u64 %rd185, %rd186;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r288,%r289,%r290,%r291}, [%rd185];
	// end inline asm
	mov.b32 	%f3820, %r288;
	mov.b32 	%f3821, %r289;
	mov.b32 	%f3822, %r290;
	add.s64 	%rd189, %rd797, 32;
	// begin inline asm
	cvta.to.global.u64 %rd188, %rd189;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r292,%r293,%r294,%r295}, [%rd188];
	// end inline asm
	mov.b32 	%f3817, %r292;
	mov.b32 	%f3818, %r293;
	mov.b32 	%f3819, %r294;

$L__BB0_45:
	setp.eq.s32 	%p24, %r1342, 0;
	@%p24 bra 	$L__BB0_47;

	mul.ftz.f32 	%f1814, %f3794, %f3824;
	fma.rn.ftz.f32 	%f1815, %f3791, %f3823, %f1814;
	fma.rn.ftz.f32 	%f334, %f3797, %f3825, %f1815;
	mul.ftz.f32 	%f1816, %f3793, %f3824;
	fma.rn.ftz.f32 	%f1817, %f3790, %f3823, %f1816;
	fma.rn.ftz.f32 	%f335, %f3796, %f3825, %f1817;
	mul.ftz.f32 	%f1818, %f3792, %f3824;
	fma.rn.ftz.f32 	%f1819, %f3789, %f3823, %f1818;
	fma.rn.ftz.f32 	%f3825, %f3795, %f3825, %f1819;
	mul.ftz.f32 	%f1820, %f3794, %f3821;
	fma.rn.ftz.f32 	%f1821, %f3791, %f3820, %f1820;
	fma.rn.ftz.f32 	%f337, %f3797, %f3822, %f1821;
	mul.ftz.f32 	%f1822, %f3793, %f3821;
	fma.rn.ftz.f32 	%f1823, %f3790, %f3820, %f1822;
	fma.rn.ftz.f32 	%f338, %f3796, %f3822, %f1823;
	mul.ftz.f32 	%f1824, %f3792, %f3821;
	fma.rn.ftz.f32 	%f1825, %f3789, %f3820, %f1824;
	fma.rn.ftz.f32 	%f3822, %f3795, %f3822, %f1825;
	mul.ftz.f32 	%f1826, %f3794, %f3818;
	fma.rn.ftz.f32 	%f1827, %f3791, %f3817, %f1826;
	fma.rn.ftz.f32 	%f340, %f3797, %f3819, %f1827;
	mul.ftz.f32 	%f1828, %f3793, %f3818;
	fma.rn.ftz.f32 	%f1829, %f3790, %f3817, %f1828;
	fma.rn.ftz.f32 	%f341, %f3796, %f3819, %f1829;
	mul.ftz.f32 	%f1830, %f3792, %f3818;
	fma.rn.ftz.f32 	%f1831, %f3789, %f3817, %f1830;
	fma.rn.ftz.f32 	%f3819, %f3795, %f3819, %f1831;
	mov.f32 	%f3817, %f340;
	mov.f32 	%f3818, %f341;
	mov.f32 	%f3820, %f337;
	mov.f32 	%f3821, %f338;
	mov.f32 	%f3823, %f334;
	mov.f32 	%f3824, %f335;

$L__BB0_47:
	add.s32 	%r1342, %r1342, 1;
	setp.lt.u32 	%p25, %r1342, %r279;
	mov.f32 	%f3789, %f3825;
	mov.f32 	%f3790, %f3824;
	mov.f32 	%f3791, %f3823;
	mov.f32 	%f3792, %f3822;
	mov.f32 	%f3793, %f3821;
	mov.f32 	%f3794, %f3820;
	mov.f32 	%f3795, %f3819;
	mov.f32 	%f3796, %f3818;
	mov.f32 	%f3797, %f3817;
	@%p25 bra 	$L__BB0_32;

$L__BB0_48:
	mul.ftz.f32 	%f1832, %f4123, %f3823;
	fma.rn.ftz.f32 	%f1833, %f4122, %f3820, %f1832;
	mul.ftz.f32 	%f1834, %f4123, %f3824;
	fma.rn.ftz.f32 	%f1835, %f4122, %f3821, %f1834;
	mul.ftz.f32 	%f1836, %f4123, %f3825;
	fma.rn.ftz.f32 	%f1837, %f4122, %f3822, %f1836;
	fma.rn.ftz.f32 	%f4121, %f228, %f3819, %f1837;
	fma.rn.ftz.f32 	%f4122, %f228, %f3818, %f1835;
	fma.rn.ftz.f32 	%f4123, %f228, %f3817, %f1833;
	bra.uni 	$L__BB0_144;

$L__BB0_49:
	mov.f32 	%f4121, %f228;
	bra.uni 	$L__BB0_144;

$L__BB0_120:
	fma.rn.ftz.f32 	%f2694, %f748, %f951, %f744;
	fma.rn.ftz.f32 	%f2695, %f749, %f951, %f745;
	fma.rn.ftz.f32 	%f2696, %f750, %f951, %f746;
	fma.rn.ftz.f32 	%f2697, %f751, %f951, %f747;
	mul.ftz.f32 	%f2698, %f951, %f951;
	fma.rn.ftz.f32 	%f2699, %f752, %f2698, %f2694;
	fma.rn.ftz.f32 	%f2700, %f753, %f2698, %f2695;
	fma.rn.ftz.f32 	%f2701, %f754, %f2698, %f2696;
	fma.rn.ftz.f32 	%f2702, %f755, %f2698, %f2697;
	add.ftz.f32 	%f2703, %f951, %f951;
	fma.rn.ftz.f32 	%f2704, %f752, %f2703, %f748;
	fma.rn.ftz.f32 	%f2705, %f753, %f2703, %f749;
	fma.rn.ftz.f32 	%f2706, %f754, %f2703, %f750;
	fma.rn.ftz.f32 	%f2707, %f755, %f2703, %f751;
	mul.ftz.f32 	%f2708, %f2705, %f2705;
	fma.rn.ftz.f32 	%f2709, %f2704, %f2704, %f2708;
	fma.rn.ftz.f32 	%f2710, %f2706, %f2706, %f2709;
	sub.ftz.f32 	%f2711, %f4057, %f2699;
	sub.ftz.f32 	%f2712, %f4058, %f2700;
	sub.ftz.f32 	%f2713, %f4059, %f2701;
	mul.ftz.f32 	%f2714, %f2705, %f2712;
	fma.rn.ftz.f32 	%f2715, %f2704, %f2711, %f2714;
	fma.rn.ftz.f32 	%f2716, %f2706, %f2713, %f2715;
	div.approx.ftz.f32 	%f2717, %f2716, %f2710;
	mul.ftz.f32 	%f2718, %f2704, %f2717;
	mul.ftz.f32 	%f2719, %f2705, %f2717;
	mul.ftz.f32 	%f2720, %f2706, %f2717;
	sub.ftz.f32 	%f2721, %f2711, %f2718;
	sub.ftz.f32 	%f2722, %f2712, %f2719;
	sub.ftz.f32 	%f2723, %f2713, %f2720;
	mul.ftz.f32 	%f2724, %f2722, %f2722;
	fma.rn.ftz.f32 	%f2725, %f2721, %f2721, %f2724;
	fma.rn.ftz.f32 	%f2726, %f2723, %f2723, %f2725;
	sqrt.approx.ftz.f32 	%f2727, %f2726;
	div.approx.ftz.f32 	%f2728, %f2702, %f2727;
	mul.ftz.f32 	%f2729, %f2721, %f2728;
	mul.ftz.f32 	%f2730, %f2722, %f2728;
	mul.ftz.f32 	%f2731, %f2723, %f2728;
	mul.ftz.f32 	%f2732, %f953, %f2730;
	fma.rn.ftz.f32 	%f2733, %f952, %f2729, %f2732;
	fma.rn.ftz.f32 	%f2734, %f954, %f2731, %f2733;
	sub.ftz.f32 	%f2735, %f2710, %f2734;
	mul.ftz.f32 	%f2736, %f2729, %f2735;
	mul.ftz.f32 	%f2737, %f2730, %f2735;
	mul.ftz.f32 	%f2738, %f2731, %f2735;
	mul.ftz.f32 	%f2739, %f2707, %f2702;
	mul.ftz.f32 	%f2740, %f2704, %f2739;
	mul.ftz.f32 	%f2741, %f2705, %f2739;
	mul.ftz.f32 	%f2742, %f2706, %f2739;
	sub.ftz.f32 	%f4060, %f2736, %f2740;
	sub.ftz.f32 	%f4061, %f2737, %f2741;
	sub.ftz.f32 	%f4062, %f2738, %f2742;

$L__BB0_123:
	mul.ftz.f32 	%f2746, %f4061, %f4061;
	fma.rn.ftz.f32 	%f2747, %f4060, %f4060, %f2746;
	fma.rn.ftz.f32 	%f2748, %f4062, %f4062, %f2747;
	rsqrt.approx.ftz.f32 	%f2749, %f2748;
	mul.ftz.f32 	%f4123, %f4060, %f2749;
	mul.ftz.f32 	%f4122, %f4061, %f2749;
	mul.ftz.f32 	%f969, %f4062, %f2749;
	// begin inline asm
	call (%r894), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p60, %r894, 0;
	@%p60 bra 	$L__BB0_143;

	// begin inline asm
	call (%r895), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f2750), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p61, %r895, 0;
	@%p61 bra 	$L__BB0_142;

	mov.u32 	%r1346, 0;

$L__BB0_126:
	.pragma "nounroll";
	// begin inline asm
	call (%rd656), _optix_get_transform_list_handle, (%r1346);
	// end inline asm
	// begin inline asm
	call (%r898), _optix_get_transform_type_from_handle, (%rd656);
	// end inline asm
	or.b32  	%r899, %r898, 1;
	setp.eq.s32 	%p62, %r899, 3;
	@%p62 bra 	$L__BB0_132;
	bra.uni 	$L__BB0_127;

$L__BB0_132:
	setp.eq.s32 	%p65, %r898, 2;
	@%p65 bra 	$L__BB0_136;
	bra.uni 	$L__BB0_133;

$L__BB0_136:
	// begin inline asm
	call (%rd728), _optix_get_matrix_motion_transform_from_handle, (%rd656);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd730, %rd728;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r987,%r988,%r989,%r990}, [%rd730];
	// end inline asm
	add.s64 	%rd734, %rd728, 16;
	// begin inline asm
	cvta.to.global.u64 %rd733, %rd734;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r991,%r992,%r993,%r994}, [%rd733];
	// end inline asm
	add.s64 	%rd737, %rd728, 32;
	// begin inline asm
	cvta.to.global.u64 %rd736, %rd737;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r995,%r996,%r997,%r998}, [%rd736];
	// end inline asm
	add.s64 	%rd740, %rd728, 48;
	// begin inline asm
	cvta.to.global.u64 %rd739, %rd740;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r999,%r1000,%r1001,%r1002}, [%rd739];
	// end inline asm
	add.s64 	%rd743, %rd728, 64;
	// begin inline asm
	cvta.to.global.u64 %rd742, %rd743;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1003,%r1004,%r1005,%r1006}, [%rd742];
	// end inline asm
	add.s64 	%rd746, %rd728, 80;
	// begin inline asm
	cvta.to.global.u64 %rd745, %rd746;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1007,%r1008,%r1009,%r1010}, [%rd745];
	// end inline asm
	add.s64 	%rd749, %rd728, 96;
	// begin inline asm
	cvta.to.global.u64 %rd748, %rd749;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1011,%r1012,%r1013,%r1014}, [%rd748];
	// end inline asm
	add.s64 	%rd752, %rd728, 112;
	// begin inline asm
	cvta.to.global.u64 %rd751, %rd752;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1015,%r1016,%r1017,%r1018}, [%rd751];
	// end inline asm
	mov.b32 	%f2853, %r990;
	mov.b32 	%f2854, %r991;
	and.b32  	%r1031, %r989, 65535;
	add.s32 	%r1032, %r1031, -1;
	cvt.rn.f32.s32 	%f2855, %r1032;
	sub.ftz.f32 	%f2856, %f2750, %f2853;
	mul.ftz.f32 	%f2857, %f2856, %f2855;
	sub.ftz.f32 	%f2858, %f2854, %f2853;
	div.approx.ftz.f32 	%f2859, %f2857, %f2858;
	min.ftz.f32 	%f2860, %f2855, %f2859;
	mov.f32 	%f2861, 0f00000000;
	max.ftz.f32 	%f2862, %f2861, %f2860;
	cvt.rmi.ftz.f32.f32 	%f2863, %f2862;
	sub.ftz.f32 	%f1029, %f2862, %f2863;
	cvt.rzi.ftz.s32.f32 	%r1033, %f2863;
	cvt.s64.s32 	%rd43, %r1033;
	mul.wide.s32 	%rd763, %r1033, 48;
	add.s64 	%rd755, %rd737, %rd763;
	// begin inline asm
	cvta.to.global.u64 %rd754, %rd755;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1019,%r1020,%r1021,%r1022}, [%rd754];
	// end inline asm
	mov.b32 	%f4088, %r1019;
	mov.b32 	%f4089, %r1020;
	mov.b32 	%f4090, %r1021;
	add.s64 	%rd758, %rd755, 16;
	// begin inline asm
	cvta.to.global.u64 %rd757, %rd758;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1023,%r1024,%r1025,%r1026}, [%rd757];
	// end inline asm
	mov.b32 	%f4085, %r1023;
	mov.b32 	%f4086, %r1024;
	mov.b32 	%f4087, %r1025;
	add.s64 	%rd761, %rd755, 32;
	// begin inline asm
	cvta.to.global.u64 %rd760, %rd761;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1027,%r1028,%r1029,%r1030}, [%rd760];
	// end inline asm
	mov.b32 	%f4082, %r1027;
	mov.b32 	%f4083, %r1028;
	mov.b32 	%f4084, %r1029;
	setp.leu.ftz.f32 	%p67, %f1029, 0f00000000;
	@%p67 bra 	$L__BB0_138;

	mov.f32 	%f2864, 0f3F800000;
	sub.ftz.f32 	%f2865, %f2864, %f1029;
	mul.lo.s64 	%rd773, %rd43, 48;
	add.s64 	%rd774, %rd728, %rd773;
	add.s64 	%rd765, %rd774, 80;
	// begin inline asm
	cvta.to.global.u64 %rd764, %rd765;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1034,%r1035,%r1036,%r1037}, [%rd764];
	// end inline asm
	mov.b32 	%f2866, %r1034;
	mov.b32 	%f2867, %r1035;
	mov.b32 	%f2868, %r1036;
	mul.ftz.f32 	%f2869, %f1029, %f2866;
	mul.ftz.f32 	%f2870, %f1029, %f2867;
	mul.ftz.f32 	%f2871, %f1029, %f2868;
	fma.rn.ftz.f32 	%f4088, %f2865, %f4088, %f2869;
	fma.rn.ftz.f32 	%f4089, %f2865, %f4089, %f2870;
	fma.rn.ftz.f32 	%f4090, %f2865, %f4090, %f2871;
	add.s64 	%rd768, %rd774, 96;
	// begin inline asm
	cvta.to.global.u64 %rd767, %rd768;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1038,%r1039,%r1040,%r1041}, [%rd767];
	// end inline asm
	mov.b32 	%f2872, %r1038;
	mov.b32 	%f2873, %r1039;
	mov.b32 	%f2874, %r1040;
	mul.ftz.f32 	%f2875, %f1029, %f2872;
	mul.ftz.f32 	%f2876, %f1029, %f2873;
	mul.ftz.f32 	%f2877, %f1029, %f2874;
	fma.rn.ftz.f32 	%f4085, %f2865, %f4085, %f2875;
	fma.rn.ftz.f32 	%f4086, %f2865, %f4086, %f2876;
	fma.rn.ftz.f32 	%f4087, %f2865, %f4087, %f2877;
	add.s64 	%rd771, %rd774, 112;
	// begin inline asm
	cvta.to.global.u64 %rd770, %rd771;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1042,%r1043,%r1044,%r1045}, [%rd770];
	// end inline asm
	mov.b32 	%f2878, %r1042;
	mov.b32 	%f2879, %r1043;
	mov.b32 	%f2880, %r1044;
	mul.ftz.f32 	%f2881, %f1029, %f2878;
	mul.ftz.f32 	%f2882, %f1029, %f2879;
	mul.ftz.f32 	%f2883, %f1029, %f2880;
	fma.rn.ftz.f32 	%f4082, %f2865, %f4082, %f2881;
	fma.rn.ftz.f32 	%f4083, %f2865, %f4083, %f2882;
	fma.rn.ftz.f32 	%f4084, %f2865, %f4084, %f2883;
	bra.uni 	$L__BB0_138;

$L__BB0_127:
	mov.f32 	%f4091, 0f00000000;
	mov.f32 	%f4093, 0f3F800000;
	setp.eq.s32 	%p63, %r898, 4;
	@%p63 bra 	$L__BB0_130;

	setp.ne.s32 	%p64, %r898, 1;
	mov.f32 	%f4092, %f4091;
	mov.f32 	%f4094, %f4091;
	mov.f32 	%f4095, %f4093;
	mov.f32 	%f4096, %f4091;
	mov.f32 	%f4097, %f4093;
	mov.f32 	%f4098, %f4091;
	mov.f32 	%f4099, %f4091;
	@%p64 bra 	$L__BB0_139;

	// begin inline asm
	call (%rd658), _optix_get_static_transform_from_handle, (%rd656);
	// end inline asm
	add.s64 	%rd801, %rd658, 64;
	bra.uni 	$L__BB0_131;

$L__BB0_133:
	// begin inline asm
	call (%rd671), _optix_get_srt_motion_transform_from_handle, (%rd656);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd673, %rd671;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r912,%r913,%r914,%r915}, [%rd673];
	// end inline asm
	add.s64 	%rd677, %rd671, 16;
	// begin inline asm
	cvta.to.global.u64 %rd676, %rd677;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r916,%r917,%r918,%r919}, [%rd676];
	// end inline asm
	add.s64 	%rd680, %rd671, 32;
	// begin inline asm
	cvta.to.global.u64 %rd679, %rd680;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r920,%r921,%r922,%r923}, [%rd679];
	// end inline asm
	add.s64 	%rd683, %rd671, 48;
	// begin inline asm
	cvta.to.global.u64 %rd682, %rd683;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r924,%r925,%r926,%r927}, [%rd682];
	// end inline asm
	add.s64 	%rd686, %rd671, 64;
	// begin inline asm
	cvta.to.global.u64 %rd685, %rd686;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r928,%r929,%r930,%r931}, [%rd685];
	// end inline asm
	add.s64 	%rd689, %rd671, 80;
	// begin inline asm
	cvta.to.global.u64 %rd688, %rd689;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r932,%r933,%r934,%r935}, [%rd688];
	// end inline asm
	add.s64 	%rd692, %rd671, 96;
	// begin inline asm
	cvta.to.global.u64 %rd691, %rd692;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r936,%r937,%r938,%r939}, [%rd691];
	// end inline asm
	add.s64 	%rd695, %rd671, 112;
	// begin inline asm
	cvta.to.global.u64 %rd694, %rd695;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r940,%r941,%r942,%r943}, [%rd694];
	// end inline asm
	add.s64 	%rd698, %rd671, 128;
	// begin inline asm
	cvta.to.global.u64 %rd697, %rd698;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r944,%r945,%r946,%r947}, [%rd697];
	// end inline asm
	add.s64 	%rd701, %rd671, 144;
	// begin inline asm
	cvta.to.global.u64 %rd700, %rd701;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r948,%r949,%r950,%r951}, [%rd700];
	// end inline asm
	mov.b32 	%f2762, %r915;
	mov.b32 	%f2763, %r916;
	and.b32  	%r968, %r914, 65535;
	add.s32 	%r969, %r968, -1;
	cvt.rn.f32.s32 	%f2764, %r969;
	sub.ftz.f32 	%f2765, %f2750, %f2762;
	mul.ftz.f32 	%f2766, %f2765, %f2764;
	sub.ftz.f32 	%f2767, %f2763, %f2762;
	div.approx.ftz.f32 	%f2768, %f2766, %f2767;
	min.ftz.f32 	%f2769, %f2764, %f2768;
	mov.f32 	%f2770, 0f00000000;
	max.ftz.f32 	%f2771, %f2770, %f2769;
	cvt.rmi.ftz.f32.f32 	%f2772, %f2771;
	sub.ftz.f32 	%f989, %f2771, %f2772;
	cvt.rzi.ftz.s32.f32 	%r970, %f2772;
	mul.wide.s32 	%rd715, %r970, 64;
	add.s64 	%rd704, %rd680, %rd715;
	// begin inline asm
	cvta.to.global.u64 %rd703, %rd704;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r952,%r953,%r954,%r955}, [%rd703];
	// end inline asm
	mov.b32 	%f4080, %r952;
	mov.b32 	%f4079, %r953;
	mov.b32 	%f4078, %r954;
	add.s64 	%rd707, %rd704, 16;
	// begin inline asm
	cvta.to.global.u64 %rd706, %rd707;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r956,%r957,%r958,%r959}, [%rd706];
	// end inline asm
	mov.b32 	%f4077, %r956;
	mov.b32 	%f4076, %r957;
	mov.b32 	%f4075, %r959;
	add.s64 	%rd710, %rd704, 32;
	// begin inline asm
	cvta.to.global.u64 %rd709, %rd710;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r960,%r961,%r962,%r963}, [%rd709];
	// end inline asm
	mov.b32 	%f4074, %r961;
	mov.b32 	%f4073, %r962;
	mov.b32 	%f4072, %r963;
	add.s64 	%rd713, %rd704, 48;
	// begin inline asm
	cvta.to.global.u64 %rd712, %rd713;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r964,%r965,%r966,%r967}, [%rd712];
	// end inline asm
	mov.b32 	%f4081, %r964;
	setp.leu.ftz.f32 	%p66, %f989, 0f00000000;
	@%p66 bra 	$L__BB0_135;

	mov.f32 	%f2773, 0f3F800000;
	sub.ftz.f32 	%f2774, %f2773, %f989;
	add.s64 	%rd717, %rd704, 64;
	// begin inline asm
	cvta.to.global.u64 %rd716, %rd717;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r971,%r972,%r973,%r974}, [%rd716];
	// end inline asm
	mov.b32 	%f2775, %r971;
	mov.b32 	%f2776, %r972;
	mov.b32 	%f2777, %r973;
	mul.ftz.f32 	%f2778, %f989, %f2775;
	mul.ftz.f32 	%f2779, %f989, %f2776;
	mul.ftz.f32 	%f2780, %f989, %f2777;
	fma.rn.ftz.f32 	%f4080, %f2774, %f4080, %f2778;
	fma.rn.ftz.f32 	%f4079, %f2774, %f4079, %f2779;
	fma.rn.ftz.f32 	%f4078, %f2774, %f4078, %f2780;
	add.s64 	%rd720, %rd704, 80;
	// begin inline asm
	cvta.to.global.u64 %rd719, %rd720;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r975,%r976,%r977,%r978}, [%rd719];
	// end inline asm
	mov.b32 	%f2781, %r975;
	mov.b32 	%f2782, %r976;
	mov.b32 	%f2783, %r978;
	mul.ftz.f32 	%f2784, %f989, %f2781;
	mul.ftz.f32 	%f2785, %f989, %f2782;
	mul.ftz.f32 	%f2786, %f989, %f2783;
	fma.rn.ftz.f32 	%f4077, %f2774, %f4077, %f2784;
	fma.rn.ftz.f32 	%f4076, %f2774, %f4076, %f2785;
	fma.rn.ftz.f32 	%f4075, %f2774, %f4075, %f2786;
	add.s64 	%rd723, %rd704, 96;
	// begin inline asm
	cvta.to.global.u64 %rd722, %rd723;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r979,%r980,%r981,%r982}, [%rd722];
	// end inline asm
	mov.b32 	%f2787, %r980;
	mov.b32 	%f2788, %r981;
	mov.b32 	%f2789, %r982;
	mul.ftz.f32 	%f2790, %f989, %f2787;
	mul.ftz.f32 	%f2791, %f989, %f2788;
	mul.ftz.f32 	%f2792, %f989, %f2789;
	fma.rn.ftz.f32 	%f2793, %f2774, %f4074, %f2790;
	fma.rn.ftz.f32 	%f2794, %f2774, %f4073, %f2791;
	fma.rn.ftz.f32 	%f2795, %f2774, %f4072, %f2792;
	add.s64 	%rd726, %rd704, 112;
	// begin inline asm
	cvta.to.global.u64 %rd725, %rd726;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r983,%r984,%r985,%r986}, [%rd725];
	// end inline asm
	mov.b32 	%f2796, %r983;
	mul.ftz.f32 	%f2797, %f989, %f2796;
	fma.rn.ftz.f32 	%f2798, %f2774, %f4081, %f2797;
	mul.ftz.f32 	%f2799, %f2794, %f2794;
	fma.rn.ftz.f32 	%f2800, %f2793, %f2793, %f2799;
	fma.rn.ftz.f32 	%f2801, %f2795, %f2795, %f2800;
	fma.rn.ftz.f32 	%f2802, %f2798, %f2798, %f2801;
	rsqrt.approx.ftz.f32 	%f2803, %f2802;
	mul.ftz.f32 	%f4074, %f2793, %f2803;
	mul.ftz.f32 	%f4073, %f2794, %f2803;
	mul.ftz.f32 	%f4072, %f2795, %f2803;
	mul.ftz.f32 	%f4081, %f2803, %f2798;

$L__BB0_135:
	mul.ftz.f32 	%f2804, %f4074, %f4074;
	fma.rn.ftz.f32 	%f2805, %f4073, %f4073, %f2804;
	fma.rn.ftz.f32 	%f2806, %f4072, %f4072, %f2805;
	fma.rn.ftz.f32 	%f2807, %f4081, %f4081, %f2806;
	rcp.approx.ftz.f32 	%f2808, %f2807;
	mul.ftz.f32 	%f2809, %f4074, %f2808;
	mul.ftz.f32 	%f2810, %f4073, %f2808;
	mul.ftz.f32 	%f2811, %f4072, %f2808;
	mul.ftz.f32 	%f2812, %f4081, %f2808;
	mul.ftz.f32 	%f2813, %f4074, %f2809;
	mul.ftz.f32 	%f2814, %f4073, %f2810;
	mul.ftz.f32 	%f2815, %f4072, %f2811;
	mul.ftz.f32 	%f2816, %f4074, %f2810;
	mul.ftz.f32 	%f2817, %f4072, %f2812;
	mul.ftz.f32 	%f2818, %f4074, %f2811;
	mul.ftz.f32 	%f2819, %f4073, %f2812;
	mul.ftz.f32 	%f2820, %f4073, %f2811;
	mul.ftz.f32 	%f2821, %f4074, %f2812;
	sub.ftz.f32 	%f2822, %f2813, %f2814;
	sub.ftz.f32 	%f2823, %f2822, %f2815;
	fma.rn.ftz.f32 	%f2824, %f4081, %f2812, %f2823;
	sub.ftz.f32 	%f2825, %f2816, %f2817;
	add.ftz.f32 	%f2826, %f2825, %f2825;
	add.ftz.f32 	%f2827, %f2818, %f2819;
	add.ftz.f32 	%f2828, %f2827, %f2827;
	add.ftz.f32 	%f2829, %f2816, %f2817;
	add.ftz.f32 	%f2830, %f2829, %f2829;
	sub.ftz.f32 	%f2831, %f2814, %f2813;
	sub.ftz.f32 	%f2832, %f2831, %f2815;
	fma.rn.ftz.f32 	%f2833, %f4081, %f2812, %f2832;
	sub.ftz.f32 	%f2834, %f2820, %f2821;
	add.ftz.f32 	%f2835, %f2834, %f2834;
	sub.ftz.f32 	%f2836, %f2818, %f2819;
	add.ftz.f32 	%f2837, %f2836, %f2836;
	add.ftz.f32 	%f2838, %f2820, %f2821;
	add.ftz.f32 	%f2839, %f2838, %f2838;
	neg.ftz.f32 	%f2840, %f2813;
	sub.ftz.f32 	%f2841, %f2840, %f2814;
	add.ftz.f32 	%f2842, %f2815, %f2841;
	fma.rn.ftz.f32 	%f2843, %f4081, %f2812, %f2842;
	mul.ftz.f32 	%f2844, %f4078, %f2824;
	fma.rn.ftz.f32 	%f2845, %f4076, %f2826, %f2844;
	fma.rn.ftz.f32 	%f4090, %f4075, %f2828, %f2845;
	mul.ftz.f32 	%f2846, %f4076, %f2833;
	fma.rn.ftz.f32 	%f2847, %f4078, %f2830, %f2846;
	fma.rn.ftz.f32 	%f4087, %f4075, %f2835, %f2847;
	mul.ftz.f32 	%f2848, %f4076, %f2839;
	fma.rn.ftz.f32 	%f2849, %f4078, %f2837, %f2848;
	fma.rn.ftz.f32 	%f4084, %f4075, %f2843, %f2849;
	mul.ftz.f32 	%f2850, %f4079, %f2824;
	fma.rn.ftz.f32 	%f4089, %f4077, %f2826, %f2850;
	mul.ftz.f32 	%f2851, %f4077, %f2833;
	fma.rn.ftz.f32 	%f4086, %f4079, %f2830, %f2851;
	mul.ftz.f32 	%f2852, %f4077, %f2839;
	fma.rn.ftz.f32 	%f4083, %f4079, %f2837, %f2852;
	mul.ftz.f32 	%f4088, %f4080, %f2824;
	mul.ftz.f32 	%f4085, %f4080, %f2830;
	mul.ftz.f32 	%f4082, %f4080, %f2837;

$L__BB0_138:
	mul.ftz.f32 	%f2884, %f4083, %f4087;
	mul.ftz.f32 	%f2885, %f4084, %f4086;
	sub.ftz.f32 	%f2886, %f2885, %f2884;
	mul.ftz.f32 	%f2887, %f4088, %f2886;
	mul.ftz.f32 	%f2888, %f4082, %f4087;
	mul.ftz.f32 	%f2889, %f4084, %f4085;
	sub.ftz.f32 	%f2890, %f2889, %f2888;
	mul.ftz.f32 	%f2891, %f2890, %f4089;
	sub.ftz.f32 	%f2892, %f2887, %f2891;
	mul.ftz.f32 	%f2893, %f4082, %f4086;
	mul.ftz.f32 	%f2894, %f4083, %f4085;
	sub.ftz.f32 	%f2895, %f2894, %f2893;
	fma.rn.ftz.f32 	%f2896, %f2895, %f4090, %f2892;
	rcp.approx.ftz.f32 	%f2897, %f2896;
	mul.ftz.f32 	%f4097, %f2886, %f2897;
	mul.ftz.f32 	%f2898, %f4084, %f4089;
	mul.ftz.f32 	%f2899, %f4083, %f4090;
	sub.ftz.f32 	%f2900, %f2899, %f2898;
	mul.ftz.f32 	%f4098, %f2900, %f2897;
	mul.ftz.f32 	%f2901, %f4086, %f4090;
	mul.ftz.f32 	%f2902, %f4087, %f4089;
	sub.ftz.f32 	%f2903, %f2902, %f2901;
	mul.ftz.f32 	%f4099, %f2903, %f2897;
	sub.ftz.f32 	%f2904, %f2888, %f2889;
	mul.ftz.f32 	%f4094, %f2904, %f2897;
	mul.ftz.f32 	%f2905, %f4082, %f4090;
	mul.ftz.f32 	%f2906, %f4084, %f4088;
	sub.ftz.f32 	%f2907, %f2906, %f2905;
	mul.ftz.f32 	%f4095, %f2907, %f2897;
	mul.ftz.f32 	%f2908, %f4087, %f4088;
	mul.ftz.f32 	%f2909, %f4085, %f4090;
	sub.ftz.f32 	%f2910, %f2909, %f2908;
	mul.ftz.f32 	%f4096, %f2910, %f2897;
	mul.ftz.f32 	%f4091, %f2895, %f2897;
	mul.ftz.f32 	%f2911, %f4083, %f4088;
	mul.ftz.f32 	%f2912, %f4082, %f4089;
	sub.ftz.f32 	%f2913, %f2912, %f2911;
	mul.ftz.f32 	%f4092, %f2913, %f2897;
	mul.ftz.f32 	%f2914, %f4085, %f4089;
	mul.ftz.f32 	%f2915, %f4086, %f4088;
	sub.ftz.f32 	%f2916, %f2915, %f2914;
	mul.ftz.f32 	%f4093, %f2916, %f2897;
	bra.uni 	$L__BB0_139;

$L__BB0_130:
	// begin inline asm
	call (%rd801), _optix_get_instance_inverse_transform_from_handle, (%rd656);
	// end inline asm

$L__BB0_131:
	// begin inline asm
	cvta.to.global.u64 %rd662, %rd801;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r900,%r901,%r902,%r903}, [%rd662];
	// end inline asm
	mov.b32 	%f4097, %r900;
	mov.b32 	%f4098, %r901;
	mov.b32 	%f4099, %r902;
	add.s64 	%rd666, %rd801, 16;
	// begin inline asm
	cvta.to.global.u64 %rd665, %rd666;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r904,%r905,%r906,%r907}, [%rd665];
	// end inline asm
	mov.b32 	%f4094, %r904;
	mov.b32 	%f4095, %r905;
	mov.b32 	%f4096, %r906;
	add.s64 	%rd669, %rd801, 32;
	// begin inline asm
	cvta.to.global.u64 %rd668, %rd669;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r908,%r909,%r910,%r911}, [%rd668];
	// end inline asm
	mov.b32 	%f4091, %r908;
	mov.b32 	%f4092, %r909;
	mov.b32 	%f4093, %r910;

$L__BB0_139:
	setp.eq.s32 	%p68, %r1346, 0;
	@%p68 bra 	$L__BB0_141;

	mul.ftz.f32 	%f2917, %f4068, %f4098;
	fma.rn.ftz.f32 	%f2918, %f4065, %f4097, %f2917;
	fma.rn.ftz.f32 	%f1075, %f4071, %f4099, %f2918;
	mul.ftz.f32 	%f2919, %f4067, %f4098;
	fma.rn.ftz.f32 	%f2920, %f4064, %f4097, %f2919;
	fma.rn.ftz.f32 	%f1076, %f4070, %f4099, %f2920;
	mul.ftz.f32 	%f2921, %f4066, %f4098;
	fma.rn.ftz.f32 	%f2922, %f4063, %f4097, %f2921;
	fma.rn.ftz.f32 	%f4099, %f4069, %f4099, %f2922;
	mul.ftz.f32 	%f2923, %f4068, %f4095;
	fma.rn.ftz.f32 	%f2924, %f4065, %f4094, %f2923;
	fma.rn.ftz.f32 	%f1078, %f4071, %f4096, %f2924;
	mul.ftz.f32 	%f2925, %f4067, %f4095;
	fma.rn.ftz.f32 	%f2926, %f4064, %f4094, %f2925;
	fma.rn.ftz.f32 	%f1079, %f4070, %f4096, %f2926;
	mul.ftz.f32 	%f2927, %f4066, %f4095;
	fma.rn.ftz.f32 	%f2928, %f4063, %f4094, %f2927;
	fma.rn.ftz.f32 	%f4096, %f4069, %f4096, %f2928;
	mul.ftz.f32 	%f2929, %f4068, %f4092;
	fma.rn.ftz.f32 	%f2930, %f4065, %f4091, %f2929;
	fma.rn.ftz.f32 	%f1081, %f4071, %f4093, %f2930;
	mul.ftz.f32 	%f2931, %f4067, %f4092;
	fma.rn.ftz.f32 	%f2932, %f4064, %f4091, %f2931;
	fma.rn.ftz.f32 	%f1082, %f4070, %f4093, %f2932;
	mul.ftz.f32 	%f2933, %f4066, %f4092;
	fma.rn.ftz.f32 	%f2934, %f4063, %f4091, %f2933;
	fma.rn.ftz.f32 	%f4093, %f4069, %f4093, %f2934;
	mov.f32 	%f4091, %f1081;
	mov.f32 	%f4092, %f1082;
	mov.f32 	%f4094, %f1078;
	mov.f32 	%f4095, %f1079;
	mov.f32 	%f4097, %f1075;
	mov.f32 	%f4098, %f1076;

$L__BB0_141:
	add.s32 	%r1346, %r1346, 1;
	setp.lt.u32 	%p69, %r1346, %r895;
	mov.f32 	%f4063, %f4099;
	mov.f32 	%f4064, %f4098;
	mov.f32 	%f4065, %f4097;
	mov.f32 	%f4066, %f4096;
	mov.f32 	%f4067, %f4095;
	mov.f32 	%f4068, %f4094;
	mov.f32 	%f4069, %f4093;
	mov.f32 	%f4070, %f4092;
	mov.f32 	%f4071, %f4091;
	@%p69 bra 	$L__BB0_126;

$L__BB0_142:
	mul.ftz.f32 	%f2935, %f4123, %f4097;
	fma.rn.ftz.f32 	%f2936, %f4122, %f4094, %f2935;
	mul.ftz.f32 	%f2937, %f4123, %f4098;
	fma.rn.ftz.f32 	%f2938, %f4122, %f4095, %f2937;
	mul.ftz.f32 	%f2939, %f4123, %f4099;
	fma.rn.ftz.f32 	%f2940, %f4122, %f4096, %f2939;
	fma.rn.ftz.f32 	%f4121, %f969, %f4093, %f2940;
	fma.rn.ftz.f32 	%f4122, %f969, %f4092, %f2938;
	fma.rn.ftz.f32 	%f4123, %f969, %f4091, %f2936;
	bra.uni 	$L__BB0_144;

$L__BB0_143:
	mov.f32 	%f4121, %f969;
	bra.uni 	$L__BB0_144;

$L__BB0_73:
	mul.ftz.f32 	%f2111, %f584, %f584;
	mul.ftz.f32 	%f2112, %f2111, 0f3E2AAAAB;
	mul.ftz.f32 	%f2113, %f2112, %f584;
	sub.ftz.f32 	%f2114, %f584, %f2111;
	fma.rn.ftz.f32 	%f2115, %f2114, 0f3F000000, %f2113;
	mul.ftz.f32 	%f2116, %f2113, 0f40800000;
	sub.ftz.f32 	%f2117, %f2111, %f2116;
	fma.rn.ftz.f32 	%f2118, %f377, %f2115, %f373;
	fma.rn.ftz.f32 	%f2119, %f378, %f2115, %f374;
	fma.rn.ftz.f32 	%f2120, %f379, %f2115, %f375;
	fma.rn.ftz.f32 	%f2121, %f380, %f2115, %f376;
	fma.rn.ftz.f32 	%f2122, %f381, %f2117, %f2118;
	fma.rn.ftz.f32 	%f2123, %f382, %f2117, %f2119;
	fma.rn.ftz.f32 	%f2124, %f383, %f2117, %f2120;
	fma.rn.ftz.f32 	%f2125, %f384, %f2117, %f2121;
	fma.rn.ftz.f32 	%f2126, %f385, %f2113, %f2122;
	fma.rn.ftz.f32 	%f2127, %f386, %f2113, %f2123;
	fma.rn.ftz.f32 	%f2128, %f387, %f2113, %f2124;
	fma.rn.ftz.f32 	%f2129, %f388, %f2113, %f2125;
	mov.f32 	%f2130, 0f3F800000;
	sub.ftz.f32 	%f2131, %f2130, %f584;
	mul.ftz.f32 	%f2132, %f2131, 0f3F000000;
	mul.ftz.f32 	%f2133, %f2131, %f2132;
	add.ftz.f32 	%f2134, %f2131, %f2131;
	mul.ftz.f32 	%f2135, %f2134, %f584;
	mul.ftz.f32 	%f2136, %f381, %f2135;
	mul.ftz.f32 	%f2137, %f382, %f2135;
	mul.ftz.f32 	%f2138, %f383, %f2135;
	mul.ftz.f32 	%f2139, %f384, %f2135;
	fma.rn.ftz.f32 	%f2140, %f377, %f2133, %f2136;
	fma.rn.ftz.f32 	%f2141, %f378, %f2133, %f2137;
	fma.rn.ftz.f32 	%f2142, %f379, %f2133, %f2138;
	fma.rn.ftz.f32 	%f2143, %f380, %f2133, %f2139;
	mul.ftz.f32 	%f2144, %f584, 0f3F000000;
	mul.ftz.f32 	%f2145, %f2144, %f584;
	fma.rn.ftz.f32 	%f2146, %f385, %f2145, %f2140;
	fma.rn.ftz.f32 	%f2147, %f386, %f2145, %f2141;
	fma.rn.ftz.f32 	%f2148, %f387, %f2145, %f2142;
	fma.rn.ftz.f32 	%f2149, %f388, %f2145, %f2143;
	mul.ftz.f32 	%f2150, %f2147, %f2147;
	fma.rn.ftz.f32 	%f2151, %f2146, %f2146, %f2150;
	fma.rn.ftz.f32 	%f2152, %f2148, %f2148, %f2151;
	sub.ftz.f32 	%f2153, %f3920, %f2126;
	sub.ftz.f32 	%f2154, %f3921, %f2127;
	sub.ftz.f32 	%f2155, %f3922, %f2128;
	mul.ftz.f32 	%f2156, %f2147, %f2154;
	fma.rn.ftz.f32 	%f2157, %f2146, %f2153, %f2156;
	fma.rn.ftz.f32 	%f2158, %f2148, %f2155, %f2157;
	div.approx.ftz.f32 	%f2159, %f2158, %f2152;
	mul.ftz.f32 	%f2160, %f2146, %f2159;
	mul.ftz.f32 	%f2161, %f2147, %f2159;
	mul.ftz.f32 	%f2162, %f2148, %f2159;
	sub.ftz.f32 	%f2163, %f2153, %f2160;
	sub.ftz.f32 	%f2164, %f2154, %f2161;
	sub.ftz.f32 	%f2165, %f2155, %f2162;
	mul.ftz.f32 	%f2166, %f2164, %f2164;
	fma.rn.ftz.f32 	%f2167, %f2163, %f2163, %f2166;
	fma.rn.ftz.f32 	%f2168, %f2165, %f2165, %f2167;
	sqrt.approx.ftz.f32 	%f2169, %f2168;
	div.approx.ftz.f32 	%f2170, %f2129, %f2169;
	mul.ftz.f32 	%f2171, %f2163, %f2170;
	mul.ftz.f32 	%f2172, %f2164, %f2170;
	mul.ftz.f32 	%f2173, %f2165, %f2170;
	add.ftz.f32 	%f2174, %f381, %f381;
	sub.ftz.f32 	%f2175, %f2174, %f377;
	add.ftz.f32 	%f2176, %f382, %f382;
	sub.ftz.f32 	%f2177, %f2176, %f378;
	add.ftz.f32 	%f2178, %f383, %f383;
	sub.ftz.f32 	%f2179, %f2178, %f379;
	mul.ftz.f32 	%f2180, %f381, 0f40800000;
	sub.ftz.f32 	%f2181, %f377, %f2180;
	mul.ftz.f32 	%f2182, %f382, 0f40800000;
	sub.ftz.f32 	%f2183, %f378, %f2182;
	mul.ftz.f32 	%f2184, %f383, 0f40800000;
	sub.ftz.f32 	%f2185, %f379, %f2184;
	add.ftz.f32 	%f2186, %f385, %f2181;
	add.ftz.f32 	%f2187, %f386, %f2183;
	add.ftz.f32 	%f2188, %f387, %f2185;
	fma.rn.ftz.f32 	%f2189, %f2186, %f584, %f2175;
	fma.rn.ftz.f32 	%f2190, %f2187, %f584, %f2177;
	fma.rn.ftz.f32 	%f2191, %f2188, %f584, %f2179;
	mul.ftz.f32 	%f2192, %f2190, %f2172;
	fma.rn.ftz.f32 	%f2193, %f2189, %f2171, %f2192;
	fma.rn.ftz.f32 	%f2194, %f2191, %f2173, %f2193;
	sub.ftz.f32 	%f2195, %f2152, %f2194;
	mul.ftz.f32 	%f2196, %f2171, %f2195;
	mul.ftz.f32 	%f2197, %f2172, %f2195;
	mul.ftz.f32 	%f2198, %f2173, %f2195;
	mul.ftz.f32 	%f2199, %f2149, %f2129;
	mul.ftz.f32 	%f2200, %f2146, %f2199;
	mul.ftz.f32 	%f2201, %f2147, %f2199;
	mul.ftz.f32 	%f2202, %f2148, %f2199;
	sub.ftz.f32 	%f3923, %f2196, %f2200;
	sub.ftz.f32 	%f3924, %f2197, %f2201;
	sub.ftz.f32 	%f3925, %f2198, %f2202;

$L__BB0_76:
	mul.ftz.f32 	%f2230, %f3924, %f3924;
	fma.rn.ftz.f32 	%f2231, %f3923, %f3923, %f2230;
	fma.rn.ftz.f32 	%f2232, %f3925, %f3925, %f2231;
	rsqrt.approx.ftz.f32 	%f2233, %f2232;
	mul.ftz.f32 	%f4123, %f3923, %f2233;
	mul.ftz.f32 	%f4122, %f3924, %f2233;
	mul.ftz.f32 	%f599, %f3925, %f2233;
	// begin inline asm
	call (%r586), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p38, %r586, 0;
	@%p38 bra 	$L__BB0_96;

	// begin inline asm
	call (%r587), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f2234), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p39, %r587, 0;
	@%p39 bra 	$L__BB0_95;

	mov.u32 	%r1344, 0;

$L__BB0_79:
	.pragma "nounroll";
	// begin inline asm
	call (%rd416), _optix_get_transform_list_handle, (%r1344);
	// end inline asm
	// begin inline asm
	call (%r590), _optix_get_transform_type_from_handle, (%rd416);
	// end inline asm
	or.b32  	%r591, %r590, 1;
	setp.eq.s32 	%p40, %r591, 3;
	@%p40 bra 	$L__BB0_85;
	bra.uni 	$L__BB0_80;

$L__BB0_85:
	setp.eq.s32 	%p43, %r590, 2;
	@%p43 bra 	$L__BB0_89;
	bra.uni 	$L__BB0_86;

$L__BB0_89:
	// begin inline asm
	call (%rd488), _optix_get_matrix_motion_transform_from_handle, (%rd416);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd490, %rd488;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r679,%r680,%r681,%r682}, [%rd490];
	// end inline asm
	add.s64 	%rd494, %rd488, 16;
	// begin inline asm
	cvta.to.global.u64 %rd493, %rd494;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r683,%r684,%r685,%r686}, [%rd493];
	// end inline asm
	add.s64 	%rd497, %rd488, 32;
	// begin inline asm
	cvta.to.global.u64 %rd496, %rd497;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r687,%r688,%r689,%r690}, [%rd496];
	// end inline asm
	add.s64 	%rd500, %rd488, 48;
	// begin inline asm
	cvta.to.global.u64 %rd499, %rd500;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r691,%r692,%r693,%r694}, [%rd499];
	// end inline asm
	add.s64 	%rd503, %rd488, 64;
	// begin inline asm
	cvta.to.global.u64 %rd502, %rd503;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r695,%r696,%r697,%r698}, [%rd502];
	// end inline asm
	add.s64 	%rd506, %rd488, 80;
	// begin inline asm
	cvta.to.global.u64 %rd505, %rd506;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r699,%r700,%r701,%r702}, [%rd505];
	// end inline asm
	add.s64 	%rd509, %rd488, 96;
	// begin inline asm
	cvta.to.global.u64 %rd508, %rd509;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r703,%r704,%r705,%r706}, [%rd508];
	// end inline asm
	add.s64 	%rd512, %rd488, 112;
	// begin inline asm
	cvta.to.global.u64 %rd511, %rd512;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r707,%r708,%r709,%r710}, [%rd511];
	// end inline asm
	mov.b32 	%f2337, %r682;
	mov.b32 	%f2338, %r683;
	and.b32  	%r723, %r681, 65535;
	add.s32 	%r724, %r723, -1;
	cvt.rn.f32.s32 	%f2339, %r724;
	sub.ftz.f32 	%f2340, %f2234, %f2337;
	mul.ftz.f32 	%f2341, %f2340, %f2339;
	sub.ftz.f32 	%f2342, %f2338, %f2337;
	div.approx.ftz.f32 	%f2343, %f2341, %f2342;
	min.ftz.f32 	%f2344, %f2339, %f2343;
	mov.f32 	%f2345, 0f00000000;
	max.ftz.f32 	%f2346, %f2345, %f2344;
	cvt.rmi.ftz.f32.f32 	%f2347, %f2346;
	sub.ftz.f32 	%f659, %f2346, %f2347;
	cvt.rzi.ftz.s32.f32 	%r725, %f2347;
	cvt.s64.s32 	%rd29, %r725;
	mul.wide.s32 	%rd523, %r725, 48;
	add.s64 	%rd515, %rd497, %rd523;
	// begin inline asm
	cvta.to.global.u64 %rd514, %rd515;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r711,%r712,%r713,%r714}, [%rd514];
	// end inline asm
	mov.b32 	%f3951, %r711;
	mov.b32 	%f3952, %r712;
	mov.b32 	%f3953, %r713;
	add.s64 	%rd518, %rd515, 16;
	// begin inline asm
	cvta.to.global.u64 %rd517, %rd518;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r715,%r716,%r717,%r718}, [%rd517];
	// end inline asm
	mov.b32 	%f3948, %r715;
	mov.b32 	%f3949, %r716;
	mov.b32 	%f3950, %r717;
	add.s64 	%rd521, %rd515, 32;
	// begin inline asm
	cvta.to.global.u64 %rd520, %rd521;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r719,%r720,%r721,%r722}, [%rd520];
	// end inline asm
	mov.b32 	%f3945, %r719;
	mov.b32 	%f3946, %r720;
	mov.b32 	%f3947, %r721;
	setp.leu.ftz.f32 	%p45, %f659, 0f00000000;
	@%p45 bra 	$L__BB0_91;

	mov.f32 	%f2348, 0f3F800000;
	sub.ftz.f32 	%f2349, %f2348, %f659;
	mul.lo.s64 	%rd533, %rd29, 48;
	add.s64 	%rd534, %rd488, %rd533;
	add.s64 	%rd525, %rd534, 80;
	// begin inline asm
	cvta.to.global.u64 %rd524, %rd525;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r726,%r727,%r728,%r729}, [%rd524];
	// end inline asm
	mov.b32 	%f2350, %r726;
	mov.b32 	%f2351, %r727;
	mov.b32 	%f2352, %r728;
	mul.ftz.f32 	%f2353, %f659, %f2350;
	mul.ftz.f32 	%f2354, %f659, %f2351;
	mul.ftz.f32 	%f2355, %f659, %f2352;
	fma.rn.ftz.f32 	%f3951, %f2349, %f3951, %f2353;
	fma.rn.ftz.f32 	%f3952, %f2349, %f3952, %f2354;
	fma.rn.ftz.f32 	%f3953, %f2349, %f3953, %f2355;
	add.s64 	%rd528, %rd534, 96;
	// begin inline asm
	cvta.to.global.u64 %rd527, %rd528;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r730,%r731,%r732,%r733}, [%rd527];
	// end inline asm
	mov.b32 	%f2356, %r730;
	mov.b32 	%f2357, %r731;
	mov.b32 	%f2358, %r732;
	mul.ftz.f32 	%f2359, %f659, %f2356;
	mul.ftz.f32 	%f2360, %f659, %f2357;
	mul.ftz.f32 	%f2361, %f659, %f2358;
	fma.rn.ftz.f32 	%f3948, %f2349, %f3948, %f2359;
	fma.rn.ftz.f32 	%f3949, %f2349, %f3949, %f2360;
	fma.rn.ftz.f32 	%f3950, %f2349, %f3950, %f2361;
	add.s64 	%rd531, %rd534, 112;
	// begin inline asm
	cvta.to.global.u64 %rd530, %rd531;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r734,%r735,%r736,%r737}, [%rd530];
	// end inline asm
	mov.b32 	%f2362, %r734;
	mov.b32 	%f2363, %r735;
	mov.b32 	%f2364, %r736;
	mul.ftz.f32 	%f2365, %f659, %f2362;
	mul.ftz.f32 	%f2366, %f659, %f2363;
	mul.ftz.f32 	%f2367, %f659, %f2364;
	fma.rn.ftz.f32 	%f3945, %f2349, %f3945, %f2365;
	fma.rn.ftz.f32 	%f3946, %f2349, %f3946, %f2366;
	fma.rn.ftz.f32 	%f3947, %f2349, %f3947, %f2367;
	bra.uni 	$L__BB0_91;

$L__BB0_80:
	mov.f32 	%f3954, 0f00000000;
	mov.f32 	%f3956, 0f3F800000;
	setp.eq.s32 	%p41, %r590, 4;
	@%p41 bra 	$L__BB0_83;

	setp.ne.s32 	%p42, %r590, 1;
	mov.f32 	%f3955, %f3954;
	mov.f32 	%f3957, %f3954;
	mov.f32 	%f3958, %f3956;
	mov.f32 	%f3959, %f3954;
	mov.f32 	%f3960, %f3956;
	mov.f32 	%f3961, %f3954;
	mov.f32 	%f3962, %f3954;
	@%p42 bra 	$L__BB0_92;

	// begin inline asm
	call (%rd418), _optix_get_static_transform_from_handle, (%rd416);
	// end inline asm
	add.s64 	%rd799, %rd418, 64;
	bra.uni 	$L__BB0_84;

$L__BB0_86:
	// begin inline asm
	call (%rd431), _optix_get_srt_motion_transform_from_handle, (%rd416);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd433, %rd431;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r604,%r605,%r606,%r607}, [%rd433];
	// end inline asm
	add.s64 	%rd437, %rd431, 16;
	// begin inline asm
	cvta.to.global.u64 %rd436, %rd437;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r608,%r609,%r610,%r611}, [%rd436];
	// end inline asm
	add.s64 	%rd440, %rd431, 32;
	// begin inline asm
	cvta.to.global.u64 %rd439, %rd440;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r612,%r613,%r614,%r615}, [%rd439];
	// end inline asm
	add.s64 	%rd443, %rd431, 48;
	// begin inline asm
	cvta.to.global.u64 %rd442, %rd443;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r616,%r617,%r618,%r619}, [%rd442];
	// end inline asm
	add.s64 	%rd446, %rd431, 64;
	// begin inline asm
	cvta.to.global.u64 %rd445, %rd446;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r620,%r621,%r622,%r623}, [%rd445];
	// end inline asm
	add.s64 	%rd449, %rd431, 80;
	// begin inline asm
	cvta.to.global.u64 %rd448, %rd449;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r624,%r625,%r626,%r627}, [%rd448];
	// end inline asm
	add.s64 	%rd452, %rd431, 96;
	// begin inline asm
	cvta.to.global.u64 %rd451, %rd452;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r628,%r629,%r630,%r631}, [%rd451];
	// end inline asm
	add.s64 	%rd455, %rd431, 112;
	// begin inline asm
	cvta.to.global.u64 %rd454, %rd455;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r632,%r633,%r634,%r635}, [%rd454];
	// end inline asm
	add.s64 	%rd458, %rd431, 128;
	// begin inline asm
	cvta.to.global.u64 %rd457, %rd458;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r636,%r637,%r638,%r639}, [%rd457];
	// end inline asm
	add.s64 	%rd461, %rd431, 144;
	// begin inline asm
	cvta.to.global.u64 %rd460, %rd461;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r640,%r641,%r642,%r643}, [%rd460];
	// end inline asm
	mov.b32 	%f2246, %r607;
	mov.b32 	%f2247, %r608;
	and.b32  	%r660, %r606, 65535;
	add.s32 	%r661, %r660, -1;
	cvt.rn.f32.s32 	%f2248, %r661;
	sub.ftz.f32 	%f2249, %f2234, %f2246;
	mul.ftz.f32 	%f2250, %f2249, %f2248;
	sub.ftz.f32 	%f2251, %f2247, %f2246;
	div.approx.ftz.f32 	%f2252, %f2250, %f2251;
	min.ftz.f32 	%f2253, %f2248, %f2252;
	mov.f32 	%f2254, 0f00000000;
	max.ftz.f32 	%f2255, %f2254, %f2253;
	cvt.rmi.ftz.f32.f32 	%f2256, %f2255;
	sub.ftz.f32 	%f619, %f2255, %f2256;
	cvt.rzi.ftz.s32.f32 	%r662, %f2256;
	mul.wide.s32 	%rd475, %r662, 64;
	add.s64 	%rd464, %rd440, %rd475;
	// begin inline asm
	cvta.to.global.u64 %rd463, %rd464;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r644,%r645,%r646,%r647}, [%rd463];
	// end inline asm
	mov.b32 	%f3943, %r644;
	mov.b32 	%f3942, %r645;
	mov.b32 	%f3941, %r646;
	add.s64 	%rd467, %rd464, 16;
	// begin inline asm
	cvta.to.global.u64 %rd466, %rd467;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r648,%r649,%r650,%r651}, [%rd466];
	// end inline asm
	mov.b32 	%f3940, %r648;
	mov.b32 	%f3939, %r649;
	mov.b32 	%f3938, %r651;
	add.s64 	%rd470, %rd464, 32;
	// begin inline asm
	cvta.to.global.u64 %rd469, %rd470;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r652,%r653,%r654,%r655}, [%rd469];
	// end inline asm
	mov.b32 	%f3937, %r653;
	mov.b32 	%f3936, %r654;
	mov.b32 	%f3935, %r655;
	add.s64 	%rd473, %rd464, 48;
	// begin inline asm
	cvta.to.global.u64 %rd472, %rd473;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r656,%r657,%r658,%r659}, [%rd472];
	// end inline asm
	mov.b32 	%f3944, %r656;
	setp.leu.ftz.f32 	%p44, %f619, 0f00000000;
	@%p44 bra 	$L__BB0_88;

	mov.f32 	%f2257, 0f3F800000;
	sub.ftz.f32 	%f2258, %f2257, %f619;
	add.s64 	%rd477, %rd464, 64;
	// begin inline asm
	cvta.to.global.u64 %rd476, %rd477;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r663,%r664,%r665,%r666}, [%rd476];
	// end inline asm
	mov.b32 	%f2259, %r663;
	mov.b32 	%f2260, %r664;
	mov.b32 	%f2261, %r665;
	mul.ftz.f32 	%f2262, %f619, %f2259;
	mul.ftz.f32 	%f2263, %f619, %f2260;
	mul.ftz.f32 	%f2264, %f619, %f2261;
	fma.rn.ftz.f32 	%f3943, %f2258, %f3943, %f2262;
	fma.rn.ftz.f32 	%f3942, %f2258, %f3942, %f2263;
	fma.rn.ftz.f32 	%f3941, %f2258, %f3941, %f2264;
	add.s64 	%rd480, %rd464, 80;
	// begin inline asm
	cvta.to.global.u64 %rd479, %rd480;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r667,%r668,%r669,%r670}, [%rd479];
	// end inline asm
	mov.b32 	%f2265, %r667;
	mov.b32 	%f2266, %r668;
	mov.b32 	%f2267, %r670;
	mul.ftz.f32 	%f2268, %f619, %f2265;
	mul.ftz.f32 	%f2269, %f619, %f2266;
	mul.ftz.f32 	%f2270, %f619, %f2267;
	fma.rn.ftz.f32 	%f3940, %f2258, %f3940, %f2268;
	fma.rn.ftz.f32 	%f3939, %f2258, %f3939, %f2269;
	fma.rn.ftz.f32 	%f3938, %f2258, %f3938, %f2270;
	add.s64 	%rd483, %rd464, 96;
	// begin inline asm
	cvta.to.global.u64 %rd482, %rd483;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r671,%r672,%r673,%r674}, [%rd482];
	// end inline asm
	mov.b32 	%f2271, %r672;
	mov.b32 	%f2272, %r673;
	mov.b32 	%f2273, %r674;
	mul.ftz.f32 	%f2274, %f619, %f2271;
	mul.ftz.f32 	%f2275, %f619, %f2272;
	mul.ftz.f32 	%f2276, %f619, %f2273;
	fma.rn.ftz.f32 	%f2277, %f2258, %f3937, %f2274;
	fma.rn.ftz.f32 	%f2278, %f2258, %f3936, %f2275;
	fma.rn.ftz.f32 	%f2279, %f2258, %f3935, %f2276;
	add.s64 	%rd486, %rd464, 112;
	// begin inline asm
	cvta.to.global.u64 %rd485, %rd486;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r675,%r676,%r677,%r678}, [%rd485];
	// end inline asm
	mov.b32 	%f2280, %r675;
	mul.ftz.f32 	%f2281, %f619, %f2280;
	fma.rn.ftz.f32 	%f2282, %f2258, %f3944, %f2281;
	mul.ftz.f32 	%f2283, %f2278, %f2278;
	fma.rn.ftz.f32 	%f2284, %f2277, %f2277, %f2283;
	fma.rn.ftz.f32 	%f2285, %f2279, %f2279, %f2284;
	fma.rn.ftz.f32 	%f2286, %f2282, %f2282, %f2285;
	rsqrt.approx.ftz.f32 	%f2287, %f2286;
	mul.ftz.f32 	%f3937, %f2277, %f2287;
	mul.ftz.f32 	%f3936, %f2278, %f2287;
	mul.ftz.f32 	%f3935, %f2279, %f2287;
	mul.ftz.f32 	%f3944, %f2287, %f2282;

$L__BB0_88:
	mul.ftz.f32 	%f2288, %f3937, %f3937;
	fma.rn.ftz.f32 	%f2289, %f3936, %f3936, %f2288;
	fma.rn.ftz.f32 	%f2290, %f3935, %f3935, %f2289;
	fma.rn.ftz.f32 	%f2291, %f3944, %f3944, %f2290;
	rcp.approx.ftz.f32 	%f2292, %f2291;
	mul.ftz.f32 	%f2293, %f3937, %f2292;
	mul.ftz.f32 	%f2294, %f3936, %f2292;
	mul.ftz.f32 	%f2295, %f3935, %f2292;
	mul.ftz.f32 	%f2296, %f3944, %f2292;
	mul.ftz.f32 	%f2297, %f3937, %f2293;
	mul.ftz.f32 	%f2298, %f3936, %f2294;
	mul.ftz.f32 	%f2299, %f3935, %f2295;
	mul.ftz.f32 	%f2300, %f3937, %f2294;
	mul.ftz.f32 	%f2301, %f3935, %f2296;
	mul.ftz.f32 	%f2302, %f3937, %f2295;
	mul.ftz.f32 	%f2303, %f3936, %f2296;
	mul.ftz.f32 	%f2304, %f3936, %f2295;
	mul.ftz.f32 	%f2305, %f3937, %f2296;
	sub.ftz.f32 	%f2306, %f2297, %f2298;
	sub.ftz.f32 	%f2307, %f2306, %f2299;
	fma.rn.ftz.f32 	%f2308, %f3944, %f2296, %f2307;
	sub.ftz.f32 	%f2309, %f2300, %f2301;
	add.ftz.f32 	%f2310, %f2309, %f2309;
	add.ftz.f32 	%f2311, %f2302, %f2303;
	add.ftz.f32 	%f2312, %f2311, %f2311;
	add.ftz.f32 	%f2313, %f2300, %f2301;
	add.ftz.f32 	%f2314, %f2313, %f2313;
	sub.ftz.f32 	%f2315, %f2298, %f2297;
	sub.ftz.f32 	%f2316, %f2315, %f2299;
	fma.rn.ftz.f32 	%f2317, %f3944, %f2296, %f2316;
	sub.ftz.f32 	%f2318, %f2304, %f2305;
	add.ftz.f32 	%f2319, %f2318, %f2318;
	sub.ftz.f32 	%f2320, %f2302, %f2303;
	add.ftz.f32 	%f2321, %f2320, %f2320;
	add.ftz.f32 	%f2322, %f2304, %f2305;
	add.ftz.f32 	%f2323, %f2322, %f2322;
	neg.ftz.f32 	%f2324, %f2297;
	sub.ftz.f32 	%f2325, %f2324, %f2298;
	add.ftz.f32 	%f2326, %f2299, %f2325;
	fma.rn.ftz.f32 	%f2327, %f3944, %f2296, %f2326;
	mul.ftz.f32 	%f2328, %f3941, %f2308;
	fma.rn.ftz.f32 	%f2329, %f3939, %f2310, %f2328;
	fma.rn.ftz.f32 	%f3953, %f3938, %f2312, %f2329;
	mul.ftz.f32 	%f2330, %f3939, %f2317;
	fma.rn.ftz.f32 	%f2331, %f3941, %f2314, %f2330;
	fma.rn.ftz.f32 	%f3950, %f3938, %f2319, %f2331;
	mul.ftz.f32 	%f2332, %f3939, %f2323;
	fma.rn.ftz.f32 	%f2333, %f3941, %f2321, %f2332;
	fma.rn.ftz.f32 	%f3947, %f3938, %f2327, %f2333;
	mul.ftz.f32 	%f2334, %f3942, %f2308;
	fma.rn.ftz.f32 	%f3952, %f3940, %f2310, %f2334;
	mul.ftz.f32 	%f2335, %f3940, %f2317;
	fma.rn.ftz.f32 	%f3949, %f3942, %f2314, %f2335;
	mul.ftz.f32 	%f2336, %f3940, %f2323;
	fma.rn.ftz.f32 	%f3946, %f3942, %f2321, %f2336;
	mul.ftz.f32 	%f3951, %f3943, %f2308;
	mul.ftz.f32 	%f3948, %f3943, %f2314;
	mul.ftz.f32 	%f3945, %f3943, %f2321;

$L__BB0_91:
	mul.ftz.f32 	%f2368, %f3946, %f3950;
	mul.ftz.f32 	%f2369, %f3947, %f3949;
	sub.ftz.f32 	%f2370, %f2369, %f2368;
	mul.ftz.f32 	%f2371, %f3951, %f2370;
	mul.ftz.f32 	%f2372, %f3945, %f3950;
	mul.ftz.f32 	%f2373, %f3947, %f3948;
	sub.ftz.f32 	%f2374, %f2373, %f2372;
	mul.ftz.f32 	%f2375, %f2374, %f3952;
	sub.ftz.f32 	%f2376, %f2371, %f2375;
	mul.ftz.f32 	%f2377, %f3945, %f3949;
	mul.ftz.f32 	%f2378, %f3946, %f3948;
	sub.ftz.f32 	%f2379, %f2378, %f2377;
	fma.rn.ftz.f32 	%f2380, %f2379, %f3953, %f2376;
	rcp.approx.ftz.f32 	%f2381, %f2380;
	mul.ftz.f32 	%f3960, %f2370, %f2381;
	mul.ftz.f32 	%f2382, %f3947, %f3952;
	mul.ftz.f32 	%f2383, %f3946, %f3953;
	sub.ftz.f32 	%f2384, %f2383, %f2382;
	mul.ftz.f32 	%f3961, %f2384, %f2381;
	mul.ftz.f32 	%f2385, %f3949, %f3953;
	mul.ftz.f32 	%f2386, %f3950, %f3952;
	sub.ftz.f32 	%f2387, %f2386, %f2385;
	mul.ftz.f32 	%f3962, %f2387, %f2381;
	sub.ftz.f32 	%f2388, %f2372, %f2373;
	mul.ftz.f32 	%f3957, %f2388, %f2381;
	mul.ftz.f32 	%f2389, %f3945, %f3953;
	mul.ftz.f32 	%f2390, %f3947, %f3951;
	sub.ftz.f32 	%f2391, %f2390, %f2389;
	mul.ftz.f32 	%f3958, %f2391, %f2381;
	mul.ftz.f32 	%f2392, %f3950, %f3951;
	mul.ftz.f32 	%f2393, %f3948, %f3953;
	sub.ftz.f32 	%f2394, %f2393, %f2392;
	mul.ftz.f32 	%f3959, %f2394, %f2381;
	mul.ftz.f32 	%f3954, %f2379, %f2381;
	mul.ftz.f32 	%f2395, %f3946, %f3951;
	mul.ftz.f32 	%f2396, %f3945, %f3952;
	sub.ftz.f32 	%f2397, %f2396, %f2395;
	mul.ftz.f32 	%f3955, %f2397, %f2381;
	mul.ftz.f32 	%f2398, %f3948, %f3952;
	mul.ftz.f32 	%f2399, %f3949, %f3951;
	sub.ftz.f32 	%f2400, %f2399, %f2398;
	mul.ftz.f32 	%f3956, %f2400, %f2381;
	bra.uni 	$L__BB0_92;

$L__BB0_83:
	// begin inline asm
	call (%rd799), _optix_get_instance_inverse_transform_from_handle, (%rd416);
	// end inline asm

$L__BB0_84:
	// begin inline asm
	cvta.to.global.u64 %rd422, %rd799;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r592,%r593,%r594,%r595}, [%rd422];
	// end inline asm
	mov.b32 	%f3960, %r592;
	mov.b32 	%f3961, %r593;
	mov.b32 	%f3962, %r594;
	add.s64 	%rd426, %rd799, 16;
	// begin inline asm
	cvta.to.global.u64 %rd425, %rd426;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r596,%r597,%r598,%r599}, [%rd425];
	// end inline asm
	mov.b32 	%f3957, %r596;
	mov.b32 	%f3958, %r597;
	mov.b32 	%f3959, %r598;
	add.s64 	%rd429, %rd799, 32;
	// begin inline asm
	cvta.to.global.u64 %rd428, %rd429;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r600,%r601,%r602,%r603}, [%rd428];
	// end inline asm
	mov.b32 	%f3954, %r600;
	mov.b32 	%f3955, %r601;
	mov.b32 	%f3956, %r602;

$L__BB0_92:
	setp.eq.s32 	%p46, %r1344, 0;
	@%p46 bra 	$L__BB0_94;

	mul.ftz.f32 	%f2401, %f3931, %f3961;
	fma.rn.ftz.f32 	%f2402, %f3928, %f3960, %f2401;
	fma.rn.ftz.f32 	%f705, %f3934, %f3962, %f2402;
	mul.ftz.f32 	%f2403, %f3930, %f3961;
	fma.rn.ftz.f32 	%f2404, %f3927, %f3960, %f2403;
	fma.rn.ftz.f32 	%f706, %f3933, %f3962, %f2404;
	mul.ftz.f32 	%f2405, %f3929, %f3961;
	fma.rn.ftz.f32 	%f2406, %f3926, %f3960, %f2405;
	fma.rn.ftz.f32 	%f3962, %f3932, %f3962, %f2406;
	mul.ftz.f32 	%f2407, %f3931, %f3958;
	fma.rn.ftz.f32 	%f2408, %f3928, %f3957, %f2407;
	fma.rn.ftz.f32 	%f708, %f3934, %f3959, %f2408;
	mul.ftz.f32 	%f2409, %f3930, %f3958;
	fma.rn.ftz.f32 	%f2410, %f3927, %f3957, %f2409;
	fma.rn.ftz.f32 	%f709, %f3933, %f3959, %f2410;
	mul.ftz.f32 	%f2411, %f3929, %f3958;
	fma.rn.ftz.f32 	%f2412, %f3926, %f3957, %f2411;
	fma.rn.ftz.f32 	%f3959, %f3932, %f3959, %f2412;
	mul.ftz.f32 	%f2413, %f3931, %f3955;
	fma.rn.ftz.f32 	%f2414, %f3928, %f3954, %f2413;
	fma.rn.ftz.f32 	%f711, %f3934, %f3956, %f2414;
	mul.ftz.f32 	%f2415, %f3930, %f3955;
	fma.rn.ftz.f32 	%f2416, %f3927, %f3954, %f2415;
	fma.rn.ftz.f32 	%f712, %f3933, %f3956, %f2416;
	mul.ftz.f32 	%f2417, %f3929, %f3955;
	fma.rn.ftz.f32 	%f2418, %f3926, %f3954, %f2417;
	fma.rn.ftz.f32 	%f3956, %f3932, %f3956, %f2418;
	mov.f32 	%f3954, %f711;
	mov.f32 	%f3955, %f712;
	mov.f32 	%f3957, %f708;
	mov.f32 	%f3958, %f709;
	mov.f32 	%f3960, %f705;
	mov.f32 	%f3961, %f706;

$L__BB0_94:
	add.s32 	%r1344, %r1344, 1;
	setp.lt.u32 	%p47, %r1344, %r587;
	mov.f32 	%f3926, %f3962;
	mov.f32 	%f3927, %f3961;
	mov.f32 	%f3928, %f3960;
	mov.f32 	%f3929, %f3959;
	mov.f32 	%f3930, %f3958;
	mov.f32 	%f3931, %f3957;
	mov.f32 	%f3932, %f3956;
	mov.f32 	%f3933, %f3955;
	mov.f32 	%f3934, %f3954;
	@%p47 bra 	$L__BB0_79;

$L__BB0_95:
	mul.ftz.f32 	%f2419, %f4123, %f3960;
	fma.rn.ftz.f32 	%f2420, %f4122, %f3957, %f2419;
	mul.ftz.f32 	%f2421, %f4123, %f3961;
	fma.rn.ftz.f32 	%f2422, %f4122, %f3958, %f2421;
	mul.ftz.f32 	%f2423, %f4123, %f3962;
	fma.rn.ftz.f32 	%f2424, %f4122, %f3959, %f2423;
	fma.rn.ftz.f32 	%f4121, %f599, %f3956, %f2424;
	fma.rn.ftz.f32 	%f4122, %f599, %f3955, %f2422;
	fma.rn.ftz.f32 	%f4123, %f599, %f3954, %f2420;
	bra.uni 	$L__BB0_144;

$L__BB0_96:
	mov.f32 	%f4121, %f599;

$L__BB0_144:
	ld.u32 	%r1046, [%rd54+100];
	setp.eq.s32 	%p70, %r1046, 14;
	@%p70 bra 	$L__BB0_146;
	bra.uni 	$L__BB0_145;

$L__BB0_146:
	ld.u64 	%rd775, [%rd54+24];
	mul.wide.u32 	%rd776, %r115, 8;
	add.s64 	%rd777, %rd775, %rd776;
	ld.v2.u32 	{%r30, %r29}, [%rd777];
	bra.uni 	$L__BB0_147;

$L__BB0_145:
	add.s32 	%r29, %r115, 1;
	mov.u32 	%r30, %r115;

$L__BB0_147:
	// begin inline asm
	call (%r1049), _optix_get_attribute_0, ();
	// end inline asm
	mov.b32 	%f1117, %r1049;
	ld.u32 	%r1052, [%rd54+96];
	and.b32  	%r1053, %r1052, 1073741823;
	setp.gt.ftz.f32 	%p71, %f1117, 0f3F000000;
	or.b32  	%r1054, %r1053, 1073741824;
	selp.b32 	%r1051, %r1054, %r1053, %p71;
	mov.u32 	%r1050, 2;
	// begin inline asm
	call _optix_set_payload, (%r1050, %r1051);
	// end inline asm
	ld.f32 	%f1118, [%rd54+156];
	ld.f32 	%f1119, [%rd54+176];
	ld.v4.f32 	{%f2941, %f2942, %f2943, %f2944}, [%rd54+112];
	ld.f32 	%f4126, [%rd54+80];
	setp.lt.ftz.f32 	%p72, %f4126, 0f00000000;
	@%p72 bra 	$L__BB0_149;
	bra.uni 	$L__BB0_148;

$L__BB0_149:
	ld.u64 	%rd44, [%rd54+8];
	ld.u8 	%rs1, [%rd54+188];
	and.b16  	%rs2, %rs1, 64;
	setp.eq.s16 	%p73, %rs2, 0;
	@%p73 bra 	$L__BB0_151;
	bra.uni 	$L__BB0_150;

$L__BB0_151:
	mul.wide.s32 	%rd780, %r29, 12;
	add.s64 	%rd781, %rd44, %rd780;
	mul.wide.s32 	%rd782, %r30, 12;
	add.s64 	%rd783, %rd44, %rd782;
	ld.f32 	%f2945, [%rd783];
	ld.f32 	%f2946, [%rd781];
	sub.ftz.f32 	%f2947, %f2946, %f2945;
	ld.f32 	%f2948, [%rd783+4];
	ld.f32 	%f2949, [%rd781+4];
	sub.ftz.f32 	%f2950, %f2949, %f2948;
	ld.f32 	%f2951, [%rd783+8];
	ld.f32 	%f2952, [%rd781+8];
	sub.ftz.f32 	%f2953, %f2952, %f2951;
	fma.rn.ftz.f32 	%f4126, %f2947, %f1117, %f2945;
	fma.rn.ftz.f32 	%f4125, %f2950, %f1117, %f2948;
	fma.rn.ftz.f32 	%f4124, %f2953, %f1117, %f2951;
	bra.uni 	$L__BB0_152;

$L__BB0_148:
	ld.f32 	%f4125, [%rd54+84];
	ld.f32 	%f4124, [%rd54+88];
	bra.uni 	$L__BB0_152;

$L__BB0_150:
	mul.wide.u32 	%rd778, %r115, 12;
	add.s64 	%rd779, %rd44, %rd778;
	ld.f32 	%f4126, [%rd779];
	ld.f32 	%f4125, [%rd779+4];
	ld.f32 	%f4124, [%rd779+8];

$L__BB0_152:
	mov.u32 	%r1056, 0;
	mul.ftz.f32 	%f1137, %f2941, %f4126;
	mov.u32 	%r1058, 1;
	mul.ftz.f32 	%f1138, %f2942, %f4125;
	mul.ftz.f32 	%f1139, %f2943, %f4124;
	// begin inline asm
	call (%r1055), _optix_get_payload, (%r1056);
	// end inline asm
	// begin inline asm
	call (%r1057), _optix_get_payload, (%r1058);
	// end inline asm
	cvt.u64.u32 	%rd784, %r1055;
	cvt.u64.u32 	%rd785, %r1057;
	bfi.b64 	%rd45, %rd784, %rd785, 32, 32;
	// begin inline asm
	call (%f2954), _optix_get_ray_tmax, ();
	// end inline asm
	st.f32 	[%rd45+108], %f2954;
	setp.geu.ftz.f32 	%p74, %f2944, 0f3F800000;
	@%p74 bra 	$L__BB0_155;

	ld.u32 	%r1059, [%rd45+28];
	mad.lo.s32 	%r1060, %r1059, 1664525, 1013904223;
	st.u32 	[%rd45+28], %r1060;
	and.b32  	%r1061, %r1060, 16777215;
	cvt.rn.f32.u32 	%f2955, %r1061;
	mov.f32 	%f2956, 0f4B800000;
	div.approx.ftz.f32 	%f2957, %f2955, %f2956;
	setp.ltu.ftz.f32 	%p75, %f2957, %f2944;
	@%p75 bra 	$L__BB0_155;
	bra.uni 	$L__BB0_154;

$L__BB0_155:
	mul.ftz.f32 	%f2960, %f4123, %f4123;
	fma.rn.ftz.f32 	%f2961, %f4122, %f4122, %f2960;
	fma.rn.ftz.f32 	%f2962, %f4121, %f4121, %f2961;
	rsqrt.approx.ftz.f32 	%f2963, %f2962;
	mul.ftz.f32 	%f2964, %f4123, %f2963;
	mul.ftz.f32 	%f2965, %f4122, %f2963;
	mul.ftz.f32 	%f2966, %f4121, %f2963;
	ld.u32 	%r1065, [%rd45+12];
	and.b32  	%r1066, %r1065, -3;
	ld.u32 	%r1067, [%rd54+188];
	or.b32  	%r1068, %r1066, %r1067;
	ld.f32 	%f2967, [%rd45+112];
	ld.f32 	%f2968, [%rd45+116];
	mul.ftz.f32 	%f2969, %f2965, %f2968;
	fma.rn.ftz.f32 	%f2970, %f2964, %f2967, %f2969;
	ld.f32 	%f2971, [%rd45+120];
	fma.rn.ftz.f32 	%f2972, %f2966, %f2971, %f2970;
	setp.ge.ftz.f32 	%p76, %f2972, 0f00000000;
	selp.b32 	%r1069, 16, 0, %p76;
	or.b32  	%r1071, %r1069, %r1068;
	st.u32 	[%rd45+12], %r1071;
	and.b32  	%r1072, %r1071, 16;
	setp.eq.s32 	%p77, %r1072, 0;
	neg.ftz.f32 	%f2973, %f2964;
	neg.ftz.f32 	%f2974, %f2965;
	neg.ftz.f32 	%f2975, %f2966;
	selp.f32 	%f1140, %f2975, %f2966, %p77;
	selp.f32 	%f1141, %f2974, %f2965, %p77;
	selp.f32 	%f1142, %f2973, %f2964, %p77;
	mov.f32 	%f4134, 0f00000000;
	st.v2.f32 	[%rd45], {%f4134, %f4134};
	st.u32 	[%rd45+8], %r1056;
	st.v4.f32 	[%rd45+48], {%f4134, %f4134, %f4134, %f4134};
	setp.leu.ftz.f32 	%p78, %f1118, 0f00000000;
	mov.f32 	%f1146, %f1140;
	mov.f32 	%f1147, %f1141;
	mov.f32 	%f1148, %f1142;
	@%p78 bra 	$L__BB0_157;

	ld.u32 	%r1073, [%rd45+28];
	mad.lo.s32 	%r1074, %r1073, 1664525, 1013904223;
	and.b32  	%r1075, %r1074, 16777215;
	cvt.rn.f32.u32 	%f2977, %r1075;
	mov.f32 	%f2978, 0f4B800000;
	div.approx.ftz.f32 	%f2979, %f2977, %f2978;
	mad.lo.s32 	%r1076, %r1074, 1664525, 1013904223;
	and.b32  	%r1077, %r1076, 16777215;
	cvt.rn.f32.u32 	%f2980, %r1077;
	div.approx.ftz.f32 	%f2981, %f2980, %f2978;
	mad.lo.s32 	%r1078, %r1076, 1664525, 1013904223;
	st.u32 	[%rd45+28], %r1078;
	and.b32  	%r1079, %r1078, 16777215;
	cvt.rn.f32.u32 	%f2982, %r1079;
	div.approx.ftz.f32 	%f2983, %f2982, %f2978;
	lg2.approx.ftz.f32 	%f2984, %f2979;
	mul.ftz.f32 	%f2985, %f2984, 0f3F317218;
	mul.ftz.f32 	%f2986, %f2985, 0fC0000000;
	sqrt.approx.ftz.f32 	%f2987, %f2986;
	mul.ftz.f32 	%f2988, %f2981, 0f40490FDB;
	mul.ftz.f32 	%f2989, %f1118, %f2987;
	sin.approx.ftz.f32 	%f2990, %f2988;
	mul.ftz.f32 	%f2991, %f2989, %f2990;
	sqrt.approx.ftz.f32 	%f2992, %f2991;
	mul.ftz.f32 	%f2993, %f2983, 0f40C90FDB;
	cos.approx.ftz.f32 	%f2994, %f2993;
	sin.approx.ftz.f32 	%f2995, %f2993;
	mov.b32 	%r1080, %f1140;
	and.b32  	%r1081, %r1080, -2147483648;
	or.b32  	%r1082, %r1081, 1065353216;
	mov.b32 	%f2996, %r1082;
	mul.ftz.f32 	%f2997, %f2996, 0f00000000;
	add.ftz.f32 	%f2998, %f1140, %f2996;
	mul.ftz.f32 	%f2999, %f1141, %f2995;
	fma.rn.ftz.f32 	%f3000, %f1142, %f2994, %f2999;
	fma.rn.ftz.f32 	%f3001, %f2997, %f2998, %f3000;
	abs.ftz.f32 	%f3002, %f1140;
	add.ftz.f32 	%f3003, %f3002, 0f3F800000;
	div.approx.ftz.f32 	%f3004, %f3001, %f3003;
	mul.ftz.f32 	%f3005, %f1142, %f3004;
	mul.ftz.f32 	%f3006, %f1141, %f3004;
	mul.ftz.f32 	%f3007, %f2998, %f3004;
	sub.ftz.f32 	%f3008, %f3005, %f2994;
	sub.ftz.f32 	%f3009, %f3006, %f2995;
	sub.ftz.f32 	%f3010, %f3007, %f2997;
	fma.rn.ftz.f32 	%f3011, %f2992, %f3008, %f1142;
	fma.rn.ftz.f32 	%f3012, %f2992, %f3009, %f1141;
	fma.rn.ftz.f32 	%f3013, %f2992, %f3010, %f1140;
	mul.ftz.f32 	%f3014, %f3012, %f3012;
	fma.rn.ftz.f32 	%f3015, %f3011, %f3011, %f3014;
	fma.rn.ftz.f32 	%f3016, %f3013, %f3013, %f3015;
	rsqrt.approx.ftz.f32 	%f3017, %f3016;
	mul.ftz.f32 	%f1148, %f3017, %f3011;
	mul.ftz.f32 	%f1147, %f3017, %f3012;
	mul.ftz.f32 	%f1146, %f3017, %f3013;

$L__BB0_157:
	ld.const.f32 	%f1149, [params+76];
	fma.rn.ftz.f32 	%f3018, %f1140, %f1149, %f3;
	fma.rn.ftz.f32 	%f3019, %f1141, %f1149, %f2;
	fma.rn.ftz.f32 	%f3020, %f1142, %f1149, %f1;
	st.v2.f32 	[%rd45+96], {%f3020, %f3019};
	st.f32 	[%rd45+104], %f3018;
	ld.f32 	%f3021, [%rd45+160];
	ld.f32 	%f3022, [%rd54+148];
	div.approx.ftz.f32 	%f1150, %f3022, %f3021;
	ld.f32 	%f3023, [%rd54+180];
	mov.f32 	%f3024, 0f3F800000;
	sub.ftz.f32 	%f3025, %f3024, %f3023;
	fma.rn.ftz.f32 	%f1162, %f1119, %f3025, %f3023;
	setp.geu.ftz.f32 	%p79, %f1119, 0f3F800000;
	@%p79 bra 	$L__BB0_165;

	ld.f32 	%f3027, [%rd45+112];
	ld.f32 	%f3028, [%rd45+116];
	mul.ftz.f32 	%f3029, %f1147, %f3028;
	fma.rn.ftz.f32 	%f3030, %f1148, %f3027, %f3029;
	ld.f32 	%f3031, [%rd45+120];
	fma.rn.ftz.f32 	%f3032, %f1146, %f3031, %f3030;
	abs.ftz.f32 	%f1152, %f3032;
	mul.ftz.f32 	%f3033, %f1152, %f1152;
	sub.ftz.f32 	%f1153, %f3024, %f3033;
	setp.leu.ftz.f32 	%p80, %f1153, 0f00000000;
	mov.f32 	%f4130, 0f00000000;
	@%p80 bra 	$L__BB0_160;

	sqrt.approx.ftz.f32 	%f3035, %f1153;
	div.approx.ftz.f32 	%f4130, %f3035, %f1150;

$L__BB0_160:
	setp.gt.ftz.f32 	%p81, %f4130, 0f3F800000;
	mov.f32 	%f4132, %f3024;
	@%p81 bra 	$L__BB0_164;

	mul.ftz.f32 	%f3038, %f4130, %f4130;
	mov.f32 	%f3039, 0f3F800000;
	sub.ftz.f32 	%f1156, %f3039, %f3038;
	setp.leu.ftz.f32 	%p82, %f1156, 0f00000000;
	mov.f32 	%f4131, 0f00000000;
	@%p82 bra 	$L__BB0_163;

	sqrt.approx.ftz.f32 	%f4131, %f1156;

$L__BB0_163:
	mul.ftz.f32 	%f3040, %f1150, %f4131;
	sub.ftz.f32 	%f3041, %f1152, %f3040;
	add.ftz.f32 	%f3042, %f1152, %f3040;
	div.approx.ftz.f32 	%f3043, %f3041, %f3042;
	mul.ftz.f32 	%f3044, %f1150, %f1152;
	sub.ftz.f32 	%f3045, %f3044, %f4131;
	add.ftz.f32 	%f3046, %f3044, %f4131;
	div.approx.ftz.f32 	%f3047, %f3045, %f3046;
	mul.ftz.f32 	%f3048, %f3047, %f3047;
	fma.rn.ftz.f32 	%f3049, %f3043, %f3043, %f3048;
	mul.ftz.f32 	%f3050, %f3049, 0f3F000000;
	min.ftz.f32 	%f4132, %f3050, 0f3F800000;

$L__BB0_164:
	sub.ftz.f32 	%f3052, %f3024, %f1119;
	fma.rn.ftz.f32 	%f3053, %f3052, %f4132, %f1119;
	mul.ftz.f32 	%f1162, %f1162, %f3053;

$L__BB0_165:
	ld.u32 	%r31, [%rd45+12];
	shr.u32 	%r1083, %r31, 29;
	and.b32  	%r1084, %r1083, 1;
	setp.eq.b32 	%p83, %r1084, 1;
	setp.lt.ftz.f32 	%p84, %f1162, 0f3F800000;
	and.pred  	%p85, %p84, %p83;
	and.b32  	%r32, %r31, 16777216;
	@%p85 bra 	$L__BB0_210;
	bra.uni 	$L__BB0_166;

$L__BB0_210:
	setp.eq.s32 	%p123, %r32, 0;
	@%p123 bra 	$L__BB0_212;

	ld.f32 	%f3432, [%rd45+16];
	mul.ftz.f32 	%f3433, %f1137, %f3432;
	st.f32 	[%rd45+16], %f3433;
	ld.f32 	%f3434, [%rd45+20];
	mul.ftz.f32 	%f3435, %f1138, %f3434;
	st.f32 	[%rd45+20], %f3435;
	ld.f32 	%f3436, [%rd45+24];
	mul.ftz.f32 	%f3437, %f1139, %f3436;
	st.f32 	[%rd45+24], %f3437;
	and.b32  	%r1216, %r31, -16777217;
	st.u32 	[%rd45+12], %r1216;

$L__BB0_212:
	ld.u32 	%r1217, [%rd45+44];
	setp.ne.s32 	%p124, %r1217, 0;
	@%p124 bra 	$L__BB0_214;

	ld.const.v2.f32 	{%f3438, %f3439}, [params+144];
	mul.ftz.f32 	%f3442, %f1141, %f3439;
	fma.rn.ftz.f32 	%f3443, %f1142, %f3438, %f3442;
	ld.const.f32 	%f3444, [params+152];
	ld.const.v2.f32 	{%f3445, %f3446}, [params+160];
	mul.ftz.f32 	%f3449, %f1141, %f3446;
	fma.rn.ftz.f32 	%f3450, %f1142, %f3445, %f3449;
	ld.const.f32 	%f3451, [params+168];
	ld.const.v2.f32 	{%f3452, %f3453}, [params+176];
	mul.ftz.f32 	%f3456, %f1141, %f3453;
	fma.rn.ftz.f32 	%f3457, %f1142, %f3452, %f3456;
	ld.const.f32 	%f3458, [params+184];
	fma.rn.ftz.f32 	%f3459, %f1140, %f3458, %f3457;
	fma.rn.ftz.f32 	%f3460, %f1140, %f3451, %f3450;
	fma.rn.ftz.f32 	%f3461, %f1140, %f3444, %f3443;
	st.v2.f32 	[%rd45+32], {%f3461, %f3460};
	st.f32 	[%rd45+40], %f3459;

$L__BB0_214:
	ld.f32 	%f3463, [%rd45+112];
	ld.f32 	%f3464, [%rd45+116];
	mul.ftz.f32 	%f3465, %f1147, %f3464;
	fma.rn.ftz.f32 	%f3466, %f1148, %f3463, %f3465;
	ld.f32 	%f3467, [%rd45+120];
	fma.rn.ftz.f32 	%f3468, %f1146, %f3467, %f3466;
	ld.f32 	%f3469, [%rd54+140];
	mul.ftz.f32 	%f3470, %f3469, %f3468;
	mul.ftz.f32 	%f3471, %f1139, %f3470;
	mul.ftz.f32 	%f3472, %f1138, %f3470;
	mul.ftz.f32 	%f3473, %f1137, %f3470;
	st.v2.f32 	[%rd45], {%f3473, %f3472};
	st.f32 	[%rd45+8], %f3471;
	ld.u32 	%r1218, [%rd45+28];
	mad.lo.s32 	%r1219, %r1218, 1664525, 1013904223;
	and.b32  	%r1220, %r1219, 16777215;
	cvt.rn.f32.u32 	%f3474, %r1220;
	mov.f32 	%f3475, 0f4B800000;
	div.approx.ftz.f32 	%f3476, %f3474, %f3475;
	mad.lo.s32 	%r74, %r1219, 1664525, 1013904223;
	st.u32 	[%rd45+28], %r74;
	and.b32  	%r1221, %r74, 16777215;
	cvt.rn.f32.u32 	%f3477, %r1221;
	div.approx.ftz.f32 	%f3478, %f3477, %f3475;
	mul.ftz.f32 	%f3479, %f3476, 0f40C90FDB;
	sqrt.approx.ftz.f32 	%f3480, %f3478;
	cos.approx.ftz.f32 	%f3481, %f3479;
	mul.ftz.f32 	%f1254, %f3480, %f3481;
	st.f32 	[%rd45+128], %f1254;
	sin.approx.ftz.f32 	%f3482, %f3479;
	mul.ftz.f32 	%f1255, %f3480, %f3482;
	st.f32 	[%rd45+132], %f1255;
	mul.ftz.f32 	%f3483, %f1254, %f1254;
	sub.ftz.f32 	%f3485, %f3024, %f3483;
	mul.ftz.f32 	%f3486, %f1255, %f1255;
	sub.ftz.f32 	%f1256, %f3485, %f3486;
	st.f32 	[%rd45+136], %f1256;
	setp.leu.ftz.f32 	%p125, %f1256, 0f00000000;
	mov.f32 	%f4149, 0f00000000;
	@%p125 bra 	$L__BB0_216;

	sqrt.approx.ftz.f32 	%f4149, %f1256;

$L__BB0_216:
	mov.b32 	%r1222, %f1146;
	and.b32  	%r1223, %r1222, -2147483648;
	or.b32  	%r1224, %r1223, 1065353216;
	mov.b32 	%f3487, %r1224;
	mul.ftz.f32 	%f3488, %f4149, %f3487;
	add.ftz.f32 	%f3489, %f1146, %f3487;
	mul.ftz.f32 	%f3490, %f1147, %f1255;
	fma.rn.ftz.f32 	%f3491, %f1148, %f1254, %f3490;
	fma.rn.ftz.f32 	%f3492, %f3489, %f3488, %f3491;
	abs.ftz.f32 	%f3493, %f1146;
	add.ftz.f32 	%f3494, %f3493, 0f3F800000;
	div.approx.ftz.f32 	%f3495, %f3492, %f3494;
	mul.ftz.f32 	%f3496, %f1148, %f3495;
	mul.ftz.f32 	%f3497, %f1147, %f3495;
	mul.ftz.f32 	%f3498, %f3489, %f3495;
	sub.ftz.f32 	%f1259, %f3496, %f1254;
	sub.ftz.f32 	%f1260, %f3497, %f1255;
	sub.ftz.f32 	%f1261, %f3498, %f3488;
	st.f32 	[%rd45+128], %f1259;
	st.f32 	[%rd45+132], %f1260;
	st.f32 	[%rd45+136], %f1261;
	mul.ftz.f32 	%f3499, %f4149, 0f3EA2F983;
	st.v4.f32 	[%rd45+48], {%f1137, %f1138, %f1139, %f3499};
	setp.le.ftz.f32 	%p126, %f3499, 0f00000000;
	@%p126 bra 	$L__BB0_218;

	mul.ftz.f32 	%f3500, %f1141, %f1260;
	fma.rn.ftz.f32 	%f3501, %f1142, %f1259, %f3500;
	fma.rn.ftz.f32 	%f3502, %f1140, %f1261, %f3501;
	setp.gtu.ftz.f32 	%p127, %f3502, 0f3A83126F;
	@%p127 bra 	$L__BB0_219;

$L__BB0_218:
	ld.u32 	%r1225, [%rd45+12];
	or.b32  	%r1226, %r1225, -2147483648;
	st.u32 	[%rd45+12], %r1226;

$L__BB0_219:
	ld.const.u32 	%r75, [params+192];
	setp.eq.s32 	%p128, %r75, 0;
	@%p128 bra 	$L__BB0_242;

	mad.lo.s32 	%r1227, %r74, 1664525, 1013904223;
	and.b32  	%r1228, %r1227, 16777215;
	cvt.rn.f32.u32 	%f3503, %r1228;
	div.approx.ftz.f32 	%f1262, %f3503, %f3475;
	mad.lo.s32 	%r76, %r1227, 1664525, 1013904223;
	mov.u64 	%rd803, 0;
	st.u32 	[%rd45+28], %r76;
	and.b32  	%r1229, %r76, 16777215;
	cvt.rn.f32.u32 	%f3505, %r1229;
	div.approx.ftz.f32 	%f1263, %f3505, %f3475;
	setp.eq.s32 	%p129, %r75, 1;
	@%p129 bra 	$L__BB0_222;

	mad.lo.s32 	%r1230, %r76, 1664525, 1013904223;
	st.u32 	[%rd45+28], %r1230;
	and.b32  	%r1231, %r1230, 16777215;
	cvt.rn.f32.u32 	%f3506, %r1231;
	div.approx.ftz.f32 	%f3508, %f3506, %f3475;
	cvt.rn.f32.u32 	%f3509, %r75;
	mul.ftz.f32 	%f3510, %f3508, %f3509;
	cvt.rmi.ftz.f32.f32 	%f3511, %f3510;
	cvt.rzi.ftz.u32.f32 	%r1232, %f3511;
	add.s32 	%r1233, %r75, -1;
	min.u32 	%r1234, %r1232, %r1233;
	cvt.s64.s32 	%rd803, %r1234;

$L__BB0_222:
	ld.const.u64 	%rd792, [params+200];
	cvta.to.global.u64 	%rd793, %rd792;
	mul.lo.s64 	%rd794, %rd803, 80;
	add.s64 	%rd52, %rd793, %rd794;
	ld.global.f32 	%f1264, [%rd52];
	ld.global.f32 	%f1265, [%rd52+4];
	ld.global.f32 	%f1266, [%rd52+8];
	ld.global.f32 	%f1267, [%rd52+16];
	ld.global.f32 	%f1268, [%rd52+20];
	ld.global.f32 	%f1269, [%rd52+24];
	ld.global.f32 	%f1270, [%rd52+28];
	ld.global.u32 	%r1235, [%rd52+12];
	setp.eq.s32 	%p130, %r1235, 0;
	@%p130 bra 	$L__BB0_227;

	ld.global.f32 	%f1271, [%rd52+44];
	ld.f32 	%f1272, [%rd45+96];
	sub.ftz.f32 	%f3513, %f1272, %f1264;
	ld.f32 	%f1273, [%rd45+100];
	sub.ftz.f32 	%f3514, %f1273, %f1265;
	ld.f32 	%f1274, [%rd45+104];
	sub.ftz.f32 	%f3515, %f1274, %f1266;
	mul.ftz.f32 	%f3516, %f3514, %f3514;
	fma.rn.ftz.f32 	%f3517, %f3513, %f3513, %f3516;
	fma.rn.ftz.f32 	%f3518, %f3515, %f3515, %f3517;
	rsqrt.approx.ftz.f32 	%f3519, %f3518;
	mul.ftz.f32 	%f1275, %f3513, %f3519;
	mul.ftz.f32 	%f1276, %f3514, %f3519;
	mul.ftz.f32 	%f1277, %f3515, %f3519;
	mul.ftz.f32 	%f3521, %f1262, 0f40C90FDB;
	cos.approx.ftz.f32 	%f3522, %f3521;
	sqrt.approx.ftz.f32 	%f3523, %f1263;
	mul.ftz.f32 	%f1278, %f3523, %f3522;
	sin.approx.ftz.f32 	%f3524, %f3521;
	mul.ftz.f32 	%f1279, %f3523, %f3524;
	mul.ftz.f32 	%f3525, %f1278, %f1278;
	sub.ftz.f32 	%f3526, %f3024, %f3525;
	mul.ftz.f32 	%f3527, %f1279, %f1279;
	sub.ftz.f32 	%f1280, %f3526, %f3527;
	setp.leu.ftz.f32 	%p131, %f1280, 0f00000000;
	mov.f32 	%f4158, 0f00000000;
	mov.f32 	%f4150, %f4158;
	@%p131 bra 	$L__BB0_225;

	sqrt.approx.ftz.f32 	%f4150, %f1280;

$L__BB0_225:
	mov.b32 	%r1236, %f1277;
	and.b32  	%r1237, %r1236, -2147483648;
	or.b32  	%r1238, %r1237, 1065353216;
	mov.b32 	%f3530, %r1238;
	mul.ftz.f32 	%f3531, %f4150, %f3530;
	add.ftz.f32 	%f3532, %f1277, %f3530;
	mul.ftz.f32 	%f3533, %f1276, %f1279;
	fma.rn.ftz.f32 	%f3534, %f1275, %f1278, %f3533;
	fma.rn.ftz.f32 	%f3535, %f3532, %f3531, %f3534;
	abs.ftz.f32 	%f3536, %f1277;
	add.ftz.f32 	%f3537, %f3536, 0f3F800000;
	div.approx.ftz.f32 	%f3538, %f3535, %f3537;
	mul.ftz.f32 	%f3539, %f1275, %f3538;
	mul.ftz.f32 	%f3540, %f1276, %f3538;
	mul.ftz.f32 	%f3541, %f3532, %f3538;
	sub.ftz.f32 	%f3542, %f3539, %f1278;
	sub.ftz.f32 	%f3543, %f3540, %f1279;
	sub.ftz.f32 	%f3544, %f3541, %f3531;
	fma.rn.ftz.f32 	%f3545, %f1271, %f3542, %f1264;
	fma.rn.ftz.f32 	%f3546, %f1271, %f3543, %f1265;
	fma.rn.ftz.f32 	%f3547, %f1271, %f3544, %f1266;
	sub.ftz.f32 	%f4151, %f3545, %f1272;
	sub.ftz.f32 	%f4152, %f3546, %f1273;
	sub.ftz.f32 	%f4153, %f3547, %f1274;
	mul.ftz.f32 	%f3548, %f4152, %f4152;
	fma.rn.ftz.f32 	%f3549, %f4151, %f4151, %f3548;
	fma.rn.ftz.f32 	%f3550, %f4153, %f4153, %f3549;
	sqrt.approx.ftz.f32 	%f4154, %f3550;
	setp.leu.ftz.f32 	%p132, %f4154, 0f358637BD;
	@%p132 bra 	$L__BB0_230;

	rcp.approx.ftz.f32 	%f3551, %f4154;
	mul.ftz.f32 	%f4151, %f4151, %f3551;
	mul.ftz.f32 	%f4152, %f4152, %f3551;
	mul.ftz.f32 	%f4153, %f4153, %f3551;
	cvt.rn.f32.u32 	%f3552, %r75;
	mul.ftz.f32 	%f4155, %f1267, %f3552;
	mul.ftz.f32 	%f4156, %f1268, %f3552;
	mul.ftz.f32 	%f4157, %f1269, %f3552;
	mul.ftz.f32 	%f3553, %f4154, %f4154;
	div.approx.ftz.f32 	%f4158, %f3553, %f1270;
	bra.uni 	$L__BB0_230;

$L__BB0_166:
	and.b32  	%r1085, %r31, 268435456;
	setp.eq.s32 	%p86, %r1085, 0;
	@%p86 bra 	$L__BB0_172;
	bra.uni 	$L__BB0_167;

$L__BB0_172:
	ld.u32 	%r1087, [%rd45+28];
	mad.lo.s32 	%r1088, %r1087, 1664525, 1013904223;
	st.u32 	[%rd45+28], %r1088;
	and.b32  	%r1089, %r1088, 16777215;
	cvt.rn.f32.u32 	%f3111, %r1089;
	mov.f32 	%f3112, 0f4B800000;
	div.approx.ftz.f32 	%f3113, %f3111, %f3112;
	setp.lt.ftz.f32 	%p89, %f3113, %f1162;
	@%p89 bra 	$L__BB0_205;
	bra.uni 	$L__BB0_173;

$L__BB0_205:
	setp.eq.s32 	%p121, %r32, 0;
	ld.f32 	%f3375, [%rd45+112];
	neg.ftz.f32 	%f3376, %f3375;
	ld.f32 	%f3377, [%rd45+116];
	neg.ftz.f32 	%f3378, %f3377;
	ld.f32 	%f3379, [%rd45+120];
	neg.ftz.f32 	%f3380, %f3379;
	mul.ftz.f32 	%f3381, %f1148, %f3376;
	mul.ftz.f32 	%f3382, %f1147, %f3377;
	sub.ftz.f32 	%f3383, %f3381, %f3382;
	mul.ftz.f32 	%f3384, %f1146, %f3379;
	sub.ftz.f32 	%f3385, %f3383, %f3384;
	add.ftz.f32 	%f3386, %f1148, %f1148;
	mul.ftz.f32 	%f3387, %f3386, %f3385;
	add.ftz.f32 	%f3388, %f1147, %f1147;
	mul.ftz.f32 	%f3389, %f3388, %f3385;
	add.ftz.f32 	%f3390, %f1146, %f1146;
	mul.ftz.f32 	%f3391, %f3390, %f3385;
	sub.ftz.f32 	%f3392, %f3380, %f3391;
	sub.ftz.f32 	%f3393, %f3378, %f3389;
	sub.ftz.f32 	%f3394, %f3376, %f3387;
	st.v2.f32 	[%rd45+128], {%f3394, %f3393};
	st.f32 	[%rd45+136], %f3392;
	ld.f32 	%f3395, [%rd54+128];
	sub.ftz.f32 	%f3396, %f1137, %f3395;
	ld.f32 	%f3397, [%rd54+132];
	sub.ftz.f32 	%f3398, %f1138, %f3397;
	ld.f32 	%f3399, [%rd54+136];
	sub.ftz.f32 	%f3400, %f1139, %f3399;
	fma.rn.ftz.f32 	%f1251, %f1119, %f3396, %f3395;
	fma.rn.ftz.f32 	%f1252, %f1119, %f3398, %f3397;
	fma.rn.ftz.f32 	%f1253, %f1119, %f3400, %f3399;
	@%p121 bra 	$L__BB0_207;

	ld.f32 	%f3401, [%rd45+16];
	mul.ftz.f32 	%f3402, %f1251, %f3401;
	st.f32 	[%rd45+16], %f3402;
	ld.f32 	%f3403, [%rd45+20];
	mul.ftz.f32 	%f3404, %f1252, %f3403;
	st.f32 	[%rd45+20], %f3404;
	ld.f32 	%f3405, [%rd45+24];
	mul.ftz.f32 	%f3406, %f1253, %f3405;
	st.f32 	[%rd45+24], %f3406;

$L__BB0_207:
	ld.u32 	%r1215, [%rd45+44];
	setp.ne.s32 	%p122, %r1215, 0;
	@%p122 bra 	$L__BB0_209;

	ld.const.v2.f32 	{%f3407, %f3408}, [params+144];
	mul.ftz.f32 	%f3411, %f1141, %f3408;
	fma.rn.ftz.f32 	%f3412, %f1142, %f3407, %f3411;
	ld.const.f32 	%f3413, [params+152];
	ld.const.v2.f32 	{%f3414, %f3415}, [params+160];
	mul.ftz.f32 	%f3418, %f1141, %f3415;
	fma.rn.ftz.f32 	%f3419, %f1142, %f3414, %f3418;
	ld.const.f32 	%f3420, [params+168];
	ld.const.v2.f32 	{%f3421, %f3422}, [params+176];
	mul.ftz.f32 	%f3425, %f1141, %f3422;
	fma.rn.ftz.f32 	%f3426, %f1142, %f3421, %f3425;
	ld.const.f32 	%f3427, [params+184];
	fma.rn.ftz.f32 	%f3428, %f1140, %f3427, %f3426;
	fma.rn.ftz.f32 	%f3429, %f1140, %f3420, %f3419;
	fma.rn.ftz.f32 	%f3430, %f1140, %f3413, %f3412;
	st.v2.f32 	[%rd45+32], {%f3430, %f3429};
	st.f32 	[%rd45+40], %f3428;

$L__BB0_209:
	st.v4.f32 	[%rd45+48], {%f1251, %f1252, %f1253, %f3024};
	bra.uni 	$L__BB0_243;

$L__BB0_154:
	st.v2.f32 	[%rd45+96], {%f1, %f2};
	st.f32 	[%rd45+104], %f3;
	mov.f32 	%f2958, 0f00000000;
	st.v2.f32 	[%rd45], {%f2958, %f2958};
	st.u32 	[%rd45+8], %r1056;
	mov.f32 	%f2959, 0f3F800000;
	st.v4.f32 	[%rd45+48], {%f2959, %f2959, %f2959, %f2959};
	ld.u32 	%r1063, [%rd45+44];
	add.s32 	%r1064, %r1063, -1;
	st.u32 	[%rd45+44], %r1064;
	bra.uni 	$L__BB0_243;

$L__BB0_167:
	setp.eq.s32 	%p87, %r32, 0;
	ld.f32 	%f3054, [%rd45+112];
	neg.ftz.f32 	%f3055, %f3054;
	ld.f32 	%f3056, [%rd45+116];
	neg.ftz.f32 	%f3057, %f3056;
	ld.f32 	%f3058, [%rd45+120];
	neg.ftz.f32 	%f3059, %f3058;
	mul.ftz.f32 	%f3060, %f1148, %f3055;
	mul.ftz.f32 	%f3061, %f1147, %f3056;
	sub.ftz.f32 	%f3062, %f3060, %f3061;
	mul.ftz.f32 	%f3063, %f1146, %f3058;
	sub.ftz.f32 	%f3064, %f3062, %f3063;
	add.ftz.f32 	%f3065, %f1148, %f1148;
	mul.ftz.f32 	%f3066, %f3065, %f3064;
	add.ftz.f32 	%f3067, %f1147, %f1147;
	mul.ftz.f32 	%f3068, %f3067, %f3064;
	add.ftz.f32 	%f3069, %f1146, %f1146;
	mul.ftz.f32 	%f3070, %f3069, %f3064;
	sub.ftz.f32 	%f3071, %f3059, %f3070;
	sub.ftz.f32 	%f3072, %f3057, %f3068;
	sub.ftz.f32 	%f3073, %f3055, %f3066;
	st.v2.f32 	[%rd45+128], {%f3073, %f3072};
	st.f32 	[%rd45+136], %f3071;
	st.f32 	[%rd45+124], %f1162;
	ld.f32 	%f3074, [%rd54+128];
	sub.ftz.f32 	%f3075, %f1137, %f3074;
	ld.f32 	%f3076, [%rd54+132];
	sub.ftz.f32 	%f3077, %f1138, %f3076;
	ld.f32 	%f3078, [%rd54+136];
	sub.ftz.f32 	%f3079, %f1139, %f3078;
	fma.rn.ftz.f32 	%f1163, %f1119, %f3075, %f3074;
	fma.rn.ftz.f32 	%f1164, %f1119, %f3077, %f3076;
	fma.rn.ftz.f32 	%f1165, %f1119, %f3079, %f3078;
	@%p87 bra 	$L__BB0_169;

	ld.f32 	%f3080, [%rd45+16];
	mul.ftz.f32 	%f3081, %f1163, %f3080;
	st.f32 	[%rd45+16], %f3081;
	ld.f32 	%f3082, [%rd45+20];
	mul.ftz.f32 	%f3083, %f1164, %f3082;
	st.f32 	[%rd45+20], %f3083;
	ld.f32 	%f3084, [%rd45+24];
	mul.ftz.f32 	%f3085, %f1165, %f3084;
	st.f32 	[%rd45+24], %f3085;

$L__BB0_169:
	ld.u32 	%r1086, [%rd45+44];
	setp.ne.s32 	%p88, %r1086, 0;
	@%p88 bra 	$L__BB0_171;

	ld.const.v2.f32 	{%f3086, %f3087}, [params+144];
	mul.ftz.f32 	%f3090, %f1141, %f3087;
	fma.rn.ftz.f32 	%f3091, %f1142, %f3086, %f3090;
	ld.const.f32 	%f3092, [params+152];
	ld.const.v2.f32 	{%f3093, %f3094}, [params+160];
	mul.ftz.f32 	%f3097, %f1141, %f3094;
	fma.rn.ftz.f32 	%f3098, %f1142, %f3093, %f3097;
	ld.const.f32 	%f3099, [params+168];
	ld.const.v2.f32 	{%f3100, %f3101}, [params+176];
	mul.ftz.f32 	%f3104, %f1141, %f3101;
	fma.rn.ftz.f32 	%f3105, %f1142, %f3100, %f3104;
	ld.const.f32 	%f3106, [params+184];
	fma.rn.ftz.f32 	%f3107, %f1140, %f3106, %f3105;
	fma.rn.ftz.f32 	%f3108, %f1140, %f3099, %f3098;
	fma.rn.ftz.f32 	%f3109, %f1140, %f3092, %f3091;
	st.v2.f32 	[%rd45+32], {%f3109, %f3108};
	st.f32 	[%rd45+40], %f3107;

$L__BB0_171:
	st.v4.f32 	[%rd45+48], {%f1163, %f1164, %f1165, %f3024};
	bra.uni 	$L__BB0_243;

$L__BB0_173:
	setp.eq.s32 	%p90, %r32, 0;
	@%p90 bra 	$L__BB0_175;

	ld.f32 	%f3114, [%rd45+16];
	mul.ftz.f32 	%f3115, %f1137, %f3114;
	st.f32 	[%rd45+16], %f3115;
	ld.f32 	%f3116, [%rd45+20];
	mul.ftz.f32 	%f3117, %f1138, %f3116;
	st.f32 	[%rd45+20], %f3117;
	ld.f32 	%f3118, [%rd45+24];
	mul.ftz.f32 	%f3119, %f1139, %f3118;
	st.f32 	[%rd45+24], %f3119;
	and.b32  	%r1090, %r31, -16777217;
	st.u32 	[%rd45+12], %r1090;

$L__BB0_175:
	ld.u32 	%r1091, [%rd45+44];
	setp.ne.s32 	%p91, %r1091, 0;
	@%p91 bra 	$L__BB0_177;

	ld.const.v2.f32 	{%f3120, %f3121}, [params+144];
	mul.ftz.f32 	%f3124, %f1141, %f3121;
	fma.rn.ftz.f32 	%f3125, %f1142, %f3120, %f3124;
	ld.const.f32 	%f3126, [params+152];
	ld.const.v2.f32 	{%f3127, %f3128}, [params+160];
	mul.ftz.f32 	%f3131, %f1141, %f3128;
	fma.rn.ftz.f32 	%f3132, %f1142, %f3127, %f3131;
	ld.const.f32 	%f3133, [params+168];
	ld.const.v2.f32 	{%f3134, %f3135}, [params+176];
	mul.ftz.f32 	%f3138, %f1141, %f3135;
	fma.rn.ftz.f32 	%f3139, %f1142, %f3134, %f3138;
	ld.const.f32 	%f3140, [params+184];
	fma.rn.ftz.f32 	%f3141, %f1140, %f3140, %f3139;
	fma.rn.ftz.f32 	%f3142, %f1140, %f3133, %f3132;
	fma.rn.ftz.f32 	%f3143, %f1140, %f3126, %f3125;
	st.v2.f32 	[%rd45+32], {%f3143, %f3142};
	st.f32 	[%rd45+40], %f3141;

$L__BB0_177:
	ld.f32 	%f3145, [%rd45+112];
	ld.f32 	%f3146, [%rd45+116];
	mul.ftz.f32 	%f3147, %f1147, %f3146;
	fma.rn.ftz.f32 	%f3148, %f1148, %f3145, %f3147;
	ld.f32 	%f3149, [%rd45+120];
	fma.rn.ftz.f32 	%f3150, %f1146, %f3149, %f3148;
	ld.f32 	%f3151, [%rd54+140];
	mul.ftz.f32 	%f3152, %f3151, %f3150;
	mul.ftz.f32 	%f3153, %f1139, %f3152;
	mul.ftz.f32 	%f3154, %f1138, %f3152;
	mul.ftz.f32 	%f3155, %f1137, %f3152;
	st.v2.f32 	[%rd45], {%f3155, %f3154};
	st.f32 	[%rd45+8], %f3153;
	ld.u32 	%r1092, [%rd45+28];
	mad.lo.s32 	%r1093, %r1092, 1664525, 1013904223;
	and.b32  	%r1094, %r1093, 16777215;
	cvt.rn.f32.u32 	%f3156, %r1094;
	div.approx.ftz.f32 	%f3158, %f3156, %f3112;
	mad.lo.s32 	%r33, %r1093, 1664525, 1013904223;
	st.u32 	[%rd45+28], %r33;
	and.b32  	%r1095, %r33, 16777215;
	cvt.rn.f32.u32 	%f3159, %r1095;
	div.approx.ftz.f32 	%f3160, %f3159, %f3112;
	mul.ftz.f32 	%f3161, %f3158, 0f40C90FDB;
	sqrt.approx.ftz.f32 	%f3162, %f3160;
	cos.approx.ftz.f32 	%f3163, %f3161;
	mul.ftz.f32 	%f1166, %f3162, %f3163;
	st.f32 	[%rd45+128], %f1166;
	sin.approx.ftz.f32 	%f3164, %f3161;
	mul.ftz.f32 	%f1167, %f3162, %f3164;
	st.f32 	[%rd45+132], %f1167;
	mul.ftz.f32 	%f3165, %f1166, %f1166;
	sub.ftz.f32 	%f3167, %f3024, %f3165;
	mul.ftz.f32 	%f3168, %f1167, %f1167;
	sub.ftz.f32 	%f1168, %f3167, %f3168;
	st.f32 	[%rd45+136], %f1168;
	setp.leu.ftz.f32 	%p92, %f1168, 0f00000000;
	@%p92 bra 	$L__BB0_179;

	sqrt.approx.ftz.f32 	%f4134, %f1168;

$L__BB0_179:
	mov.b32 	%r1096, %f1146;
	and.b32  	%r1097, %r1096, -2147483648;
	or.b32  	%r1098, %r1097, 1065353216;
	mov.b32 	%f3169, %r1098;
	mul.ftz.f32 	%f3170, %f4134, %f3169;
	add.ftz.f32 	%f3171, %f1146, %f3169;
	mul.ftz.f32 	%f3172, %f1147, %f1167;
	fma.rn.ftz.f32 	%f3173, %f1148, %f1166, %f3172;
	fma.rn.ftz.f32 	%f3174, %f3171, %f3170, %f3173;
	abs.ftz.f32 	%f3175, %f1146;
	add.ftz.f32 	%f3176, %f3175, 0f3F800000;
	div.approx.ftz.f32 	%f3177, %f3174, %f3176;
	mul.ftz.f32 	%f3178, %f1148, %f3177;
	mul.ftz.f32 	%f3179, %f1147, %f3177;
	mul.ftz.f32 	%f3180, %f3171, %f3177;
	sub.ftz.f32 	%f1171, %f3178, %f1166;
	sub.ftz.f32 	%f1172, %f3179, %f1167;
	sub.ftz.f32 	%f1173, %f3180, %f3170;
	st.f32 	[%rd45+128], %f1171;
	st.f32 	[%rd45+132], %f1172;
	st.f32 	[%rd45+136], %f1173;
	mul.ftz.f32 	%f3181, %f4134, 0f3EA2F983;
	st.v4.f32 	[%rd45+48], {%f1137, %f1138, %f1139, %f3181};
	setp.le.ftz.f32 	%p93, %f3181, 0f00000000;
	@%p93 bra 	$L__BB0_181;

	mul.ftz.f32 	%f3182, %f1141, %f1172;
	fma.rn.ftz.f32 	%f3183, %f1142, %f1171, %f3182;
	fma.rn.ftz.f32 	%f3184, %f1140, %f1173, %f3183;
	setp.gtu.ftz.f32 	%p94, %f3184, 0f3A83126F;
	@%p94 bra 	$L__BB0_182;

$L__BB0_181:
	ld.u32 	%r1099, [%rd45+12];
	or.b32  	%r1100, %r1099, -2147483648;
	st.u32 	[%rd45+12], %r1100;

$L__BB0_182:
	ld.const.u32 	%r34, [params+192];
	setp.eq.s32 	%p95, %r34, 0;
	@%p95 bra 	$L__BB0_243;

	mad.lo.s32 	%r1101, %r33, 1664525, 1013904223;
	and.b32  	%r1102, %r1101, 16777215;
	cvt.rn.f32.u32 	%f3185, %r1102;
	div.approx.ftz.f32 	%f1174, %f3185, %f3112;
	mad.lo.s32 	%r35, %r1101, 1664525, 1013904223;
	mov.u64 	%rd802, 0;
	st.u32 	[%rd45+28], %r35;
	and.b32  	%r1103, %r35, 16777215;
	cvt.rn.f32.u32 	%f3187, %r1103;
	div.approx.ftz.f32 	%f1175, %f3187, %f3112;
	setp.eq.s32 	%p96, %r34, 1;
	@%p96 bra 	$L__BB0_185;

	mad.lo.s32 	%r1104, %r35, 1664525, 1013904223;
	st.u32 	[%rd45+28], %r1104;
	and.b32  	%r1105, %r1104, 16777215;
	cvt.rn.f32.u32 	%f3188, %r1105;
	div.approx.ftz.f32 	%f3190, %f3188, %f3112;
	cvt.rn.f32.u32 	%f3191, %r34;
	mul.ftz.f32 	%f3192, %f3190, %f3191;
	cvt.rmi.ftz.f32.f32 	%f3193, %f3192;
	cvt.rzi.ftz.u32.f32 	%r1106, %f3193;
	add.s32 	%r1107, %r34, -1;
	min.u32 	%r1108, %r1106, %r1107;
	cvt.s64.s32 	%rd802, %r1108;

$L__BB0_185:
	ld.const.u64 	%rd787, [params+200];
	cvta.to.global.u64 	%rd788, %rd787;
	mul.lo.s64 	%rd789, %rd802, 80;
	add.s64 	%rd48, %rd788, %rd789;
	ld.global.f32 	%f1176, [%rd48];
	ld.global.f32 	%f1177, [%rd48+4];
	ld.global.f32 	%f1178, [%rd48+8];
	ld.global.f32 	%f1179, [%rd48+16];
	ld.global.f32 	%f1180, [%rd48+20];
	ld.global.f32 	%f1181, [%rd48+24];
	ld.global.f32 	%f1182, [%rd48+28];
	ld.global.u32 	%r1109, [%rd48+12];
	setp.eq.s32 	%p97, %r1109, 0;
	@%p97 bra 	$L__BB0_190;

	ld.global.f32 	%f1183, [%rd48+44];
	ld.f32 	%f1184, [%rd45+96];
	sub.ftz.f32 	%f3195, %f1184, %f1176;
	ld.f32 	%f1185, [%rd45+100];
	sub.ftz.f32 	%f3196, %f1185, %f1177;
	ld.f32 	%f1186, [%rd45+104];
	sub.ftz.f32 	%f3197, %f1186, %f1178;
	mul.ftz.f32 	%f3198, %f3196, %f3196;
	fma.rn.ftz.f32 	%f3199, %f3195, %f3195, %f3198;
	fma.rn.ftz.f32 	%f3200, %f3197, %f3197, %f3199;
	rsqrt.approx.ftz.f32 	%f3201, %f3200;
	mul.ftz.f32 	%f1187, %f3195, %f3201;
	mul.ftz.f32 	%f1188, %f3196, %f3201;
	mul.ftz.f32 	%f1189, %f3197, %f3201;
	mul.ftz.f32 	%f3203, %f1174, 0f40C90FDB;
	cos.approx.ftz.f32 	%f3204, %f3203;
	sqrt.approx.ftz.f32 	%f3205, %f1175;
	mul.ftz.f32 	%f1190, %f3205, %f3204;
	sin.approx.ftz.f32 	%f3206, %f3203;
	mul.ftz.f32 	%f1191, %f3205, %f3206;
	mul.ftz.f32 	%f3207, %f1190, %f1190;
	sub.ftz.f32 	%f3208, %f3024, %f3207;
	mul.ftz.f32 	%f3209, %f1191, %f1191;
	sub.ftz.f32 	%f1192, %f3208, %f3209;
	setp.leu.ftz.f32 	%p98, %f1192, 0f00000000;
	mov.f32 	%f4143, 0f00000000;
	mov.f32 	%f4135, %f4143;
	@%p98 bra 	$L__BB0_188;

	sqrt.approx.ftz.f32 	%f4135, %f1192;

$L__BB0_188:
	mov.b32 	%r1110, %f1189;
	and.b32  	%r1111, %r1110, -2147483648;
	or.b32  	%r1112, %r1111, 1065353216;
	mov.b32 	%f3212, %r1112;
	mul.ftz.f32 	%f3213, %f4135, %f3212;
	add.ftz.f32 	%f3214, %f1189, %f3212;
	mul.ftz.f32 	%f3215, %f1188, %f1191;
	fma.rn.ftz.f32 	%f3216, %f1187, %f1190, %f3215;
	fma.rn.ftz.f32 	%f3217, %f3214, %f3213, %f3216;
	abs.ftz.f32 	%f3218, %f1189;
	add.ftz.f32 	%f3219, %f3218, 0f3F800000;
	div.approx.ftz.f32 	%f3220, %f3217, %f3219;
	mul.ftz.f32 	%f3221, %f1187, %f3220;
	mul.ftz.f32 	%f3222, %f1188, %f3220;
	mul.ftz.f32 	%f3223, %f3214, %f3220;
	sub.ftz.f32 	%f3224, %f3221, %f1190;
	sub.ftz.f32 	%f3225, %f3222, %f1191;
	sub.ftz.f32 	%f3226, %f3223, %f3213;
	fma.rn.ftz.f32 	%f3227, %f1183, %f3224, %f1176;
	fma.rn.ftz.f32 	%f3228, %f1183, %f3225, %f1177;
	fma.rn.ftz.f32 	%f3229, %f1183, %f3226, %f1178;
	sub.ftz.f32 	%f4136, %f3227, %f1184;
	sub.ftz.f32 	%f4137, %f3228, %f1185;
	sub.ftz.f32 	%f4138, %f3229, %f1186;
	mul.ftz.f32 	%f3230, %f4137, %f4137;
	fma.rn.ftz.f32 	%f3231, %f4136, %f4136, %f3230;
	fma.rn.ftz.f32 	%f3232, %f4138, %f4138, %f3231;
	sqrt.approx.ftz.f32 	%f4139, %f3232;
	setp.leu.ftz.f32 	%p99, %f4139, 0f358637BD;
	@%p99 bra 	$L__BB0_193;

	rcp.approx.ftz.f32 	%f3233, %f4139;
	mul.ftz.f32 	%f4136, %f4136, %f3233;
	mul.ftz.f32 	%f4137, %f4137, %f3233;
	mul.ftz.f32 	%f4138, %f4138, %f3233;
	cvt.rn.f32.u32 	%f3234, %r34;
	mul.ftz.f32 	%f4140, %f1179, %f3234;
	mul.ftz.f32 	%f4141, %f1180, %f3234;
	mul.ftz.f32 	%f4142, %f1181, %f3234;
	mul.ftz.f32 	%f3235, %f4139, %f4139;
	div.approx.ftz.f32 	%f4143, %f3235, %f1182;
	bra.uni 	$L__BB0_193;

$L__BB0_227:
	ld.global.f32 	%f3556, [%rd52+32];
	ld.global.f32 	%f3557, [%rd52+36];
	ld.global.f32 	%f3558, [%rd52+40];
	fma.rn.ftz.f32 	%f3559, %f1262, %f3556, %f1264;
	fma.rn.ftz.f32 	%f3560, %f1262, %f3557, %f1265;
	fma.rn.ftz.f32 	%f3561, %f1262, %f3558, %f1266;
	ld.global.f32 	%f3562, [%rd52+48];
	ld.global.f32 	%f3563, [%rd52+52];
	ld.global.f32 	%f3564, [%rd52+56];
	fma.rn.ftz.f32 	%f3565, %f1263, %f3562, %f3559;
	fma.rn.ftz.f32 	%f3566, %f1263, %f3563, %f3560;
	fma.rn.ftz.f32 	%f3567, %f1263, %f3564, %f3561;
	ld.f32 	%f3568, [%rd45+96];
	sub.ftz.f32 	%f4151, %f3565, %f3568;
	ld.f32 	%f3569, [%rd45+100];
	sub.ftz.f32 	%f4152, %f3566, %f3569;
	ld.f32 	%f3570, [%rd45+104];
	sub.ftz.f32 	%f4153, %f3567, %f3570;
	mul.ftz.f32 	%f3571, %f4151, %f4151;
	fma.rn.ftz.f32 	%f3572, %f4152, %f4152, %f3571;
	fma.rn.ftz.f32 	%f3573, %f4153, %f4153, %f3572;
	sqrt.approx.ftz.f32 	%f4154, %f3573;
	setp.leu.ftz.f32 	%p133, %f4154, 0f358637BD;
	mov.f32 	%f4158, 0f00000000;
	@%p133 bra 	$L__BB0_230;

	ld.global.f32 	%f3576, [%rd52+64];
	ld.global.f32 	%f3577, [%rd52+68];
	ld.global.f32 	%f3578, [%rd52+72];
	rcp.approx.ftz.f32 	%f3579, %f4154;
	mul.ftz.f32 	%f4151, %f4151, %f3579;
	mul.ftz.f32 	%f4152, %f4152, %f3579;
	mul.ftz.f32 	%f4153, %f4153, %f3579;
	mul.ftz.f32 	%f3580, %f3576, %f4151;
	mul.ftz.f32 	%f3581, %f3577, %f4152;
	neg.ftz.f32 	%f3582, %f3581;
	sub.ftz.f32 	%f3583, %f3582, %f3580;
	mul.ftz.f32 	%f3584, %f3578, %f4153;
	sub.ftz.f32 	%f1301, %f3583, %f3584;
	setp.leu.ftz.f32 	%p134, %f1301, 0f358637BD;
	@%p134 bra 	$L__BB0_230;

	cvt.rn.f32.u32 	%f3585, %r75;
	mul.ftz.f32 	%f4155, %f1267, %f3585;
	mul.ftz.f32 	%f4156, %f1268, %f3585;
	mul.ftz.f32 	%f4157, %f1269, %f3585;
	mul.ftz.f32 	%f3586, %f1270, %f1301;
	mul.ftz.f32 	%f3587, %f4154, %f4154;
	div.approx.ftz.f32 	%f4158, %f3587, %f3586;

$L__BB0_230:
	setp.leu.ftz.f32 	%p135, %f4158, 0f00000000;
	@%p135 bra 	$L__BB0_242;

	mul.ftz.f32 	%f3588, %f1137, %f4155;
	mul.ftz.f32 	%f1314, %f3588, 0f3EA2F983;
	mul.ftz.f32 	%f3589, %f1138, %f4156;
	mul.ftz.f32 	%f1315, %f3589, 0f3EA2F983;
	mul.ftz.f32 	%f3590, %f1139, %f4157;
	mul.ftz.f32 	%f1316, %f3590, 0f3EA2F983;
	mul.ftz.f32 	%f3591, %f1147, %f4152;
	fma.rn.ftz.f32 	%f3592, %f1148, %f4151, %f3591;
	fma.rn.ftz.f32 	%f1317, %f1146, %f4153, %f3592;
	setp.eq.ftz.f32 	%p136, %f1118, 0f00000000;
	@%p136 bra 	$L__BB0_233;
	bra.uni 	$L__BB0_232;

$L__BB0_233:
	mul.ftz.f32 	%f3654, %f1317, 0f3EA2F983;
	mov.f32 	%f3655, 0f00000000;
	max.ftz.f32 	%f4159, %f3655, %f3654;
	bra.uni 	$L__BB0_234;

$L__BB0_232:
	mul.ftz.f32 	%f3593, %f1118, %f1118;
	add.ftz.f32 	%f3594, %f3593, 0f3EA8F5C3;
	add.ftz.f32 	%f3595, %f3593, 0f3DB851EC;
	div.approx.ftz.f32 	%f3596, %f3593, %f3594;
	div.approx.ftz.f32 	%f3597, %f3593, %f3595;
	fma.rn.ftz.f32 	%f3598, %f3596, 0fBF000000, 0f3F800000;
	fma.rn.ftz.f32 	%f3600, %f3597, 0f3EE66666, 0f00000000;
	mov.f32 	%f3601, 0f00000000;
	ld.f32 	%f3602, [%rd45+112];
	ld.f32 	%f3603, [%rd45+116];
	mul.ftz.f32 	%f3604, %f1147, %f3603;
	fma.rn.ftz.f32 	%f3605, %f1148, %f3602, %f3604;
	ld.f32 	%f3606, [%rd45+120];
	fma.rn.ftz.f32 	%f3607, %f1146, %f3606, %f3605;
	min.ftz.f32 	%f3608, %f1317, %f3024;
	max.ftz.f32 	%f3609, %f3601, %f3608;
	min.ftz.f32 	%f3610, %f3607, %f3024;
	max.ftz.f32 	%f3611, %f3601, %f3610;
	mul.ftz.f32 	%f3612, %f3609, %f3609;
	mul.ftz.f32 	%f3613, %f3611, %f3611;
	sub.ftz.f32 	%f3614, %f3024, %f3612;
	sub.ftz.f32 	%f3615, %f3024, %f3613;
	mul.ftz.f32 	%f3616, %f3614, %f3615;
	sqrt.approx.ftz.f32 	%f3617, %f3616;
	mul.ftz.f32 	%f3618, %f1148, %f3609;
	mul.ftz.f32 	%f3619, %f1147, %f3609;
	mul.ftz.f32 	%f3620, %f1146, %f3609;
	sub.ftz.f32 	%f3621, %f4151, %f3618;
	sub.ftz.f32 	%f3622, %f4152, %f3619;
	sub.ftz.f32 	%f3623, %f4153, %f3620;
	mul.ftz.f32 	%f3624, %f3622, %f3622;
	fma.rn.ftz.f32 	%f3625, %f3621, %f3621, %f3624;
	fma.rn.ftz.f32 	%f3626, %f3623, %f3623, %f3625;
	rsqrt.approx.ftz.f32 	%f3627, %f3626;
	mul.ftz.f32 	%f3628, %f3621, %f3627;
	mul.ftz.f32 	%f3629, %f3622, %f3627;
	mul.ftz.f32 	%f3630, %f3623, %f3627;
	mul.ftz.f32 	%f3631, %f1148, %f3611;
	mul.ftz.f32 	%f3632, %f1147, %f3611;
	mul.ftz.f32 	%f3633, %f1146, %f3611;
	sub.ftz.f32 	%f3634, %f3602, %f3631;
	sub.ftz.f32 	%f3635, %f3603, %f3632;
	sub.ftz.f32 	%f3636, %f3606, %f3633;
	mul.ftz.f32 	%f3637, %f3635, %f3635;
	fma.rn.ftz.f32 	%f3638, %f3634, %f3634, %f3637;
	fma.rn.ftz.f32 	%f3639, %f3636, %f3636, %f3638;
	rsqrt.approx.ftz.f32 	%f3640, %f3639;
	mul.ftz.f32 	%f3641, %f3634, %f3640;
	mul.ftz.f32 	%f3642, %f3635, %f3640;
	mul.ftz.f32 	%f3643, %f3636, %f3640;
	mul.ftz.f32 	%f3644, %f3629, %f3642;
	fma.rn.ftz.f32 	%f3645, %f3628, %f3641, %f3644;
	fma.rn.ftz.f32 	%f3646, %f3630, %f3643, %f3645;
	min.ftz.f32 	%f3647, %f3646, %f3024;
	max.ftz.f32 	%f3648, %f3601, %f3647;
	mul.ftz.f32 	%f3649, %f3617, %f3648;
	max.ftz.f32 	%f3650, %f3609, %f3611;
	div.approx.ftz.f32 	%f3651, %f3649, %f3650;
	fma.rn.ftz.f32 	%f3652, %f3600, %f3651, %f3598;
	mul.ftz.f32 	%f3653, %f3609, %f3652;
	mul.ftz.f32 	%f4159, %f3653, 0f3EA2F983;

$L__BB0_234:
	mul.ftz.f32 	%f3656, %f1141, %f4152;
	fma.rn.ftz.f32 	%f3657, %f1142, %f4151, %f3656;
	fma.rn.ftz.f32 	%f3658, %f1140, %f4153, %f3657;
	setp.leu.ftz.f32 	%p137, %f3658, 0f00000000;
	setp.leu.ftz.f32 	%p138, %f4159, 0f00000000;
	or.pred  	%p139, %p137, %p138;
	@%p139 bra 	$L__BB0_242;

	setp.eq.ftz.f32 	%p140, %f1314, 0f00000000;
	setp.eq.ftz.f32 	%p141, %f1315, 0f00000000;
	and.pred  	%p142, %p140, %p141;
	setp.eq.ftz.f32 	%p143, %f1316, 0f00000000;
	and.pred  	%p144, %p142, %p143;
	@%p144 bra 	$L__BB0_242;

	ld.const.u64 	%rd53, [params+280];
	ld.v4.f32 	{%f3659, %f3660, %f3661, %f3662}, [%rd45+96];
	sub.ftz.f32 	%f1324, %f4154, %f1149;
	mov.u32 	%r1352, 1065353216;
	mov.u32 	%r1280, 4;
	mov.f32 	%f4160, %f1149;
	mov.u32 	%r1353, %r1352;
	mov.u32 	%r1354, %r1352;

$L__BB0_237:
	mov.f32 	%f4161, 0f00000000;
	// begin inline asm
	call(%r1352,%r1353,%r1354,%r1245,%r1246,%r1247,%r1248,%r1249,%r1250,%r1251,%r1252,%r1253,%r1254,%r1255,%r1256,%r1257,%r1258,%r1259,%r1260,%r1261,%r1262,%r1263,%r1264,%r1265,%r1266,%r1267,%r1268,%r1269,%r1270,%r1271,%r1272,%r1273),_optix_trace_typed_32,(%r1056,%rd53,%f3659,%f3660,%f3661,%f4151,%f4152,%f4153,%f4160,%f1324,%f4161,%r1058,%r1056,%r1058,%r1050,%r1058,%r1280,%r1352,%r1353,%r1354,%r1056,%r1313,%r1314,%r1315,%r1316,%r1317,%r1318,%r1319,%r1320,%r1321,%r1322,%r1323,%r1324,%r1325,%r1326,%r1327,%r1328,%r1329,%r1330,%r1331,%r1332,%r1333,%r1334,%r1335,%r1336,%r1337,%r1338,%r1339,%r1340);
	// end inline asm
	mov.b32 	%f1326, %r1352;
	mov.b32 	%f1327, %r1353;
	mov.b32 	%f1328, %r1354;
	mul.ftz.f32 	%f3675, %f1326, %f1327;
	mul.ftz.f32 	%f3676, %f3675, %f1328;
	setp.lt.ftz.f32 	%p145, %f3676, 0f358637BD;
	mov.f32 	%f4162, %f4161;
	mov.f32 	%f4163, %f4161;
	@%p145 bra 	$L__BB0_240;

	mov.b32 	%f3677, %r1245;
	add.ftz.f32 	%f3678, %f1149, %f3677;
	add.ftz.f32 	%f4160, %f4160, %f3678;
	setp.lt.ftz.f32 	%p146, %f4160, %f1324;
	setp.ne.s32 	%p147, %r1245, 0;
	and.pred  	%p148, %p147, %p146;
	@%p148 bra 	$L__BB0_237;

	mov.f32 	%f4161, %f1326;
	mov.f32 	%f4162, %f1327;
	mov.f32 	%f4163, %f1328;

$L__BB0_240:
	setp.eq.ftz.f32 	%p149, %f4161, 0f00000000;
	setp.eq.ftz.f32 	%p150, %f4162, 0f00000000;
	setp.eq.ftz.f32 	%p151, %f4163, 0f00000000;
	and.pred  	%p152, %p150, %p149;
	and.pred  	%p153, %p151, %p152;
	@%p153 bra 	$L__BB0_242;

	mul.ftz.f32 	%f3679, %f4158, %f4158;
	fma.rn.ftz.f32 	%f3680, %f4159, %f4159, %f3679;
	div.approx.ftz.f32 	%f3681, %f3679, %f3680;
	mul.ftz.f32 	%f3682, %f1317, %f3681;
	div.approx.ftz.f32 	%f3683, %f3682, %f4158;
	mul.ftz.f32 	%f3684, %f1314, %f4161;
	mul.ftz.f32 	%f3685, %f1315, %f4162;
	mul.ftz.f32 	%f3686, %f1316, %f4163;
	ld.f32 	%f3687, [%rd45];
	fma.rn.ftz.f32 	%f3688, %f3684, %f3683, %f3687;
	st.f32 	[%rd45], %f3688;
	ld.f32 	%f3689, [%rd45+4];
	fma.rn.ftz.f32 	%f3690, %f3685, %f3683, %f3689;
	st.f32 	[%rd45+4], %f3690;
	ld.f32 	%f3691, [%rd45+8];
	fma.rn.ftz.f32 	%f3692, %f3686, %f3683, %f3691;
	st.f32 	[%rd45+8], %f3692;

$L__BB0_242:
	sub.ftz.f32 	%f3694, %f3024, %f1162;
	st.f32 	[%rd45+124], %f3694;

$L__BB0_243:
	ret;

$L__BB0_190:
	ld.global.f32 	%f3238, [%rd48+32];
	ld.global.f32 	%f3239, [%rd48+36];
	ld.global.f32 	%f3240, [%rd48+40];
	fma.rn.ftz.f32 	%f3241, %f1174, %f3238, %f1176;
	fma.rn.ftz.f32 	%f3242, %f1174, %f3239, %f1177;
	fma.rn.ftz.f32 	%f3243, %f1174, %f3240, %f1178;
	ld.global.f32 	%f3244, [%rd48+48];
	ld.global.f32 	%f3245, [%rd48+52];
	ld.global.f32 	%f3246, [%rd48+56];
	fma.rn.ftz.f32 	%f3247, %f1175, %f3244, %f3241;
	fma.rn.ftz.f32 	%f3248, %f1175, %f3245, %f3242;
	fma.rn.ftz.f32 	%f3249, %f1175, %f3246, %f3243;
	ld.f32 	%f3250, [%rd45+96];
	sub.ftz.f32 	%f4136, %f3247, %f3250;
	ld.f32 	%f3251, [%rd45+100];
	sub.ftz.f32 	%f4137, %f3248, %f3251;
	ld.f32 	%f3252, [%rd45+104];
	sub.ftz.f32 	%f4138, %f3249, %f3252;
	mul.ftz.f32 	%f3253, %f4136, %f4136;
	fma.rn.ftz.f32 	%f3254, %f4137, %f4137, %f3253;
	fma.rn.ftz.f32 	%f3255, %f4138, %f4138, %f3254;
	sqrt.approx.ftz.f32 	%f4139, %f3255;
	setp.leu.ftz.f32 	%p100, %f4139, 0f358637BD;
	mov.f32 	%f4143, 0f00000000;
	@%p100 bra 	$L__BB0_193;

	ld.global.f32 	%f3258, [%rd48+64];
	ld.global.f32 	%f3259, [%rd48+68];
	ld.global.f32 	%f3260, [%rd48+72];
	rcp.approx.ftz.f32 	%f3261, %f4139;
	mul.ftz.f32 	%f4136, %f4136, %f3261;
	mul.ftz.f32 	%f4137, %f4137, %f3261;
	mul.ftz.f32 	%f4138, %f4138, %f3261;
	mul.ftz.f32 	%f3262, %f3258, %f4136;
	mul.ftz.f32 	%f3263, %f3259, %f4137;
	neg.ftz.f32 	%f3264, %f3263;
	sub.ftz.f32 	%f3265, %f3264, %f3262;
	mul.ftz.f32 	%f3266, %f3260, %f4138;
	sub.ftz.f32 	%f1213, %f3265, %f3266;
	setp.leu.ftz.f32 	%p101, %f1213, 0f358637BD;
	@%p101 bra 	$L__BB0_193;

	cvt.rn.f32.u32 	%f3267, %r34;
	mul.ftz.f32 	%f4140, %f1179, %f3267;
	mul.ftz.f32 	%f4141, %f1180, %f3267;
	mul.ftz.f32 	%f4142, %f1181, %f3267;
	mul.ftz.f32 	%f3268, %f1182, %f1213;
	mul.ftz.f32 	%f3269, %f4139, %f4139;
	div.approx.ftz.f32 	%f4143, %f3269, %f3268;

$L__BB0_193:
	setp.leu.ftz.f32 	%p102, %f4143, 0f00000000;
	@%p102 bra 	$L__BB0_243;

	mul.ftz.f32 	%f3270, %f1137, %f4140;
	mul.ftz.f32 	%f1226, %f3270, 0f3EA2F983;
	mul.ftz.f32 	%f3271, %f1138, %f4141;
	mul.ftz.f32 	%f1227, %f3271, 0f3EA2F983;
	mul.ftz.f32 	%f3272, %f1139, %f4142;
	mul.ftz.f32 	%f1228, %f3272, 0f3EA2F983;
	mul.ftz.f32 	%f3273, %f1147, %f4137;
	fma.rn.ftz.f32 	%f3274, %f1148, %f4136, %f3273;
	fma.rn.ftz.f32 	%f1229, %f1146, %f4138, %f3274;
	setp.eq.ftz.f32 	%p103, %f1118, 0f00000000;
	@%p103 bra 	$L__BB0_196;
	bra.uni 	$L__BB0_195;

$L__BB0_196:
	mul.ftz.f32 	%f3336, %f1229, 0f3EA2F983;
	mov.f32 	%f3337, 0f00000000;
	max.ftz.f32 	%f4144, %f3337, %f3336;
	bra.uni 	$L__BB0_197;

$L__BB0_195:
	mul.ftz.f32 	%f3275, %f1118, %f1118;
	add.ftz.f32 	%f3276, %f3275, 0f3EA8F5C3;
	add.ftz.f32 	%f3277, %f3275, 0f3DB851EC;
	div.approx.ftz.f32 	%f3278, %f3275, %f3276;
	div.approx.ftz.f32 	%f3279, %f3275, %f3277;
	fma.rn.ftz.f32 	%f3280, %f3278, 0fBF000000, 0f3F800000;
	fma.rn.ftz.f32 	%f3282, %f3279, 0f3EE66666, 0f00000000;
	mov.f32 	%f3283, 0f00000000;
	ld.f32 	%f3284, [%rd45+112];
	ld.f32 	%f3285, [%rd45+116];
	mul.ftz.f32 	%f3286, %f1147, %f3285;
	fma.rn.ftz.f32 	%f3287, %f1148, %f3284, %f3286;
	ld.f32 	%f3288, [%rd45+120];
	fma.rn.ftz.f32 	%f3289, %f1146, %f3288, %f3287;
	min.ftz.f32 	%f3290, %f1229, %f3024;
	max.ftz.f32 	%f3291, %f3283, %f3290;
	min.ftz.f32 	%f3292, %f3289, %f3024;
	max.ftz.f32 	%f3293, %f3283, %f3292;
	mul.ftz.f32 	%f3294, %f3291, %f3291;
	mul.ftz.f32 	%f3295, %f3293, %f3293;
	sub.ftz.f32 	%f3296, %f3024, %f3294;
	sub.ftz.f32 	%f3297, %f3024, %f3295;
	mul.ftz.f32 	%f3298, %f3296, %f3297;
	sqrt.approx.ftz.f32 	%f3299, %f3298;
	mul.ftz.f32 	%f3300, %f1148, %f3291;
	mul.ftz.f32 	%f3301, %f1147, %f3291;
	mul.ftz.f32 	%f3302, %f1146, %f3291;
	sub.ftz.f32 	%f3303, %f4136, %f3300;
	sub.ftz.f32 	%f3304, %f4137, %f3301;
	sub.ftz.f32 	%f3305, %f4138, %f3302;
	mul.ftz.f32 	%f3306, %f3304, %f3304;
	fma.rn.ftz.f32 	%f3307, %f3303, %f3303, %f3306;
	fma.rn.ftz.f32 	%f3308, %f3305, %f3305, %f3307;
	rsqrt.approx.ftz.f32 	%f3309, %f3308;
	mul.ftz.f32 	%f3310, %f3303, %f3309;
	mul.ftz.f32 	%f3311, %f3304, %f3309;
	mul.ftz.f32 	%f3312, %f3305, %f3309;
	mul.ftz.f32 	%f3313, %f1148, %f3293;
	mul.ftz.f32 	%f3314, %f1147, %f3293;
	mul.ftz.f32 	%f3315, %f1146, %f3293;
	sub.ftz.f32 	%f3316, %f3284, %f3313;
	sub.ftz.f32 	%f3317, %f3285, %f3314;
	sub.ftz.f32 	%f3318, %f3288, %f3315;
	mul.ftz.f32 	%f3319, %f3317, %f3317;
	fma.rn.ftz.f32 	%f3320, %f3316, %f3316, %f3319;
	fma.rn.ftz.f32 	%f3321, %f3318, %f3318, %f3320;
	rsqrt.approx.ftz.f32 	%f3322, %f3321;
	mul.ftz.f32 	%f3323, %f3316, %f3322;
	mul.ftz.f32 	%f3324, %f3317, %f3322;
	mul.ftz.f32 	%f3325, %f3318, %f3322;
	mul.ftz.f32 	%f3326, %f3311, %f3324;
	fma.rn.ftz.f32 	%f3327, %f3310, %f3323, %f3326;
	fma.rn.ftz.f32 	%f3328, %f3312, %f3325, %f3327;
	min.ftz.f32 	%f3329, %f3328, %f3024;
	max.ftz.f32 	%f3330, %f3283, %f3329;
	mul.ftz.f32 	%f3331, %f3299, %f3330;
	max.ftz.f32 	%f3332, %f3291, %f3293;
	div.approx.ftz.f32 	%f3333, %f3331, %f3332;
	fma.rn.ftz.f32 	%f3334, %f3282, %f3333, %f3280;
	mul.ftz.f32 	%f3335, %f3291, %f3334;
	mul.ftz.f32 	%f4144, %f3335, 0f3EA2F983;

$L__BB0_197:
	mul.ftz.f32 	%f3338, %f1141, %f4137;
	fma.rn.ftz.f32 	%f3339, %f1142, %f4136, %f3338;
	fma.rn.ftz.f32 	%f3340, %f1140, %f4138, %f3339;
	setp.leu.ftz.f32 	%p104, %f3340, 0f00000000;
	setp.leu.ftz.f32 	%p105, %f4144, 0f00000000;
	or.pred  	%p106, %p104, %p105;
	@%p106 bra 	$L__BB0_243;

	setp.eq.ftz.f32 	%p107, %f1226, 0f00000000;
	setp.eq.ftz.f32 	%p108, %f1227, 0f00000000;
	and.pred  	%p109, %p107, %p108;
	setp.eq.ftz.f32 	%p110, %f1228, 0f00000000;
	and.pred  	%p111, %p109, %p110;
	@%p111 bra 	$L__BB0_243;

	ld.const.u64 	%rd49, [params+280];
	ld.v4.f32 	{%f3341, %f3342, %f3343, %f3344}, [%rd45+96];
	sub.ftz.f32 	%f1236, %f4139, %f1149;
	mov.u32 	%r1349, 1065353216;
	mov.u32 	%r1154, 4;
	mov.f32 	%f4145, %f1149;
	mov.u32 	%r1350, %r1349;
	mov.u32 	%r1351, %r1349;

$L__BB0_200:
	mov.f32 	%f4146, 0f00000000;
	// begin inline asm
	call(%r1349,%r1350,%r1351,%r1119,%r1120,%r1121,%r1122,%r1123,%r1124,%r1125,%r1126,%r1127,%r1128,%r1129,%r1130,%r1131,%r1132,%r1133,%r1134,%r1135,%r1136,%r1137,%r1138,%r1139,%r1140,%r1141,%r1142,%r1143,%r1144,%r1145,%r1146,%r1147),_optix_trace_typed_32,(%r1056,%rd49,%f3341,%f3342,%f3343,%f4136,%f4137,%f4138,%f4145,%f1236,%f4146,%r1058,%r1056,%r1058,%r1050,%r1058,%r1154,%r1349,%r1350,%r1351,%r1056,%r1187,%r1188,%r1189,%r1190,%r1191,%r1192,%r1193,%r1194,%r1195,%r1196,%r1197,%r1198,%r1199,%r1200,%r1201,%r1202,%r1203,%r1204,%r1205,%r1206,%r1207,%r1208,%r1209,%r1210,%r1211,%r1212,%r1213,%r1214);
	// end inline asm
	mov.b32 	%f1238, %r1349;
	mov.b32 	%f1239, %r1350;
	mov.b32 	%f1240, %r1351;
	mul.ftz.f32 	%f3357, %f1238, %f1239;
	mul.ftz.f32 	%f3358, %f3357, %f1240;
	setp.lt.ftz.f32 	%p112, %f3358, 0f358637BD;
	mov.f32 	%f4147, %f4146;
	mov.f32 	%f4148, %f4146;
	@%p112 bra 	$L__BB0_203;

	mov.b32 	%f3359, %r1119;
	add.ftz.f32 	%f3360, %f1149, %f3359;
	add.ftz.f32 	%f4145, %f4145, %f3360;
	setp.lt.ftz.f32 	%p113, %f4145, %f1236;
	setp.ne.s32 	%p114, %r1119, 0;
	and.pred  	%p115, %p114, %p113;
	@%p115 bra 	$L__BB0_200;

	mov.f32 	%f4146, %f1238;
	mov.f32 	%f4147, %f1239;
	mov.f32 	%f4148, %f1240;

$L__BB0_203:
	setp.eq.ftz.f32 	%p116, %f4146, 0f00000000;
	setp.eq.ftz.f32 	%p117, %f4147, 0f00000000;
	setp.eq.ftz.f32 	%p118, %f4148, 0f00000000;
	and.pred  	%p119, %p117, %p116;
	and.pred  	%p120, %p118, %p119;
	@%p120 bra 	$L__BB0_243;

	mul.ftz.f32 	%f3361, %f4143, %f4143;
	fma.rn.ftz.f32 	%f3362, %f4144, %f4144, %f3361;
	div.approx.ftz.f32 	%f3363, %f3361, %f3362;
	mul.ftz.f32 	%f3364, %f1229, %f3363;
	div.approx.ftz.f32 	%f3365, %f3364, %f4143;
	mul.ftz.f32 	%f3366, %f1226, %f4146;
	mul.ftz.f32 	%f3367, %f1227, %f4147;
	mul.ftz.f32 	%f3368, %f1228, %f4148;
	ld.f32 	%f3369, [%rd45];
	fma.rn.ftz.f32 	%f3370, %f3366, %f3365, %f3369;
	st.f32 	[%rd45], %f3370;
	ld.f32 	%f3371, [%rd45+4];
	fma.rn.ftz.f32 	%f3372, %f3367, %f3365, %f3371;
	st.f32 	[%rd45+4], %f3372;
	ld.f32 	%f3373, [%rd45+8];
	fma.rn.ftz.f32 	%f3374, %f3368, %f3365, %f3373;
	st.f32 	[%rd45+8], %f3374;
	bra.uni 	$L__BB0_243;

}

