//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31294372
// Cuda compilation tools, release 11.7, V11.7.64
// Based on NVVM 7.0.1
//

.version 7.7
.target sm_60
.address_size 64

	// .globl	__raygen__custom_proj_xyz2dir_camera
.const .align 8 .b8 params[288];

.visible .entry __raygen__custom_proj_xyz2dir_camera()
{
	.local .align 16 .b8 	__local_depot0[320];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<122>;
	.reg .f32 	%f<987>;
	.reg .b32 	%r<785>;
	.reg .b64 	%rd<91>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd2, %SPL, 64;
	add.u64 	%rd3, %SPL, 128;
	ld.const.v2.u32 	{%r182, %r183}, [params+64];
	// begin inline asm
	call (%r179), _optix_get_launch_index_x, ();
	// end inline asm
	ld.const.u64 	%rd20, [params+16];
	cvta.to.global.u64 	%rd21, %rd20;
	mul.wide.u32 	%rd22, %r179, 8;
	add.s64 	%rd23, %rd21, %rd22;
	ld.global.v2.u32 	{%r184, %r185}, [%rd23];
	setp.ge.s32 	%p1, %r184, %r182;
	setp.ge.s32 	%p2, %r185, %r183;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB0_110;

	mad.lo.s32 	%r186, %r185, %r182, %r184;
	ld.const.v2.u32 	{%r187, %r188}, [params+8];
	shl.b32 	%r191, %r187, 4;
	add.s32 	%r192, %r191, -1556008596;
	add.s32 	%r193, %r187, -1640531527;
	shr.u32 	%r194, %r187, 5;
	add.s32 	%r195, %r194, -939442524;
	xor.b32  	%r196, %r192, %r193;
	xor.b32  	%r197, %r196, %r195;
	add.s32 	%r198, %r186, %r197;
	shl.b32 	%r199, %r198, 4;
	add.s32 	%r200, %r199, -1383041155;
	add.s32 	%r201, %r198, -1640531527;
	xor.b32  	%r202, %r200, %r201;
	shr.u32 	%r203, %r198, 5;
	add.s32 	%r204, %r203, 2123724318;
	xor.b32  	%r205, %r202, %r204;
	add.s32 	%r206, %r205, %r187;
	shl.b32 	%r207, %r206, 4;
	add.s32 	%r208, %r207, -1556008596;
	add.s32 	%r209, %r206, 1013904242;
	shr.u32 	%r210, %r206, 5;
	add.s32 	%r211, %r210, -939442524;
	xor.b32  	%r212, %r208, %r209;
	xor.b32  	%r213, %r212, %r211;
	add.s32 	%r214, %r213, %r198;
	shl.b32 	%r215, %r214, 4;
	add.s32 	%r216, %r215, -1383041155;
	add.s32 	%r217, %r214, 1013904242;
	xor.b32  	%r218, %r216, %r217;
	shr.u32 	%r219, %r214, 5;
	add.s32 	%r220, %r219, 2123724318;
	xor.b32  	%r221, %r218, %r220;
	add.s32 	%r222, %r221, %r206;
	shl.b32 	%r223, %r222, 4;
	add.s32 	%r224, %r223, -1556008596;
	add.s32 	%r225, %r222, -626627285;
	shr.u32 	%r226, %r222, 5;
	add.s32 	%r227, %r226, -939442524;
	xor.b32  	%r228, %r224, %r225;
	xor.b32  	%r229, %r228, %r227;
	add.s32 	%r230, %r229, %r214;
	shl.b32 	%r231, %r230, 4;
	add.s32 	%r232, %r231, -1383041155;
	add.s32 	%r233, %r230, -626627285;
	xor.b32  	%r234, %r232, %r233;
	shr.u32 	%r235, %r230, 5;
	add.s32 	%r236, %r235, 2123724318;
	xor.b32  	%r237, %r234, %r236;
	add.s32 	%r238, %r237, %r222;
	shl.b32 	%r239, %r238, 4;
	add.s32 	%r240, %r239, -1556008596;
	add.s32 	%r241, %r238, 2027808484;
	shr.u32 	%r242, %r238, 5;
	add.s32 	%r243, %r242, -939442524;
	xor.b32  	%r244, %r240, %r241;
	xor.b32  	%r245, %r244, %r243;
	add.s32 	%r246, %r245, %r230;
	shl.b32 	%r247, %r246, 4;
	add.s32 	%r248, %r247, -1383041155;
	add.s32 	%r249, %r246, 2027808484;
	xor.b32  	%r250, %r248, %r249;
	shr.u32 	%r251, %r246, 5;
	add.s32 	%r252, %r251, 2123724318;
	xor.b32  	%r253, %r250, %r252;
	add.s32 	%r254, %r253, %r238;
	shl.b32 	%r255, %r254, 4;
	add.s32 	%r256, %r255, -1556008596;
	add.s32 	%r257, %r254, 387276957;
	shr.u32 	%r258, %r254, 5;
	add.s32 	%r259, %r258, -939442524;
	xor.b32  	%r260, %r256, %r257;
	xor.b32  	%r261, %r260, %r259;
	add.s32 	%r262, %r261, %r246;
	shl.b32 	%r263, %r262, 4;
	add.s32 	%r264, %r263, -1383041155;
	add.s32 	%r265, %r262, 387276957;
	xor.b32  	%r266, %r264, %r265;
	shr.u32 	%r267, %r262, 5;
	add.s32 	%r268, %r267, 2123724318;
	xor.b32  	%r269, %r266, %r268;
	add.s32 	%r270, %r269, %r254;
	shl.b32 	%r271, %r270, 4;
	add.s32 	%r272, %r271, -1556008596;
	add.s32 	%r273, %r270, -1253254570;
	shr.u32 	%r274, %r270, 5;
	add.s32 	%r275, %r274, -939442524;
	xor.b32  	%r276, %r272, %r273;
	xor.b32  	%r277, %r276, %r275;
	add.s32 	%r278, %r277, %r262;
	shl.b32 	%r279, %r278, 4;
	add.s32 	%r280, %r279, -1383041155;
	add.s32 	%r281, %r278, -1253254570;
	xor.b32  	%r282, %r280, %r281;
	shr.u32 	%r283, %r278, 5;
	add.s32 	%r284, %r283, 2123724318;
	xor.b32  	%r285, %r282, %r284;
	add.s32 	%r286, %r285, %r270;
	shl.b32 	%r287, %r286, 4;
	add.s32 	%r288, %r287, -1556008596;
	add.s32 	%r289, %r286, 1401181199;
	shr.u32 	%r290, %r286, 5;
	add.s32 	%r291, %r290, -939442524;
	xor.b32  	%r292, %r288, %r289;
	xor.b32  	%r293, %r292, %r291;
	add.s32 	%r294, %r293, %r278;
	shl.b32 	%r295, %r294, 4;
	add.s32 	%r296, %r295, -1383041155;
	add.s32 	%r297, %r294, 1401181199;
	xor.b32  	%r298, %r296, %r297;
	shr.u32 	%r299, %r294, 5;
	add.s32 	%r300, %r299, 2123724318;
	xor.b32  	%r301, %r298, %r300;
	add.s32 	%r302, %r301, %r286;
	shl.b32 	%r303, %r302, 4;
	add.s32 	%r304, %r303, -1556008596;
	add.s32 	%r305, %r302, -239350328;
	shr.u32 	%r306, %r302, 5;
	add.s32 	%r307, %r306, -939442524;
	xor.b32  	%r308, %r304, %r305;
	xor.b32  	%r309, %r308, %r307;
	add.s32 	%r310, %r309, %r294;
	shl.b32 	%r311, %r310, 4;
	add.s32 	%r312, %r311, -1383041155;
	add.s32 	%r313, %r310, -239350328;
	xor.b32  	%r314, %r312, %r313;
	shr.u32 	%r315, %r310, 5;
	add.s32 	%r316, %r315, 2123724318;
	xor.b32  	%r317, %r314, %r316;
	add.s32 	%r318, %r317, %r302;
	shl.b32 	%r319, %r318, 4;
	add.s32 	%r320, %r319, -1556008596;
	add.s32 	%r321, %r318, -1879881855;
	shr.u32 	%r322, %r318, 5;
	add.s32 	%r323, %r322, -939442524;
	xor.b32  	%r324, %r320, %r321;
	xor.b32  	%r325, %r324, %r323;
	add.s32 	%r326, %r325, %r310;
	shl.b32 	%r327, %r326, 4;
	add.s32 	%r328, %r327, -1383041155;
	add.s32 	%r329, %r326, -1879881855;
	xor.b32  	%r330, %r328, %r329;
	shr.u32 	%r331, %r326, 5;
	add.s32 	%r332, %r331, 2123724318;
	xor.b32  	%r333, %r330, %r332;
	add.s32 	%r334, %r333, %r318;
	shl.b32 	%r335, %r334, 4;
	add.s32 	%r336, %r335, -1556008596;
	add.s32 	%r337, %r334, 774553914;
	shr.u32 	%r338, %r334, 5;
	add.s32 	%r339, %r338, -939442524;
	xor.b32  	%r340, %r336, %r337;
	xor.b32  	%r341, %r340, %r339;
	add.s32 	%r342, %r341, %r326;
	shl.b32 	%r343, %r342, 4;
	add.s32 	%r344, %r343, -1383041155;
	add.s32 	%r345, %r342, 774553914;
	xor.b32  	%r346, %r344, %r345;
	shr.u32 	%r347, %r342, 5;
	add.s32 	%r348, %r347, 2123724318;
	xor.b32  	%r349, %r346, %r348;
	add.s32 	%r350, %r349, %r334;
	shl.b32 	%r351, %r350, 4;
	add.s32 	%r352, %r351, -1556008596;
	add.s32 	%r353, %r350, -865977613;
	shr.u32 	%r354, %r350, 5;
	add.s32 	%r355, %r354, -939442524;
	xor.b32  	%r356, %r352, %r353;
	xor.b32  	%r357, %r356, %r355;
	add.s32 	%r358, %r357, %r342;
	shl.b32 	%r359, %r358, 4;
	add.s32 	%r360, %r359, -1383041155;
	add.s32 	%r361, %r358, -865977613;
	xor.b32  	%r362, %r360, %r361;
	shr.u32 	%r363, %r358, 5;
	add.s32 	%r364, %r363, 2123724318;
	xor.b32  	%r365, %r362, %r364;
	add.s32 	%r366, %r365, %r350;
	shl.b32 	%r367, %r366, 4;
	add.s32 	%r368, %r367, -1556008596;
	add.s32 	%r369, %r366, 1788458156;
	shr.u32 	%r370, %r366, 5;
	add.s32 	%r371, %r370, -939442524;
	xor.b32  	%r372, %r368, %r369;
	xor.b32  	%r373, %r372, %r371;
	add.s32 	%r374, %r373, %r358;
	shl.b32 	%r375, %r374, 4;
	add.s32 	%r376, %r375, -1383041155;
	add.s32 	%r377, %r374, 1788458156;
	xor.b32  	%r378, %r376, %r377;
	shr.u32 	%r379, %r374, 5;
	add.s32 	%r380, %r379, 2123724318;
	xor.b32  	%r381, %r378, %r380;
	add.s32 	%r382, %r381, %r366;
	shl.b32 	%r383, %r382, 4;
	add.s32 	%r384, %r383, -1556008596;
	add.s32 	%r385, %r382, 147926629;
	shr.u32 	%r386, %r382, 5;
	add.s32 	%r387, %r386, -939442524;
	xor.b32  	%r388, %r384, %r385;
	xor.b32  	%r389, %r388, %r387;
	add.s32 	%r390, %r389, %r374;
	shl.b32 	%r391, %r390, 4;
	add.s32 	%r392, %r391, -1383041155;
	add.s32 	%r393, %r390, 147926629;
	xor.b32  	%r394, %r392, %r393;
	shr.u32 	%r395, %r390, 5;
	add.s32 	%r396, %r395, 2123724318;
	xor.b32  	%r397, %r394, %r396;
	add.s32 	%r398, %r397, %r382;
	shl.b32 	%r399, %r398, 4;
	add.s32 	%r400, %r399, -1556008596;
	add.s32 	%r401, %r398, -1492604898;
	shr.u32 	%r402, %r398, 5;
	add.s32 	%r403, %r402, -939442524;
	xor.b32  	%r404, %r400, %r401;
	xor.b32  	%r405, %r404, %r403;
	add.s32 	%r406, %r405, %r390;
	shl.b32 	%r407, %r406, 4;
	add.s32 	%r408, %r407, -1383041155;
	add.s32 	%r409, %r406, -1492604898;
	xor.b32  	%r410, %r408, %r409;
	shr.u32 	%r411, %r406, 5;
	add.s32 	%r412, %r411, 2123724318;
	xor.b32  	%r413, %r410, %r412;
	add.s32 	%r414, %r413, %r398;
	shl.b32 	%r415, %r414, 4;
	add.s32 	%r416, %r415, -1556008596;
	add.s32 	%r417, %r414, 1161830871;
	shr.u32 	%r418, %r414, 5;
	add.s32 	%r419, %r418, -939442524;
	xor.b32  	%r420, %r416, %r417;
	xor.b32  	%r421, %r420, %r419;
	add.s32 	%r422, %r421, %r406;
	shl.b32 	%r423, %r422, 4;
	add.s32 	%r424, %r423, -1383041155;
	add.s32 	%r425, %r422, 1161830871;
	xor.b32  	%r426, %r424, %r425;
	shr.u32 	%r427, %r422, 5;
	add.s32 	%r428, %r427, 2123724318;
	xor.b32  	%r429, %r426, %r428;
	add.s32 	%r430, %r429, %r414;
	shl.b32 	%r431, %r430, 4;
	add.s32 	%r432, %r431, -1556008596;
	add.s32 	%r433, %r430, -478700656;
	shr.u32 	%r434, %r430, 5;
	add.s32 	%r435, %r434, -939442524;
	xor.b32  	%r436, %r432, %r433;
	xor.b32  	%r437, %r436, %r435;
	add.s32 	%r5, %r437, %r422;
	add.u64 	%rd25, %SPL, 144;
	add.s64 	%rd5, %rd25, 28;
	st.local.u32 	[%rd25+28], %r5;
	setp.eq.s32 	%p4, %r188, 0;
	mov.f32 	%f868, 0f3F000000;
	mov.f32 	%f869, %f868;
	@%p4 bra 	$L__BB0_3;

	mad.lo.s32 	%r438, %r5, 1664525, 1013904223;
	and.b32  	%r439, %r438, 16777215;
	cvt.rn.f32.u32 	%f295, %r439;
	mov.f32 	%f296, 0f4B800000;
	div.approx.ftz.f32 	%f868, %f295, %f296;
	mad.lo.s32 	%r440, %r438, 1664525, 1013904223;
	st.local.u32 	[%rd5], %r440;
	and.b32  	%r441, %r440, 16777215;
	cvt.rn.f32.u32 	%f297, %r441;
	div.approx.ftz.f32 	%f869, %f297, %f296;

$L__BB0_3:
	cvt.rn.f32.s32 	%f298, %r184;
	add.ftz.f32 	%f299, %f868, %f298;
	cvt.rn.f32.s32 	%f300, %r185;
	add.ftz.f32 	%f301, %f869, %f300;
	cvt.rn.f32.s32 	%f302, %r182;
	div.approx.ftz.f32 	%f5, %f299, %f302;
	cvt.rn.f32.s32 	%f303, %r183;
	div.approx.ftz.f32 	%f304, %f301, %f303;
	ld.const.u64 	%rd26, [params+208];
	mov.f32 	%f305, 0f3F800000;
	sub.ftz.f32 	%f6, %f305, %f304;
	tex.2d.v4.f32.f32 	{%f7, %f8, %f9, %f10}, [%rd26, {%f5, %f6}];
	setp.lt.ftz.f32 	%p5, %f10, 0f00000000;
	@%p5 bra 	$L__BB0_108;
	bra.uni 	$L__BB0_4;

$L__BB0_108:
	ld.const.u32 	%r745, [params+4];
	setp.eq.s32 	%p121, %r745, 0;
	@%p121 bra 	$L__BB0_110;

	not.b32 	%r746, %r185;
	add.s32 	%r747, %r183, %r746;
	mad.lo.s32 	%r748, %r747, %r182, %r184;
	ld.const.u64 	%rd79, [params+48];
	cvta.to.global.u64 	%rd80, %rd79;
	mul.wide.u32 	%rd81, %r748, 16;
	add.s64 	%rd82, %rd80, %rd81;
	st.global.v4.f32 	[%rd82], {%f7, %f8, %f9, %f10};
	ld.const.u64 	%rd83, [params+56];
	cvta.to.global.u64 	%rd84, %rd83;
	mul.wide.u32 	%rd85, %r748, 8;
	add.s64 	%rd86, %rd84, %rd85;
	mov.u32 	%r749, -1;
	st.global.v2.u32 	[%rd86], {%r749, %r749};
	bra.uni 	$L__BB0_110;

$L__BB0_4:
	ld.const.u64 	%rd27, [params+216];
	tex.2d.v4.f32.f32 	{%f932, %f933, %f934, %f312}, [%rd27, {%f5, %f6}];
	setp.gtu.ftz.f32 	%p6, %f312, 0f00000000;
	selp.f32 	%f945, %f312, 0f5A0E1BCA, %p6;
	st.local.v2.f32 	[%rd5+68], {%f7, %f8};
	st.local.f32 	[%rd5+76], %f9;
	st.local.v2.f32 	[%rd5+20], {%f305, %f305};
	mov.u32 	%r445, 1065353216;
	st.local.u32 	[%rd5+28], %r445;
	mov.f32 	%f17, 0fBF800000;
	st.local.v4.f32 	[%rd5+100], {%f932, %f933, %f934, %f17};
	mov.u32 	%r750, 16777216;
	mov.u32 	%r758, 0;
	st.local.v4.u32 	[%rd5+-28], {%r758, %r758, %r758, %r750};
	st.local.v2.f32 	[%rd5+-12], {%f305, %f305};
	st.local.u32 	[%rd5+-4], %r445;
	mov.f32 	%f879, 0f00000000;
	st.local.v4.f32 	[%rd5+52], {%f305, %f305, %f305, %f879};
	st.local.u32 	[%rd5+48], %r758;
	st.local.v4.f32 	[%rd5+116], {%f879, %f879, %f879, %f305};
	st.local.v4.u32 	[%rd5+4], {%r758, %r758, %r445, %r758};
	st.local.u32 	[%rd5+96], %r445;
	ld.const.u32 	%r6, [params+252];
	setp.eq.s32 	%p7, %r6, 0;
	mov.u32 	%r777, -1;
	mov.f32 	%f878, %f879;
	mov.f32 	%f877, %f879;
	mov.f32 	%f946, %f879;
	mov.f32 	%f947, %f879;
	mov.f32 	%f948, %f879;
	mov.u32 	%r778, %r777;
	@%p7 bra 	$L__BB0_32;

	add.u64 	%rd88, %SP, 144;
	ld.const.u64 	%rd6, [params+280];
	ld.const.f32 	%f18, [params+76];
	shr.u64 	%rd29, %rd88, 32;
	cvt.u32.u64 	%r7, %rd29;
	cvt.u32.u64 	%r8, %rd88;
	ld.const.u32 	%r9, [params+248];
	ld.const.v2.f32 	{%f323, %f324}, [params+232];
	ld.const.f32 	%f21, [params+240];
	mov.f32 	%f870, %f932;
	mov.f32 	%f871, %f933;
	mov.f32 	%f872, %f934;
	mov.f32 	%f883, %f945;
	mov.u32 	%r757, %r777;
	mov.f32 	%f890, %f305;
	mov.f32 	%f889, %f305;
	mov.f32 	%f888, %f305;
	bra.uni 	$L__BB0_6;

$L__BB0_31:
	ld.local.v4.f32 	{%f870, %f871, %f872, %f455}, [%rd5+100];
	mov.f32 	%f883, 0f5A0E1BCA;

$L__BB0_6:
	neg.ftz.f32 	%f325, %f872;
	neg.ftz.f32 	%f326, %f870;
	neg.ftz.f32 	%f327, %f871;
	st.local.v2.f32 	[%rd5+84], {%f326, %f327};
	st.local.f32 	[%rd5+92], %f325;
	st.local.v2.f32 	[%rd5+132], {%f305, %f305};
	st.local.f32 	[%rd5+80], %f883;
	and.b32  	%r14, %r750, 822083586;
	st.local.u32 	[%rd5+-16], %r14;
	setp.lt.s32 	%p8, %r757, 0;
	@%p8 bra 	$L__BB0_11;

	or.b32  	%r451, %r14, 4096;
	st.local.u32 	[%rd5+-16], %r451;
	mul.wide.s32 	%rd30, %r757, 16;
	add.s64 	%rd7, %rd1, %rd30;
	ld.local.v4.f32 	{%f329, %f330, %f331, %f332}, [%rd7];
	add.s64 	%rd31, %rd2, %rd30;
	ld.local.v4.f32 	{%f337, %f338, %f339, %f340}, [%rd31];
	st.local.v4.f32 	[%rd5+52], {%f337, %f338, %f339, %f340};
	mul.wide.s32 	%rd32, %r757, 4;
	add.s64 	%rd33, %rd3, %rd32;
	ld.local.f32 	%f39, [%rd33];
	st.local.v4.f32 	[%rd5+36], {%f329, %f330, %f331, %f39};
	st.local.f32 	[%rd5+132], %f332;
	setp.eq.s32 	%p9, %r757, 0;
	@%p9 bra 	$L__BB0_9;

	ld.local.f32 	%f345, [%rd7+-4];
	st.local.f32 	[%rd5+136], %f345;

$L__BB0_9:
	setp.leu.ftz.f32 	%p10, %f39, 0f00000000;
	@%p10 bra 	$L__BB0_11;

	ld.local.u32 	%r452, [%rd5];
	mad.lo.s32 	%r453, %r452, 1664525, 1013904223;
	st.local.u32 	[%rd5], %r453;
	and.b32  	%r454, %r453, 16777215;
	cvt.rn.f32.u32 	%f346, %r454;
	mov.f32 	%f347, 0f4B800000;
	div.approx.ftz.f32 	%f348, %f346, %f347;
	lg2.approx.ftz.f32 	%f349, %f348;
	mul.ftz.f32 	%f350, %f349, 0fBF317218;
	mul.ftz.f32 	%f883, %f350, %f39;

$L__BB0_11:
	ld.local.v4.f32 	{%f360, %f361, %f362, %f363}, [%rd5+68];
	mov.u32 	%r525, 0;
	mov.u32 	%r488, 1;
	mov.u32 	%r491, 2;
	mov.f32 	%f359, 0f00000000;
	mov.u32 	%r493, 4;
	mov.u32 	%r497, -1;
	// begin inline asm
	call(%r455,%r456,%r457,%r458,%r459,%r460,%r461,%r462,%r463,%r464,%r465,%r466,%r467,%r468,%r469,%r470,%r471,%r472,%r473,%r474,%r475,%r476,%r477,%r478,%r479,%r480,%r481,%r482,%r483,%r484,%r485,%r486),_optix_trace_typed_32,(%r525,%rd6,%f360,%f361,%f362,%f870,%f871,%f872,%f18,%f883,%f359,%r488,%r525,%r525,%r491,%r525,%r493,%r7,%r8,%r497,%r497,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525,%r525);
	// end inline asm
	ld.local.u32 	%r526, [%rd5+16];
	add.s32 	%r758, %r526, 1;
	st.local.u32 	[%rd5+16], %r758;
	setp.ne.s32 	%p11, %r526, 0;
	@%p11 bra 	$L__BB0_13;

	ld.local.v4.f32 	{%f364, %f365, %f366, %f367}, [%rd5+68];
	add.ftz.f32 	%f948, %f948, %f364;
	add.ftz.f32 	%f947, %f947, %f365;
	add.ftz.f32 	%f946, %f946, %f366;
	mov.u32 	%r777, %r458;
	mov.u32 	%r778, %r457;

$L__BB0_13:
	ld.local.u32 	%r52, [%rd5+-16];
	and.b32  	%r750, %r52, -805306369;
	st.local.u32 	[%rd5+-16], %r750;
	and.b32  	%r527, %r52, 4096;
	setp.eq.s32 	%p12, %r527, 0;
	@%p12 bra 	$L__BB0_21;

	and.b32  	%r54, %r52, 512;
	setp.eq.s32 	%p13, %r54, 0;
	@%p13 bra 	$L__BB0_17;
	bra.uni 	$L__BB0_15;

$L__BB0_17:
	ld.local.f32 	%f883, [%rd5+80];
	bra.uni 	$L__BB0_18;

$L__BB0_15:
	st.local.f32 	[%rd5+80], %f883;
	ld.local.v4.f32 	{%f371, %f372, %f373, %f374}, [%rd5+100];
	ld.local.v4.f32 	{%f378, %f379, %f380, %f381}, [%rd5+68];
	fma.rn.ftz.f32 	%f385, %f883, %f372, %f379;
	fma.rn.ftz.f32 	%f386, %f883, %f371, %f378;
	st.local.v2.f32 	[%rd5+68], {%f386, %f385};
	fma.rn.ftz.f32 	%f387, %f883, %f373, %f380;
	st.local.f32 	[%rd5+76], %f387;
	setp.lt.u32 	%p14, %r758, %r6;
	@%p14 bra 	$L__BB0_18;

	ld.local.v4.f32 	{%f388, %f389, %f390, %f391}, [%rd5+-28];
	add.ftz.f32 	%f395, %f324, %f389;
	add.ftz.f32 	%f396, %f323, %f388;
	st.local.v2.f32 	[%rd5+-28], {%f396, %f395};
	add.ftz.f32 	%f397, %f21, %f390;
	st.local.f32 	[%rd5+-20], %f397;

$L__BB0_18:
	ld.local.v4.f32 	{%f398, %f399, %f400, %f401}, [%rd5+36];
	add.ftz.f32 	%f405, %f398, 0f38D1B717;
	add.ftz.f32 	%f406, %f399, 0f38D1B717;
	add.ftz.f32 	%f407, %f400, 0f38D1B717;
	neg.ftz.f32 	%f408, %f883;
	div.approx.ftz.f32 	%f409, %f408, %f405;
	div.approx.ftz.f32 	%f410, %f408, %f406;
	div.approx.ftz.f32 	%f411, %f408, %f407;
	mul.ftz.f32 	%f412, %f409, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f50, %f412;
	mul.ftz.f32 	%f413, %f410, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f51, %f413;
	mul.ftz.f32 	%f414, %f411, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f52, %f414;
	mul.ftz.f32 	%f888, %f888, %f50;
	mul.ftz.f32 	%f889, %f889, %f51;
	mul.ftz.f32 	%f890, %f890, %f52;
	and.b32  	%r528, %r52, 16777216;
	setp.eq.s32 	%p15, %r528, 0;
	@%p15 bra 	$L__BB0_21;

	ld.local.v4.f32 	{%f415, %f416, %f417, %f418}, [%rd5+-12];
	mul.ftz.f32 	%f422, %f51, %f416;
	mul.ftz.f32 	%f423, %f50, %f415;
	st.local.v2.f32 	[%rd5+-12], {%f423, %f422};
	mul.ftz.f32 	%f424, %f52, %f417;
	st.local.f32 	[%rd5+-4], %f424;
	@%p13 bra 	$L__BB0_21;

	and.b32  	%r750, %r52, -822083585;
	st.local.u32 	[%rd5+-16], %r750;

$L__BB0_21:
	ld.local.v4.f32 	{%f425, %f426, %f427, %f428}, [%rd5+-28];
	fma.rn.ftz.f32 	%f877, %f888, %f425, %f877;
	fma.rn.ftz.f32 	%f878, %f889, %f426, %f878;
	fma.rn.ftz.f32 	%f879, %f890, %f427, %f879;
	ld.local.f32 	%f432, [%rd5+32];
	setp.le.ftz.f32 	%p17, %f432, 0f00000000;
	setp.lt.s32 	%p18, %r750, 0;
	or.pred  	%p19, %p18, %p17;
	@%p19 bra 	$L__BB0_32;

	ld.local.v4.f32 	{%f433, %f434, %f435, %f436}, [%rd5+20];
	setp.eq.ftz.f32 	%p20, %f433, 0f00000000;
	setp.eq.ftz.f32 	%p21, %f434, 0f00000000;
	setp.eq.ftz.f32 	%p22, %f435, 0f00000000;
	and.pred  	%p23, %p20, %p21;
	and.pred  	%p24, %p22, %p23;
	@%p24 bra 	$L__BB0_32;

	mul.ftz.f32 	%f888, %f888, %f433;
	mul.ftz.f32 	%f889, %f889, %f434;
	mul.ftz.f32 	%f890, %f890, %f435;
	setp.ge.u32 	%p25, %r9, %r758;
	@%p25 bra 	$L__BB0_26;

	max.ftz.f32 	%f437, %f888, %f889;
	max.ftz.f32 	%f68, %f437, %f890;
	ld.local.u32 	%r529, [%rd5];
	mad.lo.s32 	%r530, %r529, 1664525, 1013904223;
	st.local.u32 	[%rd5], %r530;
	and.b32  	%r531, %r530, 16777215;
	cvt.rn.f32.u32 	%f438, %r531;
	mov.f32 	%f439, 0f4B800000;
	div.approx.ftz.f32 	%f440, %f438, %f439;
	setp.lt.ftz.f32 	%p26, %f68, %f440;
	@%p26 bra 	$L__BB0_32;

	rcp.approx.ftz.f32 	%f441, %f68;
	mul.ftz.f32 	%f888, %f888, %f441;
	mul.ftz.f32 	%f889, %f889, %f441;
	mul.ftz.f32 	%f890, %f890, %f441;

$L__BB0_26:
	and.b32  	%r532, %r750, 288;
	setp.ne.s32 	%p27, %r532, 256;
	@%p27 bra 	$L__BB0_30;

	and.b32  	%r533, %r750, 16;
	setp.eq.s32 	%p28, %r533, 0;
	@%p28 bra 	$L__BB0_29;
	bra.uni 	$L__BB0_28;

$L__BB0_29:
	add.s32 	%r543, %r757, -1;
	max.s32 	%r757, %r543, -1;
	bra.uni 	$L__BB0_30;

$L__BB0_28:
	add.s32 	%r534, %r757, 1;
	min.s32 	%r757, %r534, 3;
	mul.wide.s32 	%rd35, %r757, 16;
	add.s64 	%rd36, %rd1, %rd35;
	ld.local.v4.u32 	{%r535, %r536, %r537, %r538}, [%rd5+116];
	st.local.v4.u32 	[%rd36], {%r535, %r536, %r537, %r538};
	ld.local.v4.f32 	{%f442, %f443, %f444, %f445}, [%rd5+52];
	add.s64 	%rd37, %rd2, %rd35;
	st.local.v4.f32 	[%rd37], {%f442, %f443, %f444, %f445};
	ld.local.f32 	%f450, [%rd5+48];
	mul.wide.s32 	%rd38, %r757, 4;
	add.s64 	%rd39, %rd3, %rd38;
	st.local.f32 	[%rd39], %f450;

$L__BB0_30:
	setp.ge.u32 	%p29, %r758, %r6;
	@%p29 bra 	$L__BB0_32;
	bra.uni 	$L__BB0_31;

$L__BB0_32:
	ld.local.v4.f32 	{%f971, %f970, %f969, %f459}, [%rd5+-12];
	ld.local.v4.f32 	{%f974, %f973, %f972, %f463}, [%rd5+4];
	ld.local.f32 	%f930, [%rd5+96];
	setp.geu.ftz.f32 	%p30, %f930, 0f3F800000;
	setp.lt.s32 	%p31, %r758, 2;
	or.pred  	%p32, %p31, %p30;
	@%p32 bra 	$L__BB0_96;

	st.local.v2.f32 	[%rd5+68], {%f7, %f8};
	st.local.f32 	[%rd5+76], %f9;
	mov.f32 	%f467, 0f3F800000;
	st.local.v2.f32 	[%rd5+20], {%f467, %f467};
	st.local.u32 	[%rd5+28], %r445;
	st.local.v4.f32 	[%rd5+100], {%f932, %f933, %f934, %f17};
	mov.u32 	%r769, 16777216;
	mov.u32 	%r546, 0;
	st.local.v4.u32 	[%rd5+-28], {%r546, %r546, %r546, %r769};
	st.local.v2.f32 	[%rd5+-12], {%f467, %f467};
	st.local.u32 	[%rd5+-4], %r445;
	mov.f32 	%f906, 0f00000000;
	st.local.v4.f32 	[%rd5+52], {%f467, %f467, %f467, %f906};
	st.local.u32 	[%rd5+48], %r546;
	st.local.v4.f32 	[%rd5+116], {%f906, %f906, %f906, %f467};
	st.local.v4.u32 	[%rd5+4], {%r546, %r546, %r445, %r546};
	st.local.u32 	[%rd5+96], %r445;
	mov.f32 	%f905, %f906;
	mov.f32 	%f904, %f906;
	@%p7 bra 	$L__BB0_61;

	add.u64 	%rd89, %SP, 144;
	ld.const.u64 	%rd8, [params+280];
	ld.const.f32 	%f92, [params+76];
	shr.u64 	%rd41, %rd89, 32;
	cvt.u32.u64 	%r63, %rd41;
	cvt.u32.u64 	%r64, %rd89;
	ld.const.u32 	%r65, [params+248];
	ld.const.v2.f32 	{%f474, %f475}, [params+232];
	mov.u32 	%r768, -1;
	ld.const.f32 	%f95, [params+240];
	mov.f32 	%f900, %f932;
	mov.f32 	%f901, %f933;
	mov.f32 	%f902, %f934;
	mov.f32 	%f913, %f945;
	mov.f32 	%f920, %f467;
	mov.f32 	%f919, %f467;
	mov.f32 	%f918, %f467;
	bra.uni 	$L__BB0_35;

$L__BB0_60:
	ld.local.v4.f32 	{%f900, %f901, %f902, %f606}, [%rd5+100];
	mov.f32 	%f913, 0f5A0E1BCA;

$L__BB0_35:
	neg.ftz.f32 	%f476, %f902;
	neg.ftz.f32 	%f477, %f900;
	neg.ftz.f32 	%f478, %f901;
	st.local.v2.f32 	[%rd5+84], {%f477, %f478};
	st.local.f32 	[%rd5+92], %f476;
	st.local.v2.f32 	[%rd5+132], {%f467, %f467};
	st.local.f32 	[%rd5+80], %f913;
	and.b32  	%r70, %r769, 822083586;
	st.local.u32 	[%rd5+-16], %r70;
	setp.lt.s32 	%p34, %r768, 0;
	@%p34 bra 	$L__BB0_40;

	or.b32  	%r549, %r70, 4096;
	st.local.u32 	[%rd5+-16], %r549;
	mul.wide.s32 	%rd42, %r768, 16;
	add.s64 	%rd9, %rd1, %rd42;
	ld.local.v4.f32 	{%f480, %f481, %f482, %f483}, [%rd9];
	add.s64 	%rd43, %rd2, %rd42;
	ld.local.v4.f32 	{%f488, %f489, %f490, %f491}, [%rd43];
	st.local.v4.f32 	[%rd5+52], {%f488, %f489, %f490, %f491};
	mul.wide.s32 	%rd44, %r768, 4;
	add.s64 	%rd45, %rd3, %rd44;
	ld.local.f32 	%f113, [%rd45];
	st.local.v4.f32 	[%rd5+36], {%f480, %f481, %f482, %f113};
	st.local.f32 	[%rd5+132], %f483;
	setp.eq.s32 	%p35, %r768, 0;
	@%p35 bra 	$L__BB0_38;

	ld.local.f32 	%f496, [%rd9+-4];
	st.local.f32 	[%rd5+136], %f496;

$L__BB0_38:
	setp.leu.ftz.f32 	%p36, %f113, 0f00000000;
	@%p36 bra 	$L__BB0_40;

	ld.local.u32 	%r550, [%rd5];
	mad.lo.s32 	%r551, %r550, 1664525, 1013904223;
	st.local.u32 	[%rd5], %r551;
	and.b32  	%r552, %r551, 16777215;
	cvt.rn.f32.u32 	%f497, %r552;
	mov.f32 	%f498, 0f4B800000;
	div.approx.ftz.f32 	%f499, %f497, %f498;
	lg2.approx.ftz.f32 	%f500, %f499;
	mul.ftz.f32 	%f501, %f500, 0fBF317218;
	mul.ftz.f32 	%f913, %f501, %f113;

$L__BB0_40:
	ld.local.v4.f32 	{%f511, %f512, %f513, %f514}, [%rd5+68];
	mov.u32 	%r586, 1;
	mov.u32 	%r589, 2;
	mov.f32 	%f510, 0f00000000;
	mov.u32 	%r591, 4;
	mov.u32 	%r595, -1;
	// begin inline asm
	call(%r553,%r554,%r555,%r556,%r557,%r558,%r559,%r560,%r561,%r562,%r563,%r564,%r565,%r566,%r567,%r568,%r569,%r570,%r571,%r572,%r573,%r574,%r575,%r576,%r577,%r578,%r579,%r580,%r581,%r582,%r583,%r584),_optix_trace_typed_32,(%r546,%rd8,%f511,%f512,%f513,%f900,%f901,%f902,%f92,%f913,%f510,%r586,%r546,%r546,%r589,%r546,%r591,%r63,%r64,%r595,%r595,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546);
	// end inline asm
	ld.local.u32 	%r624, [%rd5+16];
	add.s32 	%r103, %r624, 1;
	st.local.u32 	[%rd5+16], %r103;
	setp.ne.s32 	%p37, %r624, 0;
	@%p37 bra 	$L__BB0_42;

	ld.local.v4.f32 	{%f515, %f516, %f517, %f518}, [%rd5+68];
	add.ftz.f32 	%f948, %f948, %f515;
	add.ftz.f32 	%f947, %f947, %f516;
	add.ftz.f32 	%f946, %f946, %f517;
	mov.u32 	%r777, %r556;
	mov.u32 	%r778, %r555;

$L__BB0_42:
	ld.local.u32 	%r108, [%rd5+-16];
	and.b32  	%r769, %r108, -805306369;
	st.local.u32 	[%rd5+-16], %r769;
	and.b32  	%r625, %r108, 4096;
	setp.eq.s32 	%p38, %r625, 0;
	@%p38 bra 	$L__BB0_50;

	and.b32  	%r110, %r108, 512;
	setp.eq.s32 	%p39, %r110, 0;
	@%p39 bra 	$L__BB0_46;
	bra.uni 	$L__BB0_44;

$L__BB0_46:
	ld.local.f32 	%f913, [%rd5+80];
	bra.uni 	$L__BB0_47;

$L__BB0_44:
	st.local.f32 	[%rd5+80], %f913;
	ld.local.v4.f32 	{%f522, %f523, %f524, %f525}, [%rd5+100];
	ld.local.v4.f32 	{%f529, %f530, %f531, %f532}, [%rd5+68];
	fma.rn.ftz.f32 	%f536, %f913, %f523, %f530;
	fma.rn.ftz.f32 	%f537, %f913, %f522, %f529;
	st.local.v2.f32 	[%rd5+68], {%f537, %f536};
	fma.rn.ftz.f32 	%f538, %f913, %f524, %f531;
	st.local.f32 	[%rd5+76], %f538;
	setp.lt.u32 	%p40, %r103, %r6;
	@%p40 bra 	$L__BB0_47;

	ld.local.v4.f32 	{%f539, %f540, %f541, %f542}, [%rd5+-28];
	add.ftz.f32 	%f546, %f475, %f540;
	add.ftz.f32 	%f547, %f474, %f539;
	st.local.v2.f32 	[%rd5+-28], {%f547, %f546};
	add.ftz.f32 	%f548, %f95, %f541;
	st.local.f32 	[%rd5+-20], %f548;

$L__BB0_47:
	ld.local.v4.f32 	{%f549, %f550, %f551, %f552}, [%rd5+36];
	add.ftz.f32 	%f556, %f549, 0f38D1B717;
	add.ftz.f32 	%f557, %f550, 0f38D1B717;
	add.ftz.f32 	%f558, %f551, 0f38D1B717;
	neg.ftz.f32 	%f559, %f913;
	div.approx.ftz.f32 	%f560, %f559, %f556;
	div.approx.ftz.f32 	%f561, %f559, %f557;
	div.approx.ftz.f32 	%f562, %f559, %f558;
	mul.ftz.f32 	%f563, %f560, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f124, %f563;
	mul.ftz.f32 	%f564, %f561, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f125, %f564;
	mul.ftz.f32 	%f565, %f562, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f126, %f565;
	mul.ftz.f32 	%f918, %f918, %f124;
	mul.ftz.f32 	%f919, %f919, %f125;
	mul.ftz.f32 	%f920, %f920, %f126;
	and.b32  	%r626, %r108, 16777216;
	setp.eq.s32 	%p41, %r626, 0;
	@%p41 bra 	$L__BB0_50;

	ld.local.v4.f32 	{%f566, %f567, %f568, %f569}, [%rd5+-12];
	mul.ftz.f32 	%f573, %f125, %f567;
	mul.ftz.f32 	%f574, %f124, %f566;
	st.local.v2.f32 	[%rd5+-12], {%f574, %f573};
	mul.ftz.f32 	%f575, %f126, %f568;
	st.local.f32 	[%rd5+-4], %f575;
	@%p39 bra 	$L__BB0_50;

	and.b32  	%r769, %r108, -822083585;
	st.local.u32 	[%rd5+-16], %r769;

$L__BB0_50:
	ld.local.v4.f32 	{%f576, %f577, %f578, %f579}, [%rd5+-28];
	fma.rn.ftz.f32 	%f904, %f918, %f576, %f904;
	fma.rn.ftz.f32 	%f905, %f919, %f577, %f905;
	fma.rn.ftz.f32 	%f906, %f920, %f578, %f906;
	ld.local.f32 	%f583, [%rd5+32];
	setp.le.ftz.f32 	%p43, %f583, 0f00000000;
	setp.lt.s32 	%p44, %r769, 0;
	or.pred  	%p45, %p44, %p43;
	@%p45 bra 	$L__BB0_61;

	ld.local.v4.f32 	{%f584, %f585, %f586, %f587}, [%rd5+20];
	setp.eq.ftz.f32 	%p46, %f584, 0f00000000;
	setp.eq.ftz.f32 	%p47, %f585, 0f00000000;
	setp.eq.ftz.f32 	%p48, %f586, 0f00000000;
	and.pred  	%p49, %p46, %p47;
	and.pred  	%p50, %p48, %p49;
	@%p50 bra 	$L__BB0_61;

	mul.ftz.f32 	%f918, %f918, %f584;
	mul.ftz.f32 	%f919, %f919, %f585;
	mul.ftz.f32 	%f920, %f920, %f586;
	setp.ge.u32 	%p51, %r65, %r103;
	@%p51 bra 	$L__BB0_55;

	max.ftz.f32 	%f588, %f918, %f919;
	max.ftz.f32 	%f142, %f588, %f920;
	ld.local.u32 	%r627, [%rd5];
	mad.lo.s32 	%r628, %r627, 1664525, 1013904223;
	st.local.u32 	[%rd5], %r628;
	and.b32  	%r629, %r628, 16777215;
	cvt.rn.f32.u32 	%f589, %r629;
	mov.f32 	%f590, 0f4B800000;
	div.approx.ftz.f32 	%f591, %f589, %f590;
	setp.lt.ftz.f32 	%p52, %f142, %f591;
	@%p52 bra 	$L__BB0_61;

	rcp.approx.ftz.f32 	%f592, %f142;
	mul.ftz.f32 	%f918, %f918, %f592;
	mul.ftz.f32 	%f919, %f919, %f592;
	mul.ftz.f32 	%f920, %f920, %f592;

$L__BB0_55:
	and.b32  	%r630, %r769, 288;
	setp.ne.s32 	%p53, %r630, 256;
	@%p53 bra 	$L__BB0_59;

	and.b32  	%r631, %r769, 16;
	setp.eq.s32 	%p54, %r631, 0;
	@%p54 bra 	$L__BB0_58;
	bra.uni 	$L__BB0_57;

$L__BB0_58:
	add.s32 	%r641, %r768, -1;
	max.s32 	%r768, %r641, -1;
	bra.uni 	$L__BB0_59;

$L__BB0_57:
	add.s32 	%r632, %r768, 1;
	min.s32 	%r768, %r632, 3;
	mul.wide.s32 	%rd47, %r768, 16;
	add.s64 	%rd48, %rd1, %rd47;
	ld.local.v4.u32 	{%r633, %r634, %r635, %r636}, [%rd5+116];
	st.local.v4.u32 	[%rd48], {%r633, %r634, %r635, %r636};
	ld.local.v4.f32 	{%f593, %f594, %f595, %f596}, [%rd5+52];
	add.s64 	%rd49, %rd2, %rd47;
	st.local.v4.f32 	[%rd49], {%f593, %f594, %f595, %f596};
	ld.local.f32 	%f601, [%rd5+48];
	mul.wide.s32 	%rd50, %r768, 4;
	add.s64 	%rd51, %rd3, %rd50;
	st.local.f32 	[%rd51], %f601;

$L__BB0_59:
	setp.ge.u32 	%p55, %r103, %r6;
	@%p55 bra 	$L__BB0_61;
	bra.uni 	$L__BB0_60;

$L__BB0_61:
	ld.local.v4.f32 	{%f607, %f608, %f609, %f610}, [%rd5+-12];
	ld.local.v4.f32 	{%f611, %f612, %f613, %f614}, [%rd5+4];
	ld.local.f32 	%f931, [%rd5+96];
	setp.gt.ftz.f32 	%p56, %f930, %f931;
	@%p56 bra 	$L__BB0_64;
	bra.uni 	$L__BB0_62;

$L__BB0_64:
	mov.u32 	%r769, 268435456;
	st.local.u32 	[%rd5+-16], %r769;
	mul.ftz.f32 	%f930, %f930, 0f3F000000;
	bra.uni 	$L__BB0_65;

$L__BB0_62:
	setp.geu.ftz.f32 	%p57, %f930, %f931;
	@%p57 bra 	$L__BB0_65;

	mov.u32 	%r769, 536870912;
	st.local.u32 	[%rd5+-16], %r769;
	mul.ftz.f32 	%f931, %f931, 0f3F000000;

$L__BB0_65:
	st.local.v2.f32 	[%rd5+68], {%f7, %f8};
	st.local.f32 	[%rd5+76], %f9;
	mov.f32 	%f618, 0f3F800000;
	st.local.v2.f32 	[%rd5+20], {%f618, %f618};
	st.local.u32 	[%rd5+28], %r445;
	st.local.v4.f32 	[%rd5+100], {%f932, %f933, %f934, %f17};
	and.b32  	%r645, %r769, 805306368;
	or.b32  	%r773, %r645, 16777216;
	st.local.v4.u32 	[%rd5+-28], {%r546, %r546, %r546, %r773};
	st.local.v2.f32 	[%rd5+-12], {%f618, %f618};
	st.local.u32 	[%rd5+-4], %r445;
	mov.f32 	%f938, 0f00000000;
	st.local.v4.f32 	[%rd5+52], {%f618, %f618, %f618, %f938};
	st.local.u32 	[%rd5+48], %r546;
	st.local.v4.f32 	[%rd5+116], {%f938, %f938, %f938, %f618};
	st.local.v4.u32 	[%rd5+4], {%r546, %r546, %r445, %r546};
	st.local.u32 	[%rd5+96], %r445;
	mov.f32 	%f937, %f938;
	mov.f32 	%f936, %f938;
	@%p7 bra 	$L__BB0_93;

	add.u64 	%rd90, %SP, 144;
	ld.const.u64 	%rd10, [params+280];
	ld.const.f32 	%f172, [params+76];
	shr.u64 	%rd53, %rd90, 32;
	cvt.u32.u64 	%r121, %rd53;
	cvt.u32.u64 	%r122, %rd90;
	ld.const.u32 	%r123, [params+248];
	ld.const.v2.f32 	{%f625, %f626}, [params+232];
	mov.u32 	%r780, -1;
	ld.const.f32 	%f175, [params+240];
	mov.f32 	%f952, %f618;
	mov.f32 	%f951, %f618;
	mov.f32 	%f950, %f618;
	bra.uni 	$L__BB0_67;

$L__BB0_92:
	ld.local.v4.f32 	{%f932, %f933, %f934, %f757}, [%rd5+100];
	mov.f32 	%f945, 0f5A0E1BCA;

$L__BB0_67:
	neg.ftz.f32 	%f627, %f934;
	neg.ftz.f32 	%f628, %f932;
	neg.ftz.f32 	%f629, %f933;
	st.local.v2.f32 	[%rd5+84], {%f628, %f629};
	st.local.f32 	[%rd5+92], %f627;
	st.local.v2.f32 	[%rd5+132], {%f618, %f618};
	st.local.f32 	[%rd5+80], %f945;
	and.b32  	%r128, %r773, 822083586;
	st.local.u32 	[%rd5+-16], %r128;
	setp.lt.s32 	%p59, %r780, 0;
	@%p59 bra 	$L__BB0_72;

	or.b32  	%r648, %r128, 4096;
	st.local.u32 	[%rd5+-16], %r648;
	mul.wide.s32 	%rd54, %r780, 16;
	add.s64 	%rd11, %rd1, %rd54;
	ld.local.v4.f32 	{%f631, %f632, %f633, %f634}, [%rd11];
	add.s64 	%rd55, %rd2, %rd54;
	ld.local.v4.f32 	{%f639, %f640, %f641, %f642}, [%rd55];
	st.local.v4.f32 	[%rd5+52], {%f639, %f640, %f641, %f642};
	mul.wide.s32 	%rd56, %r780, 4;
	add.s64 	%rd57, %rd3, %rd56;
	ld.local.f32 	%f193, [%rd57];
	st.local.v4.f32 	[%rd5+36], {%f631, %f632, %f633, %f193};
	st.local.f32 	[%rd5+132], %f634;
	setp.eq.s32 	%p60, %r780, 0;
	@%p60 bra 	$L__BB0_70;

	ld.local.f32 	%f647, [%rd11+-4];
	st.local.f32 	[%rd5+136], %f647;

$L__BB0_70:
	setp.leu.ftz.f32 	%p61, %f193, 0f00000000;
	@%p61 bra 	$L__BB0_72;

	ld.local.u32 	%r649, [%rd5];
	mad.lo.s32 	%r650, %r649, 1664525, 1013904223;
	st.local.u32 	[%rd5], %r650;
	and.b32  	%r651, %r650, 16777215;
	cvt.rn.f32.u32 	%f648, %r651;
	mov.f32 	%f649, 0f4B800000;
	div.approx.ftz.f32 	%f650, %f648, %f649;
	lg2.approx.ftz.f32 	%f651, %f650;
	mul.ftz.f32 	%f652, %f651, 0fBF317218;
	mul.ftz.f32 	%f945, %f652, %f193;

$L__BB0_72:
	ld.local.v4.f32 	{%f662, %f663, %f664, %f665}, [%rd5+68];
	mov.u32 	%r685, 1;
	mov.u32 	%r688, 2;
	mov.f32 	%f661, 0f00000000;
	mov.u32 	%r690, 4;
	mov.u32 	%r694, -1;
	// begin inline asm
	call(%r652,%r653,%r654,%r655,%r656,%r657,%r658,%r659,%r660,%r661,%r662,%r663,%r664,%r665,%r666,%r667,%r668,%r669,%r670,%r671,%r672,%r673,%r674,%r675,%r676,%r677,%r678,%r679,%r680,%r681,%r682,%r683),_optix_trace_typed_32,(%r546,%rd10,%f662,%f663,%f664,%f932,%f933,%f934,%f172,%f945,%f661,%r685,%r546,%r546,%r688,%r546,%r690,%r121,%r122,%r694,%r694,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546,%r546);
	// end inline asm
	ld.local.u32 	%r723, [%rd5+16];
	add.s32 	%r161, %r723, 1;
	st.local.u32 	[%rd5+16], %r161;
	setp.ne.s32 	%p62, %r723, 0;
	@%p62 bra 	$L__BB0_74;

	ld.local.v4.f32 	{%f666, %f667, %f668, %f669}, [%rd5+68];
	add.ftz.f32 	%f948, %f948, %f666;
	add.ftz.f32 	%f947, %f947, %f667;
	add.ftz.f32 	%f946, %f946, %f668;
	mov.u32 	%r777, %r655;
	mov.u32 	%r778, %r654;

$L__BB0_74:
	ld.local.u32 	%r166, [%rd5+-16];
	and.b32  	%r773, %r166, -805306369;
	st.local.u32 	[%rd5+-16], %r773;
	and.b32  	%r724, %r166, 4096;
	setp.eq.s32 	%p63, %r724, 0;
	@%p63 bra 	$L__BB0_82;

	and.b32  	%r168, %r166, 512;
	setp.eq.s32 	%p64, %r168, 0;
	@%p64 bra 	$L__BB0_78;
	bra.uni 	$L__BB0_76;

$L__BB0_78:
	ld.local.f32 	%f945, [%rd5+80];
	bra.uni 	$L__BB0_79;

$L__BB0_76:
	st.local.f32 	[%rd5+80], %f945;
	ld.local.v4.f32 	{%f673, %f674, %f675, %f676}, [%rd5+100];
	ld.local.v4.f32 	{%f680, %f681, %f682, %f683}, [%rd5+68];
	fma.rn.ftz.f32 	%f687, %f945, %f674, %f681;
	fma.rn.ftz.f32 	%f688, %f945, %f673, %f680;
	st.local.v2.f32 	[%rd5+68], {%f688, %f687};
	fma.rn.ftz.f32 	%f689, %f945, %f675, %f682;
	st.local.f32 	[%rd5+76], %f689;
	setp.lt.u32 	%p65, %r161, %r6;
	@%p65 bra 	$L__BB0_79;

	ld.local.v4.f32 	{%f690, %f691, %f692, %f693}, [%rd5+-28];
	add.ftz.f32 	%f697, %f626, %f691;
	add.ftz.f32 	%f698, %f625, %f690;
	st.local.v2.f32 	[%rd5+-28], {%f698, %f697};
	add.ftz.f32 	%f699, %f175, %f692;
	st.local.f32 	[%rd5+-20], %f699;

$L__BB0_79:
	ld.local.v4.f32 	{%f700, %f701, %f702, %f703}, [%rd5+36];
	add.ftz.f32 	%f707, %f700, 0f38D1B717;
	add.ftz.f32 	%f708, %f701, 0f38D1B717;
	add.ftz.f32 	%f709, %f702, 0f38D1B717;
	neg.ftz.f32 	%f710, %f945;
	div.approx.ftz.f32 	%f711, %f710, %f707;
	div.approx.ftz.f32 	%f712, %f710, %f708;
	div.approx.ftz.f32 	%f713, %f710, %f709;
	mul.ftz.f32 	%f714, %f711, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f204, %f714;
	mul.ftz.f32 	%f715, %f712, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f205, %f715;
	mul.ftz.f32 	%f716, %f713, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f206, %f716;
	mul.ftz.f32 	%f950, %f950, %f204;
	mul.ftz.f32 	%f951, %f951, %f205;
	mul.ftz.f32 	%f952, %f952, %f206;
	and.b32  	%r725, %r166, 16777216;
	setp.eq.s32 	%p66, %r725, 0;
	@%p66 bra 	$L__BB0_82;

	ld.local.v4.f32 	{%f717, %f718, %f719, %f720}, [%rd5+-12];
	mul.ftz.f32 	%f724, %f205, %f718;
	mul.ftz.f32 	%f725, %f204, %f717;
	st.local.v2.f32 	[%rd5+-12], {%f725, %f724};
	mul.ftz.f32 	%f726, %f206, %f719;
	st.local.f32 	[%rd5+-4], %f726;
	@%p64 bra 	$L__BB0_82;

	and.b32  	%r773, %r166, -822083585;
	st.local.u32 	[%rd5+-16], %r773;

$L__BB0_82:
	ld.local.v4.f32 	{%f727, %f728, %f729, %f730}, [%rd5+-28];
	fma.rn.ftz.f32 	%f936, %f950, %f727, %f936;
	fma.rn.ftz.f32 	%f937, %f951, %f728, %f937;
	fma.rn.ftz.f32 	%f938, %f952, %f729, %f938;
	ld.local.f32 	%f734, [%rd5+32];
	setp.le.ftz.f32 	%p68, %f734, 0f00000000;
	setp.lt.s32 	%p69, %r773, 0;
	or.pred  	%p70, %p69, %p68;
	@%p70 bra 	$L__BB0_93;

	ld.local.v4.f32 	{%f735, %f736, %f737, %f738}, [%rd5+20];
	setp.eq.ftz.f32 	%p71, %f735, 0f00000000;
	setp.eq.ftz.f32 	%p72, %f736, 0f00000000;
	setp.eq.ftz.f32 	%p73, %f737, 0f00000000;
	and.pred  	%p74, %p71, %p72;
	and.pred  	%p75, %p73, %p74;
	@%p75 bra 	$L__BB0_93;

	mul.ftz.f32 	%f950, %f950, %f735;
	mul.ftz.f32 	%f951, %f951, %f736;
	mul.ftz.f32 	%f952, %f952, %f737;
	setp.ge.u32 	%p76, %r123, %r161;
	@%p76 bra 	$L__BB0_87;

	max.ftz.f32 	%f739, %f950, %f951;
	max.ftz.f32 	%f222, %f739, %f952;
	ld.local.u32 	%r726, [%rd5];
	mad.lo.s32 	%r727, %r726, 1664525, 1013904223;
	st.local.u32 	[%rd5], %r727;
	and.b32  	%r728, %r727, 16777215;
	cvt.rn.f32.u32 	%f740, %r728;
	mov.f32 	%f741, 0f4B800000;
	div.approx.ftz.f32 	%f742, %f740, %f741;
	setp.lt.ftz.f32 	%p77, %f222, %f742;
	@%p77 bra 	$L__BB0_93;

	rcp.approx.ftz.f32 	%f743, %f222;
	mul.ftz.f32 	%f950, %f950, %f743;
	mul.ftz.f32 	%f951, %f951, %f743;
	mul.ftz.f32 	%f952, %f952, %f743;

$L__BB0_87:
	and.b32  	%r729, %r773, 288;
	setp.ne.s32 	%p78, %r729, 256;
	@%p78 bra 	$L__BB0_91;

	and.b32  	%r730, %r773, 16;
	setp.eq.s32 	%p79, %r730, 0;
	@%p79 bra 	$L__BB0_90;
	bra.uni 	$L__BB0_89;

$L__BB0_90:
	add.s32 	%r740, %r780, -1;
	max.s32 	%r780, %r740, -1;
	bra.uni 	$L__BB0_91;

$L__BB0_89:
	add.s32 	%r731, %r780, 1;
	min.s32 	%r780, %r731, 3;
	mul.wide.s32 	%rd59, %r780, 16;
	add.s64 	%rd60, %rd1, %rd59;
	ld.local.v4.u32 	{%r732, %r733, %r734, %r735}, [%rd5+116];
	st.local.v4.u32 	[%rd60], {%r732, %r733, %r734, %r735};
	ld.local.v4.f32 	{%f744, %f745, %f746, %f747}, [%rd5+52];
	add.s64 	%rd61, %rd2, %rd59;
	st.local.v4.f32 	[%rd61], {%f744, %f745, %f746, %f747};
	ld.local.f32 	%f752, [%rd5+48];
	mul.wide.s32 	%rd62, %r780, 4;
	add.s64 	%rd63, %rd3, %rd62;
	st.local.f32 	[%rd63], %f752;

$L__BB0_91:
	setp.ge.u32 	%p80, %r161, %r6;
	@%p80 bra 	$L__BB0_93;
	bra.uni 	$L__BB0_92;

$L__BB0_93:
	ld.local.f32 	%f962, [%rd5+96];
	setp.eq.ftz.f32 	%p81, %f930, %f931;
	@%p81 bra 	$L__BB0_95;

	mul.ftz.f32 	%f962, %f962, 0f3F000000;
	st.local.f32 	[%rd5+96], %f962;

$L__BB0_95:
	add.ftz.f32 	%f758, %f930, %f931;
	add.ftz.f32 	%f759, %f758, %f962;
	rcp.approx.ftz.f32 	%f760, %f759;
	mul.ftz.f32 	%f761, %f904, %f931;
	fma.rn.ftz.f32 	%f762, %f877, %f930, %f761;
	mul.ftz.f32 	%f763, %f905, %f931;
	fma.rn.ftz.f32 	%f764, %f878, %f930, %f763;
	mul.ftz.f32 	%f765, %f906, %f931;
	fma.rn.ftz.f32 	%f766, %f879, %f930, %f765;
	fma.rn.ftz.f32 	%f767, %f936, %f962, %f762;
	fma.rn.ftz.f32 	%f768, %f937, %f962, %f764;
	fma.rn.ftz.f32 	%f769, %f938, %f962, %f766;
	mul.ftz.f32 	%f877, %f760, %f767;
	mul.ftz.f32 	%f878, %f760, %f768;
	mul.ftz.f32 	%f879, %f760, %f769;
	mul.ftz.f32 	%f770, %f607, %f931;
	fma.rn.ftz.f32 	%f771, %f971, %f930, %f770;
	mul.ftz.f32 	%f772, %f608, %f931;
	fma.rn.ftz.f32 	%f773, %f970, %f930, %f772;
	mul.ftz.f32 	%f774, %f609, %f931;
	fma.rn.ftz.f32 	%f775, %f969, %f930, %f774;
	ld.local.v4.f32 	{%f776, %f777, %f778, %f779}, [%rd5+-12];
	fma.rn.ftz.f32 	%f783, %f962, %f776, %f771;
	fma.rn.ftz.f32 	%f784, %f962, %f777, %f773;
	fma.rn.ftz.f32 	%f785, %f962, %f778, %f775;
	mul.ftz.f32 	%f971, %f760, %f783;
	mul.ftz.f32 	%f970, %f760, %f784;
	mul.ftz.f32 	%f969, %f760, %f785;
	mul.ftz.f32 	%f786, %f611, %f931;
	fma.rn.ftz.f32 	%f787, %f974, %f930, %f786;
	mul.ftz.f32 	%f788, %f612, %f931;
	fma.rn.ftz.f32 	%f789, %f973, %f930, %f788;
	mul.ftz.f32 	%f790, %f613, %f931;
	fma.rn.ftz.f32 	%f791, %f972, %f930, %f790;
	ld.local.v4.f32 	{%f792, %f793, %f794, %f795}, [%rd5+4];
	fma.rn.ftz.f32 	%f799, %f962, %f792, %f787;
	fma.rn.ftz.f32 	%f800, %f962, %f793, %f789;
	fma.rn.ftz.f32 	%f801, %f962, %f794, %f791;
	mul.ftz.f32 	%f974, %f760, %f799;
	mul.ftz.f32 	%f973, %f760, %f800;
	mul.ftz.f32 	%f972, %f760, %f801;
	mul.ftz.f32 	%f948, %f948, 0f3EAAAAAB;
	mul.ftz.f32 	%f947, %f947, 0f3EAAAAAB;
	mul.ftz.f32 	%f946, %f946, 0f3EAAAAAB;

$L__BB0_96:
	cvt.u64.u32 	%rd87, %r179;
	mul.ftz.f32 	%f806, %f974, %f974;
	fma.rn.ftz.f32 	%f807, %f973, %f973, %f806;
	fma.rn.ftz.f32 	%f808, %f972, %f972, %f807;
	rsqrt.approx.ftz.f32 	%f809, %f808;
	mul.ftz.f32 	%f266, %f974, %f809;
	mul.ftz.f32 	%f267, %f973, %f809;
	mul.ftz.f32 	%f268, %f972, %f809;
	ld.const.u32 	%r178, [params];
	setp.eq.s32 	%p82, %r178, 0;
	ld.const.u64 	%rd64, [params+24];
	cvta.to.global.u64 	%rd65, %rd64;
	shl.b64 	%rd66, %rd87, 4;
	add.s64 	%rd12, %rd65, %rd66;
	mov.f32 	%f975, 0f00000000;
	mov.f32 	%f976, %f975;
	mov.f32 	%f977, %f975;
	mov.f32 	%f978, %f975;
	@%p82 bra 	$L__BB0_98;

	ld.global.v4.f32 	{%f975, %f976, %f977, %f978}, [%rd12];

$L__BB0_98:
	abs.ftz.f32 	%f814, %f877;
	abs.ftz.f32 	%f815, %f878;
	abs.ftz.f32 	%f816, %f879;
	setp.eq.ftz.f32 	%p83, %f816, 0f7F800000;
	setp.eq.ftz.f32 	%p84, %f815, 0f7F800000;
	setp.eq.ftz.f32 	%p85, %f814, 0f7F800000;
	setp.gtu.ftz.f32 	%p86, %f816, 0f7F800000;
	setp.gtu.ftz.f32 	%p87, %f815, 0f7F800000;
	setp.gtu.ftz.f32 	%p88, %f814, 0f7F800000;
	or.pred  	%p89, %p88, %p87;
	or.pred  	%p90, %p89, %p86;
	or.pred  	%p91, %p90, %p85;
	or.pred  	%p92, %p91, %p84;
	or.pred  	%p93, %p92, %p83;
	selp.f32 	%f817, 0f00000000, %f877, %p93;
	selp.f32 	%f818, 0f00000000, %f878, %p93;
	selp.f32 	%f819, 0f00000000, %f879, %p93;
	selp.f32 	%f820, 0f00000000, 0f3F800000, %p93;
	add.ftz.f32 	%f821, %f820, %f978;
	add.ftz.f32 	%f822, %f819, %f977;
	add.ftz.f32 	%f823, %f818, %f976;
	add.ftz.f32 	%f824, %f817, %f975;
	st.global.v4.f32 	[%rd12], {%f824, %f823, %f822, %f821};
	ld.const.u64 	%rd13, [params+32];
	setp.eq.s64 	%p94, %rd13, 0;
	@%p94 bra 	$L__BB0_102;

	cvta.to.global.u64 	%rd67, %rd13;
	add.s64 	%rd14, %rd67, %rd66;
	mov.f32 	%f979, 0f00000000;
	mov.f32 	%f980, %f979;
	mov.f32 	%f981, %f979;
	mov.f32 	%f982, %f979;
	@%p82 bra 	$L__BB0_101;

	ld.global.v4.f32 	{%f979, %f980, %f981, %f832}, [%rd14];
	add.ftz.f32 	%f982, %f832, 0f00000000;

$L__BB0_101:
	abs.ftz.f32 	%f834, %f971;
	abs.ftz.f32 	%f835, %f970;
	abs.ftz.f32 	%f836, %f969;
	setp.eq.ftz.f32 	%p96, %f836, 0f7F800000;
	setp.eq.ftz.f32 	%p97, %f835, 0f7F800000;
	setp.eq.ftz.f32 	%p98, %f834, 0f7F800000;
	setp.gtu.ftz.f32 	%p99, %f836, 0f7F800000;
	setp.gtu.ftz.f32 	%p100, %f835, 0f7F800000;
	setp.gtu.ftz.f32 	%p101, %f834, 0f7F800000;
	or.pred  	%p102, %p101, %p100;
	or.pred  	%p103, %p102, %p99;
	or.pred  	%p104, %p103, %p98;
	or.pred  	%p105, %p104, %p97;
	or.pred  	%p106, %p105, %p96;
	selp.f32 	%f837, 0f00000000, %f971, %p106;
	selp.f32 	%f838, 0f00000000, %f970, %p106;
	selp.f32 	%f839, 0f00000000, %f969, %p106;
	add.ftz.f32 	%f840, %f839, %f981;
	add.ftz.f32 	%f841, %f838, %f980;
	add.ftz.f32 	%f842, %f837, %f979;
	st.global.v4.f32 	[%rd14], {%f842, %f841, %f840, %f982};

$L__BB0_102:
	ld.const.u64 	%rd15, [params+40];
	setp.eq.s64 	%p107, %rd15, 0;
	@%p107 bra 	$L__BB0_106;

	cvta.to.global.u64 	%rd69, %rd15;
	add.s64 	%rd16, %rd69, %rd66;
	mov.f32 	%f983, 0f00000000;
	mov.f32 	%f984, %f983;
	mov.f32 	%f985, %f983;
	mov.f32 	%f986, %f983;
	@%p82 bra 	$L__BB0_105;

	ld.global.v4.f32 	{%f983, %f984, %f985, %f850}, [%rd16];
	add.ftz.f32 	%f986, %f850, 0f00000000;

$L__BB0_105:
	abs.ftz.f32 	%f852, %f266;
	abs.ftz.f32 	%f853, %f267;
	abs.ftz.f32 	%f854, %f268;
	setp.eq.ftz.f32 	%p109, %f854, 0f7F800000;
	setp.eq.ftz.f32 	%p110, %f853, 0f7F800000;
	setp.eq.ftz.f32 	%p111, %f852, 0f7F800000;
	setp.gtu.ftz.f32 	%p112, %f854, 0f7F800000;
	setp.gtu.ftz.f32 	%p113, %f853, 0f7F800000;
	setp.gtu.ftz.f32 	%p114, %f852, 0f7F800000;
	or.pred  	%p115, %p114, %p113;
	or.pred  	%p116, %p115, %p112;
	or.pred  	%p117, %p116, %p111;
	or.pred  	%p118, %p117, %p110;
	or.pred  	%p119, %p118, %p109;
	selp.f32 	%f855, 0f00000000, %f266, %p119;
	selp.f32 	%f856, 0f00000000, %f267, %p119;
	selp.f32 	%f857, 0f00000000, %f268, %p119;
	add.ftz.f32 	%f858, %f857, %f985;
	add.ftz.f32 	%f859, %f856, %f984;
	add.ftz.f32 	%f860, %f855, %f983;
	st.global.v4.f32 	[%rd16], {%f860, %f859, %f858, %f986};

$L__BB0_106:
	ld.const.u32 	%r741, [params+4];
	setp.eq.s32 	%p120, %r741, 0;
	@%p120 bra 	$L__BB0_110;

	not.b32 	%r742, %r185;
	add.s32 	%r743, %r183, %r742;
	mad.lo.s32 	%r744, %r743, %r182, %r184;
	ld.const.u64 	%rd71, [params+48];
	cvta.to.global.u64 	%rd72, %rd71;
	sub.ftz.f32 	%f861, %f948, %f7;
	mul.ftz.f32 	%f862, %f861, %f861;
	sub.ftz.f32 	%f863, %f947, %f8;
	fma.rn.ftz.f32 	%f864, %f863, %f863, %f862;
	sub.ftz.f32 	%f865, %f946, %f9;
	fma.rn.ftz.f32 	%f866, %f865, %f865, %f864;
	mul.wide.u32 	%rd73, %r744, 16;
	add.s64 	%rd74, %rd72, %rd73;
	sqrt.approx.ftz.f32 	%f867, %f866;
	st.global.v4.f32 	[%rd74], {%f948, %f947, %f946, %f867};
	ld.const.u64 	%rd75, [params+56];
	cvta.to.global.u64 	%rd76, %rd75;
	mul.wide.u32 	%rd77, %r744, 8;
	add.s64 	%rd78, %rd76, %rd77;
	st.global.v2.u32 	[%rd78], {%r778, %r777};

$L__BB0_110:
	ret;

}

