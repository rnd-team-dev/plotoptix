//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30033411
// Cuda compilation tools, release 11.4, V11.4.48
// Based on NVVM 7.0.1
//

.version 7.4
.target sm_50
.address_size 64

	// .globl	__miss__radiance_texturecart
.const .align 8 .b8 params[288];

.visible .entry __miss__radiance_texturecart()
{
	.reg .pred 	%p<8>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<87>;
	.reg .b32 	%r<27>;
	.reg .b64 	%rd<9>;


	mov.u32 	%r4, 0;
	// begin inline asm
	call (%r3), _optix_get_payload, (%r4);
	// end inline asm
	mov.u32 	%r6, 1;
	// begin inline asm
	call (%r5), _optix_get_payload, (%r6);
	// end inline asm
	cvt.u64.u32 	%rd2, %r3;
	cvt.u64.u32 	%rd3, %r5;
	bfi.b64 	%rd1, %rd2, %rd3, 32, 32;
	ld.u32 	%r1, [%rd1+12];
	and.b32  	%r7, %r1, 4096;
	setp.eq.s32 	%p1, %r7, 0;
	@%p1 bra 	$L__BB0_4;
	bra.uni 	$L__BB0_1;

$L__BB0_4:
	ld.f32 	%f45, [%rd1+128];
	ld.f32 	%f46, [%rd1+132];
	ld.f32 	%f47, [%rd1+136];
	ld.f32 	%f48, [%rd1+96];
	fma.rn.ftz.f32 	%f49, %f45, 0f5A0E1BCA, %f48;
	st.f32 	[%rd1+96], %f49;
	ld.f32 	%f50, [%rd1+100];
	fma.rn.ftz.f32 	%f51, %f46, 0f5A0E1BCA, %f50;
	st.f32 	[%rd1+100], %f51;
	ld.f32 	%f52, [%rd1+104];
	fma.rn.ftz.f32 	%f53, %f47, 0f5A0E1BCA, %f52;
	st.f32 	[%rd1+104], %f53;
	or.b32  	%r14, %r1, -2147483648;
	st.u32 	[%rd1+12], %r14;
	ld.u32 	%r15, [%rd1+44];
	setp.eq.s32 	%p3, %r15, 0;
	@%p3 bra 	$L__BB0_6;

	ld.f32 	%f54, [%rd1];
	ld.const.f32 	%f55, [params+232];
	add.ftz.f32 	%f56, %f55, %f54;
	st.f32 	[%rd1], %f56;
	ld.f32 	%f57, [%rd1+4];
	ld.const.f32 	%f58, [params+236];
	add.ftz.f32 	%f86, %f58, %f57;
	st.f32 	[%rd1+4], %f86;
	ld.f32 	%f59, [%rd1+8];
	ld.const.f32 	%f60, [params+240];
	add.ftz.f32 	%f85, %f60, %f59;
	st.f32 	[%rd1+8], %f85;
	bra.uni 	$L__BB0_7;

$L__BB0_1:
	ld.u32 	%r8, [%rd1+28];
	mad.lo.s32 	%r9, %r8, 1664525, 1013904223;
	and.b32  	%r10, %r9, 16777215;
	cvt.rn.f32.u32 	%f13, %r10;
	mov.f32 	%f14, 0f4B800000;
	div.approx.ftz.f32 	%f15, %f13, %f14;
	mad.lo.s32 	%r2, %r9, 1664525, 1013904223;
	st.u32 	[%rd1+28], %r2;
	add.ftz.f32 	%f16, %f15, %f15;
	mov.f32 	%f17, 0f3F800000;
	sub.ftz.f32 	%f18, %f17, %f16;
	st.f32 	[%rd1+136], %f18;
	mul.ftz.f32 	%f19, %f18, %f18;
	sub.ftz.f32 	%f1, %f17, %f19;
	setp.leu.ftz.f32 	%p2, %f1, 0f00000000;
	mov.f32 	%f84, 0f00000000;
	@%p2 bra 	$L__BB0_3;

	sqrt.approx.ftz.f32 	%f84, %f1;

$L__BB0_3:
	and.b32  	%r11, %r2, 16777215;
	cvt.rn.f32.u32 	%f20, %r11;
	div.approx.ftz.f32 	%f22, %f20, %f14;
	add.ftz.f32 	%f23, %f22, %f22;
	mul.ftz.f32 	%f24, %f23, 0f40490FDB;
	cos.approx.ftz.f32 	%f25, %f24;
	mul.ftz.f32 	%f26, %f84, %f25;
	st.f32 	[%rd1+128], %f26;
	sin.approx.ftz.f32 	%f27, %f24;
	mul.ftz.f32 	%f28, %f84, %f27;
	st.f32 	[%rd1+132], %f28;
	ld.f32 	%f29, [%rd1+80];
	ld.f32 	%f30, [%rd1+92];
	ld.f32 	%f31, [%rd1+84];
	ld.f32 	%f32, [%rd1+88];
	ld.f32 	%f33, [%rd1];
	fma.rn.ftz.f32 	%f34, %f30, %f29, %f33;
	st.f32 	[%rd1], %f34;
	ld.f32 	%f35, [%rd1+4];
	fma.rn.ftz.f32 	%f86, %f30, %f31, %f35;
	st.f32 	[%rd1+4], %f86;
	ld.f32 	%f36, [%rd1+8];
	fma.rn.ftz.f32 	%f85, %f30, %f32, %f36;
	st.f32 	[%rd1+8], %f85;
	ld.u32 	%r12, [%rd1+12];
	or.b32  	%r13, %r12, 514;
	st.u32 	[%rd1+12], %r13;
	ld.v4.f32 	{%f37, %f38, %f39, %f40}, [%rd1+80];
	st.v4.f32 	[%rd1+48], {%f37, %f38, %f39, %f17};
	bra.uni 	$L__BB0_7;

$L__BB0_6:
	// begin inline asm
	call (%r16), _optix_get_launch_index_x, ();
	// end inline asm
	ld.const.u64 	%rd4, [params+16];
	cvta.to.global.u64 	%rd5, %rd4;
	mul.wide.u32 	%rd6, %r16, 8;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.v2.u32 	{%r19, %r20}, [%rd7];
	cvt.rn.f32.s32 	%f61, %r19;
	cvt.rn.f32.s32 	%f62, %r20;
	add.ftz.f32 	%f63, %f61, 0f3F000000;
	add.ftz.f32 	%f64, %f62, 0f3F000000;
	ld.const.v2.u32 	{%r23, %r24}, [params+64];
	cvt.rn.f32.u32 	%f65, %r23;
	cvt.rn.f32.u32 	%f66, %r24;
	div.approx.ftz.f32 	%f67, %f63, %f65;
	div.approx.ftz.f32 	%f68, %f64, %f66;
	ld.const.u64 	%rd8, [params+224];
	tex.2d.v4.f32.f32 	{%f69, %f70, %f71, %f72}, [%rd8, {%f67, %f68}];
	ld.f32 	%f73, [%rd1];
	add.ftz.f32 	%f74, %f73, %f69;
	st.f32 	[%rd1], %f74;
	ld.f32 	%f75, [%rd1+4];
	add.ftz.f32 	%f86, %f75, %f70;
	st.f32 	[%rd1+4], %f86;
	ld.f32 	%f76, [%rd1+8];
	add.ftz.f32 	%f85, %f76, %f71;
	st.f32 	[%rd1+8], %f85;

$L__BB0_7:
	ld.u8 	%rs1, [%rd1+15];
	and.b16  	%rs2, %rs1, 1;
	setp.eq.b16 	%p4, %rs2, 1;
	mov.pred 	%p5, 0;
	xor.pred  	%p6, %p4, %p5;
	not.pred 	%p7, %p6;
	@%p7 bra 	$L__BB0_9;

	ld.f32 	%f77, [%rd1+16];
	ld.f32 	%f78, [%rd1];
	mul.ftz.f32 	%f79, %f78, %f77;
	st.f32 	[%rd1+16], %f79;
	ld.f32 	%f80, [%rd1+20];
	mul.ftz.f32 	%f81, %f86, %f80;
	st.f32 	[%rd1+20], %f81;
	ld.f32 	%f82, [%rd1+24];
	mul.ftz.f32 	%f83, %f85, %f82;
	st.f32 	[%rd1+24], %f83;

$L__BB0_9:
	ret;

}

