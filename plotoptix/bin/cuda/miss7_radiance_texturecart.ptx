//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-28540450
// Cuda compilation tools, release 11.0, V11.0.194
// Based on LLVM 3.4svn
//

.version 7.0
.target sm_50
.address_size 64

	// .globl	__miss__radiance_texturecart
.const .align 8 .b8 params[288];

.visible .entry __miss__radiance_texturecart(

)
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<96>;
	.reg .b32 	%r<28>;
	.reg .b64 	%rd<11>;


	// inline asm
	call (%r6), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r7), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd4, %r6;
	cvt.u64.u32	%rd5, %r7;
	bfi.b64 	%rd1, %rd4, %rd5, 32, 32;
	add.s64 	%rd2, %rd1, 12;
	ld.u32 	%r1, [%rd1+12];
	and.b32  	%r8, %r1, 4096;
	setp.eq.s32	%p1, %r8, 0;
	@%p1 bra 	BB0_4;

	ld.u32 	%r9, [%rd1+28];
	mad.lo.s32 	%r10, %r9, 1664525, 1013904223;
	and.b32  	%r11, %r10, 16777215;
	cvt.rn.f32.u32	%f18, %r11;
	mov.f32 	%f19, 0f4B800000;
	div.approx.ftz.f32 	%f20, %f18, %f19;
	mad.lo.s32 	%r12, %r10, 1664525, 1013904223;
	st.u32 	[%rd1+28], %r12;
	and.b32  	%r13, %r12, 16777215;
	cvt.rn.f32.u32	%f21, %r13;
	div.approx.ftz.f32 	%f1, %f21, %f19;
	fma.rn.ftz.f32 	%f22, %f20, 0fC0000000, 0f3F800000;
	st.f32 	[%rd2+124], %f22;
	mul.ftz.f32 	%f23, %f22, %f22;
	mov.f32 	%f24, 0f3F800000;
	sub.ftz.f32 	%f2, %f24, %f23;
	mov.f32 	%f92, 0f00000000;
	setp.leu.ftz.f32	%p2, %f2, 0f00000000;
	@%p2 bra 	BB0_3;

	sqrt.approx.ftz.f32 	%f92, %f2;

BB0_3:
	add.ftz.f32 	%f25, %f1, %f1;
	mul.ftz.f32 	%f26, %f25, 0f40490FDB;
	cos.approx.ftz.f32 	%f27, %f26;
	sin.approx.ftz.f32 	%f28, %f26;
	mul.ftz.f32 	%f29, %f92, %f28;
	mul.ftz.f32 	%f30, %f92, %f27;
	st.v2.f32 	[%rd1+128], {%f30, %f29};
	ld.f32 	%f31, [%rd1+80];
	ld.f32 	%f32, [%rd1+92];
	ld.f32 	%f33, [%rd1+84];
	ld.f32 	%f34, [%rd1+88];
	ld.f32 	%f35, [%rd1];
	fma.rn.ftz.f32 	%f95, %f32, %f31, %f35;
	st.f32 	[%rd1], %f95;
	ld.f32 	%f36, [%rd1+4];
	fma.rn.ftz.f32 	%f94, %f32, %f33, %f36;
	st.f32 	[%rd1+4], %f94;
	ld.f32 	%f37, [%rd1+8];
	fma.rn.ftz.f32 	%f93, %f32, %f34, %f37;
	st.f32 	[%rd1+8], %f93;
	or.b32  	%r27, %r1, 514;
	st.u32 	[%rd2], %r27;
	ld.v4.f32 	{%f38, %f39, %f40, %f41}, [%rd1+80];
	st.v4.f32 	[%rd1+48], {%f38, %f39, %f40, %f24};
	bra.uni 	BB0_7;

BB0_4:
	add.s64 	%rd3, %rd1, 128;
	ld.f32 	%f46, [%rd1+128];
	ld.f32 	%f47, [%rd1+132];
	ld.f32 	%f48, [%rd2+124];
	ld.f32 	%f49, [%rd1+96];
	fma.rn.ftz.f32 	%f50, %f46, 0f5A0E1BCA, %f49;
	st.f32 	[%rd1+96], %f50;
	ld.f32 	%f51, [%rd1+100];
	fma.rn.ftz.f32 	%f52, %f47, 0f5A0E1BCA, %f51;
	st.f32 	[%rd1+100], %f52;
	ld.f32 	%f53, [%rd1+104];
	fma.rn.ftz.f32 	%f54, %f48, 0f5A0E1BCA, %f53;
	st.f32 	[%rd1+104], %f54;
	or.b32  	%r27, %r1, -2147483648;
	st.u32 	[%rd2], %r27;
	ld.u32 	%r14, [%rd1+44];
	setp.eq.s32	%p3, %r14, 0;
	@%p3 bra 	BB0_6;

	ld.const.v2.f32 	{%f55, %f56}, [params+232];
	ld.v4.f32 	{%f59, %f60, %f61, %f62}, [%rd1];
	add.ftz.f32 	%f95, %f55, %f59;
	add.ftz.f32 	%f94, %f56, %f60;
	st.v2.f32 	[%rd1], {%f95, %f94};
	ld.const.f32 	%f66, [params+240];
	add.ftz.f32 	%f93, %f66, %f61;
	st.f32 	[%rd3+-120], %f93;
	bra.uni 	BB0_7;

BB0_6:
	// inline asm
	call (%r15), _optix_get_launch_index_x, ();
	// inline asm
	ld.const.u64 	%rd6, [params+16];
	cvta.to.global.u64 	%rd7, %rd6;
	mul.wide.u32 	%rd8, %r15, 8;
	add.s64 	%rd9, %rd7, %rd8;
	ld.global.v2.u32 	{%r18, %r19}, [%rd9];
	cvt.rn.f32.s32	%f67, %r18;
	cvt.rn.f32.s32	%f68, %r19;
	add.ftz.f32 	%f69, %f67, 0f3F000000;
	add.ftz.f32 	%f70, %f68, 0f3F000000;
	ld.const.v2.u32 	{%r22, %r23}, [params+64];
	cvt.rn.f32.u32	%f71, %r22;
	cvt.rn.f32.u32	%f72, %r23;
	div.approx.ftz.f32 	%f73, %f69, %f71;
	div.approx.ftz.f32 	%f74, %f70, %f72;
	ld.const.u64 	%rd10, [params+224];
	tex.2d.v4.f32.f32	{%f75, %f76, %f77, %f78}, [%rd10, {%f73, %f74}];
	ld.f32 	%f79, [%rd3+-128];
	add.ftz.f32 	%f95, %f79, %f75;
	st.f32 	[%rd3+-128], %f95;
	ld.f32 	%f80, [%rd3+-124];
	add.ftz.f32 	%f94, %f76, %f80;
	st.f32 	[%rd3+-124], %f94;
	ld.f32 	%f81, [%rd3+-120];
	add.ftz.f32 	%f93, %f77, %f81;
	st.f32 	[%rd3+-120], %f93;
	ld.u32 	%r27, [%rd2];

BB0_7:
	and.b32  	%r26, %r27, 16777216;
	setp.eq.s32	%p4, %r26, 0;
	@%p4 bra 	BB0_9;

	ld.v4.f32 	{%f82, %f83, %f84, %f85}, [%rd1+16];
	mul.ftz.f32 	%f89, %f94, %f83;
	mul.ftz.f32 	%f90, %f95, %f82;
	st.v2.f32 	[%rd1+16], {%f90, %f89};
	mul.ftz.f32 	%f91, %f93, %f84;
	st.f32 	[%rd1+24], %f91;

BB0_9:
	ret;
}


